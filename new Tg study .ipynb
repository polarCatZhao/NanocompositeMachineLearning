{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#file = 'Tg.CSV'\n",
    "file = 'tan_delta_study.CSV'\n",
    "\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 383 entries, 0 to 382\n",
      "Data columns (total 7 columns):\n",
      "folderID             383 non-null int64\n",
      "matrix               383 non-null object\n",
      "filler               383 non-null object\n",
      "filler percentage    383 non-null float64\n",
      "Tg                   383 non-null float64\n",
      "tan delta peak       383 non-null float64\n",
      "half width           383 non-null float64\n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 21.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['DGEBA', 'EPDM', 'Ethylene vinyl acetate rubber', 'FPEOF', 'PBAT',\n",
      "       'PC', 'PC-SAN', 'PLA', 'PMMA', 'PP', 'PVC',\n",
      "       'Poly(2-hydroxyethyl acrylate)', 'SAN', 'SC-15 epoxy',\n",
      "       'bisphenol A PC', 'bisphenol-A phthalonitrile', 'epoxy',\n",
      "       'epoxy (Epon 815)', 'epoxy (Epon 862', 'epoxy (LY564)',\n",
      "       'natural rubber', 'phenoxy', 'poly(butylene terephthalate)',\n",
      "       'poly(vinyl alcohol)', 'poly(vinyl butyral)', 'polyamide',\n",
      "       'polyamide-6', 'polyamide-6,6', 'polybenzimidazole',\n",
      "       'polybutylene succinate', 'polyimide', 'polyurethane',\n",
      "       'rigid PU foam', 'styrene butadiene rubber',\n",
      "       'waterborne UV-curable polyurethane'], dtype=object), array(['CLO30B', 'CNW', 'CaCO3', 'MMA-MWCNT', 'MWCNT', 'NAN', 'Na-MMT',\n",
      "       'Na-montmorillonite', 'PANI-organoclay', 'PDMS-clay',\n",
      "       'PMMA-g-MWCNT', 'PMMA-g-expandable graphite', 'PMMA-g-silica',\n",
      "       'SEP', 'SOMM100', 'SOMMEE', 'SWCNT', 'TiO2', 'ZrO2',\n",
      "       'butanol cellulose nanowhiskers', 'cellulose nanowhiskers', 'clay',\n",
      "       'expandable graphite', 'expanded graphite', 'graphene',\n",
      "       'graphene oxide', 'graphene platelet', 'graphite',\n",
      "       'montmorillonite', 'organo clay (Closite 20A)', 'organo-MMT',\n",
      "       'silica', 'surfactant', 'surfactant cellulose nanowhiskers',\n",
      "       'titanium dioxide'], dtype=object)]\n",
      "['x0_DGEBA' 'x0_EPDM' 'x0_Ethylene vinyl acetate rubber' 'x0_FPEOF'\n",
      " 'x0_PBAT' 'x0_PC' 'x0_PC-SAN' 'x0_PLA' 'x0_PMMA' 'x0_PP' 'x0_PVC'\n",
      " 'x0_Poly(2-hydroxyethyl acrylate)' 'x0_SAN' 'x0_SC-15 epoxy'\n",
      " 'x0_bisphenol A PC' 'x0_bisphenol-A phthalonitrile' 'x0_epoxy'\n",
      " 'x0_epoxy (Epon 815)' 'x0_epoxy (Epon 862' 'x0_epoxy (LY564)'\n",
      " 'x0_natural rubber' 'x0_phenoxy' 'x0_poly(butylene terephthalate)'\n",
      " 'x0_poly(vinyl alcohol)' 'x0_poly(vinyl butyral)' 'x0_polyamide'\n",
      " 'x0_polyamide-6' 'x0_polyamide-6,6' 'x0_polybenzimidazole'\n",
      " 'x0_polybutylene succinate' 'x0_polyimide' 'x0_polyurethane'\n",
      " 'x0_rigid PU foam' 'x0_styrene butadiene rubber'\n",
      " 'x0_waterborne UV-curable polyurethane' 'x1_CLO30B' 'x1_CNW' 'x1_CaCO3'\n",
      " 'x1_MMA-MWCNT' 'x1_MWCNT' 'x1_NAN' 'x1_Na-MMT' 'x1_Na-montmorillonite'\n",
      " 'x1_PANI-organoclay' 'x1_PDMS-clay' 'x1_PMMA-g-MWCNT'\n",
      " 'x1_PMMA-g-expandable graphite' 'x1_PMMA-g-silica' 'x1_SEP' 'x1_SOMM100'\n",
      " 'x1_SOMMEE' 'x1_SWCNT' 'x1_TiO2' 'x1_ZrO2'\n",
      " 'x1_butanol cellulose nanowhiskers' 'x1_cellulose nanowhiskers' 'x1_clay'\n",
      " 'x1_expandable graphite' 'x1_expanded graphite' 'x1_graphene'\n",
      " 'x1_graphene oxide' 'x1_graphene platelet' 'x1_graphite'\n",
      " 'x1_montmorillonite' 'x1_organo clay (Closite 20A)' 'x1_organo-MMT'\n",
      " 'x1_silica' 'x1_surfactant' 'x1_surfactant cellulose nanowhiskers'\n",
      " 'x1_titanium dioxide']\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#one hot matrix, filler\n",
    "categorical_features = df[['matrix', 'filler']]\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "cf_oneHot = enc.fit_transform(categorical_features)\n",
    "print(enc.categories_)\n",
    "print(enc.get_feature_names())\n",
    "print(cf_oneHot)\n",
    "print(type(cf_oneHot))\n",
    "#turn the nparray into a dataframe\n",
    "df_categorical = pd.DataFrame(data=cf_oneHot, columns=enc.get_feature_names())\n",
    "#add this dataframe to the original dataframe\n",
    "df_new = pd.concat([df, df_categorical], axis=1)\n",
    "#df_new.to_csv('transformed_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and y, begin modelling\n",
    "#print(df_new.info())\n",
    "#print(df_new.columns)\n",
    "#X = df_new[['RPM parameter 1', 'processing energy', 'Wpf/Wff', 'x1_PMMA', 'x1_PS', 'x2_SiO2', 'x3_Cl', 'x3_N', 'x3_O' ]].values\n",
    "df_X = pd.concat([df[['filler percentage']], df_categorical], axis=1)\n",
    "X = df_X.values\n",
    "y = df_new['Tg'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression r2:  0.9365423853039283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.847281140457733"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "#Linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, y)\n",
    "R_2 = reg.score(X, y)\n",
    "print('linear regression r2: ', R_2)\n",
    "y_pred = reg.predict(X)\n",
    "#print(list(zip(y,y_pred)))\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression with normalization r2:  0.5143742136434755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37.42360625213632"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization\n",
    "from sklearn.preprocessing import normalize\n",
    "X_normalized = normalize(X, norm='l2')\n",
    "\n",
    "#Linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_normalized, y)\n",
    "R_2 = reg.score(X_normalized, y)\n",
    "print('linear regression with normalization r2: ', R_2)\n",
    "y_pred = reg.predict(X_normalized)\n",
    "#print(list(zip(y,y_pred)))\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression with standardization r2:  0.936542272308949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.84768864151436"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature standardization\n",
    "from sklearn.preprocessing import scale\n",
    "df[\"standardized_filler_percentage\"] = scale(df[['filler percentage']])\n",
    "df_X_stand = pd.concat([df[\"standardized_filler_percentage\"], df_categorical], axis=1)\n",
    "X_standardized = df_X_stand.values\n",
    "\n",
    "#Linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_standardized, y)\n",
    "R_2 = reg.score(X_standardized, y)\n",
    "print('linear regression with standardization r2: ', R_2)\n",
    "y_pred = reg.predict(X_standardized)\n",
    "#print(list(zip(y,y_pred)))\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mean absolute error: 51771523727.59586\n",
      "average y true values: 107.94295911331595\n"
     ]
    }
   ],
   "source": [
    "#loo for linear regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "lr = LinearRegression()\n",
    "scores_lr = cross_val_score(lr, X, y, cv=loo.split(X), \n",
    "                             scoring='neg_mean_absolute_error')\n",
    "print('average mean absolute error:', np.mean(-scores_lr))\n",
    "print('average y true values:', np.mean(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.58271933e+00, -2.01366443e+00, -3.84082031e+00, -9.27734375e-02,\n",
       "       -3.53150970e+00, -2.14681020e+00, -2.01419294e-01, -6.80411200e-01,\n",
       "       -2.08985934e+00, -7.90039062e-01, -2.43541418e+01, -1.36452344e+01,\n",
       "       -3.91847656e+00, -1.20621484e+01, -7.21785156e+00, -9.81952623e+00,\n",
       "       -1.46392489e+01, -2.32070703e+01, -1.10005560e+01, -1.56764626e+01,\n",
       "       -1.78615377e+00, -1.00674162e+01, -3.39193808e+01, -3.63243331e+01,\n",
       "       -3.69007734e+01, -3.79125003e+01, -3.79111724e+01, -4.54827052e+01,\n",
       "       -4.42996991e+01, -4.25234261e+01, -3.15298479e+01, -3.15718888e+01,\n",
       "       -1.64238750e+00, -1.11228838e+00, -6.13653025e-01, -3.10791001e+00,\n",
       "       -6.04748111e+00, -3.85433043e+00, -3.37349393e+00, -1.30141672e+01,\n",
       "       -5.82200787e-01, -4.70399110e+00, -5.87268401e+00, -6.61503846e+00,\n",
       "       -3.63984307e+00, -2.02397539e+00, -3.17589397e+00, -6.95960120e+00,\n",
       "       -1.98345630e+00, -1.58133596e+01, -2.07499104e+01, -2.31681054e+01,\n",
       "       -1.13624308e+01, -1.80992057e+01, -1.84502744e+01, -1.36047539e+01,\n",
       "       -1.73979003e+01, -1.87480395e+01, -3.11579746e+01, -3.38622136e+01,\n",
       "       -3.15984646e+01, -3.35722310e+01, -3.51988000e+01, -3.38294142e+01,\n",
       "       -2.63621667e+01, -3.38612370e+01, -3.21867008e+01, -3.35119620e+01,\n",
       "       -3.18296744e+01, -2.97913369e+01, -2.27546594e+01, -1.37308458e+01,\n",
       "       -1.27457118e+01, -7.62070543e+00, -1.11313157e+01, -9.96871589e+00,\n",
       "       -1.37319068e+01, -1.27555334e+01, -7.62029148e+00, -1.11322298e+01,\n",
       "       -9.96694201e+00, -1.20463388e+00, -1.21167710e+00, -1.23245730e+00,\n",
       "       -2.49024734e+00, -3.72761134e+00, -3.22552490e-01, -1.21145020e+00,\n",
       "       -1.22656250e-01, -1.63398437e+00, -4.60797214e+00, -1.20442281e+00,\n",
       "       -1.53284864e+00, -1.22418912e+01, -3.30853981e-01, -2.43939588e+00,\n",
       "       -1.79900514e+00, -1.55727087e+00, -5.24344245e+00, -2.61403848e+00,\n",
       "       -1.42194966e+00, -1.76163101e+00, -1.02430912e+01, -1.73062343e+01,\n",
       "       -1.83896750e+01, -2.26117400e+01, -6.12388109e+00, -5.77190229e+11,\n",
       "       -3.14753942e+11, -5.68932199e+12, -6.91010742e+12, -2.97435064e+12,\n",
       "       -7.28468925e+00, -1.02845871e+01, -1.26971023e+01, -5.64115067e+00,\n",
       "       -6.14496915e+00, -2.60291505e+00, -1.00105448e+00, -9.67797421e+11,\n",
       "       -6.25465397e-01, -3.47701398e-01, -7.25763106e-01, -2.82801162e+00,\n",
       "       -1.95603297e+00, -6.18356513e+00, -1.68719534e+00, -6.51291450e-01,\n",
       "       -4.26155554e+00, -7.22849535e+00, -3.31293026e+00, -4.14597379e+00,\n",
       "       -1.63048672e+01, -9.90673547e+00, -3.38734001e+00, -2.03281259e+00,\n",
       "       -7.83728910e-01, -8.72988583e+00, -4.08402645e+00, -2.31713075e-01,\n",
       "       -2.08719106e-01, -2.33162996e+01, -2.33042282e+01, -4.78682798e+01,\n",
       "       -4.06488060e+01, -4.94340512e+01, -5.41611605e+00, -9.73895539e+00,\n",
       "       -1.76616476e+00, -8.55684892e+00, -1.11079085e+01, -4.11444512e+00,\n",
       "       -4.11898264e+00, -2.21919576e+01, -4.52483166e+00, -1.62033726e+01,\n",
       "       -7.53557083e+00, -1.12782207e+01, -3.52805626e-01, -7.21384709e+00,\n",
       "       -7.04032745e+00, -2.79225328e+00, -2.77703687e+00, -1.42644699e+00,\n",
       "       -7.62990659e+00, -1.04046910e+01, -3.26007644e+01, -2.07117835e+01,\n",
       "       -2.02299298e+01, -1.37422405e+01, -3.52085843e+00, -4.10314489e+00,\n",
       "       -1.27267575e+00, -1.69152647e+00, -4.47336393e+00, -3.76869525e-01,\n",
       "       -2.54970747e+00, -2.53260709e+00, -1.17431281e+01, -1.12164776e+01,\n",
       "       -1.27421678e+01, -1.55114465e+01, -6.69676938e+00, -2.44153881e-01,\n",
       "       -3.69333275e+00, -6.07873940e+00, -9.78493167e+00, -1.36396970e+01,\n",
       "       -1.92971088e-01, -1.42227775e+00, -4.06881911e+00, -1.11337535e+00,\n",
       "       -3.52120913e+01, -2.63374855e+01, -2.06277637e+01, -1.31477376e+01,\n",
       "       -9.18736451e+00, -1.21671160e+01, -3.48192425e+01, -2.79505507e+01,\n",
       "       -2.34737307e+01, -1.50596491e+01, -1.56615805e+01, -2.08891880e+01,\n",
       "       -7.43180531e+00, -1.59231158e+01, -4.22852040e+00, -6.52019785e+00,\n",
       "       -3.68675281e+00, -1.19796801e+00, -1.94338598e+01, -1.34532949e+00,\n",
       "       -4.46095994e+01, -3.45748851e+00, -4.72112428e+00, -5.58039517e+00,\n",
       "       -1.51066291e+01, -8.32659558e+00, -1.85049915e+01, -2.24814052e+01,\n",
       "       -1.58781376e+01, -3.58788865e+00, -1.61793573e+01, -1.61462421e+01,\n",
       "       -9.61434404e+00, -3.14827897e-01, -8.88216363e+00, -3.37291887e+11,\n",
       "       -2.00814849e+01, -2.00731944e+01, -1.45301525e-01, -6.48829737e-01,\n",
       "       -4.30807439e+00, -4.49642903e+00, -5.05909946e+00, -1.60171035e+00,\n",
       "       -7.31121540e+00, -8.95020183e+00, -3.62892901e+00, -1.23610971e+00,\n",
       "       -7.54158842e-01, -3.15089405e+00, -1.38610683e+01, -5.75292456e+00,\n",
       "       -2.98176477e+01, -1.77034099e+01, -2.55214078e+01, -1.80553919e+01,\n",
       "       -1.44233407e+01, -1.74329305e+01, -1.80313806e+01, -2.42147597e+01,\n",
       "       -2.91097787e+01, -1.06343171e+01, -3.68058328e+00, -1.25371660e+00,\n",
       "       -1.44259605e+01, -1.47505476e+00, -2.05768004e+12, -1.49825280e+00,\n",
       "       -2.97645118e+00, -2.04269004e+01, -2.84541350e+00, -1.18650566e+01,\n",
       "       -2.49492085e+01, -1.51891873e+01, -3.98125277e+00, -1.16939440e+00,\n",
       "       -5.36988681e+00, -1.64630603e+01, -1.23258222e+01, -2.30072883e+00,\n",
       "       -3.29165887e+00, -3.34066928e+00, -1.75580696e+00, -1.06633791e+01,\n",
       "       -3.29532633e+00, -1.37267206e+01, -2.12580741e+00, -8.32522411e+00,\n",
       "       -3.29033903e-01, -3.41125849e+00, -1.11534722e+01, -1.37094849e+01,\n",
       "       -2.38985519e+01, -1.00579761e+01, -9.44618036e+00, -6.71326177e+00,\n",
       "       -8.69452195e+00, -1.08970905e+00, -2.15283615e+00, -1.42598035e+01,\n",
       "       -7.29794122e-01, -1.72181162e+00, -2.33100989e+00, -9.60564936e+00,\n",
       "       -9.19176066e+00, -7.54579430e+00, -2.02014241e+00, -3.19710781e-01,\n",
       "       -6.90810979e+00, -2.38746186e+00, -1.31570752e+00, -3.58259950e+00,\n",
       "       -1.84929111e+00, -2.18896970e+00, -9.19527158e+00, -9.33682768e+00,\n",
       "       -1.71797687e-01, -3.84602745e+00, -2.07349624e+01, -2.85693562e+00,\n",
       "       -8.75891194e+00, -7.02217381e+01, -6.47508253e+01, -6.10626108e+01,\n",
       "       -5.79787362e+01, -5.51684063e+01, -4.83636362e+01, -8.97214480e+01,\n",
       "       -8.20680215e+01, -8.94376600e+01, -8.12064004e+01, -7.64677557e-01,\n",
       "       -7.41919252e-01, -1.29613883e+00, -3.34344255e-01, -1.90759293e+00,\n",
       "       -2.26439654e+00, -1.30678778e-01, -3.65588753e+00, -4.12947152e+00,\n",
       "       -5.67538081e+00, -4.97273532e+00, -4.74061581e-01, -1.41369443e+00,\n",
       "       -1.76336758e+01, -8.51859367e+00, -5.33237719e-01, -8.00699857e+00,\n",
       "       -4.15693003e+01, -3.94304666e+01, -4.41757779e+01, -4.30885344e+01,\n",
       "       -4.03337683e+01, -4.15776381e+01, -3.93844113e+01, -4.22424516e+01,\n",
       "       -1.65550475e-01, -1.37584010e+00, -7.74793500e-02, -1.48883875e-01,\n",
       "       -1.72761544e-01, -5.73279625e-01, -1.51362108e+00, -1.49145324e+00,\n",
       "       -5.50147375e-01, -4.72870927e-01, -3.99930529e+01, -2.58292187e+01,\n",
       "       -3.70643713e+01, -4.18460954e+01, -6.60396078e+01, -3.50024737e+01,\n",
       "       -3.79961864e+01, -6.29422466e+01, -3.10465422e+01, -7.78018466e+01,\n",
       "       -8.50967048e+01, -7.10724432e+01, -7.42499972e+01, -1.23711094e+00,\n",
       "       -5.89522007e-01, -6.44002119e-01, -6.50630779e+01, -6.68940773e+01,\n",
       "       -7.96299434e+01, -8.06283259e+01, -6.78262277e+01, -3.58916094e+01,\n",
       "       -7.09031500e-02, -8.41889463e+00, -2.74013258e+01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.847207491442713"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1e-11)\n",
    "ridge.fit(X, y)\n",
    "y_pred = ridge.predict(X)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mean absolute error: 19.32339005536805\n"
     ]
    }
   ],
   "source": [
    "#linear regression was overfitting, try ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "scores_ridge = cross_val_score(ridge, X, y, cv=loo.split(X), \n",
    "                                 scoring='neg_mean_absolute_error')\n",
    "print('average mean absolute error:', np.mean(-scores_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-11 average mean absolute error: 14.760499205698373\n",
      "1e-10 average mean absolute error: 14.760557064846966\n",
      "1e-09 average mean absolute error: 14.76056314934124\n",
      "1e-08 average mean absolute error: 14.760563527929113\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.00000000001,0.0000000001,0.000000001,0.00000001]:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    scores_ridge = cross_val_score(ridge, X, y, cv=loo.split(X), \n",
    "                                 scoring='neg_mean_absolute_error')\n",
    "    print(alpha, 'average mean absolute error:', np.mean(-scores_ridge))\n",
    "#best alpha=1e-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mean absolute error: 14.760499205698373\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1e-11)\n",
    "scores_ridge = cross_val_score(ridge, X, y, cv=loo.split(X), \n",
    "                                 scoring='neg_mean_absolute_error')\n",
    "print('average mean absolute error:', np.mean(-scores_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 1   leave one out mean_absolute_error:  14.546011546097157\n",
      "18 2   leave one out mean_absolute_error:  14.61115892674062\n",
      "18 3   leave one out mean_absolute_error:  17.771247119244507\n",
      "19 1   leave one out mean_absolute_error:  15.675573184002655\n",
      "19 2   leave one out mean_absolute_error:  15.878384027241497\n",
      "19 3   leave one out mean_absolute_error:  16.721311738597596\n",
      "20 1   leave one out mean_absolute_error:  15.28137467290766\n",
      "20 2   leave one out mean_absolute_error:  14.869892958247693\n",
      "20 3   leave one out mean_absolute_error:  16.913854593506606\n",
      "21 1   leave one out mean_absolute_error:  14.897359192932575\n",
      "21 2   leave one out mean_absolute_error:  14.932957308520898\n",
      "21 3   leave one out mean_absolute_error:  17.251764136610955\n",
      "22 1   leave one out mean_absolute_error:  14.335511560196428\n",
      "22 2   leave one out mean_absolute_error:  14.08246351240431\n",
      "22 3   leave one out mean_absolute_error:  17.705112824327344\n",
      "23 1   leave one out mean_absolute_error:  14.240075161933328\n",
      "23 2   leave one out mean_absolute_error:  14.145260043098629\n",
      "23 3   leave one out mean_absolute_error:  17.86175083553413\n",
      "24 1   leave one out mean_absolute_error:  13.502637126675351\n",
      "24 2   leave one out mean_absolute_error:  13.549800128240511\n",
      "24 3   leave one out mean_absolute_error:  17.288778363463628\n",
      "25 1   leave one out mean_absolute_error:  13.762151049839014\n",
      "25 2   leave one out mean_absolute_error:  13.82910293693759\n",
      "25 3   leave one out mean_absolute_error:  17.287182276644785\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "from sklearn import tree\n",
    "\n",
    "errors = np.zeros((8, 3))\n",
    "for i in range(18, 26):\n",
    "    for j in range(1, 4):\n",
    "        dt = tree.DecisionTreeRegressor(max_depth=i, min_samples_leaf=j)\n",
    "        scores_dt = cross_val_score(dt, X, y, cv=loo.split(X),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "        print(i, j, '  leave one out mean_absolute_error: ', np.mean(-scores_dt))\n",
    "        errors[i-18, j-1] = np.mean(-scores_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.502637126675351"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amin(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  leave one out mean_absolute_error:  13.929968826529903\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeRegressor()\n",
    "#dt.fit(X,y)\n",
    "#dt.score(X,y)\n",
    "scores_dt = cross_val_score(dt, X, y, cv=loo.split(X),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "print('  leave one out mean_absolute_error: ', np.mean(-scores_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  leave one out mean_absolute_error:  13.610591989227899\n"
     ]
    }
   ],
   "source": [
    "#best max_depth=33, min_samples_leaf=1\n",
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeRegressor(min_samples_leaf = 1, max_depth=33)\n",
    "scores_dt = cross_val_score(dt, X_standardized, y, cv=loo.split(X_standardized),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "print('  leave one out mean_absolute_error: ', np.mean(-scores_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 1   leave one out mean_absolute_error:  13.98536423019367\n",
      "25 2   leave one out mean_absolute_error:  13.499281219948594\n",
      "25 3   leave one out mean_absolute_error:  17.360015419370757\n",
      "26 1   leave one out mean_absolute_error:  13.742813387466668\n",
      "26 2   leave one out mean_absolute_error:  13.861030536411475\n",
      "26 3   leave one out mean_absolute_error:  17.408277050729463\n",
      "27 1   leave one out mean_absolute_error:  13.868472796619814\n",
      "27 2   leave one out mean_absolute_error:  13.954485110703207\n",
      "27 3   leave one out mean_absolute_error:  17.36748934872577\n",
      "28 1   leave one out mean_absolute_error:  13.562857195093867\n",
      "28 2   leave one out mean_absolute_error:  13.53967115384931\n",
      "28 3   leave one out mean_absolute_error:  17.343750734191392\n",
      "29 1   leave one out mean_absolute_error:  13.580553097622156\n",
      "29 2   leave one out mean_absolute_error:  13.588344103227032\n",
      "29 3   leave one out mean_absolute_error:  17.32593830808173\n",
      "30 1   leave one out mean_absolute_error:  13.732581995966369\n",
      "30 2   leave one out mean_absolute_error:  13.851594166643638\n",
      "30 3   leave one out mean_absolute_error:  17.397313863434213\n",
      "31 1   leave one out mean_absolute_error:  13.962542423731815\n",
      "31 2   leave one out mean_absolute_error:  13.743694884159517\n",
      "31 3   leave one out mean_absolute_error:  17.38890612348643\n",
      "32 1   leave one out mean_absolute_error:  14.0457543421901\n",
      "32 2   leave one out mean_absolute_error:  13.798776646825813\n",
      "32 3   leave one out mean_absolute_error:  17.32593830808173\n",
      "33 1   leave one out mean_absolute_error:  13.466672892957853\n",
      "33 2   leave one out mean_absolute_error:  13.629474274458536\n",
      "33 3   leave one out mean_absolute_error:  17.300566899900705\n",
      "34 1   leave one out mean_absolute_error:  13.66674314384931\n",
      "34 2   leave one out mean_absolute_error:  13.9202387205856\n",
      "34 3   leave one out mean_absolute_error:  17.397313863434213\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "from sklearn import tree\n",
    "\n",
    "errors = np.zeros((10, 3))\n",
    "for i in range(25, 35):\n",
    "    for j in range(1, 4):\n",
    "        dt = tree.DecisionTreeRegressor(max_depth=i, min_samples_leaf=j)\n",
    "        scores_dt = cross_val_score(dt, X_standardized, y, cv=loo.split(X_standardized),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "        print(i, j, '  leave one out mean_absolute_error: ', np.mean(-scores_dt))\n",
    "        errors[i-25, j-1] = np.mean(-scores_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.466672892957853"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amin(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802590774743261\n",
      "34\n",
      "5.380713231458411\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeRegressor()\n",
    "dt.fit(X_standardized,y)\n",
    "print(dt.score(X_standardized,y))\n",
    "\n",
    "#tree.export_graphviz(dt,\n",
    "#    out_file='tree.dot') \n",
    "\n",
    "#print(dt.feature_importances_)\n",
    "\n",
    "print(dt.tree_.max_depth)\n",
    "y_pred = dt.predict(X_standardized)\n",
    "print(mean_absolute_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802590774743261\n",
      "[1.59710987e-02 1.57550379e-03 0.00000000e+00 2.02748356e-02\n",
      " 3.24109108e-02 2.22399065e-03 0.00000000e+00 0.00000000e+00\n",
      " 2.31767863e-03 3.47703579e-02 3.19896733e-05 1.08751083e-03\n",
      " 4.55459388e-06 4.11413858e-04 0.00000000e+00 6.85394881e-03\n",
      " 9.31911513e-02 3.53534012e-03 2.40871893e-05 4.82709275e-03\n",
      " 1.47620518e-04 2.11898657e-02 1.21362424e-04 5.99824608e-04\n",
      " 6.74356776e-03 2.01993625e-02 1.42757430e-02 1.01112362e-04\n",
      " 1.20080870e-05 1.55335232e-01 2.18890648e-02 3.68562260e-01\n",
      " 4.89561384e-02 8.68490120e-03 5.00342151e-03 4.12636400e-05\n",
      " 1.33999010e-05 1.51127365e-08 3.86390701e-06 6.16407371e-04\n",
      " 2.17969060e-04 4.17364391e-06 4.94208492e-04 2.74452996e-04\n",
      " 3.29044987e-02 6.62068455e-07 0.00000000e+00 0.00000000e+00\n",
      " 5.82673430e-04 7.06437677e-07 7.63200144e-05 3.37449339e-08\n",
      " 8.59381770e-06 1.43870003e-06 1.19569901e-06 1.10324239e-04\n",
      " 0.00000000e+00 0.00000000e+00 3.32077339e-06 2.45689044e-03\n",
      " 8.45636237e-03 2.53646476e-03 3.34043743e-04 2.64418658e-03\n",
      " 3.27452206e-04 4.71091513e-03 4.76585555e-05 4.04503549e-02\n",
      " 0.00000000e+00 0.00000000e+00 1.13471993e-02]\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeRegressor()\n",
    "dt.fit(X,y)\n",
    "print(dt.score(X,y))\n",
    "\n",
    "#tree.export_graphviz(dt,\n",
    "#    out_file='tree.dot') \n",
    "\n",
    "print(dt.feature_importances_)\n",
    "\n",
    "print(dt.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Tree in module sklearn.tree._tree:\n",
      "\n",
      "class Tree(builtins.object)\n",
      " |  Array-based representation of a binary decision tree.\n",
      " |  \n",
      " |  The binary tree is represented as a number of parallel arrays. The i-th\n",
      " |  element of each array holds information about the node `i`. Node 0 is the\n",
      " |  tree's root. You can find a detailed description of all arrays in\n",
      " |  `_tree.pxd`. NOTE: Some of the arrays only apply to either leaves or split\n",
      " |  nodes, resp. In this case the values of nodes of the other type are\n",
      " |  arbitrary!\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  node_count : int\n",
      " |      The number of nodes (internal nodes + leaves) in the tree.\n",
      " |  \n",
      " |  capacity : int\n",
      " |      The current capacity (i.e., size) of the arrays, which is at least as\n",
      " |      great as `node_count`.\n",
      " |  \n",
      " |  max_depth : int\n",
      " |      The maximal depth of the tree.\n",
      " |  \n",
      " |  children_left : array of int, shape [node_count]\n",
      " |      children_left[i] holds the node id of the left child of node i.\n",
      " |      For leaves, children_left[i] == TREE_LEAF. Otherwise,\n",
      " |      children_left[i] > i. This child handles the case where\n",
      " |      X[:, feature[i]] <= threshold[i].\n",
      " |  \n",
      " |  children_right : array of int, shape [node_count]\n",
      " |      children_right[i] holds the node id of the right child of node i.\n",
      " |      For leaves, children_right[i] == TREE_LEAF. Otherwise,\n",
      " |      children_right[i] > i. This child handles the case where\n",
      " |      X[:, feature[i]] > threshold[i].\n",
      " |  \n",
      " |  feature : array of int, shape [node_count]\n",
      " |      feature[i] holds the feature to split on, for the internal node i.\n",
      " |  \n",
      " |  threshold : array of double, shape [node_count]\n",
      " |      threshold[i] holds the threshold for the internal node i.\n",
      " |  \n",
      " |  value : array of double, shape [node_count, n_outputs, max_n_classes]\n",
      " |      Contains the constant prediction value of each node.\n",
      " |  \n",
      " |  impurity : array of double, shape [node_count]\n",
      " |      impurity[i] holds the impurity (i.e., the value of the splitting\n",
      " |      criterion) at node i.\n",
      " |  \n",
      " |  n_node_samples : array of int, shape [node_count]\n",
      " |      n_node_samples[i] holds the number of training samples reaching node i.\n",
      " |  \n",
      " |  weighted_n_node_samples : array of int, shape [node_count]\n",
      " |      weighted_n_node_samples[i] holds the weighted number of training samples\n",
      " |      reaching node i.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getstate__(...)\n",
      " |      Getstate re-implementation, for pickling.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Reduce re-implementation, for pickling.\n",
      " |  \n",
      " |  __setstate__(...)\n",
      " |      Setstate re-implementation, for unpickling.\n",
      " |  \n",
      " |  apply(...)\n",
      " |      Finds the terminal region (=leaf node) for each sample in X.\n",
      " |  \n",
      " |  compute_feature_importances(...)\n",
      " |      Computes the importance of each feature (aka variable).\n",
      " |  \n",
      " |  decision_path(...)\n",
      " |      Finds the decision path (=node) for each sample in X.\n",
      " |  \n",
      " |  predict(...)\n",
      " |      Predict target for X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  capacity\n",
      " |  \n",
      " |  children_left\n",
      " |  \n",
      " |  children_right\n",
      " |  \n",
      " |  feature\n",
      " |  \n",
      " |  impurity\n",
      " |  \n",
      " |  max_depth\n",
      " |  \n",
      " |  max_n_classes\n",
      " |  \n",
      " |  n_classes\n",
      " |  \n",
      " |  n_features\n",
      " |  \n",
      " |  n_node_samples\n",
      " |  \n",
      " |  n_outputs\n",
      " |  \n",
      " |  node_count\n",
      " |  \n",
      " |  threshold\n",
      " |  \n",
      " |  value\n",
      " |  \n",
      " |  weighted_n_node_samples\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "help(sklearn.tree._tree.Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   leave one out mean_absolute_error:  13.832311941281862\n",
      "2   leave one out mean_absolute_error:  13.724583323843094\n",
      "3   leave one out mean_absolute_error:  17.226587393597708\n",
      "4   leave one out mean_absolute_error:  22.458241036908134\n",
      "5   leave one out mean_absolute_error:  27.85842330432869\n",
      "6   leave one out mean_absolute_error:  30.98143012820129\n",
      "7   leave one out mean_absolute_error:  32.797690326931324\n",
      "8   leave one out mean_absolute_error:  37.685839961888696\n",
      "9   leave one out mean_absolute_error:  39.70526610785209\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "for i in range(1, 10):\n",
    "    dt = tree.DecisionTreeRegressor(min_samples_leaf=i)\n",
    "    scores_dt = cross_val_score(dt, X, y, cv=loo.split(X),\n",
    "                        scoring='neg_mean_absolute_error')\n",
    "    print(i, '  leave one out mean_absolute_error: ', np.mean(-scores_dt))\n",
    "    errors[i] = np.mean(-scores_dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9720199169624578\n",
      "[1.35309589e-02 1.58885827e-03 0.00000000e+00 2.04466918e-02\n",
      " 3.26856363e-02 2.24284193e-03 0.00000000e+00 0.00000000e+00\n",
      " 2.33732404e-03 3.50650829e-02 0.00000000e+00 9.66397628e-04\n",
      " 2.81625766e-06 0.00000000e+00 0.00000000e+00 6.91204514e-03\n",
      " 9.39810702e-02 0.00000000e+00 0.00000000e+00 4.86800878e-03\n",
      " 0.00000000e+00 2.13694779e-02 0.00000000e+00 6.04908918e-04\n",
      " 6.80072846e-03 2.03705789e-02 1.43967489e-02 1.01969424e-04\n",
      " 1.38868139e-05 1.56651904e-01 2.20746037e-02 3.71686315e-01\n",
      " 4.93711067e-02 8.75851727e-03 5.04583215e-03 4.16134041e-05\n",
      " 1.35134830e-05 0.00000000e+00 0.00000000e+00 6.21632242e-04\n",
      " 2.87667360e-03 0.00000000e+00 4.98397566e-04 2.76779350e-04\n",
      " 3.31834081e-02 6.67680365e-07 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.69669280e-05 0.00000000e+00\n",
      " 0.00000000e+00 1.45089493e-06 1.20583414e-06 1.11259383e-04\n",
      " 0.00000000e+00 0.00000000e+00 3.34892135e-06 2.47771585e-03\n",
      " 8.51884588e-03 2.56918586e-03 2.45759127e-04 2.66659957e-03\n",
      " 3.30227799e-04 4.75084639e-03 4.80625251e-05 4.07932254e-02\n",
      " 8.00667650e-07 0.00000000e+00 8.01750256e-03]\n",
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.199385580736565"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best hyperparameter: min_samples_leaf = 1, max_depth = 24\n",
    "dt = tree.DecisionTreeRegressor(min_samples_leaf = 1, max_depth=24)\n",
    "dt.fit(X,y)\n",
    "print(dt.score(X,y))\n",
    "\n",
    "tree.export_graphviz(dt,\n",
    "    out_file='tree.dot') \n",
    "\n",
    "print(dt.feature_importances_)\n",
    "\n",
    "print(dt.tree_.max_depth)\n",
    "\n",
    "y_pred = dt.predict(X)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cf9a37edd8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(y, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MWCNT': array([ 0.00860113, -1.03260005,  0.64588594,  0.47779787,  0.24385948,\n",
       "        -0.06062395, -0.68371701,  0.2689622 , -0.22832523, -0.153621  ,\n",
       "        -0.66910374, -0.30577415, -0.89125711,  0.1151796 ,  0.45576879,\n",
       "        -0.14298658, -0.34224951, -0.33557743,  0.15413769, -0.72306806,\n",
       "         0.20277208, -0.23277667, -0.07035992, -0.46789309, -0.21163905,\n",
       "         0.20147236, -0.27588403,  0.40615338, -0.18357557, -0.41297618,\n",
       "        -0.13048166, -0.93967432, -0.15458161, -0.28475532,  0.48509288,\n",
       "         0.98409057,  0.93000638,  0.47202432, -0.17727551, -0.02319303,\n",
       "        -1.60362697, -0.03539341, -0.10192662,  0.48451814, -0.16315909,\n",
       "         0.07069767, -0.31977886,  0.5023858 ,  0.77217191, -0.34890571,\n",
       "         0.11122582,  0.03634916,  1.03076053,  0.18434379, -0.92971528,\n",
       "        -0.51226813,  0.49450997, -0.18413666, -0.46274212,  0.19861196,\n",
       "        -0.47976661,  0.68759608,  0.87635547, -0.51680321,  0.14155737,\n",
       "        -0.34496355,  0.17161381,  1.08704722, -0.14455962, -0.32796004,\n",
       "         0.48481721,  0.16840154, -0.19409737,  0.50611848,  0.52102703,\n",
       "         0.84053719, -0.28734055,  0.8662771 , -0.84961838,  0.0495216 ,\n",
       "         0.40695146,  0.41488856,  0.03566374, -1.17261243, -1.16861308,\n",
       "         0.31212527,  0.15929516,  0.71189344,  0.80220342,  0.16942829,\n",
       "         0.31409159, -0.36641762,  0.25952822,  1.04317617, -0.9533217 ,\n",
       "         0.00567266,  0.89777875, -0.0901422 , -0.08113021, -0.29945183]),\n",
       " 'PANI-organoclay': array([-0.1691732 , -0.51008676,  0.53498337,  0.31701931,  0.21074883,\n",
       "         0.03025638, -0.0176609 ,  0.22037002, -0.10485107, -0.34346484,\n",
       "        -0.2355073 , -0.12027592, -0.44024366, -0.12456127,  0.39489117,\n",
       "         0.04045985, -0.15985007, -0.24897333,  0.09513425, -0.27196442,\n",
       "         0.14989759,  0.07348364, -0.10881119, -0.39495866,  0.05958262,\n",
       "         0.13318083, -0.00925546,  0.5456647 , -0.04781733, -0.04980278,\n",
       "         0.10446497, -0.3768966 , -0.00574493, -0.27508631,  0.30563024,\n",
       "         0.44933054,  0.37602761,  0.34615102, -0.13541498, -0.20539948,\n",
       "        -0.58485506,  0.10981823,  0.15193991,  0.04655554, -0.27339473,\n",
       "         0.1388142 , -0.14824557,  0.41332738,  0.34081893, -0.34163254,\n",
       "         0.33787327,  0.17373163,  0.47399709, -0.07678776, -0.31412388,\n",
       "        -0.15009298,  0.11389104, -0.12282689, -0.28228192,  0.19718438,\n",
       "        -0.22886638,  0.58554909,  0.27529947,  0.03265953,  0.07954319,\n",
       "        -0.40010814, -0.04840863,  0.44618694, -0.15941736,  0.13141916,\n",
       "         0.41407152, -0.06644729,  0.0512438 ,  0.29014878,  0.06062986,\n",
       "         0.12122786, -0.06959328,  0.27366059, -0.32706293, -0.03817275,\n",
       "         0.2143582 ,  0.36242951,  0.03340857, -0.44071688, -0.39724848,\n",
       "         0.23706771,  0.10987512,  0.22891182,  0.16754629, -0.0741528 ,\n",
       "         0.07379743, -0.09436589,  0.24083448,  0.24504061, -0.39319929,\n",
       "         0.07773949,  0.502241  , -0.05796431,  0.07133274, -0.04976118]),\n",
       " 'Na-montmorillonite': array([-0.24260839, -0.48961154,  0.41580552,  0.37899531,  0.26241432,\n",
       "         0.07927806, -0.29907687,  0.00489778, -0.33240288, -0.25255874,\n",
       "        -0.23108174, -0.43865126, -0.35105569, -0.14805764,  0.29697759,\n",
       "        -0.21159678,  0.05655999, -0.28206261,  0.14120606, -0.35019657,\n",
       "         0.2848757 ,  0.0551282 , -0.1775008 , -0.34926985,  0.31806137,\n",
       "         0.16775218, -0.21054273,  0.58481474, -0.23037193, -0.12822681,\n",
       "         0.01375804, -0.31689202,  0.23665022, -0.36296163,  0.21468111,\n",
       "         0.52592069,  0.28955071,  0.22901717, -0.30114646, -0.15816719,\n",
       "        -0.73320219,  0.09280085,  0.15844492, -0.05154778, -0.14467818,\n",
       "         0.34605502,  0.01193412,  0.3087755 ,  0.26080622, -0.35884731,\n",
       "         0.26243345,  0.10535575,  0.57087477, -0.0466691 , -0.34437007,\n",
       "        -0.02012038,  0.08974345, -0.03494903, -0.36202072,  0.09973443,\n",
       "        -0.32174439,  0.51801848,  0.3014307 ,  0.14844882,  0.30587327,\n",
       "        -0.43483879,  0.0690241 ,  0.46616268, -0.30981738,  0.04236379,\n",
       "         0.21914323, -0.07833899,  0.20795651,  0.19057345, -0.05986821,\n",
       "        -0.00107868,  0.01973085,  0.38045   , -0.31332489, -0.10848756,\n",
       "         0.36263485,  0.48918016, -0.0153506 , -0.39786651, -0.33192814,\n",
       "         0.11300769,  0.00431003,  0.30904675,  0.15519105,  0.0526564 ,\n",
       "         0.10699137, -0.0840163 ,  0.34719053,  0.25921866, -0.48204047,\n",
       "         0.19980618,  0.40155197, -0.06639795, -0.05710758,  0.00587628]),\n",
       " 'SWCNT': array([-0.16951677, -0.50505155,  0.44529936,  0.24608248,  0.12008994,\n",
       "        -0.04581495, -0.18650547,  0.07959022,  0.09921775, -0.35727295,\n",
       "        -0.18646561,  0.01777287, -0.5559448 , -0.2334505 ,  0.4856225 ,\n",
       "        -0.02758066, -0.15770531, -0.2175447 , -0.01639855, -0.16894008,\n",
       "         0.0125938 , -0.02941629, -0.12271228, -0.26485097, -0.14771061,\n",
       "         0.08592106,  0.02508704,  0.38490531,  0.04490733, -0.05484032,\n",
       "         0.11871105, -0.35332742, -0.18355377, -0.23081669,  0.23179348,\n",
       "         0.33544248,  0.34097764,  0.33373645, -0.0490328 , -0.08175994,\n",
       "        -0.50810307,  0.17824416,  0.08924626,  0.1188806 , -0.25841358,\n",
       "        -0.05120281, -0.26915643,  0.32209828,  0.31781331, -0.17988935,\n",
       "         0.31610727,  0.28378427,  0.41121474,  0.0865899 , -0.28584599,\n",
       "        -0.26417115,  0.20506151, -0.1263109 , -0.32846692,  0.32044646,\n",
       "        -0.24538901,  0.4149166 ,  0.28628537, -0.06459849,  0.1258897 ,\n",
       "        -0.18194988, -0.09898426,  0.28159177,  0.1172333 , -0.20651826,\n",
       "         0.37622944, -0.01364431, -0.17060818,  0.24664205,  0.21547318,\n",
       "         0.01727623,  0.15284999,  0.15151072, -0.35035235, -0.06868573,\n",
       "         0.05315198, -0.0048177 , -0.03238173, -0.42359209, -0.33694437,\n",
       "         0.28682262,  0.20058416,  0.32701647,  0.1763597 , -0.03925002,\n",
       "         0.1882768 , -0.0516511 ,  0.03924431,  0.31764609, -0.32303908,\n",
       "        -0.06085352,  0.53043473, -0.13871863,  0.15474005, -0.02141076]),\n",
       " 'graphene platelet': array([ 0.0934394 , -0.43720761,  0.7115591 ,  0.50430532,  0.52794366,\n",
       "         0.30778469, -0.04715366,  0.52596802, -0.57566777, -0.05803026,\n",
       "        -0.41512965, -1.0152795 , -0.35620046,  0.66082522,  0.0016026 ,\n",
       "        -0.03913231, -0.12425753, -0.35449688,  1.13707644, -0.48169497,\n",
       "         0.69589221,  0.1360442 ,  0.27009471, -0.41028023,  0.22432984,\n",
       "        -0.04207615,  0.13953343,  0.44136755, -0.07619094, -0.34595952,\n",
       "         0.15142716, -0.54201406,  0.19759566, -0.07346712,  0.49830263,\n",
       "         0.88065377,  0.20726036, -0.10147149, -0.4446346 , -0.04024577,\n",
       "        -0.88188574,  0.30142274, -0.04207939,  0.23333677, -0.11057184,\n",
       "         0.58945993, -0.15000757,  0.49585244,  0.20892479, -0.38397329,\n",
       "         0.21799351, -0.28510496,  0.70196486, -0.70002799, -0.59483324,\n",
       "        -0.04557505, -0.064245  , -0.2324108 , -0.18749696, -0.26271308,\n",
       "        -0.36686802,  0.56553063,  0.17513427,  0.21408212,  0.37101212,\n",
       "        -0.73949981, -0.01643868,  0.61124766, -0.38928993,  0.05518454,\n",
       "         0.11882066, -0.03066581,  0.10416927,  0.50167593, -0.00881447,\n",
       "         0.38668691, -0.28926647,  0.72905269, -0.15795195, -0.22089689,\n",
       "         0.67504928,  0.6949182 ,  0.08956342, -0.64139301, -0.63806686,\n",
       "         0.3523996 , -0.22526193,  0.40593851, -0.07347932,  0.22092451,\n",
       "         0.29358473, -0.2369118 ,  0.68621521,  0.61260428, -0.54607296,\n",
       "         0.56905532,  0.02638765,  0.13668734, -0.43393007, -0.09647971]),\n",
       " 'graphene': array([ 0.46919644, -0.37633669,  0.96352094,  0.59837639,  0.606336  ,\n",
       "         0.57686889,  0.15986519,  0.83854502, -0.86083704,  0.24355772,\n",
       "        -0.48594135, -1.21372652, -0.22303404,  1.09645438, -0.2158754 ,\n",
       "         0.06534065, -0.11562412, -0.39013609,  1.75515437, -0.69072443,\n",
       "         0.98683399,  0.30521551,  0.57713854, -0.46452048,  0.43232232,\n",
       "        -0.24793634,  0.34521547,  0.56941777,  0.07403747, -0.56804073,\n",
       "         0.25735313, -0.71362478,  0.35198307,  0.06529637,  0.8222276 ,\n",
       "         1.02954197,  0.27856216, -0.26589644, -0.63560563,  0.09585736,\n",
       "        -0.86325747,  0.25093251, -0.15839659,  0.44170392,  0.04894762,\n",
       "         0.7602312 ,  0.00635727,  0.64821917,  0.18628614, -0.48031196,\n",
       "         0.08648378, -0.61639851,  0.72524285, -0.9578985 , -0.71959764,\n",
       "        -0.02588338, -0.1926627 , -0.25732684, -0.02891609, -0.58379179,\n",
       "        -0.41225132,  0.45629406,  0.10894081,  0.22344209,  0.39940995,\n",
       "        -1.09752476,  0.00906539,  0.6447016 , -0.42877769,  0.29089385,\n",
       "         0.16477473, -0.12001667,  0.06925637,  0.49549985, -0.0790678 ,\n",
       "         0.64124912, -0.65414864,  0.83693671, -0.12774491, -0.22189964,\n",
       "         1.0609417 ,  0.96386904,  0.34129262, -0.77602804, -0.75768042,\n",
       "         0.34247655, -0.42935854,  0.302773  , -0.25232276,  0.4212819 ,\n",
       "         0.23998602, -0.35723948,  0.95605201,  0.81072474, -0.5988149 ,\n",
       "         0.83243585, -0.3276819 ,  0.25652611, -0.75616968, -0.02896183]),\n",
       " 'graphene oxide': array([ 0.33580711, -0.2709747 ,  0.92126054,  0.5127777 ,  0.5413803 ,\n",
       "         0.5056982 , -0.21043084,  0.55924742, -0.99196115, -0.0033111 ,\n",
       "        -0.33210523, -1.24105197, -0.07283909,  0.842381  , -0.24338406,\n",
       "        -0.01178063,  0.24970007, -0.40003994,  1.57651651, -0.59401058,\n",
       "         0.9148795 ,  0.30750863,  0.5995571 , -0.50676639,  0.80997786,\n",
       "        -0.18926089,  0.15289684,  0.54743594, -0.13085563, -0.57291567,\n",
       "        -0.0071315 , -0.57524349,  0.52144951,  0.06879433,  0.55938251,\n",
       "         1.14343971,  0.31834222, -0.04012732, -0.51572748, -0.2066995 ,\n",
       "        -0.75397086,  0.1745405 , -0.03735448,  0.15577842, -0.06361204,\n",
       "         0.9151012 ,  0.07208219,  0.45594922,  0.06928455, -0.4315826 ,\n",
       "         0.28063223, -0.59345552,  0.71626747, -0.74188799, -0.76798111,\n",
       "         0.10148967, -0.379348  , -0.09787377,  0.07796592, -0.52883042,\n",
       "        -0.45704995,  0.74634445, -0.00189282,  0.20608268,  0.54308474,\n",
       "        -0.92828089, -0.00926903,  0.57579127, -0.40308177,  0.23260416,\n",
       "         0.29649437, -0.19492875, -0.01482617,  0.40263768, -0.24719831,\n",
       "         0.1846991 , -0.61472967,  0.72880164, -0.10898083, -0.36205385,\n",
       "         0.91301242,  1.00377902,  0.32074215, -0.74800107, -0.50801395,\n",
       "         0.33972439, -0.5871214 ,  0.19156974, -0.20787866,  0.42314613,\n",
       "         0.32049555, -0.19406132,  0.87732685,  0.39438364, -0.52222259,\n",
       "         0.8195461 , -0.27347013,  0.15305596, -0.67193377, -0.14950569]),\n",
       " 'CLO30B': array([-0.26949641, -0.53390795,  0.49049994,  0.38911107,  0.23984779,\n",
       "         0.02015445, -0.17212978,  0.18661185, -0.17630152, -0.40689272,\n",
       "        -0.25786459, -0.33664399, -0.49205884, -0.10816284,  0.30799001,\n",
       "        -0.08842939, -0.03666544, -0.25736403,  0.20097178, -0.26743475,\n",
       "         0.20996195,  0.02553303, -0.12096272, -0.30569732,  0.15353958,\n",
       "         0.14815454, -0.11331798,  0.45229679, -0.1095907 , -0.11350843,\n",
       "         0.02940514, -0.24786665,  0.02987833, -0.30120406,  0.18399328,\n",
       "         0.5665766 ,  0.27699414,  0.27433872, -0.17434593, -0.17080158,\n",
       "        -0.74256551,  0.18764105,  0.16466771, -0.05541252, -0.30861658,\n",
       "         0.30420873, -0.17277098,  0.32841042,  0.23552458, -0.31619108,\n",
       "         0.42261258,  0.20246254,  0.56484455, -0.19364612, -0.36892068,\n",
       "        -0.19363347,  0.05518688, -0.19509225, -0.33709455,  0.22178976,\n",
       "        -0.23548542,  0.65633273,  0.19832771,  0.1435591 ,  0.17727001,\n",
       "        -0.44362542, -0.09072705,  0.31443375, -0.17622311,  0.01749664,\n",
       "         0.35676485, -0.08452175,  0.06431303,  0.30312139,  0.01711173,\n",
       "        -0.04554375,  0.11431091,  0.30120018, -0.2579464 , -0.05517249,\n",
       "         0.20641951,  0.27989414, -0.01531356, -0.41401768, -0.30229259,\n",
       "         0.29013494,  0.08214387,  0.30604422,  0.07273448, -0.00341226,\n",
       "         0.10919543, -0.10412464,  0.27419308,  0.25037348, -0.32785621,\n",
       "         0.16488397,  0.39985839, -0.04214748,  0.02969062, -0.05197847]),\n",
       " 'NAN': array([-0.18050489, -0.36369231,  0.47748715,  0.29794583,  0.1916142 ,\n",
       "        -0.00052816, -0.02402142,  0.16046916, -0.1099121 , -0.3355304 ,\n",
       "        -0.12476115, -0.10259656, -0.37110347, -0.14044487,  0.28327933,\n",
       "         0.00890514, -0.06961218, -0.26131898,  0.15862598, -0.14009793,\n",
       "         0.16051668,  0.09767964, -0.04401049, -0.30464804,  0.11581561,\n",
       "         0.06806876,  0.02935251,  0.47201189, -0.01620635, -0.06834073,\n",
       "         0.09190022, -0.18753994,  0.04670811, -0.24359804,  0.21288653,\n",
       "         0.28894737,  0.24020904,  0.25157723, -0.1220596 , -0.13331535,\n",
       "        -0.42107329,  0.15930928,  0.15138628,  0.03191087, -0.23445795,\n",
       "         0.18660739, -0.13355343,  0.36184549,  0.18309925, -0.30308527,\n",
       "         0.36475629,  0.24429613,  0.42432207, -0.15401031, -0.23245063,\n",
       "        -0.10584053, -0.02743258, -0.1489203 , -0.25512242,  0.24022202,\n",
       "        -0.13858016,  0.48813036,  0.09931   ,  0.13752337,  0.13835341,\n",
       "        -0.34992662, -0.11035665,  0.21721247, -0.07540312,  0.08539046,\n",
       "         0.37783322, -0.09556317, -0.01159564,  0.22678223,  0.01308832,\n",
       "        -0.05074736,  0.0755678 ,  0.18394409, -0.17994423, -0.07956406,\n",
       "         0.18853015,  0.21311013,  0.03356138, -0.32311475, -0.18646367,\n",
       "         0.26703832,  0.05048104,  0.15284745, -0.04002455, -0.04318275,\n",
       "         0.09139196, -0.08065114,  0.22561078,  0.14586879, -0.22142085,\n",
       "         0.07711725,  0.27230418, -0.03731563,  0.0166927 ,  0.04970596]),\n",
       " 'SEP': array([-0.21135916, -0.4104605 ,  0.46462595,  0.24373251,  0.15305386,\n",
       "        -0.04547735, -0.02190676,  0.1617503 , -0.06854959, -0.37907115,\n",
       "        -0.12687245, -0.05211184, -0.39553383, -0.17266527,  0.3128151 ,\n",
       "         0.02330144, -0.08720162, -0.22044395,  0.04413036, -0.13735868,\n",
       "         0.11787097,  0.10156433, -0.06214449, -0.30200452,  0.1152506 ,\n",
       "         0.10962876,  0.00476399,  0.44658631, -0.02055071, -0.05395822,\n",
       "         0.0525272 , -0.16784289,  0.03562888, -0.23539092,  0.18365362,\n",
       "         0.30479342,  0.26768866,  0.31369695, -0.06535602, -0.19787925,\n",
       "        -0.45231327,  0.11823161,  0.17902364, -0.01598554, -0.28304753,\n",
       "         0.17205101, -0.13946596,  0.36613941,  0.16463946, -0.29420137,\n",
       "         0.40604267,  0.25857469,  0.39697   , -0.12167815, -0.18519942,\n",
       "        -0.13154429, -0.00461973, -0.14383289, -0.24557734,  0.24890183,\n",
       "        -0.12560375,  0.5654242 ,  0.12901959,  0.12996137,  0.05144418,\n",
       "        -0.31990662, -0.11051632,  0.24944475, -0.08052581,  0.10650595,\n",
       "         0.40036541, -0.09661846,  0.03297069,  0.2516025 ,  0.02269437,\n",
       "        -0.05828947,  0.08829943,  0.1781555 , -0.18817677, -0.05691245,\n",
       "         0.12163822,  0.21878587,  0.02547183, -0.33836395, -0.18249321,\n",
       "         0.26407686,  0.06153031,  0.12545507, -0.01240207, -0.06416404,\n",
       "         0.04566916, -0.08276545,  0.18382746,  0.08832913, -0.21092628,\n",
       "         0.01831149,  0.34278876, -0.0749912 ,  0.04485282, -0.00478377]),\n",
       " 'SOMM100': array([-0.1989364 , -0.40817109,  0.45336819,  0.26403624,  0.17221834,\n",
       "        -0.01712153, -0.05685071,  0.15086056, -0.11058095, -0.34428814,\n",
       "        -0.15399709, -0.11859289, -0.37707391, -0.15091924,  0.30172136,\n",
       "        -0.0033799 , -0.07116268, -0.21868478,  0.09656917, -0.17944255,\n",
       "         0.13382895,  0.08297816, -0.06566431, -0.29989636,  0.11879984,\n",
       "         0.10007773, -0.01054179,  0.43096063, -0.04164644, -0.06259424,\n",
       "         0.05233714, -0.19842222,  0.03118474, -0.25178224,  0.19575739,\n",
       "         0.36620599,  0.2538327 ,  0.28661332, -0.10068388, -0.17566517,\n",
       "        -0.48061132,  0.12613299,  0.16035017, -0.0163476 , -0.26219258,\n",
       "         0.18672368, -0.12932518,  0.34333849,  0.1958321 , -0.29175264,\n",
       "         0.37168816,  0.21732345,  0.42617881, -0.12115771, -0.22845326,\n",
       "        -0.12850176,  0.01646297, -0.14455082, -0.26274338,  0.22315966,\n",
       "        -0.16650833,  0.54420412,  0.14055268,  0.11287784,  0.09788419,\n",
       "        -0.3369872 , -0.07619704,  0.25593483, -0.10896432,  0.08392921,\n",
       "         0.36769465, -0.08756792,  0.021866  ,  0.23424096,  0.01191263,\n",
       "        -0.04418624,  0.05805164,  0.19784336, -0.20555578, -0.06269398,\n",
       "         0.15071052,  0.24630082,  0.03180411, -0.33340228, -0.22145346,\n",
       "         0.24383397,  0.06417399,  0.17075159,  0.03225816, -0.04099587,\n",
       "         0.06935944, -0.08421481,  0.19530979,  0.13377658, -0.25024736,\n",
       "         0.05351867,  0.3496033 , -0.04632244,  0.03616093, -0.00686885]),\n",
       " 'SOMMEE': array([-2.55814433e-01, -6.43523395e-01,  5.58115840e-01,  3.93375665e-01,\n",
       "         2.21497148e-01,  8.28515622e-05, -7.28691965e-02,  2.88124084e-01,\n",
       "        -9.44615006e-02, -4.33312893e-01, -3.18013936e-01, -2.08949402e-01,\n",
       "        -5.91260970e-01, -1.30025104e-01,  3.93476129e-01, -4.39594674e-04,\n",
       "        -1.61512941e-01, -2.33044401e-01,  1.28353998e-01, -2.91510403e-01,\n",
       "         1.66889936e-01,  3.57395634e-02, -1.42691895e-01, -3.37877154e-01,\n",
       "         3.93422991e-02,  1.50656328e-01, -5.24917133e-02,  4.79359657e-01,\n",
       "        -5.11683524e-02, -9.07075927e-02,  5.97716607e-02, -3.24629992e-01,\n",
       "        -6.41825944e-02, -3.02378178e-01,  2.57632494e-01,  5.91451168e-01,\n",
       "         3.64392489e-01,  3.55451345e-01, -1.31124735e-01, -1.81506082e-01,\n",
       "        -7.90291965e-01,  1.58959001e-01,  1.67675078e-01, -9.12128948e-03,\n",
       "        -3.50972027e-01,  2.07041860e-01, -2.20459074e-01,  4.08252686e-01,\n",
       "         3.03237349e-01, -3.39506149e-01,  4.39015538e-01,  2.40284741e-01,\n",
       "         5.88163614e-01, -1.83327407e-01, -3.63933235e-01, -2.80808985e-01,\n",
       "         1.19130172e-01, -2.56746501e-01, -3.72133881e-01,  2.76654243e-01,\n",
       "        -2.38293901e-01,  7.22383678e-01,  2.56283611e-01,  7.24641308e-02,\n",
       "         8.42911601e-02, -4.78037536e-01, -8.28647912e-02,  3.65632236e-01,\n",
       "        -1.55007631e-01,  5.38628958e-02,  4.58080083e-01, -8.80564898e-02,\n",
       "         4.55817506e-02,  3.70341450e-01,  8.76272023e-02,  5.15036099e-02,\n",
       "         7.24990591e-02,  3.07813615e-01, -3.32213372e-01, -1.02878371e-02,\n",
       "         1.82514295e-01,  2.84359634e-01,  5.64944465e-03, -4.87179697e-01,\n",
       "        -4.02953237e-01,  3.28643173e-01,  1.48360819e-01,  3.19006026e-01,\n",
       "         1.34125337e-01, -4.58348840e-02,  7.22373202e-02, -1.44484267e-01,\n",
       "         2.59666711e-01,  3.03264588e-01, -3.74170631e-01,  1.08293489e-01,\n",
       "         5.26884913e-01, -3.95371430e-02,  7.85505921e-02, -8.55015665e-02]),\n",
       " 'clay': array([-0.30315351, -1.07142508,  0.54391783,  0.59701699,  0.49351671,\n",
       "         0.21505527, -0.06749333,  0.53221512, -0.52513003, -0.03620803,\n",
       "        -0.74657261, -1.00357699, -0.50133568,  0.1683878 ,  0.32074603,\n",
       "        -0.16505398, -0.52601892, -0.10594029,  0.28516078, -0.90204102,\n",
       "         0.46375206, -0.01790153, -0.48434529, -0.3648316 , -0.04852839,\n",
       "         0.32265833, -0.33417568,  0.66613656, -0.44968626, -0.23836204,\n",
       "         0.22468171, -0.71563137,  0.25526816, -0.50653064,  0.59227335,\n",
       "         1.20290554,  0.30560514, -0.08862715, -0.65215069,  0.03771535,\n",
       "        -1.38460922,  0.0785071 ,  0.07138191,  0.09465334, -0.12659727,\n",
       "         0.35581276, -0.16088685,  0.56336933,  0.64224553, -0.62578994,\n",
       "        -0.15208459, -0.0975683 ,  0.83417648, -0.32998353, -0.65028203,\n",
       "        -0.13097635,  0.44352978, -0.21256357, -0.59380603, -0.06100896,\n",
       "        -0.62248302,  0.76182765,  0.65308774,  0.10144605,  0.24554153,\n",
       "        -0.89475971,  0.37559637,  0.96863443, -0.95359105,  0.2538138 ,\n",
       "        -0.04257276,  0.01437201,  0.73954153,  0.72182888, -0.01903267,\n",
       "         0.80474216, -0.37670615,  1.07553363, -0.57041484,  0.10503451,\n",
       "         0.55637181,  1.01091325, -0.08672065, -0.64817011, -1.07344019,\n",
       "        -0.11789931,  0.06655625,  0.8103748 ,  0.6414631 , -0.08217086,\n",
       "        -0.12845476, -0.39785084,  0.66616702,  0.82006699, -1.06003857,\n",
       "         0.33602345,  0.97241342,  0.0653268 , -0.11702462, -0.20867331]),\n",
       " 'organo-MMT': array([-0.34875541, -0.85369879,  0.26723329,  0.49003746,  0.16728567,\n",
       "         0.13913846, -0.41223162, -0.06655167, -0.26142266, -0.17806209,\n",
       "        -0.49447687, -0.39298421, -0.60932438, -0.34807081,  0.453789  ,\n",
       "        -0.40672026, -0.0367765 , -0.216704  , -0.2664088 , -0.63670374,\n",
       "         0.2547789 , -0.13523513, -0.58704508, -0.32717633,  0.23784256,\n",
       "         0.37835183, -0.51971883,  0.6829731 , -0.32157091, -0.10291148,\n",
       "        -0.05027669, -0.51510758,  0.1286344 , -0.64680105,  0.30637998,\n",
       "         0.78163472,  0.53155285,  0.3387249 , -0.43253334, -0.03246405,\n",
       "        -1.27443931, -0.05763271,  0.16715116, -0.08520498, -0.08723638,\n",
       "         0.28400922,  0.17508171,  0.27702658,  0.550126  , -0.42240839,\n",
       "         0.15290048,  0.0814209 ,  0.73540741,  0.19368811, -0.38623358,\n",
       "        -0.21656149,  0.54098512, -0.03410704, -0.60615338,  0.12955085,\n",
       "        -0.44175906,  0.44944715,  0.71947292, -0.06005133,  0.24030801,\n",
       "        -0.5613507 ,  0.30496399,  0.70594336, -0.48259379,  0.01497871,\n",
       "         0.14541083, -0.02647447,  0.44515019,  0.11063319,  0.02346035,\n",
       "         0.2530609 ,  0.01300573,  0.41374572, -0.63721907,  0.10530912,\n",
       "         0.43722454,  0.62249702, -0.07170374, -0.4907404 , -0.6478962 ,\n",
       "        -0.0684953 ,  0.32561491,  0.51490777,  0.55349737,  0.1354363 ,\n",
       "        -0.04572978, -0.1346133 ,  0.31738692,  0.60598153, -0.77529325,\n",
       "         0.21531126,  0.83870918, -0.0914458 ,  0.11929845, -0.02450684]),\n",
       " 'CaCO3': array([-0.16208079, -0.80025375,  0.70044667,  0.32141498,  0.29609951,\n",
       "         0.03212029, -0.09144399,  0.38746375, -0.1370734 , -0.29468927,\n",
       "        -0.32905725, -0.27398336, -0.48582718, -0.04299393,  0.513749  ,\n",
       "         0.16468334, -0.42452085, -0.19405374,  0.18133058, -0.46181229,\n",
       "         0.09073056,  0.10142835, -0.0661986 , -0.42806798, -0.25257725,\n",
       "         0.08956546,  0.11008409,  0.49056205, -0.04005038, -0.15961586,\n",
       "         0.25762391, -0.54358327, -0.07876885, -0.17171848,  0.45887855,\n",
       "         0.66366583,  0.42916644,  0.27736211, -0.18574032, -0.12090927,\n",
       "        -0.71343458,  0.19875117,  0.09121414,  0.19759105, -0.25325567,\n",
       "         0.00625145, -0.38008448,  0.5333885 ,  0.42176938, -0.39768976,\n",
       "         0.14220299,  0.20096785,  0.53277415, -0.06708495, -0.43402469,\n",
       "        -0.20991658,  0.1706122 , -0.12391621, -0.28137484,  0.26733702,\n",
       "        -0.5015766 ,  0.66868001,  0.39149943, -0.06180068,  0.18408903,\n",
       "        -0.39632392,  0.01671162,  0.61653537, -0.19111603, -0.02831499,\n",
       "         0.40461636,  0.01500679,  0.02235578,  0.62677944,  0.17104368,\n",
       "         0.40297499, -0.1789099 ,  0.59421688, -0.44250619, -0.05683102,\n",
       "         0.14316441,  0.3223052 ,  0.03649672, -0.62198883, -0.61916924,\n",
       "         0.31998625, -0.04347957,  0.41625017,  0.36722681, -0.14347336,\n",
       "         0.14299707, -0.18497467,  0.25715515,  0.39700565, -0.65332639,\n",
       "        -0.04666383,  0.82550961, -0.0941748 , -0.00553408, -0.23880772]),\n",
       " 'silica': array([-0.31271204, -1.26780236,  0.58443314,  0.64140236,  0.32175711,\n",
       "         0.40916905, -0.37241635,  0.67267853, -0.41571134, -0.03254272,\n",
       "        -0.69294494, -0.84190017, -0.44348964,  0.08655109,  0.43905395,\n",
       "         0.04000423, -0.60467184, -0.10446849,  0.34093976, -1.06268406,\n",
       "         0.15912487, -0.17222695, -0.31743047, -0.38924614, -0.28594473,\n",
       "         0.25912169, -0.20316422,  0.48551971, -0.23353927, -0.20893043,\n",
       "         0.30279186, -0.90127987,  0.01934092, -0.34379417,  0.63741493,\n",
       "         1.27029991,  0.65147072,  0.01020841, -0.62299675,  0.03559718,\n",
       "        -1.52911317,  0.2178486 ,  0.10336897,  0.21324819, -0.01941041,\n",
       "         0.10979652, -0.20384489,  0.47703609,  0.7479558 , -0.38497886,\n",
       "        -0.17124389, -0.01073423,  0.72848499, -0.00370713, -0.83391345,\n",
       "        -0.31944799,  0.436609  , -0.2037884 , -0.29021972,  0.0897716 ,\n",
       "        -0.89449692,  0.67025214,  0.8260237 , -0.37001944,  0.21660095,\n",
       "        -0.77020198,  0.2516284 ,  1.02507901, -0.5893445 , -0.26137394,\n",
       "         0.11993395,  0.06284463,  0.46423972,  0.73534185,  0.07628997,\n",
       "         0.93677121, -0.57675231,  1.00299287, -0.95497501,  0.12881131,\n",
       "         0.48390582,  0.57169443,  0.11364583, -0.85825491, -1.17853546,\n",
       "         0.13116562, -0.08347783,  0.67693937,  0.82661575,  0.09920639,\n",
       "         0.03181646, -0.40532914,  0.44061896,  0.91168749, -1.06618333,\n",
       "         0.29391634,  1.13292634, -0.29309282, -0.04337833, -0.53195989]),\n",
       " 'cellulose nanowhiskers': array([-0.20130726, -0.29397713,  0.50717865,  0.21890391,  0.26001139,\n",
       "         0.01908109, -0.28997353, -0.02802231, -0.36464316, -0.36104884,\n",
       "         0.02285612, -0.42000933, -0.1028787 , -0.11579572,  0.22369488,\n",
       "        -0.11487413,  0.14710411, -0.24306573,  0.2452004 , -0.17865027,\n",
       "         0.24361586,  0.21955736,  0.1045921 , -0.35044901,  0.4477371 ,\n",
       "         0.09056748, -0.05003111,  0.53527425, -0.22410733, -0.14654168,\n",
       "        -0.01049659, -0.12317508,  0.33054061, -0.24569887,  0.10736602,\n",
       "         0.38568015,  0.12572458,  0.26301023, -0.12750506, -0.36426163,\n",
       "        -0.3544695 ,  0.16608143,  0.243719  , -0.12311674, -0.23494458,\n",
       "         0.3845733 , -0.03817128,  0.35280962,  0.0223472 , -0.29365811,\n",
       "         0.39871681,  0.11145446,  0.36720325, -0.10560746, -0.23603825,\n",
       "         0.15153924, -0.21250336,  0.06871935, -0.16635174,  0.09895485,\n",
       "        -0.25677299,  0.66798994,  0.03860021,  0.30104975,  0.29600932,\n",
       "        -0.27620929, -0.03624965,  0.32109269, -0.19588078,  0.06918703,\n",
       "         0.29270921, -0.12273204,  0.10474175,  0.19289578, -0.16656563,\n",
       "        -0.25990272,  0.04748837,  0.31920099, -0.10022312, -0.24533971,\n",
       "         0.19800236,  0.41984231,  0.03319511, -0.28721751, -0.03970371,\n",
       "         0.20841464, -0.2088248 ,  0.12762974, -0.07294525,  0.03031326,\n",
       "         0.14253223, -0.03963201,  0.26653237, -0.13452138, -0.27697212,\n",
       "         0.06350661,  0.22926305, -0.12264811, -0.13722134, -0.04636136]),\n",
       " 'butanol cellulose nanowhiskers': array([-0.19269495, -0.28321469,  0.45690154,  0.18997229,  0.21800706,\n",
       "         0.00999439, -0.28993439, -0.05425191, -0.30570337, -0.32866085,\n",
       "         0.0238591 , -0.33675145, -0.11687568, -0.1398119 ,  0.22252628,\n",
       "        -0.11756659,  0.14597187, -0.22124405,  0.18060287, -0.15771896,\n",
       "         0.19975961,  0.19758026,  0.07467019, -0.3079619 ,  0.39548852,\n",
       "         0.08048717, -0.03955853,  0.49303691, -0.18267432, -0.12721313,\n",
       "        -0.00975069, -0.11700821,  0.28656784, -0.23499992,  0.09769704,\n",
       "         0.33108522,  0.12911279,  0.26552607, -0.10259995, -0.32367479,\n",
       "        -0.31923576,  0.14589158,  0.23112399, -0.11634771, -0.21679144,\n",
       "         0.32760355, -0.0271956 ,  0.31227844,  0.02614464, -0.25195551,\n",
       "         0.37573247,  0.11888606,  0.32935683, -0.04757917, -0.19321569,\n",
       "         0.11621398, -0.17668752,  0.07246214, -0.16314961,  0.10374172,\n",
       "        -0.24084466,  0.5951904 ,  0.05142133,  0.25660288,  0.26667031,\n",
       "        -0.22766136, -0.02789432,  0.2880653 , -0.13459557,  0.03183051,\n",
       "         0.28474039, -0.10351663,  0.0703903 ,  0.14976305, -0.1315056 ,\n",
       "        -0.26490353,  0.06303478,  0.25822754, -0.11216752, -0.22482332,\n",
       "         0.16487725,  0.34595311,  0.01943289, -0.26537593, -0.0243206 ,\n",
       "         0.18550441, -0.17927622,  0.11272961, -0.05486864,  0.03032178,\n",
       "         0.12816645, -0.01924382,  0.20828634, -0.12656461, -0.24715489,\n",
       "         0.02472311,  0.23062991, -0.12573909, -0.11920286, -0.046767  ]),\n",
       " 'surfactant cellulose nanowhiskers': array([-2.52001864e-01, -4.81622671e-01,  5.84896733e-01,  2.56775079e-01,\n",
       "         3.03009587e-01,  5.39666569e-02, -4.64739501e-01,  3.40660258e-03,\n",
       "        -4.43344201e-01, -3.76172816e-01, -7.97890287e-02, -5.98660062e-01,\n",
       "        -1.23212904e-01, -9.57691148e-02,  2.57374580e-01, -1.78945664e-01,\n",
       "         1.53316960e-01, -1.93121910e-01,  2.65902869e-01, -3.38701596e-01,\n",
       "         2.56007209e-01,  2.04944690e-01,  7.45531997e-02, -3.54255875e-01,\n",
       "         4.58957950e-01,  1.10671644e-01, -1.16430623e-01,  5.35090099e-01,\n",
       "        -3.06963146e-01, -2.18569602e-01, -3.66398363e-02, -2.35782164e-01,\n",
       "         3.42570792e-01, -2.85225262e-01,  1.24475770e-01,  6.38559625e-01,\n",
       "         1.45204753e-01,  3.07843611e-01, -1.53052442e-01, -4.11349679e-01,\n",
       "        -5.44241026e-01,  1.79483272e-01,  2.61160006e-01, -1.71502920e-01,\n",
       "        -3.00305056e-01,  4.26645751e-01, -7.03047575e-02,  3.47268075e-01,\n",
       "         7.91949596e-02, -2.91886186e-01,  3.90550181e-01,  3.53969385e-02,\n",
       "         4.42272355e-01, -6.64397242e-02, -3.61389684e-01,  1.17338582e-01,\n",
       "        -1.73047649e-01,  8.40987290e-02, -2.09218974e-01,  5.89974852e-02,\n",
       "        -4.07974382e-01,  8.33858311e-01,  1.37373728e-01,  2.77804762e-01,\n",
       "         3.40756645e-01, -3.19452276e-01,  2.39340973e-02,  4.31729058e-01,\n",
       "        -2.55830800e-01, -9.18376135e-03,  2.96228384e-01, -1.05185402e-01,\n",
       "         1.42736635e-01,  2.74013226e-01, -1.55658344e-01, -2.34451359e-01,\n",
       "        -1.09478272e-02,  4.66334080e-01, -1.99651008e-01, -2.53723785e-01,\n",
       "         1.91169952e-01,  4.95613640e-01, -6.06953477e-04, -3.98764700e-01,\n",
       "        -1.45620426e-01,  1.87128072e-01, -2.52961030e-01,  2.65811750e-01,\n",
       "         7.59389189e-02,  5.23853755e-02,  1.37831992e-01, -5.15149332e-02,\n",
       "         2.75185362e-01, -1.08863094e-01, -4.15596942e-01,  5.66848839e-02,\n",
       "         4.07314191e-01, -1.38794129e-01, -1.69529364e-01, -1.91060316e-01]),\n",
       " 'surfactant': array([-0.35339108, -0.85691375,  0.7403329 ,  0.33251742,  0.38900599,\n",
       "         0.12373779, -0.81427145,  0.06626443, -0.60074627, -0.40642077,\n",
       "        -0.28507933, -0.95596153, -0.1638813 , -0.0557159 ,  0.32473397,\n",
       "        -0.30708873,  0.16574267, -0.09323426,  0.30730781, -0.65880424,\n",
       "         0.28078991,  0.17571935,  0.01447539, -0.3618696 ,  0.48139966,\n",
       "         0.15087998, -0.24922964,  0.53472179, -0.47267479, -0.36262545,\n",
       "        -0.08892634, -0.46099633,  0.36663115, -0.36427805,  0.15869527,\n",
       "         1.14431858,  0.18416509,  0.39751038, -0.2041472 , -0.50552577,\n",
       "        -0.92378408,  0.20628695,  0.29604203, -0.26827529, -0.43102601,\n",
       "         0.51079065, -0.13457172,  0.33618498,  0.19289048, -0.28834233,\n",
       "         0.37421691, -0.11671811,  0.59241056,  0.01189575, -0.61209255,\n",
       "         0.04893726, -0.09413623,  0.11485749, -0.29495344, -0.02091723,\n",
       "        -0.71037716,  1.16559505,  0.33492076,  0.23131478,  0.4302513 ,\n",
       "        -0.40593824,  0.14430159,  0.65300179, -0.37573084, -0.16592535,\n",
       "         0.30326673, -0.07009212,  0.2187264 ,  0.43624812, -0.13384376,\n",
       "        -0.18354863, -0.12782022,  0.76060027, -0.39850679, -0.27049193,\n",
       "         0.17750514,  0.6471563 , -0.06821109, -0.62185907, -0.35745385,\n",
       "         0.14455494, -0.34123349,  0.54217577,  0.37370726,  0.09652961,\n",
       "         0.12843151, -0.07528077,  0.29249135, -0.05754652, -0.6928466 ,\n",
       "         0.04304144,  0.76341647, -0.17108616, -0.2341454 , -0.48045823]),\n",
       " 'CNW': array([-0.31905493, -0.98769975,  0.88544369,  0.42804679,  0.37710306,\n",
       "         0.03670834, -0.38951358,  0.22781116, -0.34475371, -0.60975897,\n",
       "        -0.34477317, -0.49867576, -0.55033749, -0.22321525,  0.59462738,\n",
       "        -0.10782676, -0.08280537, -0.20519172,  0.05335135, -0.592215  ,\n",
       "         0.29553047,  0.19238697, -0.06985934, -0.57530779,  0.33637604,\n",
       "         0.26036111, -0.14227253,  0.79323548, -0.29518428, -0.22722645,\n",
       "        -0.01489208, -0.50883746,  0.1206314 , -0.53190804,  0.36273596,\n",
       "         1.02065504,  0.45529479,  0.64734888, -0.12391307, -0.49009496,\n",
       "        -1.1063844 ,  0.16606879,  0.34421554, -0.12341504, -0.53362525,\n",
       "         0.40026405, -0.18993948,  0.61388969,  0.35837382, -0.49102277,\n",
       "         0.6467396 ,  0.15972462,  0.76919031, -0.0771101 , -0.4916209 ,\n",
       "        -0.16159593,  0.10030401, -0.05689597, -0.4783614 ,  0.2542074 ,\n",
       "        -0.47961122,  1.23592842,  0.49195847,  0.20343903,  0.14438376,\n",
       "        -0.58780503,  0.09789245,  0.75239241, -0.34581858,  0.07398053,\n",
       "         0.63895726, -0.13896918,  0.21575227,  0.48521271, -0.01168362,\n",
       "        -0.04572131,  0.01220367,  0.61637169, -0.51986325, -0.10753368,\n",
       "         0.20955583,  0.67601699, -0.02967497, -0.66834807, -0.5039162 ,\n",
       "         0.31788427,  0.01184242,  0.48715043,  0.33479524,  0.03595356,\n",
       "         0.05128487, -0.16776195,  0.32283068,  0.12781022, -0.7099933 ,\n",
       "        -0.01717772,  0.94414777, -0.12190668,  0.0111312 , -0.25105065]),\n",
       " 'PMMA-g-MWCNT': array([ 0.0463495 , -1.18785083,  0.8641367 ,  0.52579758,  0.22111595,\n",
       "         0.26777821, -0.13706641,  0.74832276, -0.30024945, -0.05116407,\n",
       "        -0.72557011, -0.12543157, -0.65874429, -0.01885708,  0.53348537,\n",
       "         0.21015684, -0.50932369, -0.10717454,  0.04051124, -0.95669565,\n",
       "         0.11396471, -0.07079504, -0.22642307, -0.49861331, -0.23256345,\n",
       "         0.15062782, -0.17607855,  0.62402231, -0.05311438, -0.36408649,\n",
       "         0.14964151, -0.96028879, -0.19416612, -0.22890822,  0.78275424,\n",
       "         1.14481455,  0.97461987,  0.45943105, -0.36022209,  0.04577473,\n",
       "        -1.36787146, -0.14992083,  0.01966228,  0.42122397, -0.19576971,\n",
       "         0.01645377, -0.19602632,  0.57452643,  0.86553836, -0.59456302,\n",
       "        -0.0083168 ,  0.04433071,  0.86090574,  0.13588608, -0.82503298,\n",
       "        -0.51993653,  0.50904308, -0.2154049 , -0.34791362,  0.16163385,\n",
       "        -0.57787234,  0.75190654,  0.87959591, -0.5296995 , -0.04940761,\n",
       "        -0.8426767 ,  0.19705023,  0.88940609, -0.36339843,  0.18127622,\n",
       "         0.64764628, -0.0864509 ,  0.111665  ,  0.66434422,  0.22142408,\n",
       "         0.99016035, -0.64535691,  0.80900237, -0.94897118,  0.28067805,\n",
       "         0.45282704,  0.63023242,  0.25659079, -1.00575778, -1.15846109,\n",
       "         0.12725247,  0.16806292,  0.52512005,  0.82787395,  0.03370234,\n",
       "        -0.16445224, -0.39628455,  0.41977596,  0.90531   , -0.9770506 ,\n",
       "         0.13537998,  1.1752671 , -0.10050748,  0.14413404, -0.29591958]),\n",
       " 'Na-MMT': array([-0.46224862, -1.02574307,  0.32813633,  0.6018644 ,  0.25492523,\n",
       "         0.16423887, -0.58949645, -0.16369281, -0.41183244, -0.24153502,\n",
       "        -0.59429725, -0.62260967, -0.72289589, -0.43804608,  0.54687142,\n",
       "        -0.56820504,  0.03219435, -0.28206448, -0.28859588, -0.79294002,\n",
       "         0.36232641, -0.14519962, -0.70161508, -0.42804702,  0.40696371,\n",
       "         0.47965711, -0.69652265,  0.87229937, -0.48036426, -0.13939729,\n",
       "        -0.10517553, -0.62648948,  0.2669946 , -0.82188159,  0.33382066,\n",
       "         1.02040544,  0.60751364,  0.42844397, -0.54950282, -0.10705797,\n",
       "        -1.59787542, -0.0655707 ,  0.20892853, -0.16043217, -0.11425411,\n",
       "         0.43854952,  0.22622904,  0.32902771,  0.64401579, -0.53388557,\n",
       "         0.21084341,  0.07459485,  0.94659987,  0.2308163 , -0.50042862,\n",
       "        -0.19758029,  0.62887633, -0.01441517, -0.77270871,  0.12451683,\n",
       "        -0.57826513,  0.6162664 ,  0.87967926, -0.0072728 ,  0.36159781,\n",
       "        -0.69748339,  0.40794186,  0.91572335, -0.66596876,  0.01407738,\n",
       "         0.14101908, -0.04883776,  0.60556991,  0.13479771, -0.01390982,\n",
       "         0.22611937,  0.04376297,  0.56238267, -0.7705487 ,  0.07308352,\n",
       "         0.57395029,  0.84231123, -0.10598379, -0.60529277, -0.77820566,\n",
       "        -0.10368742,  0.35281224,  0.67425069,  0.67857113,  0.17485919,\n",
       "        -0.01699505, -0.15740583,  0.43433265,  0.69269647, -0.99718112,\n",
       "         0.28890422,  1.00803217, -0.11896747,  0.1157532 , -0.02665073]),\n",
       " 'PDMS-clay': array([-3.03019971e-01, -9.82125342e-01,  6.62290126e-01,  5.35870075e-01,\n",
       "         4.17527050e-01,  1.17013599e-01, -1.00707766e-01,  4.45638493e-01,\n",
       "        -3.58200915e-01, -2.65270440e-01, -5.69408998e-01, -6.62666261e-01,\n",
       "        -5.98882884e-01, -1.04511157e-02,  4.53432485e-01, -5.89622743e-02,\n",
       "        -4.22786638e-01, -2.07528073e-01,  2.02553060e-01, -6.92426145e-01,\n",
       "         3.35233919e-01,  1.75656546e-02, -3.48134883e-01, -4.41753760e-01,\n",
       "        -4.01611086e-02,  2.82469131e-01, -1.89487927e-01,  6.87065721e-01,\n",
       "        -2.89205633e-01, -1.93505161e-01,  1.94404311e-01, -6.25063986e-01,\n",
       "         1.21360273e-01, -4.45454761e-01,  5.16295493e-01,  1.00044811e+00,\n",
       "         4.17236045e-01,  1.61215816e-01, -4.54568431e-01, -9.30773281e-02,\n",
       "        -1.20318121e+00,  1.30006842e-01,  1.31457351e-01,  8.97501931e-02,\n",
       "        -2.50801422e-01,  2.81310424e-01, -2.45008901e-01,  5.88782817e-01,\n",
       "         5.79716980e-01, -5.78283101e-01,  1.25936195e-01,  1.10013474e-01,\n",
       "         8.04715484e-01, -2.35560611e-01, -5.78791291e-01, -1.88401833e-01,\n",
       "         3.25745307e-01, -2.18864664e-01, -5.24281070e-01,  1.43554492e-01,\n",
       "        -5.34137756e-01,  8.33468765e-01,  5.48296332e-01,  6.70845136e-02,\n",
       "         2.15357922e-01, -7.52586812e-01,  1.74101645e-01,  8.14598292e-01,\n",
       "        -6.43983349e-01,  1.49459289e-01,  2.33379830e-01, -2.97423210e-02,\n",
       "         4.48770240e-01,  6.68199271e-01,  3.98751721e-02,  5.34203470e-01,\n",
       "        -2.17033314e-01,  8.22177321e-01, -5.39752632e-01,  3.05306260e-02,\n",
       "         4.17506352e-01,  7.56769389e-01, -4.96241027e-02, -6.67708695e-01,\n",
       "        -8.70359123e-01,  1.17980771e-01,  8.71015489e-02,  6.41226023e-01,\n",
       "         4.90924805e-01, -8.68457519e-02, -4.33549285e-03, -3.07315074e-01,\n",
       "         5.20510107e-01,  6.41591325e-01, -8.71119767e-01,  2.24015754e-01,\n",
       "         9.34795320e-01, -3.01538967e-02,  1.04347616e-03, -1.60314105e-01]),\n",
       " 'montmorillonite': array([-0.07121198, -0.2055933 ,  0.34212929,  0.25579527,  0.22094482,\n",
       "         0.09087735, -0.16182745,  0.08046303, -0.31116351, -0.09681828,\n",
       "        -0.07684381, -0.36080253, -0.07263882,  0.07137784,  0.08301403,\n",
       "        -0.06845529,  0.06013325, -0.21721651,  0.33308655, -0.17622334,\n",
       "         0.24659361,  0.11418828,  0.05815775, -0.23044699,  0.24873058,\n",
       "         0.00709488, -0.0069341 ,  0.36877099, -0.11657645, -0.13128686,\n",
       "         0.06576832, -0.1655633 ,  0.22699596, -0.11052497,  0.16852467,\n",
       "         0.24754292,  0.11206445,  0.01679934, -0.22437075, -0.08155147,\n",
       "        -0.30483514,  0.11079477,  0.09515152,  0.01855954, -0.05101729,\n",
       "         0.26726657,  0.00632023,  0.22286502,  0.06837354, -0.22317496,\n",
       "         0.13054097,  0.00480368,  0.3211765 , -0.15187919, -0.23565316,\n",
       "         0.08164865, -0.13290516,  0.00203197, -0.11532989, -0.00723886,\n",
       "        -0.19286157,  0.30197436,  0.04766727,  0.1696393 ,  0.25529209,\n",
       "        -0.28169003, -0.02451658,  0.24469775, -0.15697007,  0.05639026,\n",
       "         0.14590648, -0.05765461,  0.06028176,  0.13816567, -0.09164968,\n",
       "         0.00098669, -0.06459788,  0.2921814 , -0.0828945 , -0.13924427,\n",
       "         0.29384664,  0.33499715,  0.0280335 , -0.24587505, -0.13101895,\n",
       "         0.11131189, -0.18030314,  0.11955537, -0.06973878,  0.04638308,\n",
       "         0.09935988, -0.05691852,  0.29655847,  0.10739616, -0.23889185,\n",
       "         0.17295425,  0.03874739, -0.01523082, -0.20458813,  0.01895528]),\n",
       " 'TiO2': array([ 7.05203861e-02, -1.32455564e+00,  5.69556296e-01,  6.23729348e-01,\n",
       "         4.25247937e-01,  3.26179147e-01, -1.99588224e-01,  6.30475163e-01,\n",
       "        -5.16741514e-01,  1.82062015e-01, -7.45055139e-01, -4.44328308e-01,\n",
       "        -5.77039361e-01,  2.74412841e-01,  4.18059736e-01,  1.93804830e-01,\n",
       "        -6.78572714e-01, -2.51383543e-01,  4.74095494e-02, -1.09749317e+00,\n",
       "         4.92650062e-01, -9.85646471e-02, -1.49214104e-01, -4.94883716e-01,\n",
       "        -1.55202642e-01,  3.81892204e-01, -1.15045033e-01,  7.25713611e-01,\n",
       "        -2.76165247e-01, -3.43055874e-01,  1.29207626e-01, -8.96530688e-01,\n",
       "         3.99189405e-02, -4.29308653e-01,  8.77635717e-01,  1.04537034e+00,\n",
       "         9.99121547e-01,  2.49518305e-01, -5.12059093e-01,  5.14685474e-02,\n",
       "        -1.80345786e+00, -2.28651449e-01,  5.11187948e-02,  3.77853155e-01,\n",
       "        -4.59687231e-04,  1.74277976e-01,  7.41713047e-02,  6.14820957e-01,\n",
       "         8.96070957e-01, -8.05117607e-01, -1.94147870e-01, -1.56100884e-01,\n",
       "         9.73758340e-01, -4.32076082e-02, -6.78046048e-01, -3.44795376e-01,\n",
       "         3.66395742e-01, -1.46522865e-01, -3.11439395e-01,  7.81745240e-02,\n",
       "        -6.17683232e-01,  6.22285783e-01,  9.92207646e-01, -4.00115669e-01,\n",
       "        -2.79679205e-02, -8.78228307e-01,  4.61847812e-01,  1.45525849e+00,\n",
       "        -8.78370643e-01,  2.36905426e-01,  4.62822378e-01,  1.94205582e-01,\n",
       "         5.58915377e-01,  7.24605799e-01,  6.88419342e-02,  1.30257154e+00,\n",
       "        -6.71046615e-01,  1.10129941e+00, -8.34436595e-01,  3.43935370e-01,\n",
       "         8.30175698e-01,  1.17902231e+00,  7.91330487e-02, -9.56845522e-01,\n",
       "        -1.43639433e+00,  9.66951810e-03, -9.04626176e-02,  3.95836204e-01,\n",
       "         8.29321265e-01,  1.53889433e-01, -1.41565278e-01, -5.77417791e-01,\n",
       "         6.92111433e-01,  1.11038244e+00, -1.22123981e+00,  2.61097044e-01,\n",
       "         1.05942833e+00, -1.32748276e-01, -2.11894557e-01, -3.58894587e-01]),\n",
       " 'MMA-MWCNT': array([-0.16905938, -0.94024149,  0.68067864,  0.39256063,  0.24762977,\n",
       "         0.03006046, -0.81694335,  0.06902987, -0.39407428, -0.28905156,\n",
       "        -0.45813634, -0.55286887, -0.57390331, -0.06733353,  0.44475025,\n",
       "        -0.25753257, -0.0389497 , -0.25531622,  0.16235508, -0.67152801,\n",
       "         0.1874349 , -0.03524187, -0.07226913, -0.43896255,  0.18419838,\n",
       "         0.17726911, -0.29285535,  0.52454838, -0.32846121, -0.36250213,\n",
       "        -0.11626408, -0.74025619,  0.1301185 , -0.35585001,  0.32142497,\n",
       "         1.03994358,  0.6591922 ,  0.49334496, -0.22107589, -0.26797457,\n",
       "        -1.26814672,  0.03500432,  0.10883539,  0.13076634, -0.25436635,\n",
       "         0.23743469, -0.17270358,  0.40671565,  0.51905526, -0.29154944,\n",
       "         0.24579974, -0.01235193,  0.79369861,  0.23571821, -0.7878657 ,\n",
       "        -0.24144597,  0.26576146,  0.00323688, -0.38184224,  0.12381426,\n",
       "        -0.638717  ,  0.87301821,  0.63715503, -0.20912014,  0.32548405,\n",
       "        -0.3378002 ,  0.17976324,  0.87875682, -0.22787881, -0.29781781,\n",
       "         0.42851621,  0.04091375, -0.02889163,  0.42127185,  0.20919785,\n",
       "         0.28906453, -0.22130773,  0.72891867, -0.71755499, -0.11669366,\n",
       "         0.33283642,  0.49761197,  0.0169565 , -0.93124682, -0.77786103,\n",
       "         0.21752935, -0.07581937,  0.61644745,  0.62407355,  0.14969326,\n",
       "         0.24179695, -0.19407758,  0.23326533,  0.52719564, -0.85928911,\n",
       "        -0.00412209,  0.84475192, -0.18443701, -0.13248857, -0.34545532]),\n",
       " 'PMMA-g-expandable graphite': array([ 0.07379046, -0.52747953,  0.78192204,  0.3562555 ,  0.33016212,\n",
       "         0.31964764,  0.10956359,  0.56061399, -0.59568834, -0.18103178,\n",
       "        -0.37103381, -0.51425879, -0.23335323,  0.20693507,  0.22448186,\n",
       "         0.2345963 , -0.08470366, -0.22006301,  0.58178153, -0.61025847,\n",
       "         0.44591403,  0.21760982,  0.110155  , -0.5578472 ,  0.37019239,\n",
       "         0.07509798,  0.00661243,  0.63443265, -0.07941649, -0.24889595,\n",
       "         0.03608557, -0.56206484,  0.23623564, -0.13184945,  0.57367382,\n",
       "         0.96200468,  0.55221575,  0.34512956, -0.3039949 , -0.28538771,\n",
       "        -0.75563395, -0.03703431,  0.0439804 ,  0.05018863, -0.18914394,\n",
       "         0.48295596, -0.01916184,  0.52005052,  0.36097974, -0.59152367,\n",
       "         0.24116664, -0.1494008 ,  0.62581132, -0.30337183, -0.50978117,\n",
       "        -0.02317124, -0.00720174, -0.11995641, -0.08976234, -0.1247812 ,\n",
       "        -0.40926464,  0.81413384,  0.2805612 , -0.0426508 ,  0.14111843,\n",
       "        -0.84627994,  0.09933454,  0.66324095, -0.51731168,  0.44558328,\n",
       "         0.46570557, -0.22615073,  0.23759193,  0.50628851, -0.15653619,\n",
       "         0.40055214, -0.58984536,  0.60176849, -0.40513342, -0.08773126,\n",
       "         0.52432867,  0.90550574,  0.26301996, -0.61950431, -0.60549817,\n",
       "         0.19783141, -0.15145191,  0.16105434,  0.24006048,  0.0466444 ,\n",
       "        -0.02480726, -0.22908169,  0.62356317,  0.27731506, -0.62984942,\n",
       "         0.47496292,  0.54516223, -0.02235063, -0.02126099, -0.18019882]),\n",
       " 'expandable graphite': array([ 0.06863675, -0.11966849,  0.63168934,  0.2474846 ,  0.39605696,\n",
       "         0.18138127, -0.04044671,  0.22707934, -0.70744568, -0.2971941 ,\n",
       "        -0.16553247, -0.79884368, -0.13691411,  0.38684949,  0.03112181,\n",
       "         0.07024432,  0.21114345, -0.39070868,  0.9092299 , -0.32022608,\n",
       "         0.65629238,  0.28082143,  0.35647561, -0.57210404,  0.68203251,\n",
       "         0.06275533,  0.04805518,  0.53070337, -0.15779814, -0.21574552,\n",
       "        -0.16075398, -0.35264562,  0.47122878, -0.11124362,  0.32030293,\n",
       "         0.79023775,  0.31870696,  0.29427546, -0.18440802, -0.48545282,\n",
       "        -0.56739295,  0.07667266, -0.00465499, -0.10368196, -0.16952574,\n",
       "         0.743329  ,  0.00739413,  0.45674224,  0.06201721, -0.46717533,\n",
       "         0.42567967, -0.25025733,  0.5931915 , -0.49877194, -0.40449642,\n",
       "         0.22904561, -0.27259071, -0.05659805, -0.01810096, -0.24949967,\n",
       "        -0.27590793,  0.81309226, -0.02057638,  0.20732171,  0.33186394,\n",
       "        -0.59922498,  0.03775849,  0.64897895, -0.48484889,  0.32311868,\n",
       "         0.29332069, -0.16857442,  0.14767421,  0.34814778, -0.19571485,\n",
       "         0.03093646, -0.38308141,  0.52678892, -0.08353814, -0.38751414,\n",
       "         0.5371417 ,  0.93547046,  0.15577102, -0.5098049 , -0.3340927 ,\n",
       "         0.32555728, -0.3155932 ,  0.07240819, -0.06668151,  0.1209784 ,\n",
       "         0.28428714, -0.1305468 ,  0.6453329 ,  0.03225067, -0.44438438,\n",
       "         0.57990073,  0.09136562,  0.02191043, -0.21659063, -0.12410457]),\n",
       " 'expanded graphite': array([ 0.06863675, -0.11966849,  0.63168934,  0.2474846 ,  0.39605696,\n",
       "         0.18138127, -0.04044671,  0.22707934, -0.70744568, -0.2971941 ,\n",
       "        -0.16553247, -0.79884368, -0.13691411,  0.38684949,  0.03112181,\n",
       "         0.07024432,  0.21114345, -0.39070868,  0.9092299 , -0.32022608,\n",
       "         0.65629238,  0.28082143,  0.35647561, -0.57210404,  0.68203251,\n",
       "         0.06275533,  0.04805518,  0.53070337, -0.15779814, -0.21574552,\n",
       "        -0.16075398, -0.35264562,  0.47122878, -0.11124362,  0.32030293,\n",
       "         0.79023775,  0.31870696,  0.29427546, -0.18440802, -0.48545282,\n",
       "        -0.56739295,  0.07667266, -0.00465499, -0.10368196, -0.16952574,\n",
       "         0.743329  ,  0.00739413,  0.45674224,  0.06201721, -0.46717533,\n",
       "         0.42567967, -0.25025733,  0.5931915 , -0.49877194, -0.40449642,\n",
       "         0.22904561, -0.27259071, -0.05659805, -0.01810096, -0.24949967,\n",
       "        -0.27590793,  0.81309226, -0.02057638,  0.20732171,  0.33186394,\n",
       "        -0.59922498,  0.03775849,  0.64897895, -0.48484889,  0.32311868,\n",
       "         0.29332069, -0.16857442,  0.14767421,  0.34814778, -0.19571485,\n",
       "         0.03093646, -0.38308141,  0.52678892, -0.08353814, -0.38751414,\n",
       "         0.5371417 ,  0.93547046,  0.15577102, -0.5098049 , -0.3340927 ,\n",
       "         0.32555728, -0.3155932 ,  0.07240819, -0.06668151,  0.1209784 ,\n",
       "         0.28428714, -0.1305468 ,  0.6453329 ,  0.03225067, -0.44438438,\n",
       "         0.57990073,  0.09136562,  0.02191043, -0.21659063, -0.12410457]),\n",
       " 'graphite': array([ 0.30408299,  0.05594124,  0.50817865,  0.17679526,  0.40182492,\n",
       "         0.30421594,  0.06123433,  0.29813084, -0.97267979, -0.11395214,\n",
       "        -0.2852515 , -1.0975281 , -0.01364659,  0.74475783, -0.23088686,\n",
       "         0.08288742,  0.35396671, -0.35215306,  1.23520768, -0.47779685,\n",
       "         0.90191865,  0.28803352,  0.51610488, -0.58394355,  0.9245531 ,\n",
       "         0.07326937, -0.03967927,  0.37813973, -0.20218408, -0.27206555,\n",
       "        -0.38110059, -0.41296202,  0.62575024, -0.03927884,  0.35497478,\n",
       "         1.04197752,  0.36136839,  0.24175073, -0.2038541 , -0.52581102,\n",
       "        -0.74063838, -0.11564645, -0.22205488, -0.15976033, -0.03461905,\n",
       "         0.9970246 ,  0.16245128,  0.39081129,  0.01631045, -0.51449627,\n",
       "         0.29478547, -0.63415623,  0.64468145, -0.67696154, -0.46011236,\n",
       "         0.29363292, -0.25949508, -0.08471867,  0.1053408 , -0.58861977,\n",
       "        -0.25639394,  0.76396394, -0.03363262,  0.11271719,  0.27704608,\n",
       "        -0.76360166,  0.22155684,  0.79663414, -0.74284744,  0.5260883 ,\n",
       "         0.1491107 , -0.19393609,  0.29802522,  0.31518093, -0.25566015,\n",
       "         0.23462787, -0.66352975,  0.62177742, -0.03460781, -0.37228695,\n",
       "         0.73438269,  1.26862538,  0.25107846, -0.52959597, -0.44974968,\n",
       "         0.24612612, -0.37240076,  0.03605903,  0.00950988,  0.27105987,\n",
       "         0.26565742, -0.21521698,  0.84295124,  0.1125718 , -0.51792365,\n",
       "         0.89687097, -0.08985672,  0.13347855, -0.28205627, -0.17226331]),\n",
       " 'ZrO2': array([-0.05646123, -0.32698739,  0.37980941,  0.23442687,  0.13540842,\n",
       "         0.08356197, -0.015971  ,  0.20158274, -0.17785056, -0.11203801,\n",
       "        -0.11488572, -0.05312935, -0.16445394, -0.051613  ,  0.16730963,\n",
       "         0.03242443, -0.05605501, -0.15424044,  0.09171028, -0.22097482,\n",
       "         0.15492694,  0.13895519, -0.02016544, -0.23520228,  0.1626211 ,\n",
       "         0.03192446,  0.02876981,  0.42817825, -0.00845338, -0.11431611,\n",
       "         0.06922044, -0.18694481,  0.09661049, -0.17204395,  0.26073837,\n",
       "         0.23434883,  0.24553207,  0.17313516, -0.15478924, -0.07849777,\n",
       "        -0.3631829 ,  0.01048867,  0.15779024,  0.04814163, -0.11204477,\n",
       "         0.16730034,  0.04780548,  0.28151521,  0.14542098, -0.2565701 ,\n",
       "         0.20557144,  0.07825253,  0.29527214, -0.06487529, -0.15791306,\n",
       "        -0.0669176 , -0.04775725, -0.04245145, -0.12752081,  0.08031619,\n",
       "        -0.12356944,  0.35604107,  0.13527915,  0.06945669,  0.04715502,\n",
       "        -0.33416834, -0.01494429,  0.26335397, -0.10545266,  0.17223869,\n",
       "         0.3274121 , -0.08923404,  0.07326425,  0.13785593, -0.05426284,\n",
       "         0.07669816, -0.12979439,  0.20120998, -0.19900219, -0.00875043,\n",
       "         0.23493259,  0.29933622,  0.08935164, -0.27273175, -0.18112943,\n",
       "         0.09932499, -0.06299999,  0.02112869, -0.00960155,  0.02520928,\n",
       "        -0.06455988, -0.09095134,  0.21688545,  0.10127407, -0.21607758,\n",
       "         0.04577339,  0.19004709, -0.05489267, -0.10093391, -0.00873351]),\n",
       " 'organo clay (Closite 20A)': array([-2.45085947e-01, -7.50483155e-01,  4.55796748e-01,  4.37779233e-01,\n",
       "         3.11060704e-01,  1.16266611e-01, -7.46449865e-02,  3.27914964e-01,\n",
       "        -2.88976368e-01, -1.58780692e-01, -4.66125771e-01, -5.30413032e-01,\n",
       "        -4.51832607e-01, -9.57738608e-03,  3.22761163e-01, -9.84113384e-02,\n",
       "        -3.05486940e-01, -1.61064025e-01,  1.39430252e-01, -5.56869127e-01,\n",
       "         2.85907406e-01, -9.52213071e-04, -3.34182315e-01, -3.15591469e-01,\n",
       "         3.10743228e-04,  2.24228628e-01, -1.97359700e-01,  5.44171259e-01,\n",
       "        -2.38133483e-01, -1.45278588e-01,  1.48113582e-01, -4.80544157e-01,\n",
       "         1.12426126e-01, -3.85883927e-01,  3.99114780e-01,  7.64831275e-01,\n",
       "         3.10360268e-01,  8.65848549e-02, -3.98066953e-01, -2.39398517e-02,\n",
       "        -9.49653119e-01,  8.45950097e-02,  1.04782745e-01,  6.17263075e-02,\n",
       "        -1.55450441e-01,  2.35787809e-01, -1.22816741e-01,  4.27026525e-01,\n",
       "         4.53852430e-01, -4.48677614e-01,  6.31777495e-02,  6.09958060e-02,\n",
       "         6.16182297e-01, -1.72849460e-01, -4.37489465e-01, -1.45414077e-01,\n",
       "         2.90069714e-01, -1.61938671e-01, -4.34703454e-01,  7.78833982e-02,\n",
       "        -4.00049038e-01,  5.81125885e-01,  4.43934597e-01,  6.15736665e-02,\n",
       "         1.79708194e-01, -6.05240941e-01,  1.66102702e-01,  6.18351027e-01,\n",
       "        -5.24752896e-01,  1.41976898e-01,  1.29295353e-01, -1.99623909e-02,\n",
       "         3.87166670e-01,  4.58240539e-01,  1.38104632e-02,  4.27740578e-01,\n",
       "        -1.67080523e-01,  6.23489164e-01, -4.23755437e-01,  4.58774292e-02,\n",
       "         3.57171685e-01,  6.07324004e-01, -3.84476255e-02, -4.84461680e-01,\n",
       "        -6.72829300e-01,  3.35942060e-02,  1.00542400e-01,  4.95113544e-01,\n",
       "         3.85718226e-01, -5.10434499e-02, -3.56506836e-02, -2.31689923e-01,\n",
       "         4.15049069e-01,  5.28839141e-01, -6.70725957e-01,  2.07747817e-01,\n",
       "         6.99061990e-01,  1.40253454e-03, -9.78058204e-03, -1.05794119e-01]),\n",
       " 'PMMA-g-silica': array([-1.14307091e-01, -1.30545199e+00,  8.33410293e-01,  6.07599825e-01,\n",
       "         2.60064766e-01,  5.02674714e-01,  1.85839236e-02,  9.50180918e-01,\n",
       "        -3.93942505e-01,  9.37507115e-03, -7.37490714e-01, -3.93494584e-01,\n",
       "        -4.34860557e-01, -3.31713371e-02,  5.25127947e-01,  3.01652241e-01,\n",
       "        -6.40534848e-01,  8.37992504e-03,  1.33912276e-01, -1.12650365e+00,\n",
       "         9.21411039e-02, -4.05201800e-02, -3.49958345e-01, -4.59289834e-01,\n",
       "        -2.69716293e-01,  1.79452486e-01, -1.39718641e-01,  6.63705468e-01,\n",
       "        -7.80962333e-02, -2.62063622e-01,  3.66278276e-01, -9.41091567e-01,\n",
       "        -1.07204853e-01, -2.58427642e-01,  8.58915269e-01,  1.28791922e+00,\n",
       "         8.35352033e-01,  2.28523097e-01, -5.83082706e-01,  7.51698334e-02,\n",
       "        -1.33061457e+00, -2.32998282e-02,  1.22310072e-01,  2.85588995e-01,\n",
       "        -1.23895376e-01,  3.60031985e-02, -1.38059333e-01,  5.61851576e-01,\n",
       "         8.53430301e-01, -6.12599596e-01, -1.49551652e-01,  2.07890170e-02,\n",
       "         7.09767967e-01,  4.18606281e-02, -7.77132064e-01, -4.23526466e-01,\n",
       "         4.80092600e-01, -2.25230768e-01, -2.61652417e-01,  1.07213672e-01,\n",
       "        -7.85237491e-01,  7.43234575e-01,  8.54430020e-01, -4.56307620e-01,\n",
       "        -1.18858144e-02, -1.05529591e+00,  2.37057522e-01,  8.58421981e-01,\n",
       "        -5.85790873e-01,  2.14569271e-01,  4.65204649e-01, -1.39229361e-01,\n",
       "         4.40833539e-01,  7.78955907e-01, -9.44454223e-04,  1.03827736e+00,\n",
       "        -7.90062785e-01,  8.77360255e-01, -1.00164950e+00,  3.20322908e-01,\n",
       "         4.91304219e-01,  7.08635360e-01,  2.95581836e-01, -8.48579019e-01,\n",
       "        -1.16342229e+00,  3.67726497e-02,  4.66764234e-02,  5.07643014e-01,\n",
       "         8.40080112e-01, -1.40860677e-03, -3.05589804e-01, -4.15740311e-01,\n",
       "         5.10321334e-01,  8.39565665e-01, -1.03348142e+00,  2.79501826e-01,\n",
       "         1.29284090e+00, -2.01982792e-01,  1.63009981e-01, -4.12173614e-01]),\n",
       " 'titanium dioxide': array([-0.08809721, -0.14961285,  0.39663011,  0.18100432,  0.19212998,\n",
       "        -0.01067828, -0.1655231 ,  0.00211771, -0.23173961, -0.208308  ,\n",
       "         0.03414627, -0.19853184, -0.11592303, -0.04450735,  0.15071857,\n",
       "        -0.02711239,  0.08690327, -0.26209161,  0.26801907, -0.06663745,\n",
       "         0.17970786,  0.18975227,  0.11937242, -0.27723196,  0.26107714,\n",
       "        -0.00559759,  0.07286021,  0.41602227, -0.06101642, -0.12297978,\n",
       "         0.05682565, -0.10641528,  0.22345293, -0.11987736,  0.13229856,\n",
       "         0.12056583,  0.13167828,  0.14701933, -0.11334084, -0.17845028,\n",
       "        -0.17726372,  0.14517642,  0.133905  ,  0.01619376, -0.09938804,\n",
       "         0.22888944, -0.05275981,  0.30006635,  0.02727961, -0.22595311,\n",
       "         0.25691872,  0.1419922 ,  0.28564143, -0.07511796, -0.17336363,\n",
       "         0.08373815, -0.20342053,  0.02413698, -0.10479165,  0.10892298,\n",
       "        -0.16127227,  0.36742611, -0.0138988 ,  0.19279502,  0.24647027,\n",
       "        -0.18578643, -0.09232345,  0.20271031, -0.03055071,  0.03469552,\n",
       "         0.25888237, -0.08272189, -0.04662638,  0.14182713, -0.05739661,\n",
       "        -0.14836805,  0.01907738,  0.2097049 , -0.04910393, -0.20606563,\n",
       "         0.1859379 ,  0.21736703,  0.04241457, -0.25004935, -0.01978   ,\n",
       "         0.19765422, -0.18074612,  0.04795774, -0.12795417,  0.01298007,\n",
       "         0.1466176 , -0.03486789,  0.20984436, -0.04280682, -0.15929222,\n",
       "         0.03431679,  0.04703133, -0.09876098, -0.17307156,  0.03940427])}"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "pickle_in = open(\"filler_vectors.pickle\",\"rb\")\n",
    "filler_vectors = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "filler_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bisphenol A PC': array([ 0.09760512, -0.49285525,  0.59907046,  0.4076535 ,  0.13687227,\n",
       "         0.12928449,  0.20651953,  0.30990215, -0.0189062 , -0.10556737,\n",
       "        -0.2214813 ,  0.31907384, -0.50495017, -0.20957507,  0.46442664,\n",
       "         0.15363452, -0.1887982 , -0.30010779, -0.01194632, -0.28905727,\n",
       "         0.18882926,  0.14452246, -0.09500518, -0.43336631,  0.00659299,\n",
       "         0.01451863,  0.12846256,  0.74215376,  0.16430452, -0.10531601,\n",
       "         0.25095334, -0.42087046, -0.10003082, -0.27160406,  0.57401547,\n",
       "         0.17363901,  0.55069061,  0.34632709, -0.24522626,  0.09868017,\n",
       "        -0.51648107, -0.0317466 ,  0.09448896,  0.27004605, -0.09130323,\n",
       "        -0.04755371,  0.04575628,  0.48298648,  0.46183506, -0.44878054,\n",
       "         0.20680645,  0.22214416,  0.51773886,  0.06355288, -0.22401156,\n",
       "        -0.30891807,  0.16428882, -0.12187406, -0.25870324,  0.2862826 ,\n",
       "        -0.10383948,  0.21391399,  0.33919187, -0.10157377, -0.03578883,\n",
       "        -0.60724143, -0.05469615,  0.34653161, -0.00578271,  0.29550444,\n",
       "         0.61267722, -0.16462851, -0.04933715,  0.17278434,  0.09378041,\n",
       "         0.32820534, -0.07243883,  0.10764069, -0.41644698,  0.14756656,\n",
       "         0.40896941,  0.26244093,  0.17690493, -0.41118792, -0.36734163,\n",
       "         0.14986939,  0.23598914,  0.0783664 ,  0.04600529,  0.05755597,\n",
       "        -0.080169  , -0.16535635,  0.26382204,  0.44502408, -0.36514469,\n",
       "         0.04559953,  0.35259115, -0.0716411 ,  0.03655342,  0.27017505]),\n",
       " 'EPDM': array([-0.23330793, -0.63323665,  0.65095389,  0.3975119 ,  0.20754011,\n",
       "        -0.02260276,  0.01732046,  0.23253584,  0.01754653, -0.46244323,\n",
       "        -0.25640357,  0.06327686, -0.68069917, -0.3087357 ,  0.58102095,\n",
       "         0.04406188, -0.22979154, -0.32323468, -0.03750755, -0.27082548,\n",
       "         0.12892684,  0.08035441, -0.19639476, -0.49240783,  0.01217121,\n",
       "         0.1752065 ,  0.03619339,  0.71711004,  0.02982351, -0.0287504 ,\n",
       "         0.15867122, -0.42871463, -0.09412714, -0.40978879,  0.39227206,\n",
       "         0.4253214 ,  0.4846279 ,  0.47708091, -0.1502375 , -0.16864997,\n",
       "        -0.72463357,  0.15023878,  0.20112547,  0.13157816, -0.33717686,\n",
       "         0.09932439, -0.18871152,  0.56192791,  0.4264071 , -0.42044592,\n",
       "         0.49943787,  0.36875442,  0.61012876, -0.03748799, -0.31830093,\n",
       "        -0.28782079,  0.20109105, -0.21172407, -0.44423798,  0.40025944,\n",
       "        -0.21644631,  0.647654  ,  0.36115062,  0.01936085,  0.0487018 ,\n",
       "        -0.47696626, -0.08813567,  0.44215447, -0.06618693,  0.10934129,\n",
       "         0.57357079, -0.1037529 , -0.00623806,  0.31242871,  0.13929893,\n",
       "         0.08812151,  0.08475887,  0.18973939, -0.44287294, -0.0121358 ,\n",
       "         0.23745798,  0.27568898,  0.0395168 , -0.53774124, -0.43105337,\n",
       "         0.3272332 ,  0.26449156,  0.25904906,  0.14499459, -0.06620659,\n",
       "         0.09132044, -0.1187217 ,  0.21545175,  0.3472684 , -0.4121775 ,\n",
       "        -0.00146506,  0.63494116, -0.09845409,  0.1627802 ,  0.06065333]),\n",
       " 'epoxy': array([ 5.16611695e-01, -9.74640727e-01,  1.16864216e+00,  2.91230977e-01,\n",
       "         6.91876650e-01,  2.88572103e-01,  7.53185377e-02,  6.88490987e-01,\n",
       "        -7.32375264e-01,  3.83916140e-01, -1.96515813e-01, -2.19834536e-01,\n",
       "        -1.57645032e-01,  5.11036515e-01,  5.99433362e-01,  6.01395249e-01,\n",
       "        -8.12563837e-01, -2.03460634e-01,  5.43614984e-01, -7.05081522e-01,\n",
       "         5.33529639e-01,  4.17737693e-01,  5.99761724e-01, -6.82928741e-01,\n",
       "        -4.72705245e-01, -1.72443718e-01,  5.66934228e-01,  7.78689921e-01,\n",
       "        -7.52840564e-02, -6.43929720e-01,  4.57516938e-01, -9.20568109e-01,\n",
       "        -2.32031010e-02,  3.29745561e-01,  1.21753407e+00,  5.74408352e-01,\n",
       "         7.01965749e-01,  1.62015837e-02, -1.13115661e-01,  4.52968180e-02,\n",
       "        -6.23824716e-01, -1.32955723e-02, -9.82642695e-02,  7.98792601e-01,\n",
       "         5.09575708e-03, -8.09747726e-02, -4.30231243e-01,  9.25353706e-01,\n",
       "         7.01506972e-01, -1.12946606e+00, -3.57152373e-01, -3.34939733e-02,\n",
       "         9.65129375e-01, -6.13339320e-02, -6.25676394e-01,  1.02004081e-01,\n",
       "        -8.80562663e-02,  1.99367523e-01,  4.99139680e-03,  1.01857528e-01,\n",
       "        -6.44417763e-01,  5.67709208e-01,  7.40576625e-01, -6.92351758e-02,\n",
       "         1.89143136e-01, -6.38492584e-01,  2.42871746e-01,  1.39527404e+00,\n",
       "        -4.85087126e-01,  4.11436677e-01,  7.54929960e-01,  7.91731775e-02,\n",
       "        -1.15224861e-01,  1.06342852e+00,  2.46370777e-01,  1.22457612e+00,\n",
       "        -8.44001710e-01,  1.49837708e+00, -3.01946372e-01,  3.29881761e-04,\n",
       "         4.58346009e-01,  1.11148679e+00,  5.70004731e-02, -9.75143015e-01,\n",
       "        -1.20349622e+00,  1.97238058e-01, -6.10397041e-01,  4.87354159e-01,\n",
       "         5.47055781e-01, -2.90486217e-01,  1.09541260e-01, -6.45832062e-01,\n",
       "         7.95300305e-01,  6.59204304e-01, -1.27188444e+00, -2.13979766e-01,\n",
       "         9.01820362e-01,  9.87854786e-03, -4.32331562e-01, -1.51302963e-01]),\n",
       " 'SC-15 epoxy': array([ 0.22761789, -0.61394235,  0.86094746,  0.24842085,  0.46259982,\n",
       "         0.13846764,  0.05668853,  0.42691941, -0.4496403 ,  0.07813141,\n",
       "        -0.08597857, -0.10814454, -0.18048185,  0.22428704,  0.43546872,\n",
       "         0.36426128, -0.46107873, -0.23646821,  0.37908377, -0.38334023,\n",
       "         0.36447076,  0.33076546,  0.37061536, -0.51784495, -0.17587278,\n",
       "        -0.09903442,  0.39826723,  0.65873232, -0.01186353, -0.3844173 ,\n",
       "         0.30811527, -0.54652516,  0.04743508,  0.09682871,  0.76188639,\n",
       "         0.31373181,  0.45801079,  0.10892629, -0.09771282, -0.05522702,\n",
       "        -0.39689311,  0.07376602,  0.03725908,  0.46493321, -0.08154544,\n",
       "         0.03156636, -0.27219725,  0.69082515,  0.39185212, -0.73461737,\n",
       "        -0.01119746,  0.10444184,  0.65619946, -0.09352354, -0.38192318,\n",
       "         0.06343356, -0.14549451,  0.08460824, -0.06757253,  0.15486658,\n",
       "        -0.37508351,  0.50125802,  0.38828858,  0.07271525,  0.156677  ,\n",
       "        -0.44945601,  0.05134328,  0.83123197, -0.2500192 ,  0.28367889,\n",
       "         0.59012564, -0.0073309 , -0.09434872,  0.64679848,  0.11923287,\n",
       "         0.60250113, -0.42968506,  0.86728904, -0.1881995 , -0.07527911,\n",
       "         0.32736081,  0.68835945,  0.05488692, -0.64194812, -0.65906015,\n",
       "         0.21760765, -0.37512285,  0.25296077,  0.19659006, -0.18532569,\n",
       "         0.10649532, -0.37565107,  0.51772639,  0.33400174, -0.73364126,\n",
       "        -0.12976221,  0.52218235, -0.03414728, -0.28440466, -0.03741251]),\n",
       " 'DGEBA': array([-6.50465488e-02, -1.06769517e-01,  1.57647088e-01,  7.05068707e-02,\n",
       "         5.75892851e-02, -6.47223415e-03, -9.59868431e-02, -1.17622502e-02,\n",
       "        -5.92052974e-02, -1.25602275e-01, -1.29139773e-03, -7.76286423e-02,\n",
       "        -9.55019966e-02, -7.50372708e-02,  1.03360683e-01, -3.39911133e-02,\n",
       "         3.80354114e-02, -8.91681910e-02,  5.50506189e-02, -3.68122458e-02,\n",
       "         4.30361740e-02,  3.91613618e-02, -1.15725538e-03, -9.80748609e-02,\n",
       "         7.85341561e-02,  2.39735320e-02,  5.95322391e-03,  1.62590280e-01,\n",
       "        -2.30095778e-02, -3.13338153e-02,  2.00449731e-02, -5.37375920e-02,\n",
       "         5.21454960e-02, -7.31958896e-02,  3.55379842e-02,  9.74231884e-02,\n",
       "         5.63585833e-02,  9.56405550e-02, -3.87524739e-02, -6.94108382e-02,\n",
       "        -1.08093791e-01,  6.32357150e-02,  6.79769143e-02, -1.57391597e-02,\n",
       "        -6.89239278e-02,  7.22076818e-02, -3.19585055e-02,  1.03298679e-01,\n",
       "         2.93158907e-02, -7.75496736e-02,  1.22176141e-01,  7.71368593e-02,\n",
       "         1.13548756e-01, -5.63572394e-05, -7.06171915e-02,  2.27239355e-03,\n",
       "        -2.47270018e-02,  3.74445273e-03, -7.73279592e-02,  6.82479739e-02,\n",
       "        -8.21941569e-02,  1.68627009e-01,  2.84115002e-02,  6.46403804e-02,\n",
       "         9.76418629e-02, -7.15819821e-02, -2.98489071e-02,  6.42969608e-02,\n",
       "        -3.46465036e-03, -2.63320282e-02,  1.08580977e-01, -3.18519734e-02,\n",
       "        -1.95207521e-02,  5.06867953e-02, -1.73154715e-02, -9.15408656e-02,\n",
       "         4.55308035e-02,  5.81546538e-02, -5.49694709e-02, -7.31658563e-02,\n",
       "         3.91679555e-02,  5.46909235e-02, -9.86846571e-05, -9.88485590e-02,\n",
       "        -2.06038002e-02,  7.72171170e-02, -2.29365099e-02,  5.65113649e-02,\n",
       "        -1.59102585e-02, -6.06038491e-04,  5.98181449e-02,  1.59259548e-03,\n",
       "         5.11373468e-02, -4.85359412e-03, -7.92687759e-02,  2.12225644e-03,\n",
       "         9.71675813e-02, -4.91415039e-02, -6.74089603e-03,  6.19722996e-03]),\n",
       " 'PC': array([ 0.22774939, -0.81500822,  0.73873252,  0.65216088,  0.04851176,\n",
       "         0.24546896,  0.52671707,  0.53855717,  0.21516167, -0.01191932,\n",
       "        -0.46710262,  0.84197539, -0.92461115, -0.42792714,  0.75540596,\n",
       "         0.2565493 , -0.39400405, -0.38101739, -0.34050015, -0.47775933,\n",
       "         0.18344082,  0.09089881, -0.37319222, -0.5610581 , -0.20359123,\n",
       "         0.05475173,  0.13534534,  1.09255135,  0.39103165, -0.0646379 ,\n",
       "         0.42980441, -0.66507167, -0.39267936, -0.45019189,  0.94590139,\n",
       "         0.14672974,  0.95104629,  0.53210032, -0.41551223,  0.40209135,\n",
       "        -0.85924983, -0.18852367,  0.08082473,  0.48654807, -0.04348997,\n",
       "        -0.29956135,  0.19012649,  0.63172579,  0.86148989, -0.6409564 ,\n",
       "         0.18676382,  0.35113382,  0.74387676,  0.23596263, -0.22203556,\n",
       "        -0.70897651,  0.5319913 , -0.26325768, -0.44485044,  0.48097268,\n",
       "        -0.03922206,  0.009348  ,  0.68132097, -0.36113319, -0.27229348,\n",
       "        -0.9955883 , -0.0328831 ,  0.4416914 ,  0.06194903,  0.50741935,\n",
       "         0.92693412, -0.24303541, -0.03398333,  0.13802002,  0.23062733,\n",
       "         0.70542288, -0.07428401, -0.04538201, -0.77040851,  0.49151027,\n",
       "         0.63555121,  0.23024671,  0.29681587, -0.53885323, -0.63591826,\n",
       "         0.10603952,  0.66370583,  0.08674164,  0.1705761 ,  0.13450858,\n",
       "        -0.29535374, -0.2535823 ,  0.30171317,  0.91801316, -0.51928043,\n",
       "         0.05573035,  0.60232854, -0.08066569,  0.22208944,  0.52637005]),\n",
       " 'PBAT': array([-0.27037108, -1.03745222,  0.75120401,  0.4881154 ,  0.2158141 ,\n",
       "         0.04603674,  0.2224042 ,  0.70766896, -0.00185421, -0.45494667,\n",
       "        -0.61499506, -0.07214362, -0.72553641, -0.13553752,  0.50083578,\n",
       "         0.20335624, -0.50288469, -0.01216912, -0.0361317 , -0.52861947,\n",
       "         0.06238098,  0.00937653, -0.27109471, -0.34642345, -0.18912439,\n",
       "         0.19137836, -0.10731459,  0.49416122,  0.00776142, -0.09225983,\n",
       "         0.11762274, -0.44789517, -0.24436811, -0.34520608,  0.47759223,\n",
       "         0.91871291,  0.51741672,  0.45010015, -0.12624002, -0.14035606,\n",
       "        -1.03779662,  0.05315417,  0.16160712,  0.02020887, -0.54053348,\n",
       "         0.08848112, -0.32404551,  0.56260133,  0.49159291, -0.4731487 ,\n",
       "         0.37027231,  0.22690451,  0.67515808, -0.27369022, -0.46338817,\n",
       "        -0.53441405,  0.31184778, -0.46580428, -0.46263605,  0.32112563,\n",
       "        -0.27026993,  1.00333011,  0.43146634, -0.04776986, -0.22522877,\n",
       "        -0.77411467, -0.03899449,  0.43622792, -0.30117896,  0.31084293,\n",
       "         0.61924946, -0.14722526,  0.18325478,  0.59708327,  0.16244982,\n",
       "         0.42210263, -0.1262484 ,  0.45193008, -0.51567459,  0.25676012,\n",
       "         0.15139396,  0.43002281,  0.06477724, -0.60660303, -0.71465731,\n",
       "         0.2756297 ,  0.32162046,  0.45008856,  0.3771486 , -0.1733955 ,\n",
       "        -0.20269649, -0.29558221,  0.29644215,  0.46366465, -0.54227453,\n",
       "         0.08022756,  0.91746563,  0.06763332,  0.26068276, -0.20901358]),\n",
       " 'Ethylene vinyl acetate rubber': array([ 0.0126127 , -0.16358494,  0.60122111,  0.28763487,  0.31441233,\n",
       "         0.11838176, -0.18649333,  0.11285863, -0.40280841, -0.21731618,\n",
       "         0.04807297, -0.45119585, -0.00395245,  0.09329748,  0.13934282,\n",
       "         0.048335  ,  0.08103011, -0.30266509,  0.57665554, -0.13101582,\n",
       "         0.29165742,  0.22573752,  0.25267604, -0.37603637,  0.33906546,\n",
       "        -0.07665327,  0.15431017,  0.47720807, -0.13764879, -0.20852859,\n",
       "         0.13929152, -0.23475593,  0.28545582, -0.0803472 ,  0.23401503,\n",
       "         0.29539524,  0.14098704,  0.03580093, -0.22398629, -0.22176793,\n",
       "        -0.1662079 ,  0.21295582,  0.12372969,  0.12031709, -0.11238796,\n",
       "         0.29798883, -0.13101657,  0.37584256,  0.059675  , -0.28111277,\n",
       "         0.20787814,  0.05980551,  0.33622218, -0.22822534, -0.38847636,\n",
       "         0.21382237, -0.29846762,  0.02014   , -0.05700381,  0.07047245,\n",
       "        -0.28125969,  0.43766439, -0.07981035,  0.23110373,  0.37548745,\n",
       "        -0.32885772, -0.11727651,  0.21426919, -0.10752572,  0.06542069,\n",
       "         0.28671435, -0.11462714, -0.10489488,  0.26689179, -0.13653869,\n",
       "        -0.06741505, -0.14696171,  0.33803111, -0.06195671, -0.28866919,\n",
       "         0.31862114,  0.38423207,  0.12079304, -0.32177679, -0.10334824,\n",
       "         0.27047681, -0.31656015,  0.11668931, -0.15742108,  0.03964707,\n",
       "         0.2351013 , -0.06705422,  0.34156246,  0.00597388, -0.26275678,\n",
       "         0.19394791, -0.01755528, -0.0378565 , -0.23873133,  0.07662697]),\n",
       " 'PVC': array([-2.34990977e-02, -9.95150328e-01,  9.31419909e-01,  3.95470768e-01,\n",
       "         4.31740969e-01,  1.12206161e-01,  6.70686141e-02,  7.11129129e-01,\n",
       "        -1.28939345e-01, -2.35661671e-01, -4.52301294e-01, -2.50390202e-01,\n",
       "        -5.94160318e-01,  1.19834587e-01,  5.95097899e-01,  4.01697814e-01,\n",
       "        -7.46408761e-01, -1.51520446e-01,  2.70754516e-01, -5.84150851e-01,\n",
       "         1.33771911e-01,  6.05855621e-02, -1.81552451e-02, -5.08598745e-01,\n",
       "        -6.17515802e-01,  3.25692222e-02,  2.43623212e-01,  4.76433665e-01,\n",
       "         7.66602904e-03, -2.77557254e-01,  4.26316798e-01, -7.67861485e-01,\n",
       "        -3.06653440e-01, -4.45358083e-02,  7.05738604e-01,  8.14726949e-01,\n",
       "         5.67823708e-01,  2.01788336e-01, -2.09755570e-01, -9.42412671e-03,\n",
       "        -7.74168551e-01,  2.34259427e-01,  5.14891967e-02,  4.46808785e-01,\n",
       "        -3.06032032e-01, -1.55833080e-01, -5.86055696e-01,  6.64758086e-01,\n",
       "         6.23564839e-01, -5.31193435e-01, -2.54581142e-02,  1.88789040e-01,\n",
       "         6.40784979e-01, -1.58295929e-01, -6.22812212e-01, -3.12566429e-01,\n",
       "         2.61665612e-01, -1.85408011e-01, -2.92877048e-01,  3.22103947e-01,\n",
       "        -5.78957140e-01,  7.00920343e-01,  5.40859163e-01, -2.04419822e-01,\n",
       "         1.51439592e-01, -5.33613682e-01,  2.54436280e-03,  7.47649789e-01,\n",
       "        -2.54139632e-01,  5.93423620e-02,  4.89827663e-01,  7.73916468e-02,\n",
       "        -6.27429187e-02,  9.35456932e-01,  2.70615786e-01,  8.18336785e-01,\n",
       "        -3.50564569e-01,  8.50178897e-01, -5.12517929e-01,  4.48839217e-02,\n",
       "         1.63197264e-01,  4.40972507e-01,  5.37544899e-02, -7.78055131e-01,\n",
       "        -9.31159019e-01,  3.67652833e-01, -3.77886593e-02,  5.45712769e-01,\n",
       "         5.38755119e-01, -2.59879470e-01,  1.25165746e-01, -2.76026696e-01,\n",
       "         3.41818750e-01,  6.77063107e-01, -8.72024238e-01, -3.66159827e-02,\n",
       "         1.04765093e+00,  9.17599071e-03,  1.56904469e-04, -3.10247362e-01]),\n",
       " 'epoxy (Epon 815)': array([ 0.19486962, -0.79052815,  0.844484  ,  0.27617143,  0.40995649,\n",
       "         0.1320971 , -0.06522753,  0.40436174, -0.3337197 ,  0.0378511 ,\n",
       "        -0.21485704, -0.08178907, -0.37040245,  0.14069314,  0.56661916,\n",
       "         0.30242392, -0.51291546, -0.20803034,  0.25079509, -0.48006417,\n",
       "         0.28782615,  0.20452857,  0.24109589, -0.49924834, -0.3175773 ,\n",
       "        -0.04179585,  0.31402718,  0.61647119, -0.01398992, -0.37113996,\n",
       "         0.29873223, -0.68395883, -0.09601825,  0.02282742,  0.77669121,\n",
       "         0.47892746,  0.5624878 ,  0.20440186, -0.08496783, -0.02039814,\n",
       "        -0.61468187,  0.06306593, -0.00206932,  0.48339134, -0.11794569,\n",
       "        -0.07760695, -0.33490692,  0.65594791,  0.5383354 , -0.68149316,\n",
       "        -0.02440314,  0.11583857,  0.71464196,  0.03667928, -0.47398111,\n",
       "        -0.09647895,  0.07348178,  0.04775855, -0.17361415,  0.2121506 ,\n",
       "        -0.47278501,  0.51405416,  0.56035393, -0.08854511,  0.14820978,\n",
       "        -0.43107629,  0.10610529,  0.9009611 , -0.1985293 ,  0.11811045,\n",
       "         0.6032925 ,  0.04210274, -0.13758423,  0.66876957,  0.24242307,\n",
       "         0.66920362, -0.38121266,  0.86069978, -0.36587512, -0.01861002,\n",
       "         0.28316153,  0.59850217,  0.01948606, -0.74118865, -0.82858403,\n",
       "         0.22558275, -0.21694179,  0.41261744,  0.4074142 , -0.15694192,\n",
       "         0.13012629, -0.36871484,  0.42429313,  0.51383808, -0.84983504,\n",
       "        -0.16664969,  0.76157141, -0.06482252, -0.16332468, -0.10043453]),\n",
       " 'epoxy (LY564)': array([ 0.19695893, -0.77540198,  0.85384923,  0.3029446 ,  0.41520562,\n",
       "         0.13640959, -0.02252227,  0.43036237, -0.31101276,  0.03065339,\n",
       "        -0.20388975, -0.0381903 , -0.39064317,  0.14342172,  0.55306196,\n",
       "         0.3075912 , -0.51311363, -0.24043296,  0.25652346, -0.44868869,\n",
       "         0.30000314,  0.20485145,  0.23389221, -0.49928445, -0.31615409,\n",
       "        -0.05240827,  0.32734827,  0.64450845,  0.01101537, -0.3703331 ,\n",
       "         0.31407331, -0.66564398, -0.12395467,  0.03088081,  0.78584254,\n",
       "         0.43450437,  0.57625417,  0.18980274, -0.09917498,  0.01476629,\n",
       "        -0.59655729,  0.07102522,  0.0217264 ,  0.50422268, -0.12641558,\n",
       "        -0.06470817, -0.32342435,  0.66154321,  0.53828037, -0.68912155,\n",
       "         0.00396107,  0.13551233,  0.71925741,  0.01008297, -0.45641665,\n",
       "        -0.11693965,  0.05908646,  0.02805869, -0.17747941,  0.22866675,\n",
       "        -0.42732509,  0.4905716 ,  0.54789068, -0.07270325,  0.1450656 ,\n",
       "        -0.45045158,  0.07082679,  0.86646804, -0.16334755,  0.14435218,\n",
       "         0.63020197,  0.03993487, -0.16700714,  0.64255268,  0.23716655,\n",
       "         0.65810538, -0.36120532,  0.83379153, -0.35512511, -0.00968442,\n",
       "         0.30431882,  0.57974675,  0.02993787, -0.74051318, -0.80182178,\n",
       "         0.24519551, -0.20392074,  0.3762638 ,  0.3440431 , -0.16118411,\n",
       "         0.12609697, -0.36494044,  0.43519517,  0.53433657, -0.81402081,\n",
       "        -0.15504349,  0.71142671, -0.04716215, -0.17460601, -0.06954209]),\n",
       " 'PMMA': array([ 0.08409786, -1.34310162,  1.08238745,  0.57379729,  0.19837242,\n",
       "         0.59618038,  0.40958419,  1.22768331, -0.37217367,  0.05129286,\n",
       "        -0.78203648,  0.054911  , -0.42623147, -0.15289377,  0.61120194,\n",
       "         0.56330025, -0.67639786,  0.12122834, -0.07311521, -1.19032323,\n",
       "         0.02515734,  0.09118659, -0.38248622, -0.52933353, -0.25348786,\n",
       "         0.09978329, -0.07627306,  0.84189123,  0.0773468 , -0.31519681,\n",
       "         0.42976469, -0.98090327, -0.23375063, -0.17306112,  1.08041561,\n",
       "         1.30553854,  1.01923335,  0.44683778, -0.54316866,  0.11474249,\n",
       "        -1.13211596, -0.26444826,  0.14125118,  0.3579298 , -0.22838034,\n",
       "        -0.03779013, -0.07227378,  0.64666706,  0.9589048 , -0.84022033,\n",
       "        -0.12785941,  0.05231226,  0.69105095,  0.08742838, -0.72035068,\n",
       "        -0.52760494,  0.5235762 , -0.24667314, -0.23308511,  0.12465575,\n",
       "        -0.67597806,  0.81621701,  0.88283634, -0.5425958 , -0.24037258,\n",
       "        -1.34038985,  0.22248664,  0.69176495, -0.58223724,  0.69051248,\n",
       "         0.81047535, -0.34130335,  0.41742736,  0.82256997, -0.07817888,\n",
       "         1.1397835 , -1.00337327,  0.75172764, -1.04832399,  0.5118345 ,\n",
       "         0.49870262,  0.84557629,  0.47751784, -0.83890313, -1.14830911,\n",
       "        -0.05762032,  0.17683068,  0.33834666,  0.85354447, -0.1020236 ,\n",
       "        -0.64299607, -0.42615148,  0.58002371,  0.76744384, -1.00077951,\n",
       "         0.26508731,  1.45275545, -0.11087277,  0.3693983 , -0.29238734]),\n",
       " 'PLA': array([ 1.16986269e-03, -1.53370047e+00,  1.08682454e+00,  5.06380737e-01,\n",
       "         3.31775755e-01,  3.18481863e-01, -2.27200359e-01,  7.24215746e-01,\n",
       "        -3.16265315e-01, -3.84383321e-01, -7.45450914e-01, -4.42174613e-01,\n",
       "        -5.61439335e-01, -2.66374201e-01,  7.34681666e-01,  2.10262805e-01,\n",
       "        -4.91371900e-01,  2.70003051e-01, -8.00230950e-02, -1.15465033e+00,\n",
       "         9.15606394e-02,  4.48965430e-02, -2.26589561e-01, -5.16218901e-01,\n",
       "        -1.68450147e-01,  2.61199415e-01, -1.49284318e-01,  5.73947370e-01,\n",
       "        -2.22872242e-01, -4.00813192e-01,  1.80235803e-01, -9.17192519e-01,\n",
       "        -3.71839821e-01, -4.37889755e-01,  7.68160880e-01,  1.69002056e+00,\n",
       "         7.08759904e-01,  6.97656333e-01, -1.21324956e-01, -2.15795547e-01,\n",
       "        -1.32947814e+00, -1.48046541e-03,  8.99021104e-02,  1.29456922e-01,\n",
       "        -5.41580439e-01,  4.26002853e-02, -4.41131473e-01,  6.30890369e-01,\n",
       "         8.13087463e-01, -6.41017914e-01,  1.41452774e-01,  1.62643678e-02,\n",
       "         7.82471657e-01,  1.09026738e-01, -8.20348144e-01, -5.19440889e-01,\n",
       "         6.52036190e-01, -9.66450050e-02, -4.91723627e-01,  2.44297072e-01,\n",
       "        -8.38110387e-01,  1.20698929e+00,  8.98593247e-01, -2.58019894e-01,\n",
       "        -4.51055951e-02, -9.41985011e-01,  3.67482364e-01,  7.45675981e-01,\n",
       "        -4.05229896e-01,  1.56092376e-01,  7.49252558e-01, -1.80811673e-01,\n",
       "         1.79282635e-01,  7.76001692e-01,  7.09162429e-02,  6.23475850e-01,\n",
       "        -3.66837472e-01,  8.57621908e-01, -9.49290872e-01,  3.19190979e-01,\n",
       "         1.69394363e-03,  6.52038813e-01,  1.25211641e-01, -6.88845038e-01,\n",
       "        -9.89661396e-01,  1.29928231e-01,  3.23693454e-01,  8.57855141e-01,\n",
       "         1.05733728e+00,  2.84243841e-02, -2.67742366e-01, -3.23441386e-01,\n",
       "         2.40370542e-01,  4.98534679e-01, -1.07574463e+00, -4.47563967e-03,\n",
       "         1.73931634e+00,  4.60571572e-02,  4.51182812e-01, -4.88758415e-01]),\n",
       " 'SAN': array([-0.17463267, -0.78794569,  0.67721456,  0.4346478 ,  0.25359446,\n",
       "         0.03000822, -0.02392643,  0.32746333, -0.00817377, -0.27134335,\n",
       "        -0.36749256,  0.06160766, -0.64931852, -0.19859512,  0.54138052,\n",
       "         0.00566436, -0.3394998 , -0.24743633, -0.08332566, -0.39073077,\n",
       "         0.18550028,  0.08947865, -0.20756702, -0.45947823, -0.10479376,\n",
       "         0.11603462,  0.05128488,  0.71830654,  0.02025542, -0.07854137,\n",
       "         0.20765296, -0.52374327, -0.14695521, -0.43083942,  0.50534976,\n",
       "         0.43515849,  0.50888169,  0.42271692, -0.21713802, -0.05345669,\n",
       "        -0.88036203,  0.11700143,  0.23502433,  0.20791505, -0.28490913,\n",
       "         0.03679097, -0.08979148,  0.55673927,  0.46027523, -0.37417427,\n",
       "         0.39880913,  0.25240189,  0.61368579, -0.0222796 , -0.28954038,\n",
       "        -0.34761116,  0.25344816, -0.17658716, -0.44441652,  0.3208068 ,\n",
       "        -0.22288361,  0.56753916,  0.49263823, -0.01828366, -0.04655126,\n",
       "        -0.49414369,  0.02510278,  0.59651423, -0.10204972,  0.07053284,\n",
       "         0.54878324, -0.04078622,  0.07576861,  0.34196544,  0.17125866,\n",
       "         0.30499583,  0.0131729 ,  0.32474446, -0.52585334,  0.05300412,\n",
       "         0.30929506,  0.32809809,  0.0106751 , -0.58619064, -0.54832321,\n",
       "         0.22646469,  0.20451416,  0.3158567 ,  0.18461302,  0.00622394,\n",
       "        -0.01528285, -0.17273387,  0.21198837,  0.44006193, -0.51934057,\n",
       "        -0.08779763,  0.63391244, -0.08614025, -0.03019975,  0.01969482]),\n",
       " 'phenoxy': array([-0.12387145, -0.35141912,  0.54733926,  0.26112527,  0.21436836,\n",
       "         0.01806981, -0.17645349,  0.07849486, -0.18338184, -0.29358247,\n",
       "        -0.04202179, -0.16302407, -0.27076751, -0.12045487,  0.30533755,\n",
       "        -0.00949381, -0.01037293, -0.26860103,  0.21706715, -0.17322335,\n",
       "         0.16941084,  0.17317998,  0.07419836, -0.35424691,  0.15943147,\n",
       "         0.02658118,  0.08736687,  0.50752038, -0.02051166, -0.1450341 ,\n",
       "         0.1172138 , -0.22500095,  0.12106503, -0.21176393,  0.23163897,\n",
       "         0.28715849,  0.23614925,  0.27091116, -0.11345253, -0.184563  ,\n",
       "        -0.35308662,  0.1857394 ,  0.16825958,  0.04952639, -0.20040382,\n",
       "         0.18699187, -0.12679128,  0.39735097,  0.15856379, -0.28233519,\n",
       "         0.32500693,  0.20889819,  0.38667616, -0.05320951, -0.25155017,\n",
       "        -0.03778164, -0.09425785, -0.02102615, -0.20265354,  0.20265348,\n",
       "        -0.23280297,  0.48661548,  0.09751918,  0.14314693,  0.21435608,\n",
       "        -0.27505001, -0.09513904,  0.28073466, -0.01365438,  0.00127774,\n",
       "         0.38521206, -0.08875313, -0.07065735,  0.21644479, -0.01382178,\n",
       "        -0.0713939 ,  0.02937427,  0.2397031 , -0.18191652, -0.17036198,\n",
       "         0.1823487 ,  0.2184815 ,  0.05205167, -0.35575143, -0.14513882,\n",
       "         0.25185302, -0.0836575 ,  0.15306133, -0.02303715,  0.01116051,\n",
       "         0.15657552, -0.06788766,  0.19762258,  0.05398314, -0.26050442,\n",
       "        -0.00458302,  0.28248695, -0.11203405, -0.08495325,  0.00358033]),\n",
       " 'epoxy (Epon 862': array([ 0.19486962, -0.79052815,  0.844484  ,  0.27617143,  0.40995649,\n",
       "         0.1320971 , -0.06522753,  0.40436174, -0.3337197 ,  0.0378511 ,\n",
       "        -0.21485704, -0.08178907, -0.37040245,  0.14069314,  0.56661916,\n",
       "         0.30242392, -0.51291546, -0.20803034,  0.25079509, -0.48006417,\n",
       "         0.28782615,  0.20452857,  0.24109589, -0.49924834, -0.3175773 ,\n",
       "        -0.04179585,  0.31402718,  0.61647119, -0.01398992, -0.37113996,\n",
       "         0.29873223, -0.68395883, -0.09601825,  0.02282742,  0.77669121,\n",
       "         0.47892746,  0.5624878 ,  0.20440186, -0.08496783, -0.02039814,\n",
       "        -0.61468187,  0.06306593, -0.00206932,  0.48339134, -0.11794569,\n",
       "        -0.07760695, -0.33490692,  0.65594791,  0.5383354 , -0.68149316,\n",
       "        -0.02440314,  0.11583857,  0.71464196,  0.03667928, -0.47398111,\n",
       "        -0.09647895,  0.07348178,  0.04775855, -0.17361415,  0.2121506 ,\n",
       "        -0.47278501,  0.51405416,  0.56035393, -0.08854511,  0.14820978,\n",
       "        -0.43107629,  0.10610529,  0.9009611 , -0.1985293 ,  0.11811045,\n",
       "         0.6032925 ,  0.04210274, -0.13758423,  0.66876957,  0.24242307,\n",
       "         0.66920362, -0.38121266,  0.86069978, -0.36587512, -0.01861002,\n",
       "         0.28316153,  0.59850217,  0.01948606, -0.74118865, -0.82858403,\n",
       "         0.22558275, -0.21694179,  0.41261744,  0.4074142 , -0.15694192,\n",
       "         0.13012629, -0.36871484,  0.42429313,  0.51383808, -0.84983504,\n",
       "        -0.16664969,  0.76157141, -0.06482252, -0.16332468, -0.10043453]),\n",
       " 'FPEOF': array([-0.14330278, -0.51523298,  0.58240235,  0.30602902,  0.18132956,\n",
       "         0.01059383, -0.01698247,  0.29280108, -0.03858081, -0.39767307,\n",
       "        -0.23385052, -0.07960095, -0.50162107, -0.14860281,  0.38999981,\n",
       "         0.1365124 , -0.21328564, -0.22784597,  0.17224184, -0.25835717,\n",
       "         0.08544441,  0.02863346, -0.05874395, -0.34597152, -0.09545366,\n",
       "         0.08798338,  0.08924782,  0.38090539,  0.06973886, -0.10766481,\n",
       "         0.14394768, -0.34335378, -0.14817657, -0.20380005,  0.2987799 ,\n",
       "         0.48512325,  0.37884158,  0.34046197, -0.08550785, -0.13204379,\n",
       "        -0.53305793,  0.170656  ,  0.08095267,  0.11573261, -0.28918478,\n",
       "         0.07023365, -0.33259931,  0.39882362,  0.32618436, -0.31872898,\n",
       "         0.30908144,  0.28691339,  0.46254066, -0.11266769, -0.35396203,\n",
       "        -0.26220655,  0.10566179, -0.2144399 , -0.26807064,  0.30251268,\n",
       "        -0.26826939,  0.56046194,  0.19034198, -0.0542518 ,  0.10153177,\n",
       "        -0.39529255, -0.1246589 ,  0.24638823, -0.02141082, -0.01687186,\n",
       "         0.45319533, -0.06318462, -0.1260123 ,  0.39105207,  0.11205884,\n",
       "         0.12301221,  0.00916039,  0.23945466, -0.32154575, -0.04202454,\n",
       "         0.08123019,  0.13488485,  0.0673233 , -0.44225478, -0.36410859,\n",
       "         0.35269085,  0.13281147,  0.25020775,  0.17474923, -0.05721191,\n",
       "         0.14229544, -0.10080236,  0.18112099,  0.26660433, -0.31240103,\n",
       "         0.09494987,  0.56104755, -0.05579145,  0.1696189 , -0.07850449]),\n",
       " 'natural rubber': array([-0.07391032, -0.19315517,  0.68783784,  0.47905323,  0.34626812,\n",
       "         0.04717828, -0.08125749,  0.25260206, -0.24520761, -0.31663314,\n",
       "        -0.00764917, -0.28713775, -0.26169837,  0.05828892,  0.1902814 ,\n",
       "         0.00735705,  0.0797977 , -0.43195474,  0.6040398 , -0.0212128 ,\n",
       "         0.36636083,  0.27028684,  0.23287312, -0.38486445,  0.24758539,\n",
       "        -0.12013954,  0.26627438,  0.59842934,  0.10165233, -0.18575441,\n",
       "         0.20117828, -0.14872604,  0.1485191 , -0.14218805,  0.2842389 ,\n",
       "         0.06578241,  0.07896407,  0.08549218, -0.25692274, -0.07185994,\n",
       "        -0.2538798 ,  0.35749801,  0.19723554,  0.14027148, -0.18114924,\n",
       "         0.3416281 , -0.10907917,  0.4551039 , -0.02813638, -0.29366225,\n",
       "         0.4519645 ,  0.22121506,  0.48827295, -0.41175528, -0.28485849,\n",
       "        -0.01573897, -0.38927785, -0.15591776, -0.23953412,  0.18606223,\n",
       "        -0.08573448,  0.45124099, -0.14337806,  0.38234712,  0.33413868,\n",
       "        -0.4344544 , -0.32039708,  0.1061    ,  0.13440835,  0.06517679,\n",
       "         0.49017125, -0.13711481, -0.23484425,  0.19396664, -0.04092683,\n",
       "        -0.19161253,  0.14967639,  0.2384362 , -0.01524402, -0.27781034,\n",
       "         0.33804633,  0.16176877,  0.06178065, -0.30999552,  0.06244488,\n",
       "         0.42402875, -0.17364349,  0.08616795, -0.48255087,  0.05817407,\n",
       "         0.21957027, -0.03723412,  0.36578438,  0.03761001, -0.06815585,\n",
       "         0.17981191, -0.19060921, -0.04106572, -0.33068474,  0.19475967]),\n",
       " 'PP': array([-0.0722612 , -0.83415532,  0.71892405,  0.64246172,  0.28446364,\n",
       "         0.05737009,  0.17340484,  0.41833138, -0.03527312, -0.27134657,\n",
       "        -0.34285262,  0.3109023 , -0.86716855, -0.23162155,  0.50480515,\n",
       "         0.04851529, -0.29580611, -0.4447802 , -0.19862524, -0.32976317,\n",
       "         0.40859446,  0.10359499, -0.15510094, -0.4635193 ,  0.01944185,\n",
       "         0.11672062,  0.1539343 ,  0.98182362,  0.11019535, -0.14385007,\n",
       "         0.15620676, -0.40806803, -0.20720479, -0.48900563,  0.67501158,\n",
       "         0.19385144,  0.66165137,  0.42624629, -0.27088401,  0.09210663,\n",
       "        -1.05108535,  0.04223275,  0.34933379,  0.3094492 , -0.23442215,\n",
       "         0.16533889,  0.11295691,  0.61927384,  0.43800616, -0.6095401 ,\n",
       "         0.63112628,  0.35542199,  0.82395887, -0.17532657, -0.1533484 ,\n",
       "        -0.52770108,  0.1268063 , -0.24837144, -0.52465385,  0.47977215,\n",
       "        -0.01702974,  0.48317367,  0.61068356,  0.13220575, -0.12672395,\n",
       "        -0.70682937, -0.07799377,  0.60962039, -0.0573786 ,  0.33184457,\n",
       "         0.84915972, -0.04165808,  0.03136736,  0.21254359,  0.1305864 ,\n",
       "         0.22323444,  0.23115399,  0.2563017 , -0.43393579,  0.2115739 ,\n",
       "         0.56574547,  0.45021248,  0.02128978, -0.61101347, -0.48173103,\n",
       "         0.27696049,  0.25534007,  0.09196772, -0.12160524,  0.06848088,\n",
       "        -0.10537148, -0.25912637,  0.37890926,  0.6263656 , -0.44394723,\n",
       "        -0.04510486,  0.40996939, -0.04317724, -0.14704183,  0.23200367]),\n",
       " 'rigid PU foam': array([-0.16127531, -0.33081177,  0.47423427,  0.30233472,  0.23961915,\n",
       "         0.03429371, -0.06080245,  0.20131264, -0.12483693, -0.33037583,\n",
       "        -0.13191362, -0.25191622, -0.34719089, -0.0565573 ,  0.26567676,\n",
       "         0.06955247, -0.10963029, -0.27090528,  0.29405262, -0.15548033,\n",
       "         0.16117495,  0.04673549, -0.01513126, -0.30017254,  0.00367842,\n",
       "         0.07249731,  0.07080385,  0.3680396 , -0.01707963, -0.09133265,\n",
       "         0.15601893, -0.23589955, -0.00141771, -0.15707066,  0.20063736,\n",
       "         0.36851464,  0.21890853,  0.17263871, -0.14170002, -0.11218095,\n",
       "        -0.40449315,  0.2385625 ,  0.0942555 ,  0.06200027, -0.21160624,\n",
       "         0.17902851, -0.26272922,  0.32782223,  0.21221485, -0.28475423,\n",
       "         0.27645365,  0.23240465,  0.41828009, -0.20486684, -0.32707167,\n",
       "        -0.08955133, -0.03897781, -0.14904033, -0.20188131,  0.22639089,\n",
       "        -0.22098213,  0.46001905,  0.06753916,  0.08881314,  0.22989595,\n",
       "        -0.33906937, -0.14185729,  0.19961436, -0.09030229, -0.02021001,\n",
       "         0.29063337, -0.05522188, -0.06322101,  0.33477509,  0.02082936,\n",
       "         0.0317728 ,  0.035329  ,  0.26615062, -0.1748163 , -0.12821397,\n",
       "         0.14785535,  0.16030403,  0.03129839, -0.32754838, -0.23707259,\n",
       "         0.32374829,  0.00763898,  0.20551094,  0.01752757, -0.04487338,\n",
       "         0.18211207, -0.06923925,  0.24425601,  0.20281901, -0.23974876,\n",
       "         0.15801919,  0.31633101, -0.03975197,  0.04370797, -0.01924962]),\n",
       " 'PC-SAN': array([ 0.02655836, -0.80147696,  0.70797354,  0.54340434,  0.15105311,\n",
       "         0.13773859,  0.25139532,  0.43301025,  0.10349395, -0.14163134,\n",
       "        -0.41729759,  0.45179152, -0.78696483, -0.31326113,  0.64839324,\n",
       "         0.13110683, -0.36675192, -0.31422686, -0.2119129 , -0.43424505,\n",
       "         0.18447055,  0.09018873, -0.29037962, -0.51026817, -0.15419249,\n",
       "         0.08539317,  0.09331511,  0.90542895,  0.20564354, -0.07158963,\n",
       "         0.31872869, -0.59440747, -0.26981729, -0.44051565,  0.72562557,\n",
       "         0.29094411,  0.72996399,  0.47740862, -0.31632513,  0.17431733,\n",
       "        -0.86980593, -0.03576112,  0.15792453,  0.34723156, -0.16419955,\n",
       "        -0.13138519,  0.05016751,  0.59423253,  0.66088256, -0.50756533,\n",
       "         0.29278648,  0.30176786,  0.67878127,  0.10684152, -0.25578797,\n",
       "        -0.52829383,  0.39271973, -0.21992242, -0.44463348,  0.40088974,\n",
       "        -0.13105283,  0.28844358,  0.5869796 , -0.18970843, -0.15942237,\n",
       "        -0.744866  , -0.00389016,  0.51910281, -0.02005034,  0.28897609,\n",
       "         0.73785868, -0.14191081,  0.02089264,  0.23999273,  0.20094299,\n",
       "         0.50520936, -0.03055556,  0.13968123, -0.64813092,  0.27225719,\n",
       "         0.47242314,  0.2791724 ,  0.15374548, -0.56252193, -0.59212074,\n",
       "         0.16625211,  0.43410999,  0.20129917,  0.17759456,  0.07036626,\n",
       "        -0.1553183 , -0.21315809,  0.25685077,  0.67903754, -0.5193105 ,\n",
       "        -0.01603364,  0.61812049, -0.08340297,  0.09594484,  0.27303244]),\n",
       " 'polyamide': array([-3.98797356e-02, -5.49020708e-01,  6.61116660e-01,  3.03143293e-01,\n",
       "         2.05274284e-01,  8.54429156e-02,  1.26285538e-01,  4.39657301e-01,\n",
       "        -1.52826026e-01, -2.04777762e-01, -2.39832878e-01,  4.38155932e-03,\n",
       "        -3.19315135e-01, -4.15298454e-02,  3.71971011e-01,  2.14575469e-01,\n",
       "        -3.22290003e-01, -1.35887012e-01,  1.17443390e-01, -3.52750063e-01,\n",
       "         1.45127594e-01,  1.32923603e-01, -4.81608760e-04, -4.18428808e-01,\n",
       "        -8.68041068e-02,  2.27306057e-02,  1.53214812e-01,  4.87439901e-01,\n",
       "         2.70069204e-02, -1.17408171e-01,  2.12857217e-01, -4.34251070e-01,\n",
       "        -7.77864158e-02, -2.09406927e-01,  4.60519552e-01,  4.47206587e-01,\n",
       "         3.62813532e-01,  2.84622192e-01, -1.14026792e-01, -1.17156491e-01,\n",
       "        -4.82813209e-01,  8.39529932e-02,  1.13508902e-01,  2.17309296e-01,\n",
       "        -2.36845538e-01,  4.07067947e-02, -1.93823785e-01,  4.83777314e-01,\n",
       "         3.32556039e-01, -3.74855220e-01,  2.23912537e-01,  1.36724383e-01,\n",
       "         4.28726763e-01, -1.22708000e-01, -3.22281301e-01, -1.82914391e-01,\n",
       "         5.40275276e-02, -1.19690999e-01, -2.12840796e-01,  2.10113049e-01,\n",
       "        -2.19533548e-01,  5.61032712e-01,  2.81257898e-01, -3.49709280e-02,\n",
       "        -3.59036140e-02, -4.41448897e-01,  1.29046990e-02,  4.28617120e-01,\n",
       "        -1.23500586e-01,  2.16750279e-01,  4.92819250e-01, -5.15033044e-02,\n",
       "        -4.32719942e-03,  4.07912850e-01,  7.00047761e-02,  3.45308065e-01,\n",
       "        -2.06320226e-01,  3.80096734e-01, -3.51053715e-01,  2.33630333e-02,\n",
       "         2.05283925e-01,  3.74084055e-01,  1.46688372e-01, -4.75187391e-01,\n",
       "        -4.41119462e-01,  1.79794878e-01,  2.96680499e-02,  1.90697119e-01,\n",
       "         1.94236681e-01, -9.94126648e-02, -4.08587381e-02, -1.87996656e-01,\n",
       "         2.46210948e-01,  2.66995192e-01, -4.01054621e-01, -4.11948375e-02,\n",
       "         5.44938982e-01, -1.73008479e-02, -3.09540937e-03, -8.83029625e-02]),\n",
       " 'waterborne UV-curable polyurethane': array([-0.09452977, -0.11241231,  0.41457659,  0.158633  ,  0.19491603,\n",
       "         0.00826599,  0.00747527,  0.09487312, -0.21192595, -0.25512527,\n",
       "         0.04176665, -0.14859427, -0.10343409, -0.04117769,  0.1576116 ,\n",
       "         0.09273838, -0.00467038, -0.25186193,  0.27053181, -0.05261446,\n",
       "         0.16402483,  0.17243144,  0.11115101, -0.30956163,  0.19683623,\n",
       "         0.02548636,  0.09674891,  0.3915619 , -0.0448859 , -0.08446467,\n",
       "         0.09755589, -0.09576675,  0.19028301, -0.09855104,  0.15038483,\n",
       "         0.15510928,  0.14746868,  0.15970991, -0.08482827, -0.20264327,\n",
       "        -0.10552502,  0.137103  ,  0.12005249,  0.00995199, -0.14148314,\n",
       "         0.21850133, -0.11265086,  0.31596563,  0.0631333 , -0.28304752,\n",
       "         0.25505846,  0.17443092,  0.25663318, -0.15550463, -0.15909387,\n",
       "         0.10284877, -0.19779213, -0.01315379, -0.06828103,  0.13404493,\n",
       "        -0.12306699,  0.39406032, -0.04980311,  0.1697653 ,  0.19157975,\n",
       "        -0.23519452, -0.11063126,  0.17711687, -0.10564139,  0.13785239,\n",
       "         0.26521614, -0.09442819, -0.00931198,  0.20404386, -0.09404102,\n",
       "        -0.07171164, -0.04604659,  0.1913724 , -0.02385838, -0.17957798,\n",
       "         0.15762373,  0.27205547,  0.08841819, -0.21930094, -0.05588348,\n",
       "         0.21776845, -0.13597076, -0.00477879, -0.10716708, -0.0640767 ,\n",
       "         0.12244995, -0.04696337,  0.23755196, -0.04088602, -0.14506774,\n",
       "         0.09510643,  0.12233829, -0.05570161, -0.04905565,  0.03756767]),\n",
       " 'polyamide-6,6': array([-3.98797356e-02, -5.49020708e-01,  6.61116660e-01,  3.03143293e-01,\n",
       "         2.05274284e-01,  8.54429156e-02,  1.26285538e-01,  4.39657301e-01,\n",
       "        -1.52826026e-01, -2.04777762e-01, -2.39832878e-01,  4.38155932e-03,\n",
       "        -3.19315135e-01, -4.15298454e-02,  3.71971011e-01,  2.14575469e-01,\n",
       "        -3.22290003e-01, -1.35887012e-01,  1.17443390e-01, -3.52750063e-01,\n",
       "         1.45127594e-01,  1.32923603e-01, -4.81608760e-04, -4.18428808e-01,\n",
       "        -8.68041068e-02,  2.27306057e-02,  1.53214812e-01,  4.87439901e-01,\n",
       "         2.70069204e-02, -1.17408171e-01,  2.12857217e-01, -4.34251070e-01,\n",
       "        -7.77864158e-02, -2.09406927e-01,  4.60519552e-01,  4.47206587e-01,\n",
       "         3.62813532e-01,  2.84622192e-01, -1.14026792e-01, -1.17156491e-01,\n",
       "        -4.82813209e-01,  8.39529932e-02,  1.13508902e-01,  2.17309296e-01,\n",
       "        -2.36845538e-01,  4.07067947e-02, -1.93823785e-01,  4.83777314e-01,\n",
       "         3.32556039e-01, -3.74855220e-01,  2.23912537e-01,  1.36724383e-01,\n",
       "         4.28726763e-01, -1.22708000e-01, -3.22281301e-01, -1.82914391e-01,\n",
       "         5.40275276e-02, -1.19690999e-01, -2.12840796e-01,  2.10113049e-01,\n",
       "        -2.19533548e-01,  5.61032712e-01,  2.81257898e-01, -3.49709280e-02,\n",
       "        -3.59036140e-02, -4.41448897e-01,  1.29046990e-02,  4.28617120e-01,\n",
       "        -1.23500586e-01,  2.16750279e-01,  4.92819250e-01, -5.15033044e-02,\n",
       "        -4.32719942e-03,  4.07912850e-01,  7.00047761e-02,  3.45308065e-01,\n",
       "        -2.06320226e-01,  3.80096734e-01, -3.51053715e-01,  2.33630333e-02,\n",
       "         2.05283925e-01,  3.74084055e-01,  1.46688372e-01, -4.75187391e-01,\n",
       "        -4.41119462e-01,  1.79794878e-01,  2.96680499e-02,  1.90697119e-01,\n",
       "         1.94236681e-01, -9.94126648e-02, -4.08587381e-02, -1.87996656e-01,\n",
       "         2.46210948e-01,  2.66995192e-01, -4.01054621e-01, -4.11948375e-02,\n",
       "         5.44938982e-01, -1.73008479e-02, -3.09540937e-03, -8.83029625e-02]),\n",
       " 'polyamide-6': array([-3.98797356e-02, -5.49020708e-01,  6.61116660e-01,  3.03143293e-01,\n",
       "         2.05274284e-01,  8.54429156e-02,  1.26285538e-01,  4.39657301e-01,\n",
       "        -1.52826026e-01, -2.04777762e-01, -2.39832878e-01,  4.38155932e-03,\n",
       "        -3.19315135e-01, -4.15298454e-02,  3.71971011e-01,  2.14575469e-01,\n",
       "        -3.22290003e-01, -1.35887012e-01,  1.17443390e-01, -3.52750063e-01,\n",
       "         1.45127594e-01,  1.32923603e-01, -4.81608760e-04, -4.18428808e-01,\n",
       "        -8.68041068e-02,  2.27306057e-02,  1.53214812e-01,  4.87439901e-01,\n",
       "         2.70069204e-02, -1.17408171e-01,  2.12857217e-01, -4.34251070e-01,\n",
       "        -7.77864158e-02, -2.09406927e-01,  4.60519552e-01,  4.47206587e-01,\n",
       "         3.62813532e-01,  2.84622192e-01, -1.14026792e-01, -1.17156491e-01,\n",
       "        -4.82813209e-01,  8.39529932e-02,  1.13508902e-01,  2.17309296e-01,\n",
       "        -2.36845538e-01,  4.07067947e-02, -1.93823785e-01,  4.83777314e-01,\n",
       "         3.32556039e-01, -3.74855220e-01,  2.23912537e-01,  1.36724383e-01,\n",
       "         4.28726763e-01, -1.22708000e-01, -3.22281301e-01, -1.82914391e-01,\n",
       "         5.40275276e-02, -1.19690999e-01, -2.12840796e-01,  2.10113049e-01,\n",
       "        -2.19533548e-01,  5.61032712e-01,  2.81257898e-01, -3.49709280e-02,\n",
       "        -3.59036140e-02, -4.41448897e-01,  1.29046990e-02,  4.28617120e-01,\n",
       "        -1.23500586e-01,  2.16750279e-01,  4.92819250e-01, -5.15033044e-02,\n",
       "        -4.32719942e-03,  4.07912850e-01,  7.00047761e-02,  3.45308065e-01,\n",
       "        -2.06320226e-01,  3.80096734e-01, -3.51053715e-01,  2.33630333e-02,\n",
       "         2.05283925e-01,  3.74084055e-01,  1.46688372e-01, -4.75187391e-01,\n",
       "        -4.41119462e-01,  1.79794878e-01,  2.96680499e-02,  1.90697119e-01,\n",
       "         1.94236681e-01, -9.94126648e-02, -4.08587381e-02, -1.87996656e-01,\n",
       "         2.46210948e-01,  2.66995192e-01, -4.01054621e-01, -4.11948375e-02,\n",
       "         5.44938982e-01, -1.73008479e-02, -3.09540937e-03, -8.83029625e-02]),\n",
       " 'polyimide': array([-0.01648035, -0.12909463,  0.41511607,  0.26346931,  0.24011976,\n",
       "         0.08285515, -0.01530463,  0.16570254, -0.25592327, -0.14302881,\n",
       "        -0.00857787, -0.22088602, -0.10200495,  0.06001383,  0.08326064,\n",
       "         0.05554174,  0.00822869, -0.28148413,  0.37840807, -0.09118752,\n",
       "         0.25077623,  0.15082836,  0.13369437, -0.2708782 ,  0.19576037,\n",
       "        -0.01859793,  0.10861842,  0.41968337, -0.03339879, -0.14491488,\n",
       "         0.11743258, -0.12381814,  0.17511347, -0.07974751,  0.21909113,\n",
       "         0.13472567,  0.15875292,  0.0431214 , -0.17657712, -0.07126192,\n",
       "        -0.20993605,  0.14282227,  0.10770608,  0.07952008, -0.07322316,\n",
       "         0.25374126, -0.0549474 ,  0.30176464,  0.08605412, -0.30457184,\n",
       "         0.18133508,  0.10644301,  0.32235336, -0.22201648, -0.2265843 ,\n",
       "         0.06146887, -0.23022303, -0.04197759, -0.07465599,  0.09377713,\n",
       "        -0.10003738,  0.2928029 , -0.0236004 ,  0.18057024,  0.21701787,\n",
       "        -0.33161044, -0.12730734,  0.17913017, -0.11612047,  0.14627177,\n",
       "         0.26377517, -0.09150587, -0.01771232,  0.18346182, -0.08647917,\n",
       "         0.01723221, -0.07084681,  0.24732496, -0.02045745, -0.13014519,\n",
       "         0.29082388,  0.28434727,  0.09151127, -0.23631449, -0.09275886,\n",
       "         0.20228469, -0.15087862,  0.01691424, -0.17472455,  0.01077997,\n",
       "         0.1157051 , -0.08820255,  0.31276628,  0.08854213, -0.15391004,\n",
       "         0.17315631, -0.02983242, -0.01683068, -0.16445151,  0.08335079]),\n",
       " 'polybenzimidazole': array([-0.06585339, -0.0514365 ,  0.21651597,  0.09865781,  0.08761643,\n",
       "        -0.00158665, -0.03141023,  0.00704137, -0.07144462, -0.15221855,\n",
       "         0.0430028 , -0.0272002 , -0.07584222, -0.07379951,  0.09855887,\n",
       "         0.00724422,  0.04937929, -0.15283749,  0.11065166,  0.00413311,\n",
       "         0.07699807,  0.09799191,  0.03915571, -0.15036699,  0.13299659,\n",
       "        -0.00178752,  0.06322373,  0.23579739,  0.00170832, -0.03578478,\n",
       "         0.05043691, -0.02559404,  0.09329161, -0.09050409,  0.06719875,\n",
       "         0.01905143,  0.06449544,  0.10125608, -0.04190271, -0.09706594,\n",
       "        -0.03494598,  0.08495857,  0.09613758, -0.00529678, -0.0834003 ,\n",
       "         0.10726671, -0.02530507,  0.15362839, -0.0002972 , -0.1075434 ,\n",
       "         0.18367371,  0.11526223,  0.12799664, -0.05518794, -0.06107931,\n",
       "         0.03553371, -0.11698177, -0.00236126, -0.0627301 ,  0.09053845,\n",
       "        -0.03999481,  0.18825592, -0.04646417,  0.11561237,  0.10870664,\n",
       "        -0.1059873 , -0.0866063 ,  0.03922001,  0.01526454,  0.04449667,\n",
       "         0.17340997, -0.05583895, -0.0432059 ,  0.03959126, -0.0432714 ,\n",
       "        -0.12861815,  0.05145657,  0.02913352, -0.0151523 , -0.10494652,\n",
       "         0.08691278,  0.08372983,  0.02957253, -0.09343152,  0.03412861,\n",
       "         0.11774512, -0.04614861, -0.01037194, -0.11322857, -0.00706948,\n",
       "         0.06848194,  0.00600476,  0.09246761, -0.04238014, -0.02074652,\n",
       "         0.01892167,  0.01208346, -0.04666554, -0.03578039,  0.05317161]),\n",
       " 'poly(vinyl alcohol)': array([ 0.20025363, -0.02357323,  1.0198561 ,  0.39136878,  0.56346013,\n",
       "         0.32657392, -0.38804022,  0.12485707, -1.03868745, -0.17192428,\n",
       "         0.1855614 , -1.01973158,  0.44461473,  0.3586504 , -0.06638291,\n",
       "         0.1072576 ,  0.33208038, -0.46577689,  1.25904105, -0.262827  ,\n",
       "         0.56821112,  0.50160207,  0.65010291, -0.67716264,  0.98861838,\n",
       "        -0.1888874 ,  0.21206621,  0.78178267, -0.44005856, -0.45873092,\n",
       "         0.12938965, -0.38158575,  0.82570765, -0.03769985,  0.38686334,\n",
       "         0.59939628,  0.2239837 , -0.06637934, -0.45966193, -0.51815253,\n",
       "        -0.0843739 ,  0.21785465,  0.18620417,  0.16484797, -0.07987828,\n",
       "         0.69756922, -0.02929483,  0.57653895, -0.00639038, -0.50200474,\n",
       "         0.19332109, -0.1958604 ,  0.43074443, -0.39897304, -0.74678844,\n",
       "         0.6934868 , -0.72219163,  0.22953872,  0.17948161, -0.16961455,\n",
       "        -0.52626422,  0.71176253, -0.28094221,  0.42855858,  0.73338951,\n",
       "        -0.56970305, -0.06923103,  0.39058781, -0.43107362,  0.27276448,\n",
       "         0.36138335, -0.26757906, -0.07424693,  0.37986499, -0.46542446,\n",
       "        -0.1251254 , -0.61946387,  0.64583924, -0.01868203, -0.57134011,\n",
       "         0.74636069,  1.00786581,  0.346374  , -0.50125164, -0.10770548,\n",
       "         0.31073608, -0.86650566,  0.01682493, -0.2948952 ,  0.16667518,\n",
       "         0.3711682 , -0.1180206 ,  0.70686929, -0.16850098, -0.45904865,\n",
       "         0.48673601, -0.33514141, -0.01129354, -0.56876533,  0.12457808]),\n",
       " 'Poly(2-hydroxyethyl acrylate)': array([ 0.11286766, -0.00128273,  0.77067842,  0.29769312,  0.393817  ,\n",
       "         0.23136732, -0.22087613,  0.13116096, -0.71248156, -0.16546758,\n",
       "         0.14348598, -0.65624184,  0.29225392,  0.22381918, -0.04783782,\n",
       "         0.1015613 ,  0.25481008, -0.36478811,  0.89501998, -0.14709101,\n",
       "         0.40385999,  0.3808959 ,  0.45238485, -0.50328161,  0.73215119,\n",
       "        -0.13304426,  0.16468922,  0.59853611, -0.26830426, -0.32262566,\n",
       "         0.10364432, -0.23656894,  0.57946562, -0.03850101,  0.28243684,\n",
       "         0.39052163,  0.17980192, -0.00769455, -0.32712896, -0.382085  ,\n",
       "        -0.02363464,  0.16669544,  0.17333961,  0.09294331, -0.10280104,\n",
       "         0.5204608 , -0.0027526 ,  0.42684563, -0.02154559, -0.38040089,\n",
       "         0.21261621, -0.10055352,  0.30537618, -0.3005901 , -0.50394654,\n",
       "         0.4696483 , -0.54950619,  0.14557228,  0.12632903, -0.09302757,\n",
       "        -0.32479975,  0.54648596, -0.23608222,  0.33536673,  0.51038581,\n",
       "        -0.43477252, -0.09665299,  0.23321962, -0.27889359,  0.24665653,\n",
       "         0.316236  , -0.21412834, -0.06554104,  0.24230364, -0.35582081,\n",
       "        -0.14466817, -0.43072926,  0.41354153, -0.00959517, -0.40649738,\n",
       "         0.5381235 ,  0.71482932,  0.26527112, -0.34781304, -0.02393271,\n",
       "         0.24210233, -0.60047274, -0.04850669, -0.27133003,  0.10215316,\n",
       "         0.24248474, -0.06438729,  0.5040184 , -0.15357981, -0.26226234,\n",
       "         0.36160078, -0.25710511, -0.00712639, -0.38526152,  0.09946958]),\n",
       " 'polyurethane': array([-0.01019849, -0.10958932,  0.78325552,  0.34640905,  0.49711171,\n",
       "         0.15867296, -0.04059099,  0.24411279, -0.5917905 , -0.26327521,\n",
       "         0.10206451, -0.64324093,  0.01288327,  0.19945279,  0.14557716,\n",
       "         0.22582901, -0.05629735, -0.46507031,  0.94216955, -0.17236191,\n",
       "         0.38220435,  0.30774209,  0.38228476, -0.52861053,  0.25273591,\n",
       "        -0.05336183,  0.28350422,  0.60185015, -0.11293592, -0.28801647,\n",
       "         0.32623488, -0.24541068,  0.43241999,  0.02844706,  0.36243841,\n",
       "         0.34609228,  0.16854584, -0.04128363, -0.30590007, -0.22544187,\n",
       "        -0.06536744,  0.36293709,  0.05625911,  0.17531584, -0.08462654,\n",
       "         0.39346269, -0.34036756,  0.56454009,  0.13252205, -0.541224  ,\n",
       "         0.12354267,  0.19381163,  0.47200584, -0.40233323, -0.48820451,\n",
       "         0.34513763, -0.47115317,  0.03034791,  0.01519885,  0.12147711,\n",
       "        -0.40121698,  0.51767576, -0.18729098,  0.29746339,  0.62307686,\n",
       "        -0.48877797, -0.2071048 ,  0.29471403, -0.27917325,  0.15447463,\n",
       "         0.28162572, -0.14811713, -0.0807099 ,  0.53609377, -0.20911522,\n",
       "         0.08502746, -0.25680202,  0.59216821,  0.06118868, -0.40243402,\n",
       "         0.39379078,  0.51636684,  0.18962273, -0.38011861, -0.18558271,\n",
       "         0.3989341 , -0.46136919,  0.0992531 , -0.1824915 , -0.07989145,\n",
       "         0.35361886, -0.13489012,  0.5807395 ,  0.07408703, -0.36593693,\n",
       "         0.35867539,  0.07619568, -0.05674846, -0.23129818,  0.07379325]),\n",
       " 'styrene butadiene rubber': array([-0.0706508 , -0.23360502,  0.48618491,  0.2517144 ,  0.23120182,\n",
       "         0.04433386, -0.1270648 ,  0.13563531, -0.18370227, -0.2383729 ,\n",
       "        -0.02234138, -0.2720047 , -0.15390168, -0.00258953,  0.21100543,\n",
       "         0.03434389, -0.01164077, -0.22806272,  0.3461849 , -0.09872213,\n",
       "         0.17112679,  0.14609916,  0.11696734, -0.27811193,  0.10272459,\n",
       "        -0.03446741,  0.13094062,  0.36916712, -0.03333304, -0.13264815,\n",
       "         0.15150862, -0.19625667,  0.10094347, -0.09428455,  0.18766799,\n",
       "         0.21846158,  0.11109006,  0.08425092, -0.14728658, -0.13908041,\n",
       "        -0.18616717,  0.22129032,  0.11230185,  0.08349938, -0.1577137 ,\n",
       "         0.15799647, -0.17656165,  0.31621336,  0.0805482 , -0.20900892,\n",
       "         0.21082235,  0.14345632,  0.29346568, -0.15829831, -0.27840581,\n",
       "         0.04193661, -0.14969077, -0.04178752, -0.13289551,  0.14345395,\n",
       "        -0.21754374,  0.37803315, -0.01479353,  0.16866198,  0.26387616,\n",
       "        -0.2475698 , -0.13550403,  0.15577796, -0.01148293, -0.01251402,\n",
       "         0.2651324 , -0.06278597, -0.11427153,  0.2528769 , -0.02484033,\n",
       "        -0.05793217, -0.0074873 ,  0.25292987, -0.09252942, -0.19332537,\n",
       "         0.15534028,  0.1775111 ,  0.03807923, -0.26081845, -0.09497457,\n",
       "         0.25394634, -0.13757884,  0.15917392, -0.0933971 , -0.02012166,\n",
       "         0.17285973, -0.0438725 ,  0.20157981,  0.04360857, -0.20339591,\n",
       "         0.07532018,  0.1233057 , -0.05241877, -0.11921427,  0.03281681]),\n",
       " 'poly(butylene terephthalate)': array([ 0.10756735,  0.03758135,  0.81597987,  0.31146867,  0.40124339,\n",
       "         0.21627967, -0.20700622,  0.08656804, -0.74059405, -0.20196693,\n",
       "         0.20807993, -0.61699362,  0.30437614,  0.1800261 , -0.02200845,\n",
       "         0.10068403,  0.30121062, -0.42309834,  0.91741648, -0.10625079,\n",
       "         0.42599364,  0.43448783,  0.47687914, -0.55516211,  0.81774827,\n",
       "        -0.14271668,  0.18818943,  0.70111975, -0.27187745, -0.32058823,\n",
       "         0.11998562, -0.20781508,  0.64555318, -0.05638587,  0.29244154,\n",
       "         0.32205307,  0.18900303,  0.02068381, -0.34266202, -0.41417203,\n",
       "         0.04410823,  0.18023243,  0.21313099,  0.09302233, -0.09821984,\n",
       "         0.55426557,  0.02378943,  0.48004072, -0.04132609, -0.41966888,\n",
       "         0.27118448, -0.05176038,  0.31809607, -0.3044791 , -0.4809308 ,\n",
       "         0.51744954, -0.60654383,  0.17210709,  0.12221272, -0.06426862,\n",
       "        -0.30734955,  0.56109679, -0.27785293,  0.39197629,  0.54634065,\n",
       "        -0.44179938, -0.13175918,  0.22307041, -0.26527314,  0.29092772,\n",
       "         0.36635297, -0.24495694, -0.08451687,  0.21983807, -0.39148578,\n",
       "        -0.21901715, -0.40913909,  0.37888637,  0.02106832, -0.45059248,\n",
       "         0.56892357,  0.73823877,  0.28964929, -0.3436266 ,  0.04097785,\n",
       "         0.26806854, -0.63079401, -0.09635586, -0.35469618,  0.09448652,\n",
       "         0.25969388, -0.05525979,  0.52821556, -0.20524431, -0.24950858,\n",
       "         0.35523281, -0.30770891, -0.02280361, -0.41179239,  0.16442757]),\n",
       " 'poly(vinyl butyral)': array([ 2.01121968e-01, -1.17469033e-02,  9.77210104e-01,  3.71061134e-01,\n",
       "         5.30221755e-01,  3.02696198e-01, -2.82542899e-01,  1.63570258e-01,\n",
       "        -9.38757747e-01, -1.64185777e-01,  1.84422138e-01, -8.78543422e-01,\n",
       "         4.07845034e-01,  3.30539266e-01, -4.92798115e-02,  1.54149781e-01,\n",
       "         2.66412984e-01, -4.43721354e-01,  1.17048376e+00, -2.20517633e-01,\n",
       "         5.26256944e-01,  4.77607603e-01,  6.12064898e-01, -6.52156686e-01,\n",
       "         8.85357966e-01, -1.84638742e-01,  2.35469031e-01,  7.46503279e-01,\n",
       "        -3.74734487e-01, -4.20298787e-01,  1.52526587e-01, -3.50860099e-01,\n",
       "         7.42351964e-01, -2.76126998e-02,  3.88610716e-01,  5.17087777e-01,\n",
       "         2.28637132e-01, -5.71840281e-02, -4.19021597e-01, -4.73504961e-01,\n",
       "        -4.00196227e-02,  2.10088919e-01,  1.78402928e-01,  1.84054919e-01,\n",
       "        -8.83710658e-02,  6.25193333e-01, -4.47055697e-02,  5.71784253e-01,\n",
       "         5.91720889e-03, -4.96662716e-01,  1.88601437e-01, -1.51346232e-01,\n",
       "         3.92187059e-01, -3.98028463e-01, -6.82407161e-01,  6.40171615e-01,\n",
       "        -6.81210781e-01,  1.95571400e-01,  1.72400236e-01, -1.31963015e-01,\n",
       "        -4.53886847e-01,  6.57949666e-01, -2.76208706e-01,  3.99072871e-01,\n",
       "         6.49609928e-01, -5.43245812e-01, -9.08564044e-02,  3.49217912e-01,\n",
       "        -3.90697238e-01,  3.03502356e-01,  3.66160706e-01, -2.53548913e-01,\n",
       "        -8.53277507e-02,  3.64383067e-01, -4.33167763e-01, -8.24948557e-02,\n",
       "        -5.94137758e-01,  5.88693231e-01, -1.16410883e-02, -5.19932777e-01,\n",
       "         6.91682120e-01,  9.41595674e-01,  3.40394909e-01, -4.63599503e-01,\n",
       "        -1.08731666e-01,  2.99784645e-01, -7.88039227e-01, -1.81488199e-02,\n",
       "        -2.94559074e-01,  1.26306205e-01,  3.32293491e-01, -1.20001192e-01,\n",
       "         6.65768569e-01, -1.50259788e-01, -4.06983400e-01,  4.55085583e-01,\n",
       "        -3.11877839e-01,  6.25912721e-04, -5.04996662e-01,  1.35022011e-01]),\n",
       " 'polybutylene succinate': array([-0.03547357, -0.04737617,  0.10052657,  0.04766683,  0.04050344,\n",
       "        -0.00481524, -0.024601  ,  0.01299601, -0.0332299 , -0.06973929,\n",
       "         0.00070316, -0.02648226, -0.04874466, -0.03143084,  0.05466326,\n",
       "         0.00184292,  0.00913985, -0.05996606,  0.04339404, -0.01622025,\n",
       "         0.03311974,  0.03113199,  0.0073709 , -0.06837492,  0.04858783,\n",
       "         0.01179475,  0.01599961,  0.09847055, -0.00890953, -0.01200307,\n",
       "         0.01806333, -0.02781783,  0.02936418, -0.04451494,  0.03545694,\n",
       "         0.04387087,  0.04266141,  0.05172922, -0.02564965, -0.04767974,\n",
       "        -0.05595691,  0.03848814,  0.04019069, -0.00193231, -0.04311378,\n",
       "         0.04532325, -0.02076021,  0.06961527,  0.02363421, -0.05859492,\n",
       "         0.07607421,  0.04779048,  0.06935811, -0.02470314, -0.04022652,\n",
       "         0.00594113, -0.02483805, -0.00692388, -0.04132597,  0.03971057,\n",
       "        -0.03106891,  0.10166645, -0.00031601,  0.03555571,  0.04539806,\n",
       "        -0.05317113, -0.03010395,  0.03952779, -0.01239968,  0.00767586,\n",
       "         0.07378242, -0.02213864, -0.00690267,  0.03266956, -0.01089017,\n",
       "        -0.03867815,  0.01381541,  0.02844301, -0.02448803, -0.03385894,\n",
       "         0.04030115,  0.05081972,  0.0090783 , -0.05743127, -0.0174054 ,\n",
       "         0.05307046, -0.00983147,  0.01470748, -0.01769133, -0.00438399,\n",
       "         0.02875592, -0.00247629,  0.04656674,  0.00589671, -0.03578589,\n",
       "         0.01348421,  0.04380641, -0.01720517, -0.00540138,  0.01409633]),\n",
       " 'bisphenol-A phthalonitrile': array([-0.04807063, -0.23328872,  0.57562417,  0.21316231,  0.26930989,\n",
       "         0.03087469, -0.08855803,  0.13615125, -0.27381685, -0.25932977,\n",
       "         0.02297038, -0.20948165, -0.13561685, -0.01590573,  0.24699413,\n",
       "         0.09729221, -0.02332202, -0.27093826,  0.3788224 , -0.12192452,\n",
       "         0.21140475,  0.22628428,  0.18543011, -0.3696703 ,  0.18916323,\n",
       "        -0.02158757,  0.16610453,  0.48043489, -0.04275796, -0.17072672,\n",
       "         0.13157761, -0.21692442,  0.18072964, -0.09851093,  0.26328282,\n",
       "         0.24713403,  0.20199879,  0.190201  , -0.09392022, -0.21994326,\n",
       "        -0.17813903,  0.17626885,  0.12599237,  0.07575477, -0.18265612,\n",
       "         0.20787218, -0.17045692,  0.41281065,  0.11686024, -0.33111237,\n",
       "         0.25751822,  0.15609511,  0.35188578, -0.13050591, -0.27924187,\n",
       "         0.08406132, -0.21980113,  0.01098101, -0.09170688,  0.14466754,\n",
       "        -0.22487818,  0.4935469 ,  0.00251944,  0.17125932,  0.2462272 ,\n",
       "        -0.27835264, -0.11869172,  0.28580381, -0.07519401,  0.09840746,\n",
       "         0.37398501, -0.09762155, -0.0983499 ,  0.28296483, -0.04143813,\n",
       "        -0.02841298, -0.08389581,  0.31854758, -0.09208928, -0.22021411,\n",
       "         0.1934174 ,  0.31512678,  0.07964603, -0.33472854, -0.1411869 ,\n",
       "         0.25294841, -0.19646735,  0.0922038 , -0.0745436 , -0.0544895 ,\n",
       "         0.16669385, -0.08546595,  0.26865298, -0.00340387, -0.25934409,\n",
       "         0.05066741,  0.18418213, -0.074927  , -0.12571717,  0.01278828])}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"matrix_vectors.pickle\",\"rb\")\n",
    "matrix_vectors = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "matrix_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matrix</th>\n",
       "      <th>filler</th>\n",
       "      <th>filler percentage</th>\n",
       "      <th>matrix_embedding_0</th>\n",
       "      <th>matrix_embedding_1</th>\n",
       "      <th>matrix_embedding_2</th>\n",
       "      <th>matrix_embedding_3</th>\n",
       "      <th>matrix_embedding_4</th>\n",
       "      <th>matrix_embedding_5</th>\n",
       "      <th>matrix_embedding_6</th>\n",
       "      <th>...</th>\n",
       "      <th>filler_embedding_90</th>\n",
       "      <th>filler_embedding_91</th>\n",
       "      <th>filler_embedding_92</th>\n",
       "      <th>filler_embedding_93</th>\n",
       "      <th>filler_embedding_94</th>\n",
       "      <th>filler_embedding_95</th>\n",
       "      <th>filler_embedding_96</th>\n",
       "      <th>filler_embedding_97</th>\n",
       "      <th>filler_embedding_98</th>\n",
       "      <th>filler_embedding_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bisphenol A PC</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.097605</td>\n",
       "      <td>-0.492855</td>\n",
       "      <td>0.599070</td>\n",
       "      <td>0.407654</td>\n",
       "      <td>0.136872</td>\n",
       "      <td>0.129284</td>\n",
       "      <td>0.206520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bisphenol A PC</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.097605</td>\n",
       "      <td>-0.492855</td>\n",
       "      <td>0.599070</td>\n",
       "      <td>0.407654</td>\n",
       "      <td>0.136872</td>\n",
       "      <td>0.129284</td>\n",
       "      <td>0.206520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bisphenol A PC</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.097605</td>\n",
       "      <td>-0.492855</td>\n",
       "      <td>0.599070</td>\n",
       "      <td>0.407654</td>\n",
       "      <td>0.136872</td>\n",
       "      <td>0.129284</td>\n",
       "      <td>0.206520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bisphenol A PC</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.097605</td>\n",
       "      <td>-0.492855</td>\n",
       "      <td>0.599070</td>\n",
       "      <td>0.407654</td>\n",
       "      <td>0.136872</td>\n",
       "      <td>0.129284</td>\n",
       "      <td>0.206520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bisphenol A PC</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.097605</td>\n",
       "      <td>-0.492855</td>\n",
       "      <td>0.599070</td>\n",
       "      <td>0.407654</td>\n",
       "      <td>0.136872</td>\n",
       "      <td>0.129284</td>\n",
       "      <td>0.206520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EPDM</td>\n",
       "      <td>PANI-organoclay</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-0.233308</td>\n",
       "      <td>-0.633237</td>\n",
       "      <td>0.650954</td>\n",
       "      <td>0.397512</td>\n",
       "      <td>0.207540</td>\n",
       "      <td>-0.022603</td>\n",
       "      <td>0.017320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073797</td>\n",
       "      <td>-0.094366</td>\n",
       "      <td>0.240834</td>\n",
       "      <td>0.245041</td>\n",
       "      <td>-0.393199</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>0.502241</td>\n",
       "      <td>-0.057964</td>\n",
       "      <td>0.071333</td>\n",
       "      <td>-0.049761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EPDM</td>\n",
       "      <td>PANI-organoclay</td>\n",
       "      <td>20.00</td>\n",
       "      <td>-0.233308</td>\n",
       "      <td>-0.633237</td>\n",
       "      <td>0.650954</td>\n",
       "      <td>0.397512</td>\n",
       "      <td>0.207540</td>\n",
       "      <td>-0.022603</td>\n",
       "      <td>0.017320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073797</td>\n",
       "      <td>-0.094366</td>\n",
       "      <td>0.240834</td>\n",
       "      <td>0.245041</td>\n",
       "      <td>-0.393199</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>0.502241</td>\n",
       "      <td>-0.057964</td>\n",
       "      <td>0.071333</td>\n",
       "      <td>-0.049761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EPDM</td>\n",
       "      <td>PANI-organoclay</td>\n",
       "      <td>30.00</td>\n",
       "      <td>-0.233308</td>\n",
       "      <td>-0.633237</td>\n",
       "      <td>0.650954</td>\n",
       "      <td>0.397512</td>\n",
       "      <td>0.207540</td>\n",
       "      <td>-0.022603</td>\n",
       "      <td>0.017320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073797</td>\n",
       "      <td>-0.094366</td>\n",
       "      <td>0.240834</td>\n",
       "      <td>0.245041</td>\n",
       "      <td>-0.393199</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>0.502241</td>\n",
       "      <td>-0.057964</td>\n",
       "      <td>0.071333</td>\n",
       "      <td>-0.049761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EPDM</td>\n",
       "      <td>PANI-organoclay</td>\n",
       "      <td>40.00</td>\n",
       "      <td>-0.233308</td>\n",
       "      <td>-0.633237</td>\n",
       "      <td>0.650954</td>\n",
       "      <td>0.397512</td>\n",
       "      <td>0.207540</td>\n",
       "      <td>-0.022603</td>\n",
       "      <td>0.017320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073797</td>\n",
       "      <td>-0.094366</td>\n",
       "      <td>0.240834</td>\n",
       "      <td>0.245041</td>\n",
       "      <td>-0.393199</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>0.502241</td>\n",
       "      <td>-0.057964</td>\n",
       "      <td>0.071333</td>\n",
       "      <td>-0.049761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EPDM</td>\n",
       "      <td>PANI-organoclay</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.233308</td>\n",
       "      <td>-0.633237</td>\n",
       "      <td>0.650954</td>\n",
       "      <td>0.397512</td>\n",
       "      <td>0.207540</td>\n",
       "      <td>-0.022603</td>\n",
       "      <td>0.017320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073797</td>\n",
       "      <td>-0.094366</td>\n",
       "      <td>0.240834</td>\n",
       "      <td>0.245041</td>\n",
       "      <td>-0.393199</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>0.502241</td>\n",
       "      <td>-0.057964</td>\n",
       "      <td>0.071333</td>\n",
       "      <td>-0.049761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>Na-montmorillonite</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106991</td>\n",
       "      <td>-0.084016</td>\n",
       "      <td>0.347191</td>\n",
       "      <td>0.259219</td>\n",
       "      <td>-0.482040</td>\n",
       "      <td>0.199806</td>\n",
       "      <td>0.401552</td>\n",
       "      <td>-0.066398</td>\n",
       "      <td>-0.057108</td>\n",
       "      <td>0.005876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>Na-montmorillonite</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106991</td>\n",
       "      <td>-0.084016</td>\n",
       "      <td>0.347191</td>\n",
       "      <td>0.259219</td>\n",
       "      <td>-0.482040</td>\n",
       "      <td>0.199806</td>\n",
       "      <td>0.401552</td>\n",
       "      <td>-0.066398</td>\n",
       "      <td>-0.057108</td>\n",
       "      <td>0.005876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>Na-montmorillonite</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106991</td>\n",
       "      <td>-0.084016</td>\n",
       "      <td>0.347191</td>\n",
       "      <td>0.259219</td>\n",
       "      <td>-0.482040</td>\n",
       "      <td>0.199806</td>\n",
       "      <td>0.401552</td>\n",
       "      <td>-0.066398</td>\n",
       "      <td>-0.057108</td>\n",
       "      <td>0.005876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>Na-montmorillonite</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106991</td>\n",
       "      <td>-0.084016</td>\n",
       "      <td>0.347191</td>\n",
       "      <td>0.259219</td>\n",
       "      <td>-0.482040</td>\n",
       "      <td>0.199806</td>\n",
       "      <td>0.401552</td>\n",
       "      <td>-0.066398</td>\n",
       "      <td>-0.057108</td>\n",
       "      <td>0.005876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>Na-montmorillonite</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106991</td>\n",
       "      <td>-0.084016</td>\n",
       "      <td>0.347191</td>\n",
       "      <td>0.259219</td>\n",
       "      <td>-0.482040</td>\n",
       "      <td>0.199806</td>\n",
       "      <td>0.401552</td>\n",
       "      <td>-0.066398</td>\n",
       "      <td>-0.057108</td>\n",
       "      <td>0.005876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.227618</td>\n",
       "      <td>-0.613942</td>\n",
       "      <td>0.860947</td>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.138468</td>\n",
       "      <td>0.056689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188277</td>\n",
       "      <td>-0.051651</td>\n",
       "      <td>0.039244</td>\n",
       "      <td>0.317646</td>\n",
       "      <td>-0.323039</td>\n",
       "      <td>-0.060854</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>-0.138719</td>\n",
       "      <td>0.154740</td>\n",
       "      <td>-0.021411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.227618</td>\n",
       "      <td>-0.613942</td>\n",
       "      <td>0.860947</td>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.138468</td>\n",
       "      <td>0.056689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188277</td>\n",
       "      <td>-0.051651</td>\n",
       "      <td>0.039244</td>\n",
       "      <td>0.317646</td>\n",
       "      <td>-0.323039</td>\n",
       "      <td>-0.060854</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>-0.138719</td>\n",
       "      <td>0.154740</td>\n",
       "      <td>-0.021411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.227618</td>\n",
       "      <td>-0.613942</td>\n",
       "      <td>0.860947</td>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.138468</td>\n",
       "      <td>0.056689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188277</td>\n",
       "      <td>-0.051651</td>\n",
       "      <td>0.039244</td>\n",
       "      <td>0.317646</td>\n",
       "      <td>-0.323039</td>\n",
       "      <td>-0.060854</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>-0.138719</td>\n",
       "      <td>0.154740</td>\n",
       "      <td>-0.021411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.227618</td>\n",
       "      <td>-0.613942</td>\n",
       "      <td>0.860947</td>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.138468</td>\n",
       "      <td>0.056689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188277</td>\n",
       "      <td>-0.051651</td>\n",
       "      <td>0.039244</td>\n",
       "      <td>0.317646</td>\n",
       "      <td>-0.323039</td>\n",
       "      <td>-0.060854</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>-0.138719</td>\n",
       "      <td>0.154740</td>\n",
       "      <td>-0.021411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.227618</td>\n",
       "      <td>-0.613942</td>\n",
       "      <td>0.860947</td>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.138468</td>\n",
       "      <td>0.056689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188277</td>\n",
       "      <td>-0.051651</td>\n",
       "      <td>0.039244</td>\n",
       "      <td>0.317646</td>\n",
       "      <td>-0.323039</td>\n",
       "      <td>-0.060854</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>-0.138719</td>\n",
       "      <td>0.154740</td>\n",
       "      <td>-0.021411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.227618</td>\n",
       "      <td>-0.613942</td>\n",
       "      <td>0.860947</td>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.138468</td>\n",
       "      <td>0.056689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188277</td>\n",
       "      <td>-0.051651</td>\n",
       "      <td>0.039244</td>\n",
       "      <td>0.317646</td>\n",
       "      <td>-0.323039</td>\n",
       "      <td>-0.060854</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>-0.138719</td>\n",
       "      <td>0.154740</td>\n",
       "      <td>-0.021411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.227618</td>\n",
       "      <td>-0.613942</td>\n",
       "      <td>0.860947</td>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.138468</td>\n",
       "      <td>0.056689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188277</td>\n",
       "      <td>-0.051651</td>\n",
       "      <td>0.039244</td>\n",
       "      <td>0.317646</td>\n",
       "      <td>-0.323039</td>\n",
       "      <td>-0.060854</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>-0.138719</td>\n",
       "      <td>0.154740</td>\n",
       "      <td>-0.021411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.065047</td>\n",
       "      <td>-0.106770</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.070507</td>\n",
       "      <td>0.057589</td>\n",
       "      <td>-0.006472</td>\n",
       "      <td>-0.095987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.065047</td>\n",
       "      <td>-0.106770</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.070507</td>\n",
       "      <td>0.057589</td>\n",
       "      <td>-0.006472</td>\n",
       "      <td>-0.095987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.065047</td>\n",
       "      <td>-0.106770</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.070507</td>\n",
       "      <td>0.057589</td>\n",
       "      <td>-0.006472</td>\n",
       "      <td>-0.095987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.065047</td>\n",
       "      <td>-0.106770</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.070507</td>\n",
       "      <td>0.057589</td>\n",
       "      <td>-0.006472</td>\n",
       "      <td>-0.095987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.065047</td>\n",
       "      <td>-0.106770</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.070507</td>\n",
       "      <td>0.057589</td>\n",
       "      <td>-0.006472</td>\n",
       "      <td>-0.095987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.065047</td>\n",
       "      <td>-0.106770</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.070507</td>\n",
       "      <td>0.057589</td>\n",
       "      <td>-0.006472</td>\n",
       "      <td>-0.095987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.065047</td>\n",
       "      <td>-0.106770</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.070507</td>\n",
       "      <td>0.057589</td>\n",
       "      <td>-0.006472</td>\n",
       "      <td>-0.095987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.065047</td>\n",
       "      <td>-0.106770</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.070507</td>\n",
       "      <td>0.057589</td>\n",
       "      <td>-0.006472</td>\n",
       "      <td>-0.095987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>-0.366418</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>1.043176</td>\n",
       "      <td>-0.953322</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.897779</td>\n",
       "      <td>-0.090142</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.299452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>poly(vinyl butyral)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.201122</td>\n",
       "      <td>-0.011747</td>\n",
       "      <td>0.977210</td>\n",
       "      <td>0.371061</td>\n",
       "      <td>0.530222</td>\n",
       "      <td>0.302696</td>\n",
       "      <td>-0.282543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>poly(vinyl butyral)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.201122</td>\n",
       "      <td>-0.011747</td>\n",
       "      <td>0.977210</td>\n",
       "      <td>0.371061</td>\n",
       "      <td>0.530222</td>\n",
       "      <td>0.302696</td>\n",
       "      <td>-0.282543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>poly(vinyl butyral)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.201122</td>\n",
       "      <td>-0.011747</td>\n",
       "      <td>0.977210</td>\n",
       "      <td>0.371061</td>\n",
       "      <td>0.530222</td>\n",
       "      <td>0.302696</td>\n",
       "      <td>-0.282543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>poly(vinyl butyral)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.201122</td>\n",
       "      <td>-0.011747</td>\n",
       "      <td>0.977210</td>\n",
       "      <td>0.371061</td>\n",
       "      <td>0.530222</td>\n",
       "      <td>0.302696</td>\n",
       "      <td>-0.282543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>poly(vinyl butyral)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.201122</td>\n",
       "      <td>-0.011747</td>\n",
       "      <td>0.977210</td>\n",
       "      <td>0.371061</td>\n",
       "      <td>0.530222</td>\n",
       "      <td>0.302696</td>\n",
       "      <td>-0.282543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.200254</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>1.019856</td>\n",
       "      <td>0.391369</td>\n",
       "      <td>0.563460</td>\n",
       "      <td>0.326574</td>\n",
       "      <td>-0.388040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200254</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>1.019856</td>\n",
       "      <td>0.391369</td>\n",
       "      <td>0.563460</td>\n",
       "      <td>0.326574</td>\n",
       "      <td>-0.388040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.200254</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>1.019856</td>\n",
       "      <td>0.391369</td>\n",
       "      <td>0.563460</td>\n",
       "      <td>0.326574</td>\n",
       "      <td>-0.388040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.200254</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>1.019856</td>\n",
       "      <td>0.391369</td>\n",
       "      <td>0.563460</td>\n",
       "      <td>0.326574</td>\n",
       "      <td>-0.388040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.200254</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>1.019856</td>\n",
       "      <td>0.391369</td>\n",
       "      <td>0.563460</td>\n",
       "      <td>0.326574</td>\n",
       "      <td>-0.388040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.200254</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>1.019856</td>\n",
       "      <td>0.391369</td>\n",
       "      <td>0.563460</td>\n",
       "      <td>0.326574</td>\n",
       "      <td>-0.388040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.200254</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>1.019856</td>\n",
       "      <td>0.391369</td>\n",
       "      <td>0.563460</td>\n",
       "      <td>0.326574</td>\n",
       "      <td>-0.388040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.200254</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>1.019856</td>\n",
       "      <td>0.391369</td>\n",
       "      <td>0.563460</td>\n",
       "      <td>0.326574</td>\n",
       "      <td>-0.388040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.200254</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>1.019856</td>\n",
       "      <td>0.391369</td>\n",
       "      <td>0.563460</td>\n",
       "      <td>0.326574</td>\n",
       "      <td>-0.388040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>polybutylene succinate</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-0.035474</td>\n",
       "      <td>-0.047376</td>\n",
       "      <td>0.100527</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.040503</td>\n",
       "      <td>-0.004815</td>\n",
       "      <td>-0.024601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>polybutylene succinate</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-0.035474</td>\n",
       "      <td>-0.047376</td>\n",
       "      <td>0.100527</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.040503</td>\n",
       "      <td>-0.004815</td>\n",
       "      <td>-0.024601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>polybutylene succinate</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.035474</td>\n",
       "      <td>-0.047376</td>\n",
       "      <td>0.100527</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.040503</td>\n",
       "      <td>-0.004815</td>\n",
       "      <td>-0.024601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>-0.974641</td>\n",
       "      <td>1.168642</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.691877</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>bisphenol-A phthalonitrile</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.048071</td>\n",
       "      <td>-0.233289</td>\n",
       "      <td>0.575624</td>\n",
       "      <td>0.213162</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>-0.088558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>bisphenol-A phthalonitrile</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-0.048071</td>\n",
       "      <td>-0.233289</td>\n",
       "      <td>0.575624</td>\n",
       "      <td>0.213162</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>-0.088558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>bisphenol-A phthalonitrile</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-0.048071</td>\n",
       "      <td>-0.233289</td>\n",
       "      <td>0.575624</td>\n",
       "      <td>0.213162</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>-0.088558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>bisphenol-A phthalonitrile</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>6.00</td>\n",
       "      <td>-0.048071</td>\n",
       "      <td>-0.233289</td>\n",
       "      <td>0.575624</td>\n",
       "      <td>0.213162</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>-0.088558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>-0.042807</td>\n",
       "      <td>-0.159292</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>-0.173072</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         matrix              filler  filler percentage  \\\n",
       "0                bisphenol A PC               MWCNT              10.00   \n",
       "1                bisphenol A PC               MWCNT               2.00   \n",
       "2                bisphenol A PC               MWCNT               5.00   \n",
       "3                bisphenol A PC               MWCNT               5.00   \n",
       "4                bisphenol A PC               MWCNT               0.00   \n",
       "5                          EPDM     PANI-organoclay              10.00   \n",
       "6                          EPDM     PANI-organoclay              20.00   \n",
       "7                          EPDM     PANI-organoclay              30.00   \n",
       "8                          EPDM     PANI-organoclay              40.00   \n",
       "9                          EPDM     PANI-organoclay               0.00   \n",
       "10                        epoxy  Na-montmorillonite               0.00   \n",
       "11                        epoxy  Na-montmorillonite               1.00   \n",
       "12                        epoxy  Na-montmorillonite               7.00   \n",
       "13                        epoxy  Na-montmorillonite               1.00   \n",
       "14                        epoxy  Na-montmorillonite               7.00   \n",
       "15                  SC-15 epoxy               SWCNT               0.00   \n",
       "16                  SC-15 epoxy               SWCNT               0.50   \n",
       "17                  SC-15 epoxy               SWCNT               0.50   \n",
       "18                  SC-15 epoxy               SWCNT               0.50   \n",
       "19                  SC-15 epoxy               SWCNT               0.50   \n",
       "20                  SC-15 epoxy               SWCNT               0.50   \n",
       "21                  SC-15 epoxy               SWCNT               0.50   \n",
       "22                        DGEBA               MWCNT               0.05   \n",
       "23                        DGEBA               MWCNT               0.05   \n",
       "24                        DGEBA               MWCNT               0.10   \n",
       "25                        DGEBA               MWCNT               0.10   \n",
       "26                        DGEBA               MWCNT               0.25   \n",
       "27                        DGEBA               MWCNT               0.25   \n",
       "28                        DGEBA               MWCNT               0.50   \n",
       "29                        DGEBA               MWCNT               0.50   \n",
       "..                          ...                 ...                ...   \n",
       "353         poly(vinyl butyral)    titanium dioxide               5.00   \n",
       "354         poly(vinyl butyral)    titanium dioxide               7.00   \n",
       "355         poly(vinyl butyral)    titanium dioxide               7.00   \n",
       "356         poly(vinyl butyral)    titanium dioxide               0.00   \n",
       "357         poly(vinyl butyral)    titanium dioxide               0.00   \n",
       "358         poly(vinyl alcohol)    titanium dioxide               1.50   \n",
       "359         poly(vinyl alcohol)    titanium dioxide               0.20   \n",
       "360         poly(vinyl alcohol)    titanium dioxide               0.50   \n",
       "361         poly(vinyl alcohol)    titanium dioxide               1.00   \n",
       "362         poly(vinyl alcohol)    titanium dioxide               1.50   \n",
       "363         poly(vinyl alcohol)    titanium dioxide               1.50   \n",
       "364         poly(vinyl alcohol)    titanium dioxide               1.50   \n",
       "365         poly(vinyl alcohol)    titanium dioxide               1.50   \n",
       "366         poly(vinyl alcohol)    titanium dioxide               0.00   \n",
       "367                       epoxy    titanium dioxide               5.00   \n",
       "368                       epoxy    titanium dioxide              10.00   \n",
       "369                       epoxy    titanium dioxide              15.00   \n",
       "370                       epoxy    titanium dioxide               0.00   \n",
       "371      polybutylene succinate    titanium dioxide               5.00   \n",
       "372      polybutylene succinate    titanium dioxide              10.00   \n",
       "373      polybutylene succinate    titanium dioxide               0.00   \n",
       "374                       epoxy    titanium dioxide               0.50   \n",
       "375                       epoxy    titanium dioxide               1.00   \n",
       "376                       epoxy    titanium dioxide               3.00   \n",
       "377                       epoxy    titanium dioxide               4.00   \n",
       "378                       epoxy    titanium dioxide               0.00   \n",
       "379  bisphenol-A phthalonitrile    titanium dioxide               0.00   \n",
       "380  bisphenol-A phthalonitrile    titanium dioxide               2.00   \n",
       "381  bisphenol-A phthalonitrile    titanium dioxide               4.00   \n",
       "382  bisphenol-A phthalonitrile    titanium dioxide               6.00   \n",
       "\n",
       "     matrix_embedding_0  matrix_embedding_1  matrix_embedding_2  \\\n",
       "0              0.097605           -0.492855            0.599070   \n",
       "1              0.097605           -0.492855            0.599070   \n",
       "2              0.097605           -0.492855            0.599070   \n",
       "3              0.097605           -0.492855            0.599070   \n",
       "4              0.097605           -0.492855            0.599070   \n",
       "5             -0.233308           -0.633237            0.650954   \n",
       "6             -0.233308           -0.633237            0.650954   \n",
       "7             -0.233308           -0.633237            0.650954   \n",
       "8             -0.233308           -0.633237            0.650954   \n",
       "9             -0.233308           -0.633237            0.650954   \n",
       "10             0.516612           -0.974641            1.168642   \n",
       "11             0.516612           -0.974641            1.168642   \n",
       "12             0.516612           -0.974641            1.168642   \n",
       "13             0.516612           -0.974641            1.168642   \n",
       "14             0.516612           -0.974641            1.168642   \n",
       "15             0.227618           -0.613942            0.860947   \n",
       "16             0.227618           -0.613942            0.860947   \n",
       "17             0.227618           -0.613942            0.860947   \n",
       "18             0.227618           -0.613942            0.860947   \n",
       "19             0.227618           -0.613942            0.860947   \n",
       "20             0.227618           -0.613942            0.860947   \n",
       "21             0.227618           -0.613942            0.860947   \n",
       "22            -0.065047           -0.106770            0.157647   \n",
       "23            -0.065047           -0.106770            0.157647   \n",
       "24            -0.065047           -0.106770            0.157647   \n",
       "25            -0.065047           -0.106770            0.157647   \n",
       "26            -0.065047           -0.106770            0.157647   \n",
       "27            -0.065047           -0.106770            0.157647   \n",
       "28            -0.065047           -0.106770            0.157647   \n",
       "29            -0.065047           -0.106770            0.157647   \n",
       "..                  ...                 ...                 ...   \n",
       "353            0.201122           -0.011747            0.977210   \n",
       "354            0.201122           -0.011747            0.977210   \n",
       "355            0.201122           -0.011747            0.977210   \n",
       "356            0.201122           -0.011747            0.977210   \n",
       "357            0.201122           -0.011747            0.977210   \n",
       "358            0.200254           -0.023573            1.019856   \n",
       "359            0.200254           -0.023573            1.019856   \n",
       "360            0.200254           -0.023573            1.019856   \n",
       "361            0.200254           -0.023573            1.019856   \n",
       "362            0.200254           -0.023573            1.019856   \n",
       "363            0.200254           -0.023573            1.019856   \n",
       "364            0.200254           -0.023573            1.019856   \n",
       "365            0.200254           -0.023573            1.019856   \n",
       "366            0.200254           -0.023573            1.019856   \n",
       "367            0.516612           -0.974641            1.168642   \n",
       "368            0.516612           -0.974641            1.168642   \n",
       "369            0.516612           -0.974641            1.168642   \n",
       "370            0.516612           -0.974641            1.168642   \n",
       "371           -0.035474           -0.047376            0.100527   \n",
       "372           -0.035474           -0.047376            0.100527   \n",
       "373           -0.035474           -0.047376            0.100527   \n",
       "374            0.516612           -0.974641            1.168642   \n",
       "375            0.516612           -0.974641            1.168642   \n",
       "376            0.516612           -0.974641            1.168642   \n",
       "377            0.516612           -0.974641            1.168642   \n",
       "378            0.516612           -0.974641            1.168642   \n",
       "379           -0.048071           -0.233289            0.575624   \n",
       "380           -0.048071           -0.233289            0.575624   \n",
       "381           -0.048071           -0.233289            0.575624   \n",
       "382           -0.048071           -0.233289            0.575624   \n",
       "\n",
       "     matrix_embedding_3  matrix_embedding_4  matrix_embedding_5  \\\n",
       "0              0.407654            0.136872            0.129284   \n",
       "1              0.407654            0.136872            0.129284   \n",
       "2              0.407654            0.136872            0.129284   \n",
       "3              0.407654            0.136872            0.129284   \n",
       "4              0.407654            0.136872            0.129284   \n",
       "5              0.397512            0.207540           -0.022603   \n",
       "6              0.397512            0.207540           -0.022603   \n",
       "7              0.397512            0.207540           -0.022603   \n",
       "8              0.397512            0.207540           -0.022603   \n",
       "9              0.397512            0.207540           -0.022603   \n",
       "10             0.291231            0.691877            0.288572   \n",
       "11             0.291231            0.691877            0.288572   \n",
       "12             0.291231            0.691877            0.288572   \n",
       "13             0.291231            0.691877            0.288572   \n",
       "14             0.291231            0.691877            0.288572   \n",
       "15             0.248421            0.462600            0.138468   \n",
       "16             0.248421            0.462600            0.138468   \n",
       "17             0.248421            0.462600            0.138468   \n",
       "18             0.248421            0.462600            0.138468   \n",
       "19             0.248421            0.462600            0.138468   \n",
       "20             0.248421            0.462600            0.138468   \n",
       "21             0.248421            0.462600            0.138468   \n",
       "22             0.070507            0.057589           -0.006472   \n",
       "23             0.070507            0.057589           -0.006472   \n",
       "24             0.070507            0.057589           -0.006472   \n",
       "25             0.070507            0.057589           -0.006472   \n",
       "26             0.070507            0.057589           -0.006472   \n",
       "27             0.070507            0.057589           -0.006472   \n",
       "28             0.070507            0.057589           -0.006472   \n",
       "29             0.070507            0.057589           -0.006472   \n",
       "..                  ...                 ...                 ...   \n",
       "353            0.371061            0.530222            0.302696   \n",
       "354            0.371061            0.530222            0.302696   \n",
       "355            0.371061            0.530222            0.302696   \n",
       "356            0.371061            0.530222            0.302696   \n",
       "357            0.371061            0.530222            0.302696   \n",
       "358            0.391369            0.563460            0.326574   \n",
       "359            0.391369            0.563460            0.326574   \n",
       "360            0.391369            0.563460            0.326574   \n",
       "361            0.391369            0.563460            0.326574   \n",
       "362            0.391369            0.563460            0.326574   \n",
       "363            0.391369            0.563460            0.326574   \n",
       "364            0.391369            0.563460            0.326574   \n",
       "365            0.391369            0.563460            0.326574   \n",
       "366            0.391369            0.563460            0.326574   \n",
       "367            0.291231            0.691877            0.288572   \n",
       "368            0.291231            0.691877            0.288572   \n",
       "369            0.291231            0.691877            0.288572   \n",
       "370            0.291231            0.691877            0.288572   \n",
       "371            0.047667            0.040503           -0.004815   \n",
       "372            0.047667            0.040503           -0.004815   \n",
       "373            0.047667            0.040503           -0.004815   \n",
       "374            0.291231            0.691877            0.288572   \n",
       "375            0.291231            0.691877            0.288572   \n",
       "376            0.291231            0.691877            0.288572   \n",
       "377            0.291231            0.691877            0.288572   \n",
       "378            0.291231            0.691877            0.288572   \n",
       "379            0.213162            0.269310            0.030875   \n",
       "380            0.213162            0.269310            0.030875   \n",
       "381            0.213162            0.269310            0.030875   \n",
       "382            0.213162            0.269310            0.030875   \n",
       "\n",
       "     matrix_embedding_6         ...           filler_embedding_90  \\\n",
       "0              0.206520         ...                      0.314092   \n",
       "1              0.206520         ...                      0.314092   \n",
       "2              0.206520         ...                      0.314092   \n",
       "3              0.206520         ...                      0.314092   \n",
       "4              0.206520         ...                      0.314092   \n",
       "5              0.017320         ...                      0.073797   \n",
       "6              0.017320         ...                      0.073797   \n",
       "7              0.017320         ...                      0.073797   \n",
       "8              0.017320         ...                      0.073797   \n",
       "9              0.017320         ...                      0.073797   \n",
       "10             0.075319         ...                      0.106991   \n",
       "11             0.075319         ...                      0.106991   \n",
       "12             0.075319         ...                      0.106991   \n",
       "13             0.075319         ...                      0.106991   \n",
       "14             0.075319         ...                      0.106991   \n",
       "15             0.056689         ...                      0.188277   \n",
       "16             0.056689         ...                      0.188277   \n",
       "17             0.056689         ...                      0.188277   \n",
       "18             0.056689         ...                      0.188277   \n",
       "19             0.056689         ...                      0.188277   \n",
       "20             0.056689         ...                      0.188277   \n",
       "21             0.056689         ...                      0.188277   \n",
       "22            -0.095987         ...                      0.314092   \n",
       "23            -0.095987         ...                      0.314092   \n",
       "24            -0.095987         ...                      0.314092   \n",
       "25            -0.095987         ...                      0.314092   \n",
       "26            -0.095987         ...                      0.314092   \n",
       "27            -0.095987         ...                      0.314092   \n",
       "28            -0.095987         ...                      0.314092   \n",
       "29            -0.095987         ...                      0.314092   \n",
       "..                  ...         ...                           ...   \n",
       "353           -0.282543         ...                      0.146618   \n",
       "354           -0.282543         ...                      0.146618   \n",
       "355           -0.282543         ...                      0.146618   \n",
       "356           -0.282543         ...                      0.146618   \n",
       "357           -0.282543         ...                      0.146618   \n",
       "358           -0.388040         ...                      0.146618   \n",
       "359           -0.388040         ...                      0.146618   \n",
       "360           -0.388040         ...                      0.146618   \n",
       "361           -0.388040         ...                      0.146618   \n",
       "362           -0.388040         ...                      0.146618   \n",
       "363           -0.388040         ...                      0.146618   \n",
       "364           -0.388040         ...                      0.146618   \n",
       "365           -0.388040         ...                      0.146618   \n",
       "366           -0.388040         ...                      0.146618   \n",
       "367            0.075319         ...                      0.146618   \n",
       "368            0.075319         ...                      0.146618   \n",
       "369            0.075319         ...                      0.146618   \n",
       "370            0.075319         ...                      0.146618   \n",
       "371           -0.024601         ...                      0.146618   \n",
       "372           -0.024601         ...                      0.146618   \n",
       "373           -0.024601         ...                      0.146618   \n",
       "374            0.075319         ...                      0.146618   \n",
       "375            0.075319         ...                      0.146618   \n",
       "376            0.075319         ...                      0.146618   \n",
       "377            0.075319         ...                      0.146618   \n",
       "378            0.075319         ...                      0.146618   \n",
       "379           -0.088558         ...                      0.146618   \n",
       "380           -0.088558         ...                      0.146618   \n",
       "381           -0.088558         ...                      0.146618   \n",
       "382           -0.088558         ...                      0.146618   \n",
       "\n",
       "     filler_embedding_91  filler_embedding_92  filler_embedding_93  \\\n",
       "0              -0.366418             0.259528             1.043176   \n",
       "1              -0.366418             0.259528             1.043176   \n",
       "2              -0.366418             0.259528             1.043176   \n",
       "3              -0.366418             0.259528             1.043176   \n",
       "4              -0.366418             0.259528             1.043176   \n",
       "5              -0.094366             0.240834             0.245041   \n",
       "6              -0.094366             0.240834             0.245041   \n",
       "7              -0.094366             0.240834             0.245041   \n",
       "8              -0.094366             0.240834             0.245041   \n",
       "9              -0.094366             0.240834             0.245041   \n",
       "10             -0.084016             0.347191             0.259219   \n",
       "11             -0.084016             0.347191             0.259219   \n",
       "12             -0.084016             0.347191             0.259219   \n",
       "13             -0.084016             0.347191             0.259219   \n",
       "14             -0.084016             0.347191             0.259219   \n",
       "15             -0.051651             0.039244             0.317646   \n",
       "16             -0.051651             0.039244             0.317646   \n",
       "17             -0.051651             0.039244             0.317646   \n",
       "18             -0.051651             0.039244             0.317646   \n",
       "19             -0.051651             0.039244             0.317646   \n",
       "20             -0.051651             0.039244             0.317646   \n",
       "21             -0.051651             0.039244             0.317646   \n",
       "22             -0.366418             0.259528             1.043176   \n",
       "23             -0.366418             0.259528             1.043176   \n",
       "24             -0.366418             0.259528             1.043176   \n",
       "25             -0.366418             0.259528             1.043176   \n",
       "26             -0.366418             0.259528             1.043176   \n",
       "27             -0.366418             0.259528             1.043176   \n",
       "28             -0.366418             0.259528             1.043176   \n",
       "29             -0.366418             0.259528             1.043176   \n",
       "..                   ...                  ...                  ...   \n",
       "353            -0.034868             0.209844            -0.042807   \n",
       "354            -0.034868             0.209844            -0.042807   \n",
       "355            -0.034868             0.209844            -0.042807   \n",
       "356            -0.034868             0.209844            -0.042807   \n",
       "357            -0.034868             0.209844            -0.042807   \n",
       "358            -0.034868             0.209844            -0.042807   \n",
       "359            -0.034868             0.209844            -0.042807   \n",
       "360            -0.034868             0.209844            -0.042807   \n",
       "361            -0.034868             0.209844            -0.042807   \n",
       "362            -0.034868             0.209844            -0.042807   \n",
       "363            -0.034868             0.209844            -0.042807   \n",
       "364            -0.034868             0.209844            -0.042807   \n",
       "365            -0.034868             0.209844            -0.042807   \n",
       "366            -0.034868             0.209844            -0.042807   \n",
       "367            -0.034868             0.209844            -0.042807   \n",
       "368            -0.034868             0.209844            -0.042807   \n",
       "369            -0.034868             0.209844            -0.042807   \n",
       "370            -0.034868             0.209844            -0.042807   \n",
       "371            -0.034868             0.209844            -0.042807   \n",
       "372            -0.034868             0.209844            -0.042807   \n",
       "373            -0.034868             0.209844            -0.042807   \n",
       "374            -0.034868             0.209844            -0.042807   \n",
       "375            -0.034868             0.209844            -0.042807   \n",
       "376            -0.034868             0.209844            -0.042807   \n",
       "377            -0.034868             0.209844            -0.042807   \n",
       "378            -0.034868             0.209844            -0.042807   \n",
       "379            -0.034868             0.209844            -0.042807   \n",
       "380            -0.034868             0.209844            -0.042807   \n",
       "381            -0.034868             0.209844            -0.042807   \n",
       "382            -0.034868             0.209844            -0.042807   \n",
       "\n",
       "     filler_embedding_94  filler_embedding_95  filler_embedding_96  \\\n",
       "0              -0.953322             0.005673             0.897779   \n",
       "1              -0.953322             0.005673             0.897779   \n",
       "2              -0.953322             0.005673             0.897779   \n",
       "3              -0.953322             0.005673             0.897779   \n",
       "4              -0.953322             0.005673             0.897779   \n",
       "5              -0.393199             0.077739             0.502241   \n",
       "6              -0.393199             0.077739             0.502241   \n",
       "7              -0.393199             0.077739             0.502241   \n",
       "8              -0.393199             0.077739             0.502241   \n",
       "9              -0.393199             0.077739             0.502241   \n",
       "10             -0.482040             0.199806             0.401552   \n",
       "11             -0.482040             0.199806             0.401552   \n",
       "12             -0.482040             0.199806             0.401552   \n",
       "13             -0.482040             0.199806             0.401552   \n",
       "14             -0.482040             0.199806             0.401552   \n",
       "15             -0.323039            -0.060854             0.530435   \n",
       "16             -0.323039            -0.060854             0.530435   \n",
       "17             -0.323039            -0.060854             0.530435   \n",
       "18             -0.323039            -0.060854             0.530435   \n",
       "19             -0.323039            -0.060854             0.530435   \n",
       "20             -0.323039            -0.060854             0.530435   \n",
       "21             -0.323039            -0.060854             0.530435   \n",
       "22             -0.953322             0.005673             0.897779   \n",
       "23             -0.953322             0.005673             0.897779   \n",
       "24             -0.953322             0.005673             0.897779   \n",
       "25             -0.953322             0.005673             0.897779   \n",
       "26             -0.953322             0.005673             0.897779   \n",
       "27             -0.953322             0.005673             0.897779   \n",
       "28             -0.953322             0.005673             0.897779   \n",
       "29             -0.953322             0.005673             0.897779   \n",
       "..                   ...                  ...                  ...   \n",
       "353            -0.159292             0.034317             0.047031   \n",
       "354            -0.159292             0.034317             0.047031   \n",
       "355            -0.159292             0.034317             0.047031   \n",
       "356            -0.159292             0.034317             0.047031   \n",
       "357            -0.159292             0.034317             0.047031   \n",
       "358            -0.159292             0.034317             0.047031   \n",
       "359            -0.159292             0.034317             0.047031   \n",
       "360            -0.159292             0.034317             0.047031   \n",
       "361            -0.159292             0.034317             0.047031   \n",
       "362            -0.159292             0.034317             0.047031   \n",
       "363            -0.159292             0.034317             0.047031   \n",
       "364            -0.159292             0.034317             0.047031   \n",
       "365            -0.159292             0.034317             0.047031   \n",
       "366            -0.159292             0.034317             0.047031   \n",
       "367            -0.159292             0.034317             0.047031   \n",
       "368            -0.159292             0.034317             0.047031   \n",
       "369            -0.159292             0.034317             0.047031   \n",
       "370            -0.159292             0.034317             0.047031   \n",
       "371            -0.159292             0.034317             0.047031   \n",
       "372            -0.159292             0.034317             0.047031   \n",
       "373            -0.159292             0.034317             0.047031   \n",
       "374            -0.159292             0.034317             0.047031   \n",
       "375            -0.159292             0.034317             0.047031   \n",
       "376            -0.159292             0.034317             0.047031   \n",
       "377            -0.159292             0.034317             0.047031   \n",
       "378            -0.159292             0.034317             0.047031   \n",
       "379            -0.159292             0.034317             0.047031   \n",
       "380            -0.159292             0.034317             0.047031   \n",
       "381            -0.159292             0.034317             0.047031   \n",
       "382            -0.159292             0.034317             0.047031   \n",
       "\n",
       "     filler_embedding_97  filler_embedding_98  filler_embedding_99  \n",
       "0              -0.090142            -0.081130            -0.299452  \n",
       "1              -0.090142            -0.081130            -0.299452  \n",
       "2              -0.090142            -0.081130            -0.299452  \n",
       "3              -0.090142            -0.081130            -0.299452  \n",
       "4              -0.090142            -0.081130            -0.299452  \n",
       "5              -0.057964             0.071333            -0.049761  \n",
       "6              -0.057964             0.071333            -0.049761  \n",
       "7              -0.057964             0.071333            -0.049761  \n",
       "8              -0.057964             0.071333            -0.049761  \n",
       "9              -0.057964             0.071333            -0.049761  \n",
       "10             -0.066398            -0.057108             0.005876  \n",
       "11             -0.066398            -0.057108             0.005876  \n",
       "12             -0.066398            -0.057108             0.005876  \n",
       "13             -0.066398            -0.057108             0.005876  \n",
       "14             -0.066398            -0.057108             0.005876  \n",
       "15             -0.138719             0.154740            -0.021411  \n",
       "16             -0.138719             0.154740            -0.021411  \n",
       "17             -0.138719             0.154740            -0.021411  \n",
       "18             -0.138719             0.154740            -0.021411  \n",
       "19             -0.138719             0.154740            -0.021411  \n",
       "20             -0.138719             0.154740            -0.021411  \n",
       "21             -0.138719             0.154740            -0.021411  \n",
       "22             -0.090142            -0.081130            -0.299452  \n",
       "23             -0.090142            -0.081130            -0.299452  \n",
       "24             -0.090142            -0.081130            -0.299452  \n",
       "25             -0.090142            -0.081130            -0.299452  \n",
       "26             -0.090142            -0.081130            -0.299452  \n",
       "27             -0.090142            -0.081130            -0.299452  \n",
       "28             -0.090142            -0.081130            -0.299452  \n",
       "29             -0.090142            -0.081130            -0.299452  \n",
       "..                   ...                  ...                  ...  \n",
       "353            -0.098761            -0.173072             0.039404  \n",
       "354            -0.098761            -0.173072             0.039404  \n",
       "355            -0.098761            -0.173072             0.039404  \n",
       "356            -0.098761            -0.173072             0.039404  \n",
       "357            -0.098761            -0.173072             0.039404  \n",
       "358            -0.098761            -0.173072             0.039404  \n",
       "359            -0.098761            -0.173072             0.039404  \n",
       "360            -0.098761            -0.173072             0.039404  \n",
       "361            -0.098761            -0.173072             0.039404  \n",
       "362            -0.098761            -0.173072             0.039404  \n",
       "363            -0.098761            -0.173072             0.039404  \n",
       "364            -0.098761            -0.173072             0.039404  \n",
       "365            -0.098761            -0.173072             0.039404  \n",
       "366            -0.098761            -0.173072             0.039404  \n",
       "367            -0.098761            -0.173072             0.039404  \n",
       "368            -0.098761            -0.173072             0.039404  \n",
       "369            -0.098761            -0.173072             0.039404  \n",
       "370            -0.098761            -0.173072             0.039404  \n",
       "371            -0.098761            -0.173072             0.039404  \n",
       "372            -0.098761            -0.173072             0.039404  \n",
       "373            -0.098761            -0.173072             0.039404  \n",
       "374            -0.098761            -0.173072             0.039404  \n",
       "375            -0.098761            -0.173072             0.039404  \n",
       "376            -0.098761            -0.173072             0.039404  \n",
       "377            -0.098761            -0.173072             0.039404  \n",
       "378            -0.098761            -0.173072             0.039404  \n",
       "379            -0.098761            -0.173072             0.039404  \n",
       "380            -0.098761            -0.173072             0.039404  \n",
       "381            -0.098761            -0.173072             0.039404  \n",
       "382            -0.098761            -0.173072             0.039404  \n",
       "\n",
       "[383 rows x 203 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "df_embedding = pd.DataFrame(data=df[['matrix','filler','filler percentage']], copy=True)\n",
    "\n",
    "df_matrix_embedding = pd.DataFrame(data=matrix_vectors)\n",
    "df_matrix_embedding = df_matrix_embedding.T\n",
    "\n",
    "df_filler_embedding = pd.DataFrame(data=filler_vectors)\n",
    "df_filler_embedding = df_filler_embedding.T\n",
    "\n",
    "df_embedding = pd.merge(left=df_embedding, right=df_matrix_embedding, left_on='matrix', \n",
    "                        right_index=True, how='left', validate='many_to_one')\n",
    "df_embedding = df_embedding.rename(columns= lambda name: 'matrix_embedding_'+str(name) if isinstance(name, int) else name)\n",
    "\n",
    "df_embedding = pd.merge(left=df_embedding, right=df_filler_embedding, left_on='filler',\n",
    "                       right_index=True, how='left', validate='many_to_one')\n",
    "df_embedding = df_embedding.rename(columns= lambda name: 'filler_embedding_'+str(name) if isinstance(name, int) else name)\n",
    "\n",
    "#check the correctness of df_embedding\n",
    "compare_df = []\n",
    "compare_matrix_eb = []\n",
    "compare_filler_eb = []\n",
    "for index, row in df_embedding.iterrows():\n",
    "    compare_df.append(row['filler percentage']==df.iloc[index]['filler percentage'])\n",
    "    #print(row['filler percentage'])\n",
    "    compare_matrix_eb.append(row['matrix_embedding_19']== matrix_vectors[row['matrix']][19])\n",
    "    #print(row['matrix_embedding_19'])\n",
    "    compare_filler_eb.append(row['filler_embedding_38']== filler_vectors[row['filler']][38])\n",
    "    #print(row['filler_embedding_38'])\n",
    "print(all(compare_df))\n",
    "print(all(compare_matrix_eb))\n",
    "print(all(compare_filler_eb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X_embedding\n",
    "df_embedding_dropped = df_embedding.drop(labels=['matrix', 'filler'], axis='columns')\n",
    "X_embedding = df_embedding_dropped.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression r2:  0.9215392606917359\n",
      "[(169.4545455, 168.84118788018094), (167.7575758, 169.0839513656303), (172.0, 168.9929150585869), (169.0, 168.9929150585869), (166.8434903, 169.14464223699287), (-31.562947899999998, -31.019948623185513), (-31.163326799999997, -31.32340297999744), (-32.249276300000005, -31.626857336808456), (-32.6414639, -31.930311693620382), (-29.0, -30.716494266374497), (97.86, 118.8891241323229), (107.22, 118.85877869664299), (121.98, 118.6767060825562), (108.64, 118.85877869664299), (124.92, 118.6767060825562), (92.81061509999999, 84.34130662957655), (71.7704191, 84.32613391173568), (104.21, 84.32613391173568), (74.890069, 84.32613391173568), (70.8811546, 84.32613391173568), (82.7875767, 84.32613391173568), (92.94827559999999, 84.32613391173568), (148.3378378, 115.93808097793071), (150.6329268, 115.93808097793071), (151.1756757, 115.93656370614671), (152.14135159999998, 115.93656370614671), (152.1216216, 115.9320118907945), (159.35086930000003, 115.9320118907945), (158.1756757, 115.92442553187406), (156.4789925, 115.92442553187406), (146.0675676, 115.9395982497147), (146.1060685, 115.9395982497147), (102.0395583, 103.29480266825459), (102.2809001, 103.24928451473278), (102.4976751, 103.20376636121108), (106.1952723, 103.29480266825459), (108.5478168, 103.24928451473278), (106.40914, 103.20376636121108), (105.7675369, 103.15824820768927), (92.24120390000002, 103.32514810393565), (162.0301039, 162.48007000904448), (158.3338507, 162.47157328705265), (157.2131009, 162.45488329742778), (156.3859381, 162.42150331817987), (165.8305169, 162.48826327667751), (164.3569832, 162.48007000904448), (165.3365385, 162.47157328705265), (168.6191471, 162.45488329742778), (164.0381438, 162.42150331817987), (124.100675, 109.03709130266093), (128.678072, 109.03102221552494), (130.90492179999998, 109.02495312838896), (119.86351040000001, 109.01888404125297), (126.0046622, 108.98853860557124), (91.7549868, 108.9581931698895), (96.1313301, 108.92784773420958), (92.4524415, 108.89750229852784), (126.86571529999999, 109.04316038979691), (138.46633569999997, 109.0492294769329), (83.63778640000001, 115.9395982497147), (85.7989963, 115.9395982497147), (83.91434129999999, 115.93808097793071), (82.3295203, 115.9320118907945), (83.596367, 115.92442553187406), (90.6847083, 115.91683917295386), (83.63778640000001, 115.93808097793071), (85.2288265, 115.93656370614671), (83.95599449999999, 115.93504643436249), (85.54703459999999, 115.9320118907945), (87.4562827, 115.92442553187406), (94.13865109999999, 115.91683917295386), (73.78099499999999, 80.3502588392017), (77.39100690000001, 83.47103313919987), (82.4316017, 85.94861193920184), (87.594275, 81.742310989202), (80.496372, 85.18550368920111), (86.76779549999999, 80.19853166079665), (89.3993322, 83.31930596079482), (89.313895, 85.79688476079679), (75.7386198, 81.59058381079694), (89.7229082, 85.03377651079606), (69.8238085, 70.42728869999976), (71.0307689, 70.42728869999976), (-30.802769800000004, -29.903197590459698), (-31.934095000000003, -29.963888461822265), (-26.912037100000003, -29.781815847735018), (82.8, 82.41293179459996), (83.1, 82.33706820539652), (81.9, 82.26120461619308), (81.7, 82.48879538380339), (93.251832, 127.23151104916103), (99.9429482, 111.50548997733783), (90.8775752, 127.21785560310506), (89.77764, 111.49183453128187), (89.5524468, 127.23302832094593), (90.5352135, 104.85515687360005), (91.0185913, 104.85394305617213), (91.20395959999999, 104.85546032795703), (102.97694770000001, 111.50700724912183), (103.5769291, 89.12913580177594), (102.67870740000001, 89.12792198434893), (102.9376564, 89.12943925613293), (119.3274418, 108.46958558543126), (126.036703, 108.43924014974952), (126.9629172, 108.4088947140696), (130.92716969999998, 108.37854927838787), (114.7693889, 108.34820384270613), (52.100120399999994, 58.78194985795425), (72.9026937, 72.90269369999986), (75.8295422, 65.80679801308182), (77.8811242, 81.22203892898581), (51.8170678, 51.81706780000081), (133.77956229999998, 127.61238407243654), (135.4396164, 127.43031145834793), (135.996907, 127.15720253721774), (133.38773270000002, 127.82480212220325), (133.09709469999999, 127.6730749437982), (131.36585449999998, 127.94618386492839), (106.18900900000001, 106.58712247350458), (109.17019909999999, 110.41617825951293), (107.3376236, 106.57194975566371), (106.4630591, 106.54160431998288), (107.5592592, 106.60229519134545), (97.41472519999999, 99.1673872864922), (99.8367245, 98.84572566827187), (102.5487995, 98.68489485916147), (98.2727656, 99.14918002508334), (99.5536352, 99.00959102095025), (96.4430343, 99.2129054400139), (151.42262769999996, 127.22999377737794), (154.53716740000002, 127.22695923380995), (160.4867941, 127.22392469024105), (170.2047695, 127.22089014667306), (149.2907743, 127.23302832094593), (-36.7332229, -34.16312131718953), (-35.7954545, -34.19346675287036), (-33.6937186, -34.22381218855164), (-27.7811005, -34.31484849559504), (-36.9941827, -34.10243044582696), (-56.5085213, -56.617737532674155), (-56.7297152, -56.620498967320955), (75.3267668, 87.03657663216828), (98.7767319, 87.0669220678491), (81.78430809999999, 127.36107979873695), (88.5679298, 127.33983799375919), (80.33297759999999, 127.37018342944093), (115.9315402, 119.94653529633807), (126.7093686, 119.67342637520788), (118.62769509999998, 119.90101714281637), (126.52364579999998, 119.82515355361475), (111.53076340000001, 119.97688073201981), (153.7489666, 151.69011404999637), (149.6312615, 151.69011404999637), (156.1577779, 136.90662372801913), (140.237234, 136.90662372801913), (151.53168069999998, 137.058350906426), (143.700793, 137.058350906426), (147.8079448, 137.21007808483105), (125.7810588, 125.42148770029239), (131.8190717, 125.40934952602042), (119.22261200000001, 125.42452224386038), (123.81190659999999, 122.77237634295895), (121.91491869999999, 122.95444895704574), (138.41778, 137.79255298763454), (143.7240228, 137.79255298763454), (129.760226, 138.09600734444646), (140.3697616, 108.31785840702621), (128.8096076, 108.31785840702621), (128.3409527, 108.31785840702621), (122.71709399999999, 108.46958558543126), (119.4510654, 122.41595757318052), (126.122432, 122.41595757318052), (121.270293, 122.3856121375006), (123.86535459999999, 122.3856121375006), (125.8542233, 122.2945758304572), (121.6094586, 122.2945758304572), (120.44833940000001, 122.44630300886226), (120.4637308, 122.44630300886226), (120.7789557, 108.46958558543126), (120.13346979999999, 108.43924014974952), (121.4777635, 108.4088947140696), (123.7530618, 108.31785840702621), (119.5044025, 125.41935104781992), (125.6421031, 125.4125729092339), (128.6581765, 125.40322721298985), (130.7362101, 125.39434170527606), (133.9723096, 125.38232561069167), (113.3557559, 125.42452224386038), (138.1927711, 138.0322819295168), (136.746988, 137.95186652496048), (141.08433730000002, 137.87569948140188), (137.71084340000002, 138.09600734444646), (75.28864109999999, 108.46958558543126), (83.7128075, 108.43924014974952), (88.92811400000001, 108.37854927838787), (95.8883952, 108.31785840702621), (99.44007690000001, 108.25716753566273), (96.2473127, 108.19647666430107), (75.6689777, 108.46958558543126), (82.1431993, 108.43924014974952), (86.1637205, 108.37854927838787), (94.027387, 108.31785840702621), (93.1405073, 108.25716753566273), (87.760104, 108.19647666430107), (130.03401499999998, 137.02800547074426), (123.2487592, 137.21007808483105), (123.4100294, 127.35501071160097), (121.1489916, 127.33983799375919), (123.70753429999999, 127.30949255807927), (125.79006909999998, 127.2488016867158), (108.9719019, 127.37018342944093), (99.60472890000001, 98.49930237585264), (91.1433303, 127.9431493213604), (101.2619929, 98.49323328871665), (102.2428528, 98.48716420158067), (102.90110440000001, 98.48109511444287), (86.45245290000001, 98.50233691942063), (119.57233020000001, 127.37018342944093), (144.5916614, 127.24879237066698), (148.0325145, 127.18051556522032), (142.55721469999997, 127.34511451880671), (130.7089824, 127.32042701995333), (142.3720758, 127.24879237066698), (142.2253437, 127.22568134754356), (135.76912919999998, 127.18051556522032), (127.6988611, 127.34511451880671), (119.0416645, 127.37018342944093), (207.8671329, 207.4620934854933), (203.67132869999998, 193.8936406894104), (183.74125869999997, 193.9239861250917), (79.72147340000001, 79.52202303329877), (77.2357438, 76.60075499460733), (82.69802800000001, 79.49167759761885), (82.6939388, 79.46133216193711), (80.2480643, 76.54006412324567), (77.35561659999999, 76.47937325188401), (71.41186809999999, 76.63110043028907), (73.0489742, 79.5523684689805), (125.1784743, 122.34158798568446), (121.38596059999999, 122.31124255000454), (122.4368981, 122.22020624296114), (120.2436372, 122.3719334213662), (159.30247450000002, 147.31718863678202), (152.2597605, 147.25649776542036), (122.3282263, 147.1958068940587), (161.1680095, 147.04407971565183), (125.21754479999998, 147.04407971565183), (162.92917119999998, 147.34753407246376), (121.970704, 108.16613122861934), (123.286202, 107.86267687180741), (122.023324, 107.5592225149973), (125.6014784, 107.25576815818538), (127.2853158, 106.95231380137345), (119.7080476, 108.46958558543126), (104.9070632, 108.27992661242358), (108.3643123, 108.00317623901144), (95.4275093, 108.46958558543126), (88.9037657, 88.46174720004889), (84.083682, 82.56767656414961), (88.7698745, 88.43140176436715), (86.22594140000001, 88.52243807141237), (105.6578774, 66.740132749544), (123.4714511, 66.43667839273253), (130.2332207, 66.28495121432657), (140.25999950000002, 66.13322403592106), (109.1960666, 66.5884055711385), (118.14594450000001, 66.51254198193551), (21.560019399999998, 20.966397760796283), (15.931871, 20.814670582390548), (33.749071, 21.11812493920202), (12.928084, 21.269852117607755), (25.156790700000002, 66.740132749544), (24.222013, 66.70978731386272), (22.865148899999998, 66.43667839273253), (25.156790700000002, 66.6490964425006), (34.792956700000005, 66.5884055711385), (31.5503768, 66.43667839273253), (45.049169299999996, 66.5884055711385), (33.1592878, 66.5884055711385), (29.256563, 66.740132749544), (389.9840632, 388.95581033133533), (392.4395788, 388.87994674213235), (398.805816, 388.72821956372684), (400.383313, 388.5764923853209), (408.8386154, 388.42476520691537), (380.4903637, 388.95581033133533), (380.6641712, 388.87994674213235), (382.4309643, 388.72821956372684), (379.9002157, 388.5764923853209), (386.12687420000003, 388.42476520691537), (388.0854451, 389.0316739205383), (377.0443957, 389.0316739205383), (325.0024992, 323.49460155510576), (324.399546, 323.1911471982943), (324.198823, 323.03942001988855), (332.0411352, 323.3428743767), (316.3536495, 323.49460155510576), (316.3014347, 323.1911471982943), (323.9260262, 323.03942001988855), (323.9129725, 323.3428743767), (72.50841700000001, 77.20419423141418), (75.2595108, 76.90073987460316), (77.3227876, 76.59728551779124), (77.9744452, 76.29383116098022), (71.4368417, 75.99037680416829), (73.5952197, 75.68692244735728), (26.8142499, 33.478366385371785), (25.921473100000004, 33.32663920696673), (33.026444500000004, 33.17491202856077), (35.7337838, 33.023184850154806), (49.3564224, 32.87145767174975), (33.385194899999995, 32.71973049334379), (27.986815600000003, 33.63009356377775), (13.020617199999998, 77.20419423141418), (15.8652636, 76.90073987460316), (17.8773306, 76.59728551779124), (20.028160800000002, 76.29383116098022), (22.5258991, 75.99037680416829), (29.047771299999997, 75.68692244735728), (51.8264285, -27.847132775390193), (45.139798799999994, -27.831960057549324), (51.545326, -27.862305493231062), (44.236185600000006, -27.89265092891189), (-1.3939195, -0.31018527006112606), (-1.3741214, -0.31018527006112606), (0.4077111, -0.31018527006112606), (-1.0177549000000001, -0.31018527006112606), (0.9422609000000001, -0.31018527006112606), (1.2540816000000001, -0.31018527006112606), (-0.8395716000000001, -0.31018527006112606), (0.4077111, 0.557694190419582), (75.0365441, 77.18902151357422), (84.061123, 77.14350336005252), (82.97807590000001, 77.05246705300912), (77.0811142, 76.90073987460316), (75.44885440000002, 76.7490126961972), (62.4297397, 77.20419423141418), (59.9033593, 54.09819430233411), (53.716274, 54.06784886665328), (48.5839133, 54.03750343097154), (-40.40792329999999, -2.593553983847322), (-38.5275125, -2.608726701688191), (-42.981564, -2.63907213736902), (-42.1256438, -2.6694175730498486), (-39.8786902, -2.7301084444124157), (-41.2390151, -2.790799315774983), (-39.5683375, -2.881835622818379), (-40.9449968, -2.5783812660064527), (34.4965589, 34.38295186849032), (33.4054099, 34.38295186849032), (34.425135600000004, 34.32226099712685), (34.2163505, 34.32226099712685), (34.2103592, 34.26157012576519), (33.5380485, 34.26157012576519), (35.121470200000005, 34.20087925440353), (35.1007672, 34.20087925440353), (34.288872399999995, 34.41329730417024), (34.3589467, 34.41329730417024), (140.09900990000003, 102.41225486943554), (127.14855459999998, 102.45170393582126), (137.5057776, 102.44260030511728), (141.8741334, 102.42742758727641), (164.2229574, 102.41225486943554), (135.4785479, 102.41225486943554), (138.2508251, 102.41225486943554), (161.35313530000002, 102.41225486943554), (131.99576090000002, 102.45777302295724), (186.5909091, 115.25048324606112), (192.2727273, 115.09875606765607), (178.18181819999998, 114.9470288892492), (184.0909091, 115.40221042446618), (-24.7707626, -25.59501233333407), (-26.721346500000003, -25.746739511739804), (-25.2929279, -25.443285154928333), (55.4595697, 115.38703770662622), (53.6936913, 115.37186498878626), (41.6566777, 115.31117411742278), (40.6065374, 115.28082868174286), (52.992619999999995, 115.40221042446618), (314.58885939999993, 341.1387816820409), (341.24668439999994, 341.07809081067904), (347.2148541, 341.0173999393165), (361.1405836, 340.95670906795436)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.111225806268317"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_embedding, y)\n",
    "R_2 = reg.score(X_embedding, y)\n",
    "print('linear regression r2: ', R_2)\n",
    "y_pred = reg.predict(X_embedding)\n",
    "print(list(zip(y,y_pred)))\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mean absolute error: 106412685.5161467\n",
      "average y true values: 107.94295911331595\n"
     ]
    }
   ],
   "source": [
    "#loo for linear regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "lr = LinearRegression()\n",
    "scores_lr = cross_val_score(lr, X_embedding, y, cv=loo.split(X_embedding), \n",
    "                             scoring='neg_mean_absolute_error')\n",
    "print('average mean absolute error:', np.mean(-scores_lr))\n",
    "print('average y true values:', np.mean(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mean absolute error: 50.03905714782927\n"
     ]
    }
   ],
   "source": [
    "#linear regression was overfitting, try ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "scores_ridge = cross_val_score(ridge, X_embedding, y, cv=loo.split(X_embedding), \n",
    "                                 scoring='neg_mean_absolute_error')\n",
    "print('average mean absolute error:', np.mean(-scores_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-10 average mean absolute error: 17.171431435227344\n",
      "1e-09 average mean absolute error: 17.17637222379524\n",
      "1e-08 average mean absolute error: 17.17643145946686\n",
      "1e-07 average mean absolute error: 17.176494349801484\n",
      "1e-06 average mean absolute error: 17.17650987786787\n",
      "1e-05 average mean absolute error: 17.176741636069092\n",
      "0.0001 average mean absolute error: 17.1828057705657\n",
      "0.001 average mean absolute error: 17.319015575493882\n",
      "0.01 average mean absolute error: 19.008147424207852\n",
      "0.1 average mean absolute error: 27.06465183394454\n"
     ]
    }
   ],
   "source": [
    "for alpha in [1e-10, 1e-9, 1e-8, 1e-7,1e-6, 1e-5,1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    scores_ridge = cross_val_score(ridge, X_embedding_scaled, y, cv=loo.split(X_embedding_scaled), \n",
    "                                 scoring='neg_mean_absolute_error')\n",
    "    print(alpha, 'average mean absolute error:', np.mean(-scores_ridge))\n",
    "#best alpha=1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mean absolute error: 17.17811400998142\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1e-10)\n",
    "scores_ridge = cross_val_score(ridge, X_embedding, y, cv=loo.split(X_embedding), \n",
    "                                 scoring='neg_mean_absolute_error')\n",
    "print('average mean absolute error:', np.mean(-scores_ridge))\n",
    "#worse than one hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 1   leave one out mean_absolute_error:  16.91368962846252\n",
      "11 2   leave one out mean_absolute_error:  16.660829641202167\n",
      "11 3   leave one out mean_absolute_error:  18.134889910819076\n",
      "11 4   leave one out mean_absolute_error:  19.174433872823567\n",
      "12 1   leave one out mean_absolute_error:  16.418325483933067\n",
      "12 2   leave one out mean_absolute_error:  16.316154967487847\n",
      "12 3   leave one out mean_absolute_error:  17.700758762578978\n",
      "12 4   leave one out mean_absolute_error:  18.97789263000112\n",
      "13 1   leave one out mean_absolute_error:  16.268371133728294\n",
      "13 2   leave one out mean_absolute_error:  16.04849716859601\n",
      "13 3   leave one out mean_absolute_error:  17.846988171825238\n",
      "13 4   leave one out mean_absolute_error:  19.10943656917223\n",
      "14 1   leave one out mean_absolute_error:  15.925569922607414\n",
      "14 2   leave one out mean_absolute_error:  15.900149130983623\n",
      "14 3   leave one out mean_absolute_error:  17.814117984611638\n",
      "14 4   leave one out mean_absolute_error:  19.063586141492923\n",
      "15 1   leave one out mean_absolute_error:  15.720986555946176\n",
      "15 2   leave one out mean_absolute_error:  15.94108900863954\n",
      "15 3   leave one out mean_absolute_error:  17.891213524352896\n",
      "15 4   leave one out mean_absolute_error:  19.08736028094523\n",
      "16 1   leave one out mean_absolute_error:  15.757428271020238\n",
      "16 2   leave one out mean_absolute_error:  15.87661528664749\n",
      "16 3   leave one out mean_absolute_error:  17.807963188129836\n",
      "16 4   leave one out mean_absolute_error:  19.023104424335862\n",
      "17 1   leave one out mean_absolute_error:  15.686340863953747\n",
      "17 2   leave one out mean_absolute_error:  15.989793717385304\n",
      "17 3   leave one out mean_absolute_error:  17.794271269471487\n",
      "17 4   leave one out mean_absolute_error:  19.093798833857182\n",
      "18 1   leave one out mean_absolute_error:  15.471653827456795\n",
      "18 2   leave one out mean_absolute_error:  15.77062431657155\n",
      "18 3   leave one out mean_absolute_error:  17.803626981339985\n",
      "18 4   leave one out mean_absolute_error:  18.957648332281902\n",
      "19 1   leave one out mean_absolute_error:  15.54551378144722\n",
      "19 2   leave one out mean_absolute_error:  15.835454472694266\n",
      "19 3   leave one out mean_absolute_error:  17.887917944565775\n",
      "19 4   leave one out mean_absolute_error:  18.97579115000166\n",
      "20 1   leave one out mean_absolute_error:  15.442965373483776\n",
      "20 2   leave one out mean_absolute_error:  15.850908498151187\n",
      "20 3   leave one out mean_absolute_error:  17.936114137472646\n",
      "20 4   leave one out mean_absolute_error:  18.934038178672242\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "from sklearn import tree\n",
    "\n",
    "errors = np.zeros((10, 4))\n",
    "for i in range(11, 21):\n",
    "    for j in range(1, 5):\n",
    "        dt = tree.DecisionTreeRegressor(max_depth=i, min_samples_leaf=j)\n",
    "        scores_dt = cross_val_score(dt, X_embedding, y, cv=loo.split(X_embedding),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "        print(i, j, '  leave one out mean_absolute_error: ', np.mean(-scores_dt))\n",
    "        errors[i-11, j-1] = np.mean(-scores_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.442965373483776"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amin(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  leave one out mean_absolute_error:  15.56295249228273\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeRegressor()\n",
    "#dt.fit(X,y)\n",
    "#dt.score(X,y)\n",
    "scores_dt = cross_val_score(dt, X_embedding, y, cv=loo.split(X_embedding),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "print('  leave one out mean_absolute_error: ', np.mean(-scores_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  leave one out mean_absolute_error:  15.502604140280987\n",
      "0.9743565276557459\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.394016166358324"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeRegressor()\n",
    "#dt.fit(X,y)\n",
    "#dt.score(X,y)\n",
    "scores_dt = cross_val_score(dt, X_embedding_scaled, y, cv=loo.split(X_embedding_scaled),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "print('  leave one out mean_absolute_error: ', np.mean(-scores_dt))\n",
    "\n",
    "dt = tree.DecisionTreeRegressor()\n",
    "dt.fit(X_embedding_scaled,y)\n",
    "print(dt.score(X_embedding_scaled,y))\n",
    "\n",
    "#tree.export_graphviz(dt,\n",
    "#    out_file='tree.dot') \n",
    "\n",
    "#print(dt.feature_importances_)\n",
    "\n",
    "print(dt.tree_.max_depth)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = dt.predict(X_embedding_scaled)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9743565276557459\n",
      "[2.32381481e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.85060941e-03 0.00000000e+00\n",
      " 5.23496748e-05 0.00000000e+00 3.61244330e-06 9.30905128e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.60415676e-04\n",
      " 0.00000000e+00 4.59099457e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.35982894e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.05604776e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.26156871e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.96932761e-02 0.00000000e+00 0.00000000e+00\n",
      " 6.75102467e-07 2.93971047e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 4.39196942e-04 2.51262869e-03 0.00000000e+00 0.00000000e+00\n",
      " 2.86639230e-05 0.00000000e+00 2.20710030e-01 7.81581413e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.95760832e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 6.19250375e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.77428132e-02 4.93734545e-04\n",
      " 0.00000000e+00 0.00000000e+00 1.97782982e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.64625955e-05 2.77453002e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.31372804e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.30718870e-05 1.58251887e-06 5.08610639e-07\n",
      " 0.00000000e+00 0.00000000e+00 2.47314200e-06 1.69504570e-05\n",
      " 2.47123491e-05 5.25241567e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.55227815e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 7.10717203e-07 0.00000000e+00 0.00000000e+00\n",
      " 5.61618163e-04 2.28975680e-03 0.00000000e+00 9.82163731e-03\n",
      " 0.00000000e+00 9.38450205e-04 3.54794994e-04 1.18908215e-05\n",
      " 3.56318417e-05 0.00000000e+00 0.00000000e+00 2.51058596e-04\n",
      " 1.31416728e-06 9.08975744e-05 0.00000000e+00 2.64548739e-02\n",
      " 3.70985446e-04 8.56180415e-05 0.00000000e+00 5.49474339e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 7.70436371e-03\n",
      " 2.30013927e-05 0.00000000e+00 1.62204535e-09 0.00000000e+00\n",
      " 1.81688978e-04 2.16023002e-04 6.43109699e-04 0.00000000e+00\n",
      " 0.00000000e+00 6.67714742e-06 1.58836289e-02 3.34089028e-06\n",
      " 0.00000000e+00 0.00000000e+00 2.45169770e-04 3.19033239e-01\n",
      " 0.00000000e+00 0.00000000e+00 7.98747564e-07 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.35996007e-05 0.00000000e+00\n",
      " 0.00000000e+00 3.72015213e-06 8.27126870e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 7.68412445e-06 4.31489440e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 6.48507624e-08 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 4.10009598e-04 0.00000000e+00\n",
      " 0.00000000e+00 3.47895478e-04 2.61411043e-08 1.76523216e-04\n",
      " 0.00000000e+00]\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.394016166358324"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeRegressor()\n",
    "dt.fit(X_embedding,y)\n",
    "print(dt.score(X_embedding,y))\n",
    "\n",
    "#tree.export_graphviz(dt,\n",
    "#    out_file='tree.dot') \n",
    "\n",
    "print(dt.feature_importances_)\n",
    "\n",
    "print(dt.tree_.max_depth)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = dt.predict(X_embedding)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   leave one out mean_absolute_error:  15.591118898940694\n",
      "2   leave one out mean_absolute_error:  16.02678036503543\n",
      "3   leave one out mean_absolute_error:  17.835557836711114\n",
      "4   leave one out mean_absolute_error:  18.85099993459043\n",
      "5   leave one out mean_absolute_error:  18.925804692807525\n",
      "6   leave one out mean_absolute_error:  19.98473175914705\n",
      "7   leave one out mean_absolute_error:  20.178194729003028\n",
      "8   leave one out mean_absolute_error:  23.087347361170988\n",
      "9   leave one out mean_absolute_error:  23.851762332995698\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "for i in range(1, 10):\n",
    "    dt = tree.DecisionTreeRegressor(min_samples_leaf=i)\n",
    "    scores_dt = cross_val_score(dt, X_embedding, y, cv=loo.split(X_embedding),\n",
    "                        scoring='neg_mean_absolute_error')\n",
    "    print(i, '  leave one out mean_absolute_error: ', np.mean(-scores_dt))\n",
    "    errors[i] = np.mean(-scores_dt)\n",
    "#worse than one hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9743565276557459\n",
      "[2.32381481e-02 0.00000000e+00 1.49578013e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.76588362e-02 0.00000000e+00\n",
      " 4.71891935e-05 0.00000000e+00 3.95760832e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.27461607e-04 3.54794994e-04 0.00000000e+00 3.70985446e-04\n",
      " 1.05604776e-02 0.00000000e+00 0.00000000e+00 1.97782982e-05\n",
      " 4.16989289e-04 7.81581413e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 7.85060941e-03\n",
      " 0.00000000e+00 8.30422129e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.27126870e-06 1.95436981e-02 1.64625955e-05 4.61460586e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.51262869e-03 4.56774166e-04\n",
      " 0.00000000e+00 4.39196942e-04 1.94283966e-03 0.00000000e+00\n",
      " 7.03227437e-04 0.00000000e+00 2.20703662e-01 0.00000000e+00\n",
      " 6.75102467e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.61618163e-04 0.00000000e+00\n",
      " 6.36859711e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.93971047e-04 0.00000000e+00 0.00000000e+00 3.61244330e-06\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00483000e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.47123491e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.31372804e-01 0.00000000e+00 6.67714742e-06 0.00000000e+00\n",
      " 9.08975744e-05 3.88897129e-05 0.00000000e+00 0.00000000e+00\n",
      " 3.34089028e-06 9.82341822e-05 0.00000000e+00 1.58251887e-06\n",
      " 1.91819638e-03 0.00000000e+00 4.31489440e-04 0.00000000e+00\n",
      " 4.10009598e-04 3.32662472e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.55227815e-03 1.58836289e-02 9.44231247e-06\n",
      " 0.00000000e+00 0.00000000e+00 3.17739169e-01 0.00000000e+00\n",
      " 0.00000000e+00 1.31416728e-06 0.00000000e+00 9.82163731e-03\n",
      " 0.00000000e+00 0.00000000e+00 2.31775585e-03 0.00000000e+00\n",
      " 1.11453895e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.86639230e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.45169770e-04 6.48507624e-08 2.61411043e-08 5.01470984e-04\n",
      " 0.00000000e+00 0.00000000e+00 2.00566570e-05 7.70436371e-03\n",
      " 5.23496748e-05 4.97454697e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 6.66619703e-04 0.00000000e+00\n",
      " 0.00000000e+00 7.10717203e-07 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.02527435e-04 2.47314200e-06 1.31036343e-05\n",
      " 1.29406988e-03 0.00000000e+00 8.56180415e-05 3.39520198e-04\n",
      " 0.00000000e+00 1.18908215e-05 1.62204535e-09 0.00000000e+00\n",
      " 6.31095854e-04 0.00000000e+00 0.00000000e+00 2.64548739e-02\n",
      " 0.00000000e+00 3.56318417e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.38450205e-04 0.00000000e+00\n",
      " 8.60415676e-04 0.00000000e+00 0.00000000e+00 3.71560428e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.51058596e-04\n",
      " 0.00000000e+00 0.00000000e+00 6.28889002e-06 0.00000000e+00\n",
      " 1.81688978e-04]\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.394016166358324"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best hyperparameter: min_samples_leaf = 1, max_depth = 20\n",
    "dt = tree.DecisionTreeRegressor(min_samples_leaf = 1, max_depth=20)\n",
    "dt.fit(X_embedding,y)\n",
    "print(dt.score(X_embedding,y))\n",
    "\n",
    "tree.export_graphviz(dt,\n",
    "    out_file='embedding_tree.dot') \n",
    "\n",
    "print(dt.feature_importances_)\n",
    "\n",
    "print(dt.tree_.max_depth)\n",
    "\n",
    "y_pred = dt.predict(X_embedding)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_in = open(\"filler_vectors35.pickle\",\"rb\")\n",
    "filler_vectors = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"matrix_vectors35.pickle\",\"rb\")\n",
    "matrix_vectors = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "-0.5916339233517647\n",
      "-0.15449611842632294\n",
      "2.0\n",
      "-0.5916339233517647\n",
      "-0.15449611842632294\n",
      "5.0\n",
      "-0.5916339233517647\n",
      "-0.15449611842632294\n",
      "5.0\n",
      "-0.5916339233517647\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "-0.5916339233517647\n",
      "-0.15449611842632294\n",
      "10.0\n",
      "-0.5271478295326233\n",
      "0.17776067554950714\n",
      "20.0\n",
      "-0.5271478295326233\n",
      "0.17776067554950714\n",
      "30.0\n",
      "-0.5271478295326233\n",
      "0.17776067554950714\n",
      "40.0\n",
      "-0.5271478295326233\n",
      "0.17776067554950714\n",
      "0.0\n",
      "-0.5271478295326233\n",
      "0.17776067554950714\n",
      "0.0\n",
      "-1.4655009508132935\n",
      "0.0698855766095221\n",
      "1.0\n",
      "-1.4655009508132935\n",
      "0.0698855766095221\n",
      "7.0\n",
      "-1.4655009508132935\n",
      "0.0698855766095221\n",
      "1.0\n",
      "-1.4655009508132935\n",
      "0.0698855766095221\n",
      "7.0\n",
      "-1.4655009508132935\n",
      "0.0698855766095221\n",
      "0.0\n",
      "-0.7700728923082352\n",
      "0.24411192536354065\n",
      "0.5\n",
      "-0.7700728923082352\n",
      "0.24411192536354065\n",
      "0.5\n",
      "-0.7700728923082352\n",
      "0.24411192536354065\n",
      "0.5\n",
      "-0.7700728923082352\n",
      "0.24411192536354065\n",
      "0.5\n",
      "-0.7700728923082352\n",
      "0.24411192536354065\n",
      "0.5\n",
      "-0.7700728923082352\n",
      "0.24411192536354065\n",
      "0.5\n",
      "-0.7700728923082352\n",
      "0.24411192536354065\n",
      "0.05\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.05\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.1\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.1\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.25\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.25\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.5\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.5\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "1.0\n",
      "-0.06448161602020264\n",
      "0.16229432821273804\n",
      "2.5\n",
      "-0.06448161602020264\n",
      "0.16229432821273804\n",
      "4.0\n",
      "-0.06448161602020264\n",
      "0.16229432821273804\n",
      "1.0\n",
      "-0.06448161602020264\n",
      "0.16229432821273804\n",
      "2.5\n",
      "-0.06448161602020264\n",
      "0.16229432821273804\n",
      "4.0\n",
      "-0.06448161602020264\n",
      "0.16229432821273804\n",
      "5.5\n",
      "-0.06448161602020264\n",
      "0.16229432821273804\n",
      "0.0\n",
      "-0.06448161602020264\n",
      "0.16229432821273804\n",
      "0.27\n",
      "-0.9934011697769165\n",
      "0.24379952251911163\n",
      "0.55\n",
      "-0.9934011697769165\n",
      "0.24379952251911163\n",
      "1.1\n",
      "-0.9934011697769165\n",
      "0.24379952251911163\n",
      "2.2\n",
      "-0.9934011697769165\n",
      "0.24379952251911163\n",
      "0.0\n",
      "-0.9934011697769165\n",
      "0.24379952251911163\n",
      "0.27\n",
      "-0.9934011697769165\n",
      "0.24379952251911163\n",
      "0.55\n",
      "-0.9934011697769165\n",
      "0.24379952251911163\n",
      "1.1\n",
      "-0.9934011697769165\n",
      "0.24379952251911163\n",
      "2.2\n",
      "-0.9934011697769165\n",
      "0.24379952251911163\n",
      "0.4\n",
      "-1.4655009508132935\n",
      "-0.21291788667440414\n",
      "0.6\n",
      "-1.4655009508132935\n",
      "-0.21291788667440414\n",
      "0.8\n",
      "-1.4655009508132935\n",
      "-0.21291788667440414\n",
      "1.0\n",
      "-1.4655009508132935\n",
      "-0.21291788667440414\n",
      "2.0\n",
      "-1.4655009508132935\n",
      "-0.21291788667440414\n",
      "3.0\n",
      "-1.4655009508132935\n",
      "-0.21291788667440414\n",
      "4.0\n",
      "-1.4655009508132935\n",
      "-0.21291788667440414\n",
      "5.0\n",
      "-1.4655009508132935\n",
      "-0.21291788667440414\n",
      "0.2\n",
      "-1.4655009508132935\n",
      "-0.21291788667440414\n",
      "0.0\n",
      "-1.4655009508132935\n",
      "-0.21291788667440414\n",
      "0.0\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.05\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.25\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.5\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.75\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.05\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.1\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.15\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.25\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.5\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "0.75\n",
      "-0.06448161602020264\n",
      "-0.15449611842632294\n",
      "5.0\n",
      "-0.9901455640792847\n",
      "0.07952114194631577\n",
      "5.0\n",
      "-0.9901455640792847\n",
      "0.14900214970111847\n",
      "5.0\n",
      "-0.9901455640792847\n",
      "0.08951891958713531\n",
      "5.0\n",
      "-0.9901455640792847\n",
      "0.08641987293958664\n",
      "5.0\n",
      "-0.9901455640792847\n",
      "0.11454272270202637\n",
      "10.0\n",
      "-0.9901455640792847\n",
      "0.07952114194631577\n",
      "10.0\n",
      "-0.9901455640792847\n",
      "0.14900214970111847\n",
      "10.0\n",
      "-0.9901455640792847\n",
      "0.08951891958713531\n",
      "10.0\n",
      "-0.9901455640792847\n",
      "0.08641987293958664\n",
      "10.0\n",
      "-0.9901455640792847\n",
      "0.11454272270202637\n",
      "0.0\n",
      "-0.9901455640792847\n",
      "0.5279211401939392\n",
      "0.0\n",
      "-0.9901455640792847\n",
      "0.5279211401939392\n",
      "4.0\n",
      "-0.2480307947844267\n",
      "0.04172765836119652\n",
      "6.0\n",
      "-0.2480307947844267\n",
      "0.04172765836119652\n",
      "0.0\n",
      "-0.2480307947844267\n",
      "0.04172765836119652\n",
      "2.5\n",
      "-1.1583880186080933\n",
      "0.4902346432209015\n",
      "5.0\n",
      "-1.1583880186080933\n",
      "0.4902346432209015\n",
      "7.5\n",
      "-1.1583880186080933\n",
      "0.4902346432209015\n",
      "0.0\n",
      "-1.1583880186080933\n",
      "0.4902346432209015\n",
      "0.05\n",
      "-0.9805150330066681\n",
      "-0.15449611842632294\n",
      "0.05\n",
      "-0.9192309826612473\n",
      "-0.15449611842632294\n",
      "0.5\n",
      "-0.9805150330066681\n",
      "-0.15449611842632294\n",
      "0.5\n",
      "-0.9192309826612473\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "-0.9805150330066681\n",
      "-0.15449611842632294\n",
      "0.01\n",
      "-0.9805150330066681\n",
      "0.24411192536354065\n",
      "0.05\n",
      "-0.9805150330066681\n",
      "0.24411192536354065\n",
      "0.0\n",
      "-0.9805150330066681\n",
      "0.24411192536354065\n",
      "0.0\n",
      "-0.9192309826612473\n",
      "-0.15449611842632294\n",
      "0.01\n",
      "-0.9192309826612473\n",
      "0.24411192536354065\n",
      "0.05\n",
      "-0.9192309826612473\n",
      "0.24411192536354065\n",
      "0.0\n",
      "-0.9192309826612473\n",
      "0.24411192536354065\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "2.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "3.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "4.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-2.2065484523773193\n",
      "-0.033773377537727356\n",
      "5.0\n",
      "-2.2065484523773193\n",
      "-0.030359299232562382\n",
      "25.0\n",
      "-2.2065484523773193\n",
      "-0.06882751484711964\n",
      "20.0\n",
      "-2.2065484523773193\n",
      "-0.13893578946590424\n",
      "0.0\n",
      "-2.2065484523773193\n",
      "-0.07099425792694092\n",
      "11.0\n",
      "-2.3567590713500977\n",
      "-0.15449611842632294\n",
      "17.0\n",
      "-2.3567590713500977\n",
      "-0.15449611842632294\n",
      "26.0\n",
      "-2.3567590713500977\n",
      "-0.15449611842632294\n",
      "4.0\n",
      "-2.3567590713500977\n",
      "-0.15449611842632294\n",
      "9.0\n",
      "-2.3567590713500977\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "-0.15449611842632294\n",
      "0.5\n",
      "-0.7392863035202026\n",
      "0.28239307552576065\n",
      "1.0\n",
      "-0.7392863035202026\n",
      "-0.15449611842632294\n",
      "1.0\n",
      "-0.7392863035202026\n",
      "0.28239307552576065\n",
      "2.0\n",
      "-0.7392863035202026\n",
      "0.28239307552576065\n",
      "0.0\n",
      "-0.7392863035202026\n",
      "0.28239307552576065\n",
      "1.5\n",
      "-0.3161190450191498\n",
      "-0.15449611842632294\n",
      "12.1\n",
      "-0.3161190450191498\n",
      "-0.15449611842632294\n",
      "17.4\n",
      "-0.3161190450191498\n",
      "-0.15449611842632294\n",
      "2.1\n",
      "-0.3161190450191498\n",
      "-0.15449611842632294\n",
      "6.7\n",
      "-0.3161190450191498\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "-0.3161190450191498\n",
      "-0.15449611842632294\n",
      "0.1\n",
      "-0.9805150330066681\n",
      "-0.15449611842632294\n",
      "0.2\n",
      "-0.9805150330066681\n",
      "-0.15449611842632294\n",
      "0.3\n",
      "-0.9805150330066681\n",
      "-0.15449611842632294\n",
      "0.4\n",
      "-0.9805150330066681\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "-0.9805150330066681\n",
      "-0.15449611842632294\n",
      "2.0\n",
      "-0.46800947189331055\n",
      "-0.15449611842632294\n",
      "3.0\n",
      "-0.46800947189331055\n",
      "-0.15449611842632294\n",
      "4.0\n",
      "-0.46800947189331055\n",
      "-0.15449611842632294\n",
      "7.0\n",
      "-0.46800947189331055\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "-0.46800947189331055\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "0.09912572428584099\n",
      "-0.15449611842632294\n",
      "0.091\n",
      "0.09912572428584099\n",
      "-0.15449611842632294\n",
      "1.0\n",
      "-0.5599599480628967\n",
      "-0.15449611842632294\n",
      "0.0\n",
      "-0.5599599480628967\n",
      "-0.15449611842632294\n",
      "0.3\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "0.04172765836119652\n",
      "10.0\n",
      "-2.3567590713500977\n",
      "0.04172765836119652\n",
      "2.5\n",
      "-2.3567590713500977\n",
      "0.04172765836119652\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.04172765836119652\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.04172765836119652\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "-0.026956902351230383\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "-0.026956902351230383\n",
      "10.0\n",
      "-2.3567590713500977\n",
      "0.0698855766095221\n",
      "10.0\n",
      "-2.3567590713500977\n",
      "0.0698855766095221\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.0698855766095221\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.0698855766095221\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.0698855766095221\n",
      "0.1\n",
      "-2.3567590713500977\n",
      "0.24379952251911163\n",
      "0.5\n",
      "-2.3567590713500977\n",
      "0.24379952251911163\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.24379952251911163\n",
      "6.0\n",
      "-2.3567590713500977\n",
      "0.423273429274559\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.423273429274559\n",
      "10.0\n",
      "-2.3567590713500977\n",
      "0.12661251425743103\n",
      "10.0\n",
      "-2.3567590713500977\n",
      "0.12661251425743103\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.12661251425743103\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "0.21205393970012665\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "0.21205393970012665\n",
      "2.0\n",
      "-2.3567590713500977\n",
      "0.21205393970012665\n",
      "2.0\n",
      "-2.3567590713500977\n",
      "0.21205393970012665\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.21205393970012665\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.21205393970012665\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.21205393970012665\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.21205393970012665\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "2.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "0.17041099999999998\n",
      "-2.3567590713500977\n",
      "0.24379952251911163\n",
      "0.393777\n",
      "-2.3567590713500977\n",
      "0.24379952251911163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.701754\n",
      "-2.3567590713500977\n",
      "0.24379952251911163\n",
      "0.994566\n",
      "-2.3567590713500977\n",
      "0.24379952251911163\n",
      "1.390543\n",
      "-2.3567590713500977\n",
      "0.24379952251911163\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.24379952251911163\n",
      "2.1\n",
      "-2.3567590713500977\n",
      "0.12661251425743103\n",
      "4.75\n",
      "-2.3567590713500977\n",
      "0.12661251425743103\n",
      "7.26\n",
      "-2.3567590713500977\n",
      "0.12661251425743103\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.12661251425743103\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "3.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "7.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "9.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "3.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "7.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "9.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "6.0\n",
      "-2.3567590713500977\n",
      "0.0698855766095221\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.0698855766095221\n",
      "0.5\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "2.0\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "4.0\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "0.1\n",
      "-2.3567590713500977\n",
      "-0.13117187097668648\n",
      "0.1\n",
      "-2.3567590713500977\n",
      "-0.15449611842632294\n",
      "0.3\n",
      "-2.3567590713500977\n",
      "-0.13117187097668648\n",
      "0.5\n",
      "-2.3567590713500977\n",
      "-0.13117187097668648\n",
      "0.7\n",
      "-2.3567590713500977\n",
      "-0.13117187097668648\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "-0.13117187097668648\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "4.000307\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "6.250293\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "0.826118\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "1.6396669999999998\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "4.000307\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "4.7619050000000005\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "6.250293\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "0.826118\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "-0.21291788667440414\n",
      "1.0\n",
      "-0.2655276531974475\n",
      "-0.09491003770381212\n",
      "1.0\n",
      "-0.2655276531974475\n",
      "-0.5020061912946403\n",
      "0.0\n",
      "-0.2655276531974475\n",
      "-0.5020061912946403\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "-0.5020061912946403\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "-0.9921177625656128\n",
      "2.0\n",
      "-2.3567590713500977\n",
      "-0.5020061912946403\n",
      "3.0\n",
      "-2.3567590713500977\n",
      "-0.5020061912946403\n",
      "3.0\n",
      "-2.3567590713500977\n",
      "-0.9921177625656128\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "-0.9921177625656128\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "-0.9921177625656128\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "-0.5020061912946403\n",
      "1.0\n",
      "-2.3567590713500977\n",
      "0.09443836659193039\n",
      "2.0\n",
      "-2.3567590713500977\n",
      "0.09443836659193039\n",
      "5.0\n",
      "-2.3567590713500977\n",
      "0.09443836659193039\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.09443836659193039\n",
      "1.0\n",
      "-0.8663437366485596\n",
      "0.3392244502902031\n",
      "3.0\n",
      "-0.8663437366485596\n",
      "0.3392244502902031\n",
      "5.0\n",
      "-0.8663437366485596\n",
      "0.3392244502902031\n",
      "10.0\n",
      "-0.8663437366485596\n",
      "0.3392244502902031\n",
      "10.0\n",
      "-0.8663437366485596\n",
      "0.3392244502902031\n",
      "0.0\n",
      "-0.8663437366485596\n",
      "0.3392244502902031\n",
      "10.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "20.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "30.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "40.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "50.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "6.25\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "15.37\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-2.3567590713500977\n",
      "0.6318838596343994\n",
      "2.0\n",
      "-1.1583880186080933\n",
      "0.6755830645561218\n",
      "2.0\n",
      "-1.1583880186080933\n",
      "0.6318838596343994\n",
      "3.0\n",
      "-1.1583880186080933\n",
      "0.6755830645561218\n",
      "0.0\n",
      "-1.1583880186080933\n",
      "0.6755830645561218\n",
      "0.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "10.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "15.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "20.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "7.5\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "10.0\n",
      "-0.10745626245625317\n",
      "0.6318838596343994\n",
      "15.0\n",
      "-0.10745626245625317\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-0.10745626245625317\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.10745626245625317\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "1.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "10.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "3.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "10.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.6776256561279297\n",
      "0.6318838596343994\n",
      "2.5\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "10.0\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "15.0\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "20.0\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "2.5\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "10.0\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "15.0\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "20.0\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.16202975809574127\n",
      "0.6318838596343994\n",
      "0.0\n",
      "0.024908803403377533\n",
      "0.6318838596343994\n",
      "10.0\n",
      "0.024908803403377533\n",
      "0.6318838596343994\n",
      "15.0\n",
      "0.024908803403377533\n",
      "0.6318838596343994\n",
      "5.0\n",
      "0.024908803403377533\n",
      "0.6318838596343994\n",
      "0.0\n",
      "0.024908803403377533\n",
      "0.6318838596343994\n",
      "10.0\n",
      "0.024908803403377533\n",
      "0.6318838596343994\n",
      "15.0\n",
      "0.024908803403377533\n",
      "0.6318838596343994\n",
      "5.0\n",
      "0.024908803403377533\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "10.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "20.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "30.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "40.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "50.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-0.32224714507659274\n",
      "0.6318838596343994\n",
      "10.0\n",
      "-0.32224714507659274\n",
      "0.6318838596343994\n",
      "15.0\n",
      "-0.32224714507659274\n",
      "0.6318838596343994\n",
      "20.0\n",
      "-0.32224714507659274\n",
      "0.6318838596343994\n",
      "25.0\n",
      "-0.32224714507659274\n",
      "0.6318838596343994\n",
      "30.0\n",
      "-0.32224714507659274\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.32224714507659274\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "10.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "20.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "30.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "40.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "50.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "0.5\n",
      "-0.36956632137298584\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.36956632137298584\n",
      "0.6318838596343994\n",
      "1.0\n",
      "-0.36956632137298584\n",
      "0.6318838596343994\n",
      "2.0\n",
      "-0.36956632137298584\n",
      "0.6318838596343994\n",
      "28.6\n",
      "-0.14792417486508688\n",
      "0.6318838596343994\n",
      "28.6\n",
      "-0.14792417486508688\n",
      "0.6318838596343994\n",
      "28.6\n",
      "-0.14792417486508688\n",
      "0.6318838596343994\n",
      "28.6\n",
      "-0.14792417486508688\n",
      "0.6318838596343994\n",
      "28.6\n",
      "-0.14792417486508688\n",
      "0.6318838596343994\n",
      "28.6\n",
      "-0.14792417486508688\n",
      "0.6318838596343994\n",
      "28.6\n",
      "-0.14792417486508688\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.14792417486508688\n",
      "0.6318838596343994\n",
      "0.5\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "2.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "5.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "10.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "15.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.5908986131350199\n",
      "0.6318838596343994\n",
      "0.0\n",
      "-0.24506790190935135\n",
      "0.6318838596343994\n",
      "1.0\n",
      "-0.24506790190935135\n",
      "0.6318838596343994\n",
      "2.0\n",
      "-0.24506790190935135\n",
      "0.6318838596343994\n",
      "0.5\n",
      "-0.36956632137298584\n",
      "0.08100556954741478\n",
      "1.0\n",
      "-0.36956632137298584\n",
      "0.08100556954741478\n",
      "2.0\n",
      "-0.36956632137298584\n",
      "0.08100556954741478\n",
      "3.0\n",
      "-0.36956632137298584\n",
      "0.08100556954741478\n",
      "5.0\n",
      "-0.36956632137298584\n",
      "0.08100556954741478\n",
      "7.0\n",
      "-0.36956632137298584\n",
      "0.08100556954741478\n",
      "10.0\n",
      "-0.36956632137298584\n",
      "0.08100556954741478\n",
      "0.0\n",
      "-0.36956632137298584\n",
      "0.08100556954741478\n",
      "1.0\n",
      "-0.49758725861708325\n",
      "0.08100556954741478\n",
      "1.0\n",
      "-0.49758725861708325\n",
      "0.08100556954741478\n",
      "3.0\n",
      "-0.49758725861708325\n",
      "0.08100556954741478\n",
      "3.0\n",
      "-0.49758725861708325\n",
      "0.08100556954741478\n",
      "5.0\n",
      "-0.49758725861708325\n",
      "0.08100556954741478\n",
      "5.0\n",
      "-0.49758725861708325\n",
      "0.08100556954741478\n",
      "7.0\n",
      "-0.49758725861708325\n",
      "0.08100556954741478\n",
      "7.0\n",
      "-0.49758725861708325\n",
      "0.08100556954741478\n",
      "0.0\n",
      "-0.49758725861708325\n",
      "0.08100556954741478\n",
      "0.0\n",
      "-0.49758725861708325\n",
      "0.08100556954741478\n",
      "1.5\n",
      "-0.5908986131350199\n",
      "0.08100556954741478\n",
      "0.2\n",
      "-0.5908986131350199\n",
      "0.08100556954741478\n",
      "0.5\n",
      "-0.5908986131350199\n",
      "0.08100556954741478\n",
      "1.0\n",
      "-0.5908986131350199\n",
      "0.08100556954741478\n",
      "1.5\n",
      "-0.5908986131350199\n",
      "0.08100556954741478\n",
      "1.5\n",
      "-0.5908986131350199\n",
      "0.08100556954741478\n",
      "1.5\n",
      "-0.5908986131350199\n",
      "0.08100556954741478\n",
      "1.5\n",
      "-0.5908986131350199\n",
      "0.08100556954741478\n",
      "0.0\n",
      "-0.5908986131350199\n",
      "0.08100556954741478\n",
      "5.0\n",
      "-1.4655009508132935\n",
      "0.08100556954741478\n",
      "10.0\n",
      "-1.4655009508132935\n",
      "0.08100556954741478\n",
      "15.0\n",
      "-1.4655009508132935\n",
      "0.08100556954741478\n",
      "0.0\n",
      "-1.4655009508132935\n",
      "0.08100556954741478\n",
      "5.0\n",
      "-0.024797560647130013\n",
      "0.08100556954741478\n",
      "10.0\n",
      "-0.024797560647130013\n",
      "0.08100556954741478\n",
      "0.0\n",
      "-0.024797560647130013\n",
      "0.08100556954741478\n",
      "0.5\n",
      "-1.4655009508132935\n",
      "0.08100556954741478\n",
      "1.0\n",
      "-1.4655009508132935\n",
      "0.08100556954741478\n",
      "3.0\n",
      "-1.4655009508132935\n",
      "0.08100556954741478\n",
      "4.0\n",
      "-1.4655009508132935\n",
      "0.08100556954741478\n",
      "0.0\n",
      "-1.4655009508132935\n",
      "0.08100556954741478\n",
      "0.0\n",
      "-0.2293734923005104\n",
      "0.08100556954741478\n",
      "2.0\n",
      "-0.2293734923005104\n",
      "0.08100556954741478\n",
      "4.0\n",
      "-0.2293734923005104\n",
      "0.08100556954741478\n",
      "6.0\n",
      "-0.2293734923005104\n",
      "0.08100556954741478\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "df_embedding = pd.DataFrame(data=df[['matrix','filler','filler percentage']], copy=True)\n",
    "\n",
    "df_matrix_embedding = pd.DataFrame(data=matrix_vectors)\n",
    "df_matrix_embedding = df_matrix_embedding.T\n",
    "\n",
    "df_filler_embedding = pd.DataFrame(data=filler_vectors)\n",
    "df_filler_embedding = df_filler_embedding.T\n",
    "\n",
    "df_embedding = pd.merge(left=df_embedding, right=df_matrix_embedding, left_on='matrix', \n",
    "                        right_index=True, how='left', validate='many_to_one')\n",
    "df_embedding = df_embedding.rename(columns= lambda name: 'matrix_embedding_'+str(name) if isinstance(name, int) else name)\n",
    "\n",
    "df_embedding = pd.merge(left=df_embedding, right=df_filler_embedding, left_on='filler',\n",
    "                       right_index=True, how='left', validate='many_to_one')\n",
    "df_embedding = df_embedding.rename(columns= lambda name: 'filler_embedding_'+str(name) if isinstance(name, int) else name)\n",
    "\n",
    "#check the correctness of df_embedding\n",
    "compare_df = []\n",
    "compare_matrix_eb = []\n",
    "compare_filler_eb = []\n",
    "for index, row in df_embedding.iterrows():\n",
    "    compare_df.append(row['filler percentage']==df.iloc[index]['filler percentage'])\n",
    "    print(row['filler percentage'])\n",
    "    compare_matrix_eb.append(row['matrix_embedding_19']== matrix_vectors[row['matrix']][19])\n",
    "    print(row['matrix_embedding_19'])\n",
    "    compare_filler_eb.append(row['filler_embedding_30']== filler_vectors[row['filler']][30])\n",
    "    print(row['filler_embedding_30'])\n",
    "print(all(compare_df))\n",
    "print(all(compare_matrix_eb))\n",
    "print(all(compare_filler_eb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X_embedding\n",
    "df_embedding_dropped = df_embedding.drop(labels=['matrix', 'filler'], axis='columns')\n",
    "X_embedding = df_embedding_dropped.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression r2:  0.9215392606917364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.111225806268232"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_embedding, y)\n",
    "R_2 = reg.score(X_embedding, y)\n",
    "print('linear regression r2: ', R_2)\n",
    "y_pred = reg.predict(X_embedding)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mean absolute error: 2898965286.6908274\n",
      "average y true values: 107.94295911331595\n"
     ]
    }
   ],
   "source": [
    "#loo for linear regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "lr = LinearRegression()\n",
    "scores_lr = cross_val_score(lr, X_embedding, y, cv=loo.split(X_embedding), \n",
    "                             scoring='neg_mean_absolute_error')\n",
    "print('average mean absolute error:', np.mean(-scores_lr))\n",
    "print('average y true values:', np.mean(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-10 average mean absolute error: 17.80948778633193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804536e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.799273e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.802515e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.802515e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801650e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.803367e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.831369e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.900832e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.009479e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.797620e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.808196e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.796931e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.796155e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.796931e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.796155e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.769139e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.764951e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.764951e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.764951e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.764951e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.764951e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.764951e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.796025e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.796025e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.790285e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.790285e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.799289e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.799289e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.790250e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.790250e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.794808e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.794808e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.824719e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.818637e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.818692e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.824719e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.818637e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.820249e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.818463e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.819561e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.847533e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.835250e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.838750e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.834132e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.846992e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.848308e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.842925e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.838660e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.827660e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.826983e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.825257e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.831542e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.831259e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.823517e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.812390e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.816742e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.811548e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.830169e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.834141e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801247e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801247e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801982e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.791744e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.791955e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.796627e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.802526e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801912e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.803606e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.794207e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.790387e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.790703e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.773033e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.799987e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.802278e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.791558e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.778499e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.773017e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.786963e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.807449e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.780056e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.772573e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804932e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804932e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.820539e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.826469e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.807180e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.795516e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.787219e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.787220e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.795106e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.810773e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801964e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801937e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.811402e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806211e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.776025e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.766161e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.770142e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.810200e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.773672e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.774808e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.772542e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.808405e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.809390e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.807411e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800664e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.805176e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806346e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.722050e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.871905e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800991e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.952760e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800176e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.805597e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.834212e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.797466e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801246e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.813325e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.789202e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.793922e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.786244e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.789908e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.791071e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.777079e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806918e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.835983e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.789527e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.792391e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785377e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.814821e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.807539e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804520e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806912e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.807779e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.788789e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.784456e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.793969e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.790012e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.787781e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.788491e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.789414e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801825e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.807742e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.841097e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.833213e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.840826e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.802947e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.791727e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.799808e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.796038e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.813287e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.817465e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.817465e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.775149e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.775149e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785874e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785874e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.810228e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.835206e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.836744e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.835274e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.771360e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.790675e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.789021e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.789021e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.831706e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800702e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800702e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800702e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.814655e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806436e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806436e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804953e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804953e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.803131e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.803131e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.810356e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.810356e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.811422e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.805045e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800954e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.802239e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.834730e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.838864e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.829651e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.838166e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.830069e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.832944e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.814480e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801741e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785997e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.825627e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.817302e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806193e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.807081e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804636e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806906e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.793456e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.813965e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806193e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.807836e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804636e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800051e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.793456e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.784259e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804990e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.834948e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.837875e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.830478e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.812592e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.839968e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.836283e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.815310e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.834802e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.835386e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.833113e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.830716e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.840043e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.808120e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.803393e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.835062e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.820934e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.808120e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.809837e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806802e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.836324e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.841357e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.812609e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.803097e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.802080e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804894e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.839790e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.807761e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801537e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.822820e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.825814e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.842083e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.814827e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.802869e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.795155e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.784785e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.811312e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.826201e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.821990e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.817630e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.813595e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.813595e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.826410e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.805326e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.836613e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.907167e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.005700e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.158300e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.819293e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800346e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.820321e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.814678e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.769753e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.798359e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.770550e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.770689e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.813592e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.830125e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.861425e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.893395e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.816876e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.821566e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.819595e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.854726e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800289e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.782081e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.810810e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.809701e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.832468e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.817089e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.813032e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.832468e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.813032e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.813032e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.799832e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801898e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804853e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.823203e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.867860e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.911455e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.801898e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.805914e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.823203e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.867860e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.908849e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.793781e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.793781e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.788672e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.828186e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.863213e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806926e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.792137e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.828186e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.863213e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.806926e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785820e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.834888e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.934217e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.051246e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.228103e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.451225e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.800394e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.833601e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.868717e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.911915e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.965302e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.040720e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.782925e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.793665e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.832294e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.925910e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.058328e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.224790e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.458481e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.779781e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.774715e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.791188e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.789551e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.005526e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.005526e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.005526e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.005526e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.005526e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.005526e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.005526e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.799303e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.789638e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.793767e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.804411e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.836740e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.882294e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.788030e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.787414e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.792016e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.789936e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.787502e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.784468e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.782803e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.779182e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.777224e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.789195e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.788185e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785788e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.774764e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.774764e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.778125e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.778125e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.775149e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.775149e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.775626e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.775626e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.773943e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.773943e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.777482e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.777813e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.782013e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.774687e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785395e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785395e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785395e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785395e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.781964e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.782265e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-11 average mean absolute error: 17.809284139776516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.766227e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.772647e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.796246e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.788417e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.794665e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.797242e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.793281e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.798957e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.791021e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.785006e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.805446e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.779722e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.781289e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.780845e-17\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.779935e-17\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "for alpha in [1e-10, 1e-9, 1e-8,1e-7, 1e-6, 1e-5,1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    scores_ridge = cross_val_score(ridge, X_embedding, y, cv=loo.split(X_embedding), \n",
    "                                 scoring='neg_mean_absolute_error')\n",
    "    print(alpha, 'average mean absolute error:', np.mean(-scores_ridge))\n",
    "#best alpha=1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mean absolute error: 17.80948778633193\n"
     ]
    }
   ],
   "source": [
    "#linear regression was overfitting, try ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=1e-10)\n",
    "scores_ridge = cross_val_score(ridge, X_embedding, y, cv=loo.split(X_embedding), \n",
    "                                 scoring='neg_mean_absolute_error')\n",
    "print('average mean absolute error:', np.mean(-scores_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.111225901392876"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1e-10)\n",
    "ridge.fit(X_embedding, y)\n",
    "y_pred = ridge.predict(X_embedding)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.394016166358324\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(383, 71)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dt = tree.DecisionTreeRegressor(max_depth=13, min_samples_leaf=2)\n",
    "dt=tree.DecisionTreeRegressor()\n",
    "dt.fit(X_embedding,y)\n",
    "y_pred = dt.predict(X_embedding)\n",
    "print(mean_absolute_error(y, y_pred))\n",
    "print(dt.tree_.max_depth)\n",
    "X_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 1   leave one out mean_absolute_error:  15.82837297078708\n",
      "11 2   leave one out mean_absolute_error:  15.537587133437212\n",
      "11 3   leave one out mean_absolute_error:  16.65111437320004\n",
      "11 4   leave one out mean_absolute_error:  20.292188225785885\n",
      "12 1   leave one out mean_absolute_error:  15.481187302739178\n",
      "12 2   leave one out mean_absolute_error:  15.488719406217353\n",
      "12 3   leave one out mean_absolute_error:  16.771209140609034\n",
      "12 4   leave one out mean_absolute_error:  20.127134447648935\n",
      "13 1   leave one out mean_absolute_error:  16.047836515627353\n",
      "13 2   leave one out mean_absolute_error:  15.340608549114828\n",
      "13 3   leave one out mean_absolute_error:  16.971602874517185\n",
      "13 4   leave one out mean_absolute_error:  20.191283910241516\n",
      "14 1   leave one out mean_absolute_error:  16.504205632963174\n",
      "14 2   leave one out mean_absolute_error:  16.131336346807792\n",
      "14 3   leave one out mean_absolute_error:  17.040063989119684\n",
      "14 4   leave one out mean_absolute_error:  20.23838258100771\n",
      "15 1   leave one out mean_absolute_error:  16.550886779429938\n",
      "15 2   leave one out mean_absolute_error:  16.11845801955834\n",
      "15 3   leave one out mean_absolute_error:  16.996585655689007\n",
      "15 4   leave one out mean_absolute_error:  20.1773432100143\n",
      "16 1   leave one out mean_absolute_error:  16.613605714234424\n",
      "16 2   leave one out mean_absolute_error:  16.27160581194455\n",
      "16 3   leave one out mean_absolute_error:  17.12822284996519\n",
      "16 4   leave one out mean_absolute_error:  20.153411072821086\n",
      "17 1   leave one out mean_absolute_error:  16.077520103596918\n",
      "17 2   leave one out mean_absolute_error:  16.13722863187057\n",
      "17 3   leave one out mean_absolute_error:  17.130964315735422\n",
      "17 4   leave one out mean_absolute_error:  20.153411072821086\n",
      "18 1   leave one out mean_absolute_error:  16.077235612495958\n",
      "18 2   leave one out mean_absolute_error:  15.88314226090016\n",
      "18 3   leave one out mean_absolute_error:  16.895365154064404\n",
      "18 4   leave one out mean_absolute_error:  20.153411072821086\n",
      "19 1   leave one out mean_absolute_error:  16.72115531473704\n",
      "19 2   leave one out mean_absolute_error:  16.458520075978488\n",
      "19 3   leave one out mean_absolute_error:  16.994532121492604\n",
      "19 4   leave one out mean_absolute_error:  20.177343210014296\n",
      "20 1   leave one out mean_absolute_error:  15.978424954423723\n",
      "20 2   leave one out mean_absolute_error:  15.972775169337933\n",
      "20 3   leave one out mean_absolute_error:  16.931714255252395\n",
      "20 4   leave one out mean_absolute_error:  20.153411072821086\n"
     ]
    }
   ],
   "source": [
    "#best hyperparameters max_depth=13, min_samples_leaf = 2\n",
    "errors = np.zeros((10, 4))\n",
    "for i in range(11, 21):\n",
    "    for j in range(1, 5):\n",
    "        dt = tree.DecisionTreeRegressor(max_depth=i, min_samples_leaf=j)\n",
    "        scores_dt = cross_val_score(dt, X_embedding, y, cv=loo.split(X_embedding),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "        print(i, j, '  leave one out mean_absolute_error: ', np.mean(-scores_dt))\n",
    "        errors[i-11, j-1] = np.mean(-scores_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MWCNT': array([ 0.55086416, -4.51871109,  1.6920799 ,  1.56675076,  0.42575949,\n",
       "        -0.75069565, -1.20676959,  1.44917583,  0.25179839,  0.12424786]),\n",
       " 'PANI-organoclay': array([-0.43800949, -1.8286491 ,  1.20080251,  0.88750005,  0.59499562,\n",
       "         0.21101476,  0.22231548,  0.58128893, -0.23783574, -0.82252178]),\n",
       " 'Na-montmorillonite': array([-0.78271002, -1.93688473,  0.86539462,  1.07374999,  0.69783625,\n",
       "         0.35308173, -0.62549374, -0.09889354, -0.98820141, -0.40138971]),\n",
       " 'SWCNT': array([-0.32910991, -1.86763716,  1.35645902,  0.74885857,  0.3345376 ,\n",
       "        -0.18298559, -0.43751082,  0.41648161,  0.82546049, -0.88708031]),\n",
       " 'graphene platelet': array([ 0.26536921, -1.83385324,  1.17463055,  1.20818263,  2.00783521,\n",
       "         1.21362227, -0.55061544,  1.53515393, -2.04789037, -0.10040238]),\n",
       " 'graphene': array([ 1.31299651, -1.72147596,  1.7397002 ,  1.49586642,  2.23058581,\n",
       "         2.17566586, -0.20950468,  1.98398519, -3.15768814,  0.43581003]),\n",
       " 'graphene oxide': array([ 1.24591959, -1.41075975,  1.72847444,  1.10619298,  1.58916032,\n",
       "         2.02553988, -1.14541522,  1.48053712, -3.50186634, -0.41970107]),\n",
       " 'CLO30B': array([-0.78042984, -1.74215496,  1.09852219,  1.18551469,  0.6749981 ,\n",
       "         0.14704737, -0.37619564,  0.72968721, -0.60199136, -1.03048432]),\n",
       " 'NAN': array([-0.51303709, -1.05302835,  1.19605231,  0.93931299,  0.53824633,\n",
       "         0.08169177,  0.01202125,  0.44297004, -0.39662087, -0.8430137 ]),\n",
       " 'SEP': array([-0.69111019, -1.23352313,  1.24210382,  0.78132647,  0.44174504,\n",
       "        -0.15369676, -0.01402364,  0.43961495, -0.31212804, -1.13492429]),\n",
       " 'SOMM100': array([-0.57119656, -1.2628026 ,  1.08039939,  0.72726631,  0.43564597,\n",
       "        -0.05226183, -0.03612777,  0.43162143, -0.35772499, -0.87546146]),\n",
       " 'SOMMEE': array([-0.76158708, -2.13131452,  1.2906183 ,  1.24403596,  0.60425359,\n",
       "         0.05869298, -0.07792927,  0.96118426, -0.29680502, -1.18211722]),\n",
       " 'clay': array([-1.1972723 , -4.40273523,  0.71994573,  1.35661709,  1.6785388 ,\n",
       "         0.78963864,  0.04282912,  1.61485028, -1.73039377,  0.50584882]),\n",
       " 'organo-MMT': array([-1.36236566, -3.72520339,  0.49254949,  1.63134882,  0.23325981,\n",
       "         0.57929376, -0.46134639, -0.32941   , -0.59295318, -0.21405641]),\n",
       " 'CaCO3': array([-0.30369809, -2.91639066,  1.81045902,  0.49171075,  0.96872753,\n",
       "         0.07232532,  0.03707575,  1.32025647, -0.08685587, -0.51807022]),\n",
       " 'silica': array([-1.04203296, -4.55780268,  1.1762383 ,  1.01771176,  0.74764138,\n",
       "         1.75780666, -0.33466932,  2.36482096, -0.70686299,  0.37258747]),\n",
       " 'cellulose nanowhiskers': array([-0.35891556, -0.95869201,  1.29623127,  0.27742151,  0.68640058,\n",
       "         0.10976626, -0.78261051, -0.12490551, -1.29617555, -0.89446227]),\n",
       " 'butanol cellulose nanowhiskers': array([-0.38868041, -0.90749892,  1.20790486,  0.26442288,  0.55616962,\n",
       "         0.07415845, -0.77540421, -0.24172273, -1.0539387 , -0.80289736]),\n",
       " 'surfactant cellulose nanowhiskers': array([-0.49693159, -1.62147796,  1.39844676,  0.20193608,  0.66825356,\n",
       "         0.24542768, -1.25946544,  0.05674485, -1.43707074, -0.78506165]),\n",
       " 'surfactant': array([-0.77296364, -2.94704986,  1.60287774,  0.05096521,  0.6319595 ,\n",
       "         0.51675051, -2.2131753 ,  0.42004555, -1.7188611 , -0.5662604 ]),\n",
       " 'CNW': array([-0.66158539, -3.33849549,  1.87631464,  0.70755088,  0.79656237,\n",
       "         0.1246759 , -0.85865641,  0.40714127, -1.09364259, -1.5204078 ]),\n",
       " 'PMMA-g-MWCNT': array([ 0.07140028, -4.63268924,  1.88735729,  1.21610141,  0.15757739,\n",
       "         0.80609563,  0.32760316,  1.99252534, -0.22995934, -0.10646386]),\n",
       " 'Na-MMT': array([-1.78347582, -4.64689326,  0.5258993 ,  1.96469307,  0.4770079 ,\n",
       "         0.65994316, -0.7799972 , -0.65765622, -0.98515049, -0.26702777]),\n",
       " 'PDMS-clay': array([-0.97540867, -3.68104756,  1.20170328,  1.26175207,  1.31912246,\n",
       "         0.46241352, -0.03726377,  1.32341641, -1.06322156, -0.26224366]),\n",
       " 'montmorillonite': array([-0.14218618, -0.70155066,  0.83351117,  0.63843769,  0.65420711,\n",
       "         0.39310557, -0.48616028,  0.18581578, -1.08714592, -0.03635888]),\n",
       " 'TiO2': array([ 0.05075401, -5.47760439,  1.14691186,  1.62704062,  1.14036512,\n",
       "         0.85445631,  0.8136912 ,  1.58604312, -1.38497722,  0.39373428]),\n",
       " 'MMA-MWCNT': array([-0.06009981, -3.81351614,  1.76134074,  0.84840554,  0.24819911,\n",
       "        -0.12764524, -1.76736373,  0.6595741 , -0.51034403, -0.33671248]),\n",
       " 'PMMA-g-expandable graphite': array([ 0.1908531 , -2.41878211,  1.46677905,  0.638566  ,  0.84021284,\n",
       "         1.41432258,  0.35491912,  1.28830125, -2.05174293, -0.95841836]),\n",
       " 'expandable graphite': array([ 0.49031145, -1.25483948,  1.15885124,  0.52512297,  1.31562161,\n",
       "         0.94004042, -0.39860928,  0.66451445, -2.72175586, -1.26903975]),\n",
       " 'expanded graphite': array([ 0.49031145, -1.25483948,  1.15885124,  0.52512297,  1.31562161,\n",
       "         0.94004042, -0.39860928,  0.66451445, -2.72175586, -1.26903975]),\n",
       " 'graphite': array([ 1.17980218, -1.52612293,  0.61339945,  0.42302018,  1.50452328,\n",
       "         1.45744216, -0.2712239 ,  0.92853898, -3.87220573, -1.26305509]),\n",
       " 'ZrO2': array([-0.25793847, -0.92166436,  0.86947924,  0.59708887,  0.20403826,\n",
       "         0.36970782,  0.1360203 ,  0.2678571 , -0.66187114, -0.31909445]),\n",
       " 'organo clay (Closite 20A)': array([-0.88914293, -2.86578715,  0.77526209,  1.09949544,  0.96625401,\n",
       "         0.47069886, -0.04234822,  0.94386993, -0.91762802, -0.0773145 ]),\n",
       " 'PMMA-g-silica': array([-0.72504827, -4.65223503,  1.62943649,  0.9415819 ,  0.31851833,\n",
       "         2.06034678,  0.76365329,  2.4503479 , -0.70929003,  0.01770595]),\n",
       " 'titanium dioxide': array([-0.14396921, -0.34504957,  1.08530813,  0.4138388 ,  0.52512468,\n",
       "        -0.08562495, -0.49371408, -0.10673738, -0.71007052, -0.48286374])}"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"filler_vectors10.pickle\",\"rb\")\n",
    "filler_vectors = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "filler_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bisphenol A PC': array([ 0.19254186, -1.63254824,  1.65980744,  1.34189341,  0.17859112,\n",
       "         0.38662618,  1.01789029,  0.15182979,  0.12017697, -0.49324986]),\n",
       " 'EPDM': array([-0.61325181, -2.00965095,  1.65668488,  1.27910805,  0.62848037,\n",
       "         0.00298446,  0.35616291,  0.47969103,  0.24446543, -1.15096569]),\n",
       " 'epoxy': array([ 1.52049184, -3.90701342,  3.07330513,  0.0843989 ,  2.35595798,\n",
       "         0.42000118,  1.33304811,  1.3662672 , -1.37882268,  0.88977653]),\n",
       " 'SC-15 epoxy': array([ 0.70005244, -2.18085974,  2.32401186,  0.27812884,  1.54064429,\n",
       "         0.16593077,  0.77047026,  0.75336398, -0.96667758,  0.17000002]),\n",
       " 'DGEBA': array([-0.09600299, -0.28693527,  0.44168127,  0.12781978,  0.10768621,\n",
       "        -0.02791941, -0.29781774, -0.02223026, -0.17410693, -0.31919357]),\n",
       " 'PC': array([ 0.31046706, -2.84972262,  2.11279631,  2.45332575, -0.28202781,\n",
       "         0.75617921,  2.4311583 ,  0.24069124,  1.00844741, -0.48942995]),\n",
       " 'PBAT': array([-0.82806438, -3.30043149,  1.34486926,  1.29061043,  0.4274466 ,\n",
       "         0.27409863,  0.94909918,  2.14797282, -0.07459161, -1.05093932]),\n",
       " 'Ethylene vinyl acetate rubber': array([ 0.46446973, -0.4124532 ,  1.58944967,  0.50689273,  0.81526483,\n",
       "         0.51929221, -0.66419256,  0.22123566, -1.20957579, -0.4679241 ]),\n",
       " 'PVC': array([ 0.29875231, -3.45887995,  2.22376394,  0.46497205,  1.38349986,\n",
       "         0.38849828,  0.49898571,  2.22787356,  0.13066773, -0.11259557]),\n",
       " 'epoxy (Epon 815)': array([ 0.69395683, -3.0204283 ,  2.33786398,  0.41300224,  1.30292308,\n",
       "         0.14643026,  0.51020223,  0.89666352, -0.29351965,  0.08652699]),\n",
       " 'epoxy (LY564)': array([ 0.67559689, -2.9252215 ,  2.36097091,  0.54837861,  1.34263605,\n",
       "         0.17966035,  0.61971659,  0.95560992, -0.28933915,  0.08328182]),\n",
       " 'PMMA': array([-0.40806359, -4.74666739,  2.08263469,  0.86545205, -0.11060472,\n",
       "         2.36288691,  1.86197591,  2.53587484, -0.71171707, -0.33717558]),\n",
       " 'PLA': array([ 0.37291285, -5.39183998,  2.00175285,  0.53274035,  0.1222178 ,\n",
       "         0.97405368,  0.03558121,  1.82719135, -0.33893213, -1.23010838]),\n",
       " 'SAN': array([-0.55406821, -2.46105719,  1.70474041,  1.23592997,  0.69804847,\n",
       "         0.05968859,  0.47341362,  0.62522233,  0.21086465, -0.39117938]),\n",
       " 'phenoxy': array([-0.15262458, -0.86935848,  1.51445973,  0.6283434 ,  0.54074085,\n",
       "         0.08056461, -0.35816786,  0.13121673, -0.44406661, -0.62283236]),\n",
       " 'epoxy (Epon 862': array([ 0.69395683, -3.0204283 ,  2.33786398,  0.41300224,  1.30292308,\n",
       "         0.14643026,  0.51020223,  0.89666352, -0.29351965,  0.08652699]),\n",
       " 'FPEOF': array([-0.15776858, -1.52179039,  1.32394111,  0.79195356,  0.39158985,\n",
       "         0.14484905,  0.04193589,  1.00171161,  0.09083053, -0.93789482]),\n",
       " 'natural rubber': array([ 0.0419343 ,  0.24514161,  1.70983791,  1.46660772,  0.85866043,\n",
       "         0.20372996, -0.50661369,  0.61828902, -0.84927789, -0.51212239]),\n",
       " 'PP': array([-0.29475278, -2.27415276,  1.67700124,  2.56500244,  0.73987776,\n",
       "         0.04071035,  1.3321892 ,  0.25400621, -0.11491551, -0.88093305]),\n",
       " 'rigid PU foam': array([-0.35008914, -0.91105602,  1.02666519,  0.7436886 ,  0.71824598,\n",
       "         0.26614496, -0.19933924,  0.72034155, -0.25221127, -0.70863128]),\n",
       " 'PC-SAN': array([-0.12180057, -2.6553899 ,  1.90876836,  1.84462786,  0.20801033,\n",
       "         0.4079339 ,  1.45228596,  0.43295678,  0.60965603, -0.44030467]),\n",
       " 'polyamide': array([-0.07375653, -1.69338655,  1.56765211,  0.62679052,  0.39587307,\n",
       "         0.35495692,  0.59573519,  1.01564944, -0.41527805, -0.43811524]),\n",
       " 'waterborne UV-curable polyurethane': array([-0.20659266, -0.22021595,  0.9987715 ,  0.27185599,  0.60958704,\n",
       "         0.09689666, -0.00945735,  0.20207661, -0.77904148, -0.6739143 ]),\n",
       " 'polyamide-6,6': array([-0.07375653, -1.69338655,  1.56765211,  0.62679052,  0.39587307,\n",
       "         0.35495692,  0.59573519,  1.01564944, -0.41527805, -0.43811524]),\n",
       " 'polyamide-6': array([-0.07375653, -1.69338655,  1.56765211,  0.62679052,  0.39587307,\n",
       "         0.35495692,  0.59573519,  1.01564944, -0.41527805, -0.43811524]),\n",
       " 'polyimide': array([ 0.05249779, -0.1945931 ,  0.98134154,  0.7309649 ,  0.74409682,\n",
       "         0.38464099, -0.04285718,  0.34402969, -0.86699933, -0.33841038]),\n",
       " 'polybenzimidazole': array([-0.14298318,  0.03860308,  0.57626653,  0.2572858 ,  0.2466943 ,\n",
       "         0.0466008 , -0.09413722, -0.0586478 , -0.20506175, -0.38430876]),\n",
       " 'poly(vinyl alcohol)': array([ 1.38126259, -0.31367062,  2.72081979,  0.37903544,  1.4226071 ,\n",
       "         1.33084106, -1.4181507 ,  0.0855952 , -3.33390474, -0.38892351]),\n",
       " 'Poly(2-hydroxyethyl acrylate)': array([ 0.80064896, -0.02139379,  2.03781931,  0.39326828,  0.95741262,\n",
       "         1.00006244, -0.91527712,  0.14486528, -2.35282398, -0.39373965]),\n",
       " 'polyurethane': array([ 0.28542951, -0.33599848,  1.8075006 ,  0.40666598,  1.68395436,\n",
       "         0.74616605, -0.33264259,  0.71091008, -1.85346556, -0.5221625 ]),\n",
       " 'styrene butadiene rubber': array([ 0.07181603, -0.4636794 ,  1.25249906,  0.4658766 ,  0.56329519,\n",
       "         0.21129735, -0.47291677,  0.40834733, -0.49049219, -0.38964473]),\n",
       " 'poly(butylene terephthalate)': array([ 0.80532453,  0.14964349,  2.22390238,  0.475546  ,  0.95453519,\n",
       "         0.91864419, -0.86016757, -0.09731166, -2.48940144, -0.53064474]),\n",
       " 'poly(vinyl butyral)': array([ 1.32086303, -0.22731231,  2.61289287,  0.42640088,  1.37230577,\n",
       "         1.25609341, -1.1291957 ,  0.16341727, -3.04222329, -0.36978788]),\n",
       " 'polybutylene succinate': array([-0.08331339, -0.08160636,  0.2675213 ,  0.11744355,  0.10513968,\n",
       "        -0.02737981, -0.08388484,  0.03955494, -0.10351859, -0.15016264]),\n",
       " 'bisphenol-A phthalonitrile': array([ 0.07239467, -0.5791122 ,  1.48573124,  0.3166595 ,  0.74078032,\n",
       "         0.1220933 , -0.29598308,  0.21905031, -0.82247302, -0.61909592])}"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"matrix_vectors10.pickle\",\"rb\")\n",
    "matrix_vectors = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "matrix_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "0.38662617933005095\n",
      "0.2517983913421631\n",
      "2.0\n",
      "0.38662617933005095\n",
      "0.2517983913421631\n",
      "5.0\n",
      "0.38662617933005095\n",
      "0.2517983913421631\n",
      "5.0\n",
      "0.38662617933005095\n",
      "0.2517983913421631\n",
      "0.0\n",
      "0.38662617933005095\n",
      "0.2517983913421631\n",
      "10.0\n",
      "0.00298446137458086\n",
      "-0.23783574253320694\n",
      "20.0\n",
      "0.00298446137458086\n",
      "-0.23783574253320694\n",
      "30.0\n",
      "0.00298446137458086\n",
      "-0.23783574253320694\n",
      "40.0\n",
      "0.00298446137458086\n",
      "-0.23783574253320694\n",
      "0.0\n",
      "0.00298446137458086\n",
      "-0.23783574253320694\n",
      "0.0\n",
      "0.42000117897987366\n",
      "-0.9882014095783234\n",
      "1.0\n",
      "0.42000117897987366\n",
      "-0.9882014095783234\n",
      "7.0\n",
      "0.42000117897987366\n",
      "-0.9882014095783234\n",
      "1.0\n",
      "0.42000117897987366\n",
      "-0.9882014095783234\n",
      "7.0\n",
      "0.42000117897987366\n",
      "-0.9882014095783234\n",
      "0.0\n",
      "0.16593077033758163\n",
      "0.8254604935646057\n",
      "0.5\n",
      "0.16593077033758163\n",
      "0.8254604935646057\n",
      "0.5\n",
      "0.16593077033758163\n",
      "0.8254604935646057\n",
      "0.5\n",
      "0.16593077033758163\n",
      "0.8254604935646057\n",
      "0.5\n",
      "0.16593077033758163\n",
      "0.8254604935646057\n",
      "0.5\n",
      "0.16593077033758163\n",
      "0.8254604935646057\n",
      "0.5\n",
      "0.16593077033758163\n",
      "0.8254604935646057\n",
      "0.05\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.05\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.1\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.1\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.25\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.25\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.5\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.5\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.0\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.0\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "1.0\n",
      "-0.027919407933950424\n",
      "-2.047890365123749\n",
      "2.5\n",
      "-0.027919407933950424\n",
      "-2.047890365123749\n",
      "4.0\n",
      "-0.027919407933950424\n",
      "-2.047890365123749\n",
      "1.0\n",
      "-0.027919407933950424\n",
      "-2.047890365123749\n",
      "2.5\n",
      "-0.027919407933950424\n",
      "-2.047890365123749\n",
      "4.0\n",
      "-0.027919407933950424\n",
      "-2.047890365123749\n",
      "5.5\n",
      "-0.027919407933950424\n",
      "-2.047890365123749\n",
      "0.0\n",
      "-0.027919407933950424\n",
      "-2.047890365123749\n",
      "0.27\n",
      "0.7561792135238647\n",
      "-3.1576881408691406\n",
      "0.55\n",
      "0.7561792135238647\n",
      "-3.1576881408691406\n",
      "1.1\n",
      "0.7561792135238647\n",
      "-3.1576881408691406\n",
      "2.2\n",
      "0.7561792135238647\n",
      "-3.1576881408691406\n",
      "0.0\n",
      "0.7561792135238647\n",
      "-3.1576881408691406\n",
      "0.27\n",
      "0.7561792135238647\n",
      "-3.1576881408691406\n",
      "0.55\n",
      "0.7561792135238647\n",
      "-3.1576881408691406\n",
      "1.1\n",
      "0.7561792135238647\n",
      "-3.1576881408691406\n",
      "2.2\n",
      "0.7561792135238647\n",
      "-3.1576881408691406\n",
      "0.4\n",
      "0.42000117897987366\n",
      "-3.501866340637207\n",
      "0.6\n",
      "0.42000117897987366\n",
      "-3.501866340637207\n",
      "0.8\n",
      "0.42000117897987366\n",
      "-3.501866340637207\n",
      "1.0\n",
      "0.42000117897987366\n",
      "-3.501866340637207\n",
      "2.0\n",
      "0.42000117897987366\n",
      "-3.501866340637207\n",
      "3.0\n",
      "0.42000117897987366\n",
      "-3.501866340637207\n",
      "4.0\n",
      "0.42000117897987366\n",
      "-3.501866340637207\n",
      "5.0\n",
      "0.42000117897987366\n",
      "-3.501866340637207\n",
      "0.2\n",
      "0.42000117897987366\n",
      "-3.501866340637207\n",
      "0.0\n",
      "0.42000117897987366\n",
      "-3.501866340637207\n",
      "0.0\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.0\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.05\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.25\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.5\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.75\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.05\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.1\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.15\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.25\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.5\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "0.75\n",
      "-0.027919407933950424\n",
      "0.2517983913421631\n",
      "5.0\n",
      "0.27409863471984863\n",
      "-0.6019913554191589\n",
      "5.0\n",
      "0.27409863471984863\n",
      "-0.39662086963653564\n",
      "5.0\n",
      "0.27409863471984863\n",
      "-0.3121280372142792\n",
      "5.0\n",
      "0.27409863471984863\n",
      "-0.35772499442100525\n",
      "5.0\n",
      "0.27409863471984863\n",
      "-0.2968050241470337\n",
      "10.0\n",
      "0.27409863471984863\n",
      "-0.6019913554191589\n",
      "10.0\n",
      "0.27409863471984863\n",
      "-0.39662086963653564\n",
      "10.0\n",
      "0.27409863471984863\n",
      "-0.3121280372142792\n",
      "10.0\n",
      "0.27409863471984863\n",
      "-0.35772499442100525\n",
      "10.0\n",
      "0.27409863471984863\n",
      "-0.2968050241470337\n",
      "0.0\n",
      "0.27409863471984863\n",
      "-1.7303937673568726\n",
      "0.0\n",
      "0.27409863471984863\n",
      "-1.7303937673568726\n",
      "4.0\n",
      "0.5192922130227089\n",
      "-0.5929531790316105\n",
      "6.0\n",
      "0.5192922130227089\n",
      "-0.5929531790316105\n",
      "0.0\n",
      "0.5192922130227089\n",
      "-0.5929531790316105\n",
      "2.5\n",
      "0.3884982764720917\n",
      "-0.08685586601495743\n",
      "5.0\n",
      "0.3884982764720917\n",
      "-0.08685586601495743\n",
      "7.5\n",
      "0.3884982764720917\n",
      "-0.08685586601495743\n",
      "0.0\n",
      "0.3884982764720917\n",
      "-0.08685586601495743\n",
      "0.05\n",
      "0.14643026143312454\n",
      "0.2517983913421631\n",
      "0.05\n",
      "0.1796603463590145\n",
      "0.2517983913421631\n",
      "0.5\n",
      "0.14643026143312454\n",
      "0.2517983913421631\n",
      "0.5\n",
      "0.1796603463590145\n",
      "0.2517983913421631\n",
      "0.0\n",
      "0.14643026143312454\n",
      "0.2517983913421631\n",
      "0.01\n",
      "0.14643026143312454\n",
      "0.8254604935646057\n",
      "0.05\n",
      "0.14643026143312454\n",
      "0.8254604935646057\n",
      "0.0\n",
      "0.14643026143312454\n",
      "0.8254604935646057\n",
      "0.0\n",
      "0.1796603463590145\n",
      "0.2517983913421631\n",
      "0.01\n",
      "0.1796603463590145\n",
      "0.8254604935646057\n",
      "0.05\n",
      "0.1796603463590145\n",
      "0.8254604935646057\n",
      "0.0\n",
      "0.1796603463590145\n",
      "0.8254604935646057\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "1.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "2.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "3.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "4.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "0.974053680896759\n",
      "-1.296175554394722\n",
      "5.0\n",
      "0.974053680896759\n",
      "-1.0539386967817943\n",
      "25.0\n",
      "0.974053680896759\n",
      "-1.4370707372824352\n",
      "20.0\n",
      "0.974053680896759\n",
      "-1.7188611030578613\n",
      "0.0\n",
      "0.974053680896759\n",
      "-1.0936425924301147\n",
      "11.0\n",
      "2.362886905670166\n",
      "0.2517983913421631\n",
      "17.0\n",
      "2.362886905670166\n",
      "0.2517983913421631\n",
      "26.0\n",
      "2.362886905670166\n",
      "0.2517983913421631\n",
      "4.0\n",
      "2.362886905670166\n",
      "0.2517983913421631\n",
      "9.0\n",
      "2.362886905670166\n",
      "0.2517983913421631\n",
      "0.0\n",
      "2.362886905670166\n",
      "0.2517983913421631\n",
      "0.5\n",
      "0.059688594192266464\n",
      "-0.22995933890342712\n",
      "1.0\n",
      "0.059688594192266464\n",
      "0.2517983913421631\n",
      "1.0\n",
      "0.059688594192266464\n",
      "-0.22995933890342712\n",
      "2.0\n",
      "0.059688594192266464\n",
      "-0.22995933890342712\n",
      "0.0\n",
      "0.059688594192266464\n",
      "-0.22995933890342712\n",
      "1.5\n",
      "0.08056461066007614\n",
      "0.2517983913421631\n",
      "12.1\n",
      "0.08056461066007614\n",
      "0.2517983913421631\n",
      "17.4\n",
      "0.08056461066007614\n",
      "0.2517983913421631\n",
      "2.1\n",
      "0.08056461066007614\n",
      "0.2517983913421631\n",
      "6.7\n",
      "0.08056461066007614\n",
      "0.2517983913421631\n",
      "0.0\n",
      "0.08056461066007614\n",
      "0.2517983913421631\n",
      "0.1\n",
      "0.14643026143312454\n",
      "0.2517983913421631\n",
      "0.2\n",
      "0.14643026143312454\n",
      "0.2517983913421631\n",
      "0.3\n",
      "0.14643026143312454\n",
      "0.2517983913421631\n",
      "0.4\n",
      "0.14643026143312454\n",
      "0.2517983913421631\n",
      "0.0\n",
      "0.14643026143312454\n",
      "0.2517983913421631\n",
      "2.0\n",
      "0.1448490470647812\n",
      "0.2517983913421631\n",
      "3.0\n",
      "0.1448490470647812\n",
      "0.2517983913421631\n",
      "4.0\n",
      "0.1448490470647812\n",
      "0.2517983913421631\n",
      "7.0\n",
      "0.1448490470647812\n",
      "0.2517983913421631\n",
      "0.0\n",
      "0.1448490470647812\n",
      "0.2517983913421631\n",
      "0.0\n",
      "0.20372996479272842\n",
      "0.2517983913421631\n",
      "0.091\n",
      "0.20372996479272842\n",
      "0.2517983913421631\n",
      "1.0\n",
      "0.04071034863591194\n",
      "0.2517983913421631\n",
      "0.0\n",
      "0.04071034863591194\n",
      "0.2517983913421631\n",
      "0.3\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "1.0\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "0.0\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "1.0\n",
      "2.362886905670166\n",
      "-0.5929531790316105\n",
      "10.0\n",
      "2.362886905670166\n",
      "-0.5929531790316105\n",
      "2.5\n",
      "2.362886905670166\n",
      "-0.5929531790316105\n",
      "5.0\n",
      "2.362886905670166\n",
      "-0.5929531790316105\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.5929531790316105\n",
      "1.0\n",
      "2.362886905670166\n",
      "-0.9851504862308502\n",
      "1.0\n",
      "2.362886905670166\n",
      "-0.9851504862308502\n",
      "10.0\n",
      "2.362886905670166\n",
      "-0.9882014095783234\n",
      "10.0\n",
      "2.362886905670166\n",
      "-0.9882014095783234\n",
      "5.0\n",
      "2.362886905670166\n",
      "-0.9882014095783234\n",
      "5.0\n",
      "2.362886905670166\n",
      "-0.9882014095783234\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.9882014095783234\n",
      "0.1\n",
      "2.362886905670166\n",
      "-3.1576881408691406\n",
      "0.5\n",
      "2.362886905670166\n",
      "-3.1576881408691406\n",
      "0.0\n",
      "2.362886905670166\n",
      "-3.1576881408691406\n",
      "6.0\n",
      "2.362886905670166\n",
      "-1.0632215589284897\n",
      "0.0\n",
      "2.362886905670166\n",
      "-1.0632215589284897\n",
      "10.0\n",
      "2.362886905670166\n",
      "-1.0871459245681763\n",
      "10.0\n",
      "2.362886905670166\n",
      "-1.0871459245681763\n",
      "0.0\n",
      "2.362886905670166\n",
      "-1.0871459245681763\n",
      "5.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "1.0\n",
      "2.362886905670166\n",
      "-1.3849772214889526\n",
      "1.0\n",
      "2.362886905670166\n",
      "-1.3849772214889526\n",
      "2.0\n",
      "2.362886905670166\n",
      "-1.3849772214889526\n",
      "2.0\n",
      "2.362886905670166\n",
      "-1.3849772214889526\n",
      "5.0\n",
      "2.362886905670166\n",
      "-1.3849772214889526\n",
      "5.0\n",
      "2.362886905670166\n",
      "-1.3849772214889526\n",
      "0.0\n",
      "2.362886905670166\n",
      "-1.3849772214889526\n",
      "0.0\n",
      "2.362886905670166\n",
      "-1.3849772214889526\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "1.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "2.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "0.17041099999999998\n",
      "2.362886905670166\n",
      "-3.1576881408691406\n",
      "0.393777\n",
      "2.362886905670166\n",
      "-3.1576881408691406\n",
      "0.701754\n",
      "2.362886905670166\n",
      "-3.1576881408691406\n",
      "0.994566\n",
      "2.362886905670166\n",
      "-3.1576881408691406\n",
      "1.390543\n",
      "2.362886905670166\n",
      "-3.1576881408691406\n",
      "0.0\n",
      "2.362886905670166\n",
      "-3.1576881408691406\n",
      "2.1\n",
      "2.362886905670166\n",
      "-1.0871459245681763\n",
      "4.75\n",
      "2.362886905670166\n",
      "-1.0871459245681763\n",
      "7.26\n",
      "2.362886905670166\n",
      "-1.0871459245681763\n",
      "0.0\n",
      "2.362886905670166\n",
      "-1.0871459245681763\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "1.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "3.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "7.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "9.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "1.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "3.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "7.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "9.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "6.0\n",
      "2.362886905670166\n",
      "-0.9882014095783234\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.9882014095783234\n",
      "0.5\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "1.0\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "2.0\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "4.0\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "0.0\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "0.1\n",
      "2.362886905670166\n",
      "-0.5103440284729004\n",
      "0.1\n",
      "2.362886905670166\n",
      "0.2517983913421631\n",
      "0.3\n",
      "2.362886905670166\n",
      "-0.5103440284729004\n",
      "0.5\n",
      "2.362886905670166\n",
      "-0.5103440284729004\n",
      "0.7\n",
      "2.362886905670166\n",
      "-0.5103440284729004\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.5103440284729004\n",
      "0.0\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "4.000307\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "6.250293\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "0.826118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "1.6396669999999998\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "4.000307\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "4.7619050000000005\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "6.250293\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "0.826118\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "0.0\n",
      "2.362886905670166\n",
      "-3.501866340637207\n",
      "1.0\n",
      "0.2661449561516444\n",
      "-2.0517429312070212\n",
      "1.0\n",
      "0.2661449561516444\n",
      "-2.721755862236023\n",
      "0.0\n",
      "0.2661449561516444\n",
      "-2.721755862236023\n",
      "1.0\n",
      "2.362886905670166\n",
      "-2.721755862236023\n",
      "1.0\n",
      "2.362886905670166\n",
      "-3.8722057342529297\n",
      "2.0\n",
      "2.362886905670166\n",
      "-2.721755862236023\n",
      "3.0\n",
      "2.362886905670166\n",
      "-2.721755862236023\n",
      "3.0\n",
      "2.362886905670166\n",
      "-3.8722057342529297\n",
      "5.0\n",
      "2.362886905670166\n",
      "-3.8722057342529297\n",
      "0.0\n",
      "2.362886905670166\n",
      "-3.8722057342529297\n",
      "0.0\n",
      "2.362886905670166\n",
      "-2.721755862236023\n",
      "1.0\n",
      "2.362886905670166\n",
      "-0.6618711352348328\n",
      "2.0\n",
      "2.362886905670166\n",
      "-0.6618711352348328\n",
      "5.0\n",
      "2.362886905670166\n",
      "-0.6618711352348328\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.6618711352348328\n",
      "1.0\n",
      "0.4079339038580656\n",
      "-0.9176280237734318\n",
      "3.0\n",
      "0.4079339038580656\n",
      "-0.9176280237734318\n",
      "5.0\n",
      "0.4079339038580656\n",
      "-0.9176280237734318\n",
      "10.0\n",
      "0.4079339038580656\n",
      "-0.9176280237734318\n",
      "10.0\n",
      "0.4079339038580656\n",
      "-0.9176280237734318\n",
      "0.0\n",
      "0.4079339038580656\n",
      "-0.9176280237734318\n",
      "10.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "20.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "30.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "40.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "50.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "6.25\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "15.37\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "2.362886905670166\n",
      "-0.7068629860877991\n",
      "2.0\n",
      "0.3884982764720917\n",
      "-0.7092900276184082\n",
      "2.0\n",
      "0.3884982764720917\n",
      "-0.7068629860877991\n",
      "3.0\n",
      "0.3884982764720917\n",
      "-0.7092900276184082\n",
      "0.0\n",
      "0.3884982764720917\n",
      "-0.7092900276184082\n",
      "0.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "15.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "20.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "7.5\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "0.0968966637738049\n",
      "-0.7068629860877991\n",
      "15.0\n",
      "0.0968966637738049\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "0.0968966637738049\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "0.0968966637738049\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "1.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "3.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "0.3549569249153137\n",
      "-0.7068629860877991\n",
      "2.5\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "15.0\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "20.0\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "2.5\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "15.0\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "20.0\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "0.38464099168777466\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "0.04660079628229141\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "0.04660079628229141\n",
      "-0.7068629860877991\n",
      "15.0\n",
      "0.04660079628229141\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "0.04660079628229141\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "0.04660079628229141\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "0.04660079628229141\n",
      "-0.7068629860877991\n",
      "15.0\n",
      "0.04660079628229141\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "0.04660079628229141\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "20.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "30.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "40.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "50.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "1.0000624358654022\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "1.0000624358654022\n",
      "-0.7068629860877991\n",
      "15.0\n",
      "1.0000624358654022\n",
      "-0.7068629860877991\n",
      "20.0\n",
      "1.0000624358654022\n",
      "-0.7068629860877991\n",
      "25.0\n",
      "1.0000624358654022\n",
      "-0.7068629860877991\n",
      "30.0\n",
      "1.0000624358654022\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "1.0000624358654022\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "20.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "30.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "40.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "50.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "0.5\n",
      "0.7461660504341125\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "0.7461660504341125\n",
      "-0.7068629860877991\n",
      "1.0\n",
      "0.7461660504341125\n",
      "-0.7068629860877991\n",
      "2.0\n",
      "0.7461660504341125\n",
      "-0.7068629860877991\n",
      "28.6\n",
      "0.21129734814167023\n",
      "-0.7068629860877991\n",
      "28.6\n",
      "0.21129734814167023\n",
      "-0.7068629860877991\n",
      "28.6\n",
      "0.21129734814167023\n",
      "-0.7068629860877991\n",
      "28.6\n",
      "0.21129734814167023\n",
      "-0.7068629860877991\n",
      "28.6\n",
      "0.21129734814167023\n",
      "-0.7068629860877991\n",
      "28.6\n",
      "0.21129734814167023\n",
      "-0.7068629860877991\n",
      "28.6\n",
      "0.21129734814167023\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "0.21129734814167023\n",
      "-0.7068629860877991\n",
      "0.5\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "2.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "5.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "10.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "15.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "1.330841064453125\n",
      "-0.7068629860877991\n",
      "0.0\n",
      "0.9186441898345947\n",
      "-0.7068629860877991\n",
      "1.0\n",
      "0.9186441898345947\n",
      "-0.7068629860877991\n",
      "2.0\n",
      "0.9186441898345947\n",
      "-0.7068629860877991\n",
      "0.5\n",
      "0.7461660504341125\n",
      "-0.7100705206394196\n",
      "1.0\n",
      "0.7461660504341125\n",
      "-0.7100705206394196\n",
      "2.0\n",
      "0.7461660504341125\n",
      "-0.7100705206394196\n",
      "3.0\n",
      "0.7461660504341125\n",
      "-0.7100705206394196\n",
      "5.0\n",
      "0.7461660504341125\n",
      "-0.7100705206394196\n",
      "7.0\n",
      "0.7461660504341125\n",
      "-0.7100705206394196\n",
      "10.0\n",
      "0.7461660504341125\n",
      "-0.7100705206394196\n",
      "0.0\n",
      "0.7461660504341125\n",
      "-0.7100705206394196\n",
      "1.0\n",
      "1.256093407670657\n",
      "-0.7100705206394196\n",
      "1.0\n",
      "1.256093407670657\n",
      "-0.7100705206394196\n",
      "3.0\n",
      "1.256093407670657\n",
      "-0.7100705206394196\n",
      "3.0\n",
      "1.256093407670657\n",
      "-0.7100705206394196\n",
      "5.0\n",
      "1.256093407670657\n",
      "-0.7100705206394196\n",
      "5.0\n",
      "1.256093407670657\n",
      "-0.7100705206394196\n",
      "7.0\n",
      "1.256093407670657\n",
      "-0.7100705206394196\n",
      "7.0\n",
      "1.256093407670657\n",
      "-0.7100705206394196\n",
      "0.0\n",
      "1.256093407670657\n",
      "-0.7100705206394196\n",
      "0.0\n",
      "1.256093407670657\n",
      "-0.7100705206394196\n",
      "1.5\n",
      "1.330841064453125\n",
      "-0.7100705206394196\n",
      "0.2\n",
      "1.330841064453125\n",
      "-0.7100705206394196\n",
      "0.5\n",
      "1.330841064453125\n",
      "-0.7100705206394196\n",
      "1.0\n",
      "1.330841064453125\n",
      "-0.7100705206394196\n",
      "1.5\n",
      "1.330841064453125\n",
      "-0.7100705206394196\n",
      "1.5\n",
      "1.330841064453125\n",
      "-0.7100705206394196\n",
      "1.5\n",
      "1.330841064453125\n",
      "-0.7100705206394196\n",
      "1.5\n",
      "1.330841064453125\n",
      "-0.7100705206394196\n",
      "0.0\n",
      "1.330841064453125\n",
      "-0.7100705206394196\n",
      "5.0\n",
      "0.42000117897987366\n",
      "-0.7100705206394196\n",
      "10.0\n",
      "0.42000117897987366\n",
      "-0.7100705206394196\n",
      "15.0\n",
      "0.42000117897987366\n",
      "-0.7100705206394196\n",
      "0.0\n",
      "0.42000117897987366\n",
      "-0.7100705206394196\n",
      "5.0\n",
      "-0.02737981453537941\n",
      "-0.7100705206394196\n",
      "10.0\n",
      "-0.02737981453537941\n",
      "-0.7100705206394196\n",
      "0.0\n",
      "-0.02737981453537941\n",
      "-0.7100705206394196\n",
      "0.5\n",
      "0.42000117897987366\n",
      "-0.7100705206394196\n",
      "1.0\n",
      "0.42000117897987366\n",
      "-0.7100705206394196\n",
      "3.0\n",
      "0.42000117897987366\n",
      "-0.7100705206394196\n",
      "4.0\n",
      "0.42000117897987366\n",
      "-0.7100705206394196\n",
      "0.0\n",
      "0.42000117897987366\n",
      "-0.7100705206394196\n",
      "0.0\n",
      "0.12209330033510923\n",
      "-0.7100705206394196\n",
      "2.0\n",
      "0.12209330033510923\n",
      "-0.7100705206394196\n",
      "4.0\n",
      "0.12209330033510923\n",
      "-0.7100705206394196\n",
      "6.0\n",
      "0.12209330033510923\n",
      "-0.7100705206394196\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "df_embedding = pd.DataFrame(data=df[['matrix','filler','filler percentage']], copy=True)\n",
    "\n",
    "df_matrix_embedding = pd.DataFrame(data=matrix_vectors)\n",
    "df_matrix_embedding = df_matrix_embedding.T\n",
    "\n",
    "df_filler_embedding = pd.DataFrame(data=filler_vectors)\n",
    "df_filler_embedding = df_filler_embedding.T\n",
    "\n",
    "df_embedding = pd.merge(left=df_embedding, right=df_matrix_embedding, left_on='matrix', \n",
    "                        right_index=True, how='left', validate='many_to_one')\n",
    "df_embedding = df_embedding.rename(columns= lambda name: 'matrix_embedding_'+str(name) if isinstance(name, int) else name)\n",
    "\n",
    "df_embedding = pd.merge(left=df_embedding, right=df_filler_embedding, left_on='filler',\n",
    "                       right_index=True, how='left', validate='many_to_one')\n",
    "df_embedding = df_embedding.rename(columns= lambda name: 'filler_embedding_'+str(name) if isinstance(name, int) else name)\n",
    "\n",
    "#check the correctness of df_embedding\n",
    "compare_df = []\n",
    "compare_matrix_eb = []\n",
    "compare_filler_eb = []\n",
    "for index, row in df_embedding.iterrows():\n",
    "    compare_df.append(row['filler percentage']==df.iloc[index]['filler percentage'])\n",
    "    print(row['filler percentage'])\n",
    "    compare_matrix_eb.append(row['matrix_embedding_5']== matrix_vectors[row['matrix']][5])\n",
    "    print(row['matrix_embedding_5'])\n",
    "    compare_filler_eb.append(row['filler_embedding_8']== filler_vectors[row['filler']][8])\n",
    "    print(row['filler_embedding_8'])\n",
    "print(all(compare_df))\n",
    "print(all(compare_matrix_eb))\n",
    "print(all(compare_filler_eb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X_embedding\n",
    "df_embedding_dropped = df_embedding.drop(labels=['matrix', 'filler'], axis='columns')\n",
    "X_embedding = df_embedding_dropped.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression r2:  0.27334420556129624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.1993241410567"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_embedding, y)\n",
    "R_2 = reg.score(X_embedding, y)\n",
    "print('linear regression r2: ', R_2)\n",
    "y_pred = reg.predict(X_embedding)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mean absolute error: 53.04335545755355\n",
      "average y true values: 107.94295911331595\n"
     ]
    }
   ],
   "source": [
    "#loo for linear regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "lr = LinearRegression()\n",
    "scores_lr = cross_val_score(lr, X_embedding, y, cv=loo.split(X_embedding), \n",
    "                             scoring='neg_mean_absolute_error')\n",
    "print('average mean absolute error:', np.mean(-scores_lr))\n",
    "print('average y true values:', np.mean(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.394016166358324\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeRegressor()\n",
    "#dt=tree.DecisionTreeRegressor()\n",
    "dt.fit(X_embedding,y)\n",
    "y_pred = dt.predict(X_embedding)\n",
    "print(mean_absolute_error(y, y_pred))\n",
    "print(dt.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  leave one out mean_absolute_error:  15.854657014308094\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeRegressor()\n",
    "scores_dt = cross_val_score(dt, X_embedding, y, cv=loo.split(X_embedding),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "print('  leave one out mean_absolute_error: ', np.mean(-scores_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 1   leave one out mean_absolute_error:  15.594495019285121\n",
      "11 2   leave one out mean_absolute_error:  15.552752075072855\n",
      "11 3   leave one out mean_absolute_error:  17.82518946359393\n",
      "11 4   leave one out mean_absolute_error:  19.6733912248401\n",
      "12 1   leave one out mean_absolute_error:  15.668734452766563\n",
      "12 2   leave one out mean_absolute_error:  15.70650155920918\n",
      "12 3   leave one out mean_absolute_error:  18.115240970100366\n",
      "12 4   leave one out mean_absolute_error:  19.7952174810239\n",
      "13 1   leave one out mean_absolute_error:  15.478299484214121\n",
      "13 2   leave one out mean_absolute_error:  15.6296195021352\n",
      "13 3   leave one out mean_absolute_error:  17.896489570685375\n",
      "13 4   leave one out mean_absolute_error:  19.690903182197044\n",
      "14 1   leave one out mean_absolute_error:  15.664386877543851\n",
      "14 2   leave one out mean_absolute_error:  15.798464064177336\n",
      "14 3   leave one out mean_absolute_error:  17.92835368075065\n",
      "14 4   leave one out mean_absolute_error:  19.687436330982948\n",
      "15 1   leave one out mean_absolute_error:  15.868930592103691\n",
      "15 2   leave one out mean_absolute_error:  15.78866640988406\n",
      "15 3   leave one out mean_absolute_error:  17.761563289425897\n",
      "15 4   leave one out mean_absolute_error:  19.847647848987425\n",
      "16 1   leave one out mean_absolute_error:  15.725351158161754\n",
      "16 2   leave one out mean_absolute_error:  15.59075819647022\n",
      "16 3   leave one out mean_absolute_error:  17.82956227175152\n",
      "16 4   leave one out mean_absolute_error:  19.81047008492737\n",
      "17 1   leave one out mean_absolute_error:  15.648206162791867\n",
      "17 2   leave one out mean_absolute_error:  15.850469477982095\n",
      "17 3   leave one out mean_absolute_error:  17.843707542110838\n",
      "17 4   leave one out mean_absolute_error:  19.678626212640907\n",
      "18 1   leave one out mean_absolute_error:  15.644475210167847\n",
      "18 2   leave one out mean_absolute_error:  15.560678099211737\n",
      "18 3   leave one out mean_absolute_error:  17.88476843146245\n",
      "18 4   leave one out mean_absolute_error:  19.80668594186632\n",
      "19 1   leave one out mean_absolute_error:  15.815833749462888\n",
      "19 2   leave one out mean_absolute_error:  15.67817900581375\n",
      "19 3   leave one out mean_absolute_error:  17.8958700632118\n",
      "19 4   leave one out mean_absolute_error:  19.690740026048218\n",
      "20 1   leave one out mean_absolute_error:  15.825026352204402\n",
      "20 2   leave one out mean_absolute_error:  15.643782944107917\n",
      "20 3   leave one out mean_absolute_error:  17.91617079373586\n",
      "20 4   leave one out mean_absolute_error:  19.684275880526027\n"
     ]
    }
   ],
   "source": [
    "\n",
    "errors = np.zeros((10, 4))\n",
    "for i in range(11, 21):\n",
    "    for j in range(1, 5):\n",
    "        dt = tree.DecisionTreeRegressor(max_depth=i, min_samples_leaf=j)\n",
    "        scores_dt = cross_val_score(dt, X_embedding, y, cv=loo.split(X_embedding),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "        print(i, j, '  leave one out mean_absolute_error: ', np.mean(-scores_dt))\n",
    "        errors[i-11, j-1] = np.mean(-scores_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1   leave one out mean_absolute_error:  56.64051015910062\n",
      "1 2   leave one out mean_absolute_error:  56.64051015910062\n",
      "1 3   leave one out mean_absolute_error:  56.64051015910062\n",
      "1 4   leave one out mean_absolute_error:  56.64051015910064\n",
      "2 1   leave one out mean_absolute_error:  36.344038335130634\n",
      "2 2   leave one out mean_absolute_error:  36.34403833513063\n",
      "2 3   leave one out mean_absolute_error:  36.34403833513063\n",
      "2 4   leave one out mean_absolute_error:  36.34403833513062\n",
      "3 1   leave one out mean_absolute_error:  31.634680676587816\n",
      "3 2   leave one out mean_absolute_error:  31.634680676587816\n",
      "3 3   leave one out mean_absolute_error:  32.52548414746294\n",
      "3 4   leave one out mean_absolute_error:  34.17912074593828\n",
      "4 1   leave one out mean_absolute_error:  25.963687315782824\n",
      "4 2   leave one out mean_absolute_error:  25.851709125347664\n",
      "4 3   leave one out mean_absolute_error:  26.77637451155969\n",
      "4 4   leave one out mean_absolute_error:  28.168269691404277\n",
      "5 1   leave one out mean_absolute_error:  20.31533916844011\n",
      "5 2   leave one out mean_absolute_error:  20.404820358052046\n",
      "5 3   leave one out mean_absolute_error:  21.315303733073804\n",
      "5 4   leave one out mean_absolute_error:  22.616997313256217\n",
      "6 1   leave one out mean_absolute_error:  18.248285437221888\n",
      "6 2   leave one out mean_absolute_error:  18.142079575431694\n",
      "6 3   leave one out mean_absolute_error:  19.61168896311546\n",
      "6 4   leave one out mean_absolute_error:  20.09422764815773\n",
      "7 1   leave one out mean_absolute_error:  17.146323942316553\n",
      "7 2   leave one out mean_absolute_error:  16.863907996697073\n",
      "7 3   leave one out mean_absolute_error:  18.564822445435308\n",
      "7 4   leave one out mean_absolute_error:  20.512012998917736\n",
      "8 1   leave one out mean_absolute_error:  17.30860567676132\n",
      "8 2   leave one out mean_absolute_error:  17.006872865894728\n",
      "8 3   leave one out mean_absolute_error:  18.649803309340196\n",
      "8 4   leave one out mean_absolute_error:  19.09661676373654\n",
      "9 1   leave one out mean_absolute_error:  15.863201965542125\n",
      "9 2   leave one out mean_absolute_error:  15.608616441907287\n",
      "9 3   leave one out mean_absolute_error:  17.773257055950022\n",
      "9 4   leave one out mean_absolute_error:  19.706030288351595\n",
      "10 1   leave one out mean_absolute_error:  15.773395231029795\n",
      "10 2   leave one out mean_absolute_error:  15.68257974978658\n",
      "10 3   leave one out mean_absolute_error:  18.22931840142471\n",
      "10 4   leave one out mean_absolute_error:  20.081673792434884\n"
     ]
    }
   ],
   "source": [
    "errors2 = np.zeros((10, 4))\n",
    "for i in range(1, 11):\n",
    "    for j in range(1, 5):\n",
    "        dt = tree.DecisionTreeRegressor(max_depth=i, min_samples_leaf=j)\n",
    "        scores_dt = cross_val_score(dt, X_embedding, y, cv=loo.split(X_embedding),\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "        print(i, j, '  leave one out mean_absolute_error: ', np.mean(-scores_dt))\n",
    "        errors2[i-1, j-1] = np.mean(-scores_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.608616441907287"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amin(errors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.315494848021881\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "#best hyperparameters max_depth=13, min_samples_leaf =1\n",
    "dt = tree.DecisionTreeRegressor(max_depth=13, min_samples_leaf=1)\n",
    "#dt=tree.DecisionTreeRegressor()\n",
    "dt.fit(X_embedding,y)\n",
    "y_pred = dt.predict(X_embedding)\n",
    "print(mean_absolute_error(y, y_pred))\n",
    "print(dt.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def SimpleModel(input_shape):\n",
    "    X_input = Input(shape=input_shape)\n",
    "    #X = Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.01))(X_input)\n",
    "    X = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1))(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    #X = Dropout(rate=0.5)(X)\n",
    "    X = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    X = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    X = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    #X = Dropout(rate=0.5)(X)\n",
    "    X = Dense(1, kernel_regularizer=regularizers.l2(1))(X)\n",
    "    model = Model(inputs=X_input, outputs=X, name='SimpleModel')\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleModel = SimpleModel((201, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.00001)\n",
    "simpleModel.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_embedding_scaled, y, test_size=0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "344/344 [==============================] - 24s 69ms/step - loss: 427.1558 - mean_absolute_error: 12.2498\n",
      "Epoch 2/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 433.3559 - mean_absolute_error: 12.4058\n",
      "Epoch 3/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 426.8253 - mean_absolute_error: 12.1560\n",
      "Epoch 4/5000\n",
      "344/344 [==============================] - 0s 291us/step - loss: 423.9260 - mean_absolute_error: 12.0152\n",
      "Epoch 5/5000\n",
      "344/344 [==============================] - 0s 290us/step - loss: 445.1770 - mean_absolute_error: 12.5025\n",
      "Epoch 6/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 456.6558 - mean_absolute_error: 12.8915\n",
      "Epoch 7/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 450.7604 - mean_absolute_error: 12.7643\n",
      "Epoch 8/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 440.5377 - mean_absolute_error: 12.7760\n",
      "Epoch 9/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 448.4322 - mean_absolute_error: 12.7326\n",
      "Epoch 10/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 411.4615 - mean_absolute_error: 12.3608\n",
      "Epoch 11/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 429.6171 - mean_absolute_error: 12.3971\n",
      "Epoch 12/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 432.1151 - mean_absolute_error: 11.9322\n",
      "Epoch 13/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 459.8599 - mean_absolute_error: 12.6388\n",
      "Epoch 14/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 444.3328 - mean_absolute_error: 12.7015\n",
      "Epoch 15/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 438.3245 - mean_absolute_error: 12.3770\n",
      "Epoch 16/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 450.5319 - mean_absolute_error: 12.2311\n",
      "Epoch 17/5000\n",
      "344/344 [==============================] - 0s 274us/step - loss: 455.7226 - mean_absolute_error: 12.3669\n",
      "Epoch 18/5000\n",
      "344/344 [==============================] - 0s 309us/step - loss: 423.3679 - mean_absolute_error: 12.1951\n",
      "Epoch 19/5000\n",
      "344/344 [==============================] - 0s 286us/step - loss: 422.5342 - mean_absolute_error: 12.2167\n",
      "Epoch 20/5000\n",
      "344/344 [==============================] - 0s 284us/step - loss: 445.3034 - mean_absolute_error: 12.6654\n",
      "Epoch 21/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 448.6438 - mean_absolute_error: 12.5510\n",
      "Epoch 22/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 418.6804 - mean_absolute_error: 11.8646\n",
      "Epoch 23/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.2538 - mean_absolute_error: 12.1928\n",
      "Epoch 24/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 415.5631 - mean_absolute_error: 11.9796\n",
      "Epoch 25/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 439.0358 - mean_absolute_error: 12.2738\n",
      "Epoch 26/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 424.9083 - mean_absolute_error: 12.2160\n",
      "Epoch 27/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 410.7077 - mean_absolute_error: 11.9832\n",
      "Epoch 28/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 436.6670 - mean_absolute_error: 12.3524\n",
      "Epoch 29/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 425.1463 - mean_absolute_error: 12.1111\n",
      "Epoch 30/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 462.6950 - mean_absolute_error: 13.1730\n",
      "Epoch 31/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 421.7737 - mean_absolute_error: 12.0665\n",
      "Epoch 32/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 421.2656 - mean_absolute_error: 12.1595\n",
      "Epoch 33/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 421.9950 - mean_absolute_error: 12.3271\n",
      "Epoch 34/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 424.1975 - mean_absolute_error: 12.4621\n",
      "Epoch 35/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 437.7452 - mean_absolute_error: 12.1460\n",
      "Epoch 36/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 405.7116 - mean_absolute_error: 11.9160\n",
      "Epoch 37/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 411.4019 - mean_absolute_error: 11.9939\n",
      "Epoch 38/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 425.6302 - mean_absolute_error: 12.3158\n",
      "Epoch 39/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 447.2763 - mean_absolute_error: 12.9136\n",
      "Epoch 40/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.4582 - mean_absolute_error: 11.8807\n",
      "Epoch 41/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 431.8885 - mean_absolute_error: 12.2127\n",
      "Epoch 42/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 427.6481 - mean_absolute_error: 12.1525\n",
      "Epoch 43/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 468.3651 - mean_absolute_error: 12.9365\n",
      "Epoch 44/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 415.6929 - mean_absolute_error: 11.9793\n",
      "Epoch 45/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 423.0855 - mean_absolute_error: 11.8797\n",
      "Epoch 46/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 405.3800 - mean_absolute_error: 11.9284\n",
      "Epoch 47/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 410.6098 - mean_absolute_error: 11.7771\n",
      "Epoch 48/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 458.3787 - mean_absolute_error: 12.7576\n",
      "Epoch 49/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.8816 - mean_absolute_error: 12.1904\n",
      "Epoch 50/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 423.1071 - mean_absolute_error: 12.1525\n",
      "Epoch 51/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 438.5543 - mean_absolute_error: 12.3613\n",
      "Epoch 52/5000\n",
      "344/344 [==============================] - 0s 313us/step - loss: 438.0551 - mean_absolute_error: 12.1496\n",
      "Epoch 53/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 440.6268 - mean_absolute_error: 12.4501\n",
      "Epoch 54/5000\n",
      "344/344 [==============================] - 0s 316us/step - loss: 419.8280 - mean_absolute_error: 12.0716\n",
      "Epoch 55/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 434.6823 - mean_absolute_error: 12.2545\n",
      "Epoch 56/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 454.7872 - mean_absolute_error: 12.5682\n",
      "Epoch 57/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 422.2508 - mean_absolute_error: 12.0454\n",
      "Epoch 58/5000\n",
      "344/344 [==============================] - 0s 259us/step - loss: 420.2356 - mean_absolute_error: 12.2380\n",
      "Epoch 59/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 459.9594 - mean_absolute_error: 12.9795\n",
      "Epoch 60/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 446.1294 - mean_absolute_error: 12.8099\n",
      "Epoch 61/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 425.7010 - mean_absolute_error: 12.3849\n",
      "Epoch 62/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 431.4445 - mean_absolute_error: 12.3354\n",
      "Epoch 63/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 429.4457 - mean_absolute_error: 12.3631\n",
      "Epoch 64/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 461.0459 - mean_absolute_error: 12.7884\n",
      "Epoch 65/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 417.8685 - mean_absolute_error: 12.1024\n",
      "Epoch 66/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 423.4983 - mean_absolute_error: 12.1314\n",
      "Epoch 67/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 419.6789 - mean_absolute_error: 11.9969\n",
      "Epoch 68/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 407.4009 - mean_absolute_error: 11.6858\n",
      "Epoch 69/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 413.3666 - mean_absolute_error: 11.9462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 435.9622 - mean_absolute_error: 12.4557\n",
      "Epoch 71/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 423.0443 - mean_absolute_error: 12.1760\n",
      "Epoch 72/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 410.3004 - mean_absolute_error: 11.7397\n",
      "Epoch 73/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 424.6543 - mean_absolute_error: 12.4463\n",
      "Epoch 74/5000\n",
      "344/344 [==============================] - 0s 281us/step - loss: 420.7336 - mean_absolute_error: 12.1461\n",
      "Epoch 75/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 406.6946 - mean_absolute_error: 11.8299\n",
      "Epoch 76/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 452.3020 - mean_absolute_error: 12.7435\n",
      "Epoch 77/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 428.6793 - mean_absolute_error: 12.1210\n",
      "Epoch 78/5000\n",
      "344/344 [==============================] - 0s 299us/step - loss: 430.0594 - mean_absolute_error: 12.2118\n",
      "Epoch 79/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 439.2692 - mean_absolute_error: 12.3813\n",
      "Epoch 80/5000\n",
      "344/344 [==============================] - 0s 290us/step - loss: 437.6235 - mean_absolute_error: 12.3924\n",
      "Epoch 81/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 424.1314 - mean_absolute_error: 12.1174\n",
      "Epoch 82/5000\n",
      "344/344 [==============================] - 0s 336us/step - loss: 422.0704 - mean_absolute_error: 12.0296\n",
      "Epoch 83/5000\n",
      "344/344 [==============================] - 0s 313us/step - loss: 417.6031 - mean_absolute_error: 12.1644\n",
      "Epoch 84/5000\n",
      "344/344 [==============================] - 0s 299us/step - loss: 433.3196 - mean_absolute_error: 12.7103\n",
      "Epoch 85/5000\n",
      "344/344 [==============================] - 0s 290us/step - loss: 421.9500 - mean_absolute_error: 12.3968\n",
      "Epoch 86/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 431.1609 - mean_absolute_error: 12.3892\n",
      "Epoch 87/5000\n",
      "344/344 [==============================] - 0s 296us/step - loss: 424.0488 - mean_absolute_error: 11.8481\n",
      "Epoch 88/5000\n",
      "344/344 [==============================] - 0s 302us/step - loss: 433.0580 - mean_absolute_error: 12.3118\n",
      "Epoch 89/5000\n",
      "344/344 [==============================] - 0s 284us/step - loss: 437.7073 - mean_absolute_error: 12.3603\n",
      "Epoch 90/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 422.9338 - mean_absolute_error: 11.9946\n",
      "Epoch 91/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 426.8855 - mean_absolute_error: 12.3845\n",
      "Epoch 92/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.7368 - mean_absolute_error: 12.2145\n",
      "Epoch 93/5000\n",
      "344/344 [==============================] - 0s 215us/step - loss: 430.3084 - mean_absolute_error: 12.2302\n",
      "Epoch 94/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 467.5951 - mean_absolute_error: 12.3510\n",
      "Epoch 95/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 462.7957 - mean_absolute_error: 12.6999\n",
      "Epoch 96/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 449.6292 - mean_absolute_error: 12.5100\n",
      "Epoch 97/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 424.2198 - mean_absolute_error: 12.3387\n",
      "Epoch 98/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 446.6870 - mean_absolute_error: 12.6637\n",
      "Epoch 99/5000\n",
      "344/344 [==============================] - 0s 284us/step - loss: 428.6704 - mean_absolute_error: 12.0278\n",
      "Epoch 100/5000\n",
      "344/344 [==============================] - 0s 277us/step - loss: 416.3738 - mean_absolute_error: 12.0831\n",
      "Epoch 101/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 426.5646 - mean_absolute_error: 12.3583\n",
      "Epoch 102/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 447.2187 - mean_absolute_error: 12.4854\n",
      "Epoch 103/5000\n",
      "344/344 [==============================] - 0s 257us/step - loss: 438.0938 - mean_absolute_error: 12.8811\n",
      "Epoch 104/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 414.6942 - mean_absolute_error: 12.0105\n",
      "Epoch 105/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 393.6947 - mean_absolute_error: 11.6218\n",
      "Epoch 106/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 446.5057 - mean_absolute_error: 12.9284\n",
      "Epoch 107/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 407.2109 - mean_absolute_error: 11.7855\n",
      "Epoch 108/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 420.5314 - mean_absolute_error: 12.1371\n",
      "Epoch 109/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 431.1141 - mean_absolute_error: 12.2751\n",
      "Epoch 110/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 396.8275 - mean_absolute_error: 11.5563\n",
      "Epoch 111/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 439.6055 - mean_absolute_error: 12.4324\n",
      "Epoch 112/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 430.8429 - mean_absolute_error: 12.0749\n",
      "Epoch 113/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 415.2393 - mean_absolute_error: 11.9533\n",
      "Epoch 114/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 442.0637 - mean_absolute_error: 12.8007\n",
      "Epoch 115/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 429.9526 - mean_absolute_error: 12.3689\n",
      "Epoch 116/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 429.6484 - mean_absolute_error: 12.1940\n",
      "Epoch 117/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.9870 - mean_absolute_error: 12.0177\n",
      "Epoch 118/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.6592 - mean_absolute_error: 12.2502\n",
      "Epoch 119/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 435.1473 - mean_absolute_error: 12.2646\n",
      "Epoch 120/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 448.8758 - mean_absolute_error: 12.8972\n",
      "Epoch 121/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 427.2847 - mean_absolute_error: 12.1134\n",
      "Epoch 122/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.7692 - mean_absolute_error: 11.9304\n",
      "Epoch 123/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 426.2737 - mean_absolute_error: 12.4132\n",
      "Epoch 124/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 425.3051 - mean_absolute_error: 12.1353\n",
      "Epoch 125/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 436.5555 - mean_absolute_error: 12.3311\n",
      "Epoch 126/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 428.0602 - mean_absolute_error: 12.2971\n",
      "Epoch 127/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 424.7894 - mean_absolute_error: 11.9703\n",
      "Epoch 128/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 447.5855 - mean_absolute_error: 12.3762\n",
      "Epoch 129/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 444.3398 - mean_absolute_error: 12.8325\n",
      "Epoch 130/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 433.5660 - mean_absolute_error: 12.4374\n",
      "Epoch 131/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 432.7208 - mean_absolute_error: 12.4366\n",
      "Epoch 132/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 421.0360 - mean_absolute_error: 12.3130\n",
      "Epoch 133/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 434.1840 - mean_absolute_error: 12.3585\n",
      "Epoch 134/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 434.2361 - mean_absolute_error: 12.3933\n",
      "Epoch 135/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 399.4142 - mean_absolute_error: 11.7475\n",
      "Epoch 136/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.5865 - mean_absolute_error: 11.9602\n",
      "Epoch 137/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 436.0912 - mean_absolute_error: 12.3890\n",
      "Epoch 138/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 434.2650 - mean_absolute_error: 12.4439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 431.0577 - mean_absolute_error: 12.2349\n",
      "Epoch 140/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 401.9352 - mean_absolute_error: 11.7770\n",
      "Epoch 141/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.7977 - mean_absolute_error: 12.1913\n",
      "Epoch 142/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.6537 - mean_absolute_error: 12.1340\n",
      "Epoch 143/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 446.6523 - mean_absolute_error: 12.5929\n",
      "Epoch 144/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.5374 - mean_absolute_error: 11.5720\n",
      "Epoch 145/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 432.0904 - mean_absolute_error: 12.3365\n",
      "Epoch 146/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 431.0804 - mean_absolute_error: 12.4194\n",
      "Epoch 147/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.9643 - mean_absolute_error: 12.2958\n",
      "Epoch 148/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 428.3563 - mean_absolute_error: 12.1953\n",
      "Epoch 149/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.3900 - mean_absolute_error: 11.7221\n",
      "Epoch 150/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 443.8800 - mean_absolute_error: 12.8795\n",
      "Epoch 151/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 447.7397 - mean_absolute_error: 12.7104\n",
      "Epoch 152/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 427.3030 - mean_absolute_error: 12.1474\n",
      "Epoch 153/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 420.5694 - mean_absolute_error: 11.8823\n",
      "Epoch 154/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 433.4358 - mean_absolute_error: 12.5759\n",
      "Epoch 155/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 432.7235 - mean_absolute_error: 12.7610\n",
      "Epoch 156/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 435.0920 - mean_absolute_error: 12.0952\n",
      "Epoch 157/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.0709 - mean_absolute_error: 11.9359\n",
      "Epoch 158/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 435.0324 - mean_absolute_error: 12.2115\n",
      "Epoch 159/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.6381 - mean_absolute_error: 11.9991\n",
      "Epoch 160/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 437.0289 - mean_absolute_error: 12.1658\n",
      "Epoch 161/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 405.6302 - mean_absolute_error: 12.0244\n",
      "Epoch 162/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.9044 - mean_absolute_error: 11.9944\n",
      "Epoch 163/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.5674 - mean_absolute_error: 11.9932\n",
      "Epoch 164/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 426.9958 - mean_absolute_error: 12.1735\n",
      "Epoch 165/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 437.8606 - mean_absolute_error: 12.3543\n",
      "Epoch 166/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 433.0333 - mean_absolute_error: 12.3927\n",
      "Epoch 167/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.5734 - mean_absolute_error: 11.9614\n",
      "Epoch 168/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 437.1942 - mean_absolute_error: 12.3792\n",
      "Epoch 169/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.9134 - mean_absolute_error: 12.0208\n",
      "Epoch 170/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 430.1374 - mean_absolute_error: 12.4346\n",
      "Epoch 171/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 430.1714 - mean_absolute_error: 12.2005\n",
      "Epoch 172/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.2499 - mean_absolute_error: 11.6670\n",
      "Epoch 173/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 462.1546 - mean_absolute_error: 12.9690\n",
      "Epoch 174/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 435.3969 - mean_absolute_error: 12.6724\n",
      "Epoch 175/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.0658 - mean_absolute_error: 12.4406\n",
      "Epoch 176/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.6922 - mean_absolute_error: 11.8743\n",
      "Epoch 177/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 431.7417 - mean_absolute_error: 12.1546\n",
      "Epoch 178/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.8447 - mean_absolute_error: 12.0895\n",
      "Epoch 179/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 429.2383 - mean_absolute_error: 12.0491\n",
      "Epoch 180/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 402.8959 - mean_absolute_error: 11.8816\n",
      "Epoch 181/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 427.4834 - mean_absolute_error: 12.2574\n",
      "Epoch 182/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 424.6143 - mean_absolute_error: 12.2641\n",
      "Epoch 183/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 436.7108 - mean_absolute_error: 12.6966\n",
      "Epoch 184/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 430.5145 - mean_absolute_error: 12.3760\n",
      "Epoch 185/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 438.7805 - mean_absolute_error: 12.4915\n",
      "Epoch 186/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 457.6907 - mean_absolute_error: 12.8468\n",
      "Epoch 187/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 467.8990 - mean_absolute_error: 12.5834\n",
      "Epoch 188/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 421.9250 - mean_absolute_error: 11.6230\n",
      "Epoch 189/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 439.0299 - mean_absolute_error: 12.5568\n",
      "Epoch 190/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 451.8464 - mean_absolute_error: 12.5134\n",
      "Epoch 191/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 433.2097 - mean_absolute_error: 12.4091\n",
      "Epoch 192/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.6122 - mean_absolute_error: 12.3666\n",
      "Epoch 193/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 454.8759 - mean_absolute_error: 12.5969\n",
      "Epoch 194/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 388.4625 - mean_absolute_error: 11.4784\n",
      "Epoch 195/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.8759 - mean_absolute_error: 12.1687\n",
      "Epoch 196/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.7148 - mean_absolute_error: 12.1871\n",
      "Epoch 197/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.4756 - mean_absolute_error: 12.2044\n",
      "Epoch 198/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 431.6879 - mean_absolute_error: 12.5489\n",
      "Epoch 199/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 396.9236 - mean_absolute_error: 11.5492\n",
      "Epoch 200/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 419.0011 - mean_absolute_error: 11.8974\n",
      "Epoch 201/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 417.6454 - mean_absolute_error: 12.1017\n",
      "Epoch 202/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.2977 - mean_absolute_error: 11.9754\n",
      "Epoch 203/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 430.8502 - mean_absolute_error: 12.3745\n",
      "Epoch 204/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.4387 - mean_absolute_error: 11.6238\n",
      "Epoch 205/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 433.1249 - mean_absolute_error: 12.3341\n",
      "Epoch 206/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 412.6512 - mean_absolute_error: 11.8868\n",
      "Epoch 207/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.6447 - mean_absolute_error: 12.2031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 420.0358 - mean_absolute_error: 11.7619\n",
      "Epoch 209/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 433.5598 - mean_absolute_error: 12.5111\n",
      "Epoch 210/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 418.3889 - mean_absolute_error: 11.8979\n",
      "Epoch 211/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 426.6230 - mean_absolute_error: 12.4123\n",
      "Epoch 212/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.4093 - mean_absolute_error: 11.9550\n",
      "Epoch 213/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 416.7694 - mean_absolute_error: 11.8386\n",
      "Epoch 214/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 446.3287 - mean_absolute_error: 12.4697\n",
      "Epoch 215/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.0170 - mean_absolute_error: 12.0204\n",
      "Epoch 216/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.3358 - mean_absolute_error: 12.4548\n",
      "Epoch 217/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.3300 - mean_absolute_error: 12.1074\n",
      "Epoch 218/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 469.2292 - mean_absolute_error: 12.4281\n",
      "Epoch 219/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.9291 - mean_absolute_error: 11.9554\n",
      "Epoch 220/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 430.2374 - mean_absolute_error: 12.3029\n",
      "Epoch 221/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 425.1576 - mean_absolute_error: 12.2418\n",
      "Epoch 222/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.1384 - mean_absolute_error: 12.1026\n",
      "Epoch 223/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.6519 - mean_absolute_error: 12.3650\n",
      "Epoch 224/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.3425 - mean_absolute_error: 12.0051\n",
      "Epoch 225/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 444.8102 - mean_absolute_error: 12.7704\n",
      "Epoch 226/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 433.1059 - mean_absolute_error: 12.5495\n",
      "Epoch 227/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 443.2912 - mean_absolute_error: 12.7172\n",
      "Epoch 228/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 429.8994 - mean_absolute_error: 11.9926\n",
      "Epoch 229/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.1637 - mean_absolute_error: 11.6401\n",
      "Epoch 230/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.2872 - mean_absolute_error: 12.2645\n",
      "Epoch 231/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.0676 - mean_absolute_error: 12.0522\n",
      "Epoch 232/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 430.7288 - mean_absolute_error: 12.1715\n",
      "Epoch 233/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.8649 - mean_absolute_error: 11.8391\n",
      "Epoch 234/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 427.5678 - mean_absolute_error: 12.0540\n",
      "Epoch 235/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 441.6092 - mean_absolute_error: 12.5131\n",
      "Epoch 236/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 410.1011 - mean_absolute_error: 11.7042\n",
      "Epoch 237/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 420.9500 - mean_absolute_error: 12.2332\n",
      "Epoch 238/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.1553 - mean_absolute_error: 12.2429\n",
      "Epoch 239/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.7010 - mean_absolute_error: 12.1856\n",
      "Epoch 240/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.6787 - mean_absolute_error: 12.0589\n",
      "Epoch 241/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.7495 - mean_absolute_error: 11.9848\n",
      "Epoch 242/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 446.5848 - mean_absolute_error: 12.5455\n",
      "Epoch 243/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.8216 - mean_absolute_error: 11.9086\n",
      "Epoch 244/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 428.5256 - mean_absolute_error: 11.8970\n",
      "Epoch 245/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.2337 - mean_absolute_error: 12.5021\n",
      "Epoch 246/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 445.6025 - mean_absolute_error: 12.7999\n",
      "Epoch 247/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 454.4385 - mean_absolute_error: 12.5316\n",
      "Epoch 248/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 403.9700 - mean_absolute_error: 11.6370\n",
      "Epoch 249/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.8386 - mean_absolute_error: 11.6518\n",
      "Epoch 250/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 467.1359 - mean_absolute_error: 12.5830\n",
      "Epoch 251/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 442.5574 - mean_absolute_error: 12.6307\n",
      "Epoch 252/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 430.1306 - mean_absolute_error: 12.3515\n",
      "Epoch 253/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 430.7229 - mean_absolute_error: 12.4671\n",
      "Epoch 254/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 423.7050 - mean_absolute_error: 12.2394\n",
      "Epoch 255/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 402.7777 - mean_absolute_error: 11.8956\n",
      "Epoch 256/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 455.9903 - mean_absolute_error: 12.6294\n",
      "Epoch 257/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 451.9528 - mean_absolute_error: 12.8104\n",
      "Epoch 258/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 429.1295 - mean_absolute_error: 12.4872\n",
      "Epoch 259/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.3436 - mean_absolute_error: 12.1607\n",
      "Epoch 260/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 429.4772 - mean_absolute_error: 12.3921\n",
      "Epoch 261/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 423.2563 - mean_absolute_error: 12.0402\n",
      "Epoch 262/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 433.7243 - mean_absolute_error: 12.3539\n",
      "Epoch 263/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 427.5454 - mean_absolute_error: 12.4263\n",
      "Epoch 264/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 503.7800 - mean_absolute_error: 12.7295\n",
      "Epoch 265/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.2466 - mean_absolute_error: 12.1017\n",
      "Epoch 266/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 418.1835 - mean_absolute_error: 12.1247\n",
      "Epoch 267/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 415.9468 - mean_absolute_error: 11.8587\n",
      "Epoch 268/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.8638 - mean_absolute_error: 11.9991\n",
      "Epoch 269/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.1020 - mean_absolute_error: 11.7078\n",
      "Epoch 270/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.2256 - mean_absolute_error: 12.1481\n",
      "Epoch 271/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.9053 - mean_absolute_error: 11.8205\n",
      "Epoch 272/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 430.5290 - mean_absolute_error: 12.2052\n",
      "Epoch 273/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.5856 - mean_absolute_error: 12.1708\n",
      "Epoch 274/5000\n",
      "344/344 [==============================] - 0s 260us/step - loss: 429.3046 - mean_absolute_error: 12.1337\n",
      "Epoch 275/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 409.0321 - mean_absolute_error: 11.5366\n",
      "Epoch 276/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 430.5807 - mean_absolute_error: 12.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 436.2814 - mean_absolute_error: 12.1903\n",
      "Epoch 278/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.2847 - mean_absolute_error: 12.1880\n",
      "Epoch 279/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.1791 - mean_absolute_error: 11.9951\n",
      "Epoch 280/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.3539 - mean_absolute_error: 12.3011\n",
      "Epoch 281/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.1841 - mean_absolute_error: 12.1027\n",
      "Epoch 282/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.2003 - mean_absolute_error: 11.9155\n",
      "Epoch 283/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 426.4698 - mean_absolute_error: 12.1215\n",
      "Epoch 284/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.7320 - mean_absolute_error: 12.2380\n",
      "Epoch 285/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 423.8518 - mean_absolute_error: 11.9892\n",
      "Epoch 286/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 437.8913 - mean_absolute_error: 12.2518\n",
      "Epoch 287/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 465.5290 - mean_absolute_error: 12.4702\n",
      "Epoch 288/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.3959 - mean_absolute_error: 12.1388\n",
      "Epoch 289/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.3801 - mean_absolute_error: 12.2234\n",
      "Epoch 290/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 446.3753 - mean_absolute_error: 12.5948\n",
      "Epoch 291/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 431.7641 - mean_absolute_error: 12.5670\n",
      "Epoch 292/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 422.6143 - mean_absolute_error: 11.8963\n",
      "Epoch 293/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.0780 - mean_absolute_error: 12.0267\n",
      "Epoch 294/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 435.7932 - mean_absolute_error: 12.3880\n",
      "Epoch 295/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.7506 - mean_absolute_error: 12.2042\n",
      "Epoch 296/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.4374 - mean_absolute_error: 11.9351\n",
      "Epoch 297/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.1714 - mean_absolute_error: 11.8605\n",
      "Epoch 298/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 441.0461 - mean_absolute_error: 12.6014\n",
      "Epoch 299/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 429.4006 - mean_absolute_error: 12.0521\n",
      "Epoch 300/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 421.2748 - mean_absolute_error: 12.0662\n",
      "Epoch 301/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.8679 - mean_absolute_error: 11.8553\n",
      "Epoch 302/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 439.9156 - mean_absolute_error: 12.8307\n",
      "Epoch 303/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 407.9116 - mean_absolute_error: 11.5472\n",
      "Epoch 304/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 408.9245 - mean_absolute_error: 11.7703\n",
      "Epoch 305/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 443.3496 - mean_absolute_error: 12.4505\n",
      "Epoch 306/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 432.0377 - mean_absolute_error: 12.2205\n",
      "Epoch 307/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.1783 - mean_absolute_error: 11.3674\n",
      "Epoch 308/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 441.5974 - mean_absolute_error: 12.5031\n",
      "Epoch 309/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 430.0312 - mean_absolute_error: 12.7304\n",
      "Epoch 310/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.3006 - mean_absolute_error: 11.9954\n",
      "Epoch 311/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.4509 - mean_absolute_error: 11.9061\n",
      "Epoch 312/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 443.8954 - mean_absolute_error: 12.3586\n",
      "Epoch 313/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 438.7271 - mean_absolute_error: 12.3800\n",
      "Epoch 314/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.4790 - mean_absolute_error: 11.7390\n",
      "Epoch 315/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 452.2033 - mean_absolute_error: 12.5696\n",
      "Epoch 316/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 431.5850 - mean_absolute_error: 12.4651\n",
      "Epoch 317/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.5751 - mean_absolute_error: 12.1969\n",
      "Epoch 318/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 445.5470 - mean_absolute_error: 12.6129\n",
      "Epoch 319/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 432.4752 - mean_absolute_error: 12.2574\n",
      "Epoch 320/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.0848 - mean_absolute_error: 11.8888\n",
      "Epoch 321/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 450.8776 - mean_absolute_error: 12.5817\n",
      "Epoch 322/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 408.5241 - mean_absolute_error: 11.5210\n",
      "Epoch 323/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 424.6523 - mean_absolute_error: 12.0820\n",
      "Epoch 324/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 409.2266 - mean_absolute_error: 11.5816\n",
      "Epoch 325/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 415.4540 - mean_absolute_error: 11.8016\n",
      "Epoch 326/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 435.6367 - mean_absolute_error: 12.5637\n",
      "Epoch 327/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.4620 - mean_absolute_error: 12.0500\n",
      "Epoch 328/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.6956 - mean_absolute_error: 12.2534\n",
      "Epoch 329/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 413.7809 - mean_absolute_error: 11.7978\n",
      "Epoch 330/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 437.2172 - mean_absolute_error: 12.4793\n",
      "Epoch 331/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.3447 - mean_absolute_error: 12.1977\n",
      "Epoch 332/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 421.1919 - mean_absolute_error: 12.0402\n",
      "Epoch 333/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 440.7238 - mean_absolute_error: 12.6959\n",
      "Epoch 334/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 428.8932 - mean_absolute_error: 11.9900\n",
      "Epoch 335/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 406.6974 - mean_absolute_error: 11.9569\n",
      "Epoch 336/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 419.9878 - mean_absolute_error: 12.0188\n",
      "Epoch 337/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 428.1185 - mean_absolute_error: 12.0051\n",
      "Epoch 338/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 436.6951 - mean_absolute_error: 12.5466\n",
      "Epoch 339/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 409.0993 - mean_absolute_error: 11.9225\n",
      "Epoch 340/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 412.3481 - mean_absolute_error: 11.9495\n",
      "Epoch 341/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 444.6073 - mean_absolute_error: 12.7118\n",
      "Epoch 342/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 429.2822 - mean_absolute_error: 12.4369\n",
      "Epoch 343/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 415.2294 - mean_absolute_error: 11.8695\n",
      "Epoch 344/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 475.1666 - mean_absolute_error: 13.1171\n",
      "Epoch 345/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 432.7823 - mean_absolute_error: 12.7579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 424.7183 - mean_absolute_error: 12.2526\n",
      "Epoch 347/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.5371 - mean_absolute_error: 11.9652\n",
      "Epoch 348/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.7768 - mean_absolute_error: 12.3061\n",
      "Epoch 349/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 420.5070 - mean_absolute_error: 12.2507\n",
      "Epoch 350/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 432.6719 - mean_absolute_error: 12.3435\n",
      "Epoch 351/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.6602 - mean_absolute_error: 11.9000\n",
      "Epoch 352/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 429.0054 - mean_absolute_error: 12.1910\n",
      "Epoch 353/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 415.2677 - mean_absolute_error: 11.6797\n",
      "Epoch 354/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.1667 - mean_absolute_error: 12.1452\n",
      "Epoch 355/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 411.7359 - mean_absolute_error: 11.6451\n",
      "Epoch 356/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 526.4279 - mean_absolute_error: 12.9377\n",
      "Epoch 357/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.7822 - mean_absolute_error: 12.0030\n",
      "Epoch 358/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 431.3678 - mean_absolute_error: 12.2036\n",
      "Epoch 359/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 455.7602 - mean_absolute_error: 12.4474\n",
      "Epoch 360/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.4176 - mean_absolute_error: 11.6248\n",
      "Epoch 361/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 448.5892 - mean_absolute_error: 12.2952\n",
      "Epoch 362/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 398.1206 - mean_absolute_error: 11.6582\n",
      "Epoch 363/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 435.7777 - mean_absolute_error: 12.2866\n",
      "Epoch 364/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 422.6664 - mean_absolute_error: 11.7694\n",
      "Epoch 365/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 437.6666 - mean_absolute_error: 12.2231\n",
      "Epoch 366/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 397.1037 - mean_absolute_error: 11.5632\n",
      "Epoch 367/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 435.0721 - mean_absolute_error: 12.0818\n",
      "Epoch 368/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.0409 - mean_absolute_error: 12.2933\n",
      "Epoch 369/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 443.1816 - mean_absolute_error: 12.8510\n",
      "Epoch 370/5000\n",
      "344/344 [==============================] - 0s 250us/step - loss: 412.8951 - mean_absolute_error: 11.9719\n",
      "Epoch 371/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 429.3902 - mean_absolute_error: 12.2760\n",
      "Epoch 372/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 442.8336 - mean_absolute_error: 12.0026\n",
      "Epoch 373/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 420.6849 - mean_absolute_error: 12.4077\n",
      "Epoch 374/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 444.3756 - mean_absolute_error: 12.5550\n",
      "Epoch 375/5000\n",
      "344/344 [==============================] - 0s 262us/step - loss: 430.6772 - mean_absolute_error: 12.3763\n",
      "Epoch 376/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 446.8721 - mean_absolute_error: 12.7055\n",
      "Epoch 377/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.0645 - mean_absolute_error: 11.9043\n",
      "Epoch 378/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 435.5724 - mean_absolute_error: 12.3223\n",
      "Epoch 379/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 430.5253 - mean_absolute_error: 12.1255\n",
      "Epoch 380/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.3723 - mean_absolute_error: 11.6533\n",
      "Epoch 381/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 416.3962 - mean_absolute_error: 12.1401\n",
      "Epoch 382/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 443.2020 - mean_absolute_error: 12.4206\n",
      "Epoch 383/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 396.1386 - mean_absolute_error: 11.4838\n",
      "Epoch 384/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 409.4768 - mean_absolute_error: 11.7493\n",
      "Epoch 385/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 430.9523 - mean_absolute_error: 12.3266\n",
      "Epoch 386/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 407.1940 - mean_absolute_error: 11.5451\n",
      "Epoch 387/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.9494 - mean_absolute_error: 11.5801\n",
      "Epoch 388/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.4673 - mean_absolute_error: 11.9483\n",
      "Epoch 389/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 434.0482 - mean_absolute_error: 12.3514\n",
      "Epoch 390/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.7212 - mean_absolute_error: 12.2894\n",
      "Epoch 391/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 413.0907 - mean_absolute_error: 12.1743\n",
      "Epoch 392/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 409.5069 - mean_absolute_error: 11.7854\n",
      "Epoch 393/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 444.4391 - mean_absolute_error: 12.1936\n",
      "Epoch 394/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 428.5959 - mean_absolute_error: 12.0934\n",
      "Epoch 395/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 431.4031 - mean_absolute_error: 12.2332\n",
      "Epoch 396/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 388.3966 - mean_absolute_error: 11.4467\n",
      "Epoch 397/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 442.0043 - mean_absolute_error: 12.5491\n",
      "Epoch 398/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.5789 - mean_absolute_error: 12.0610\n",
      "Epoch 399/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.7756 - mean_absolute_error: 12.1428\n",
      "Epoch 400/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 449.5624 - mean_absolute_error: 12.8677\n",
      "Epoch 401/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 436.5299 - mean_absolute_error: 12.3284\n",
      "Epoch 402/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.5567 - mean_absolute_error: 11.5635\n",
      "Epoch 403/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 433.4161 - mean_absolute_error: 12.3541\n",
      "Epoch 404/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 425.0581 - mean_absolute_error: 12.1287\n",
      "Epoch 405/5000\n",
      "344/344 [==============================] - 0s 224us/step - loss: 429.1456 - mean_absolute_error: 12.3210\n",
      "Epoch 406/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.4283 - mean_absolute_error: 11.8715\n",
      "Epoch 407/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 416.1151 - mean_absolute_error: 12.0229\n",
      "Epoch 408/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 430.2693 - mean_absolute_error: 12.3528\n",
      "Epoch 409/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 420.6493 - mean_absolute_error: 12.1945\n",
      "Epoch 410/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.9977 - mean_absolute_error: 11.5303\n",
      "Epoch 411/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 418.9122 - mean_absolute_error: 12.0576\n",
      "Epoch 412/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 406.2733 - mean_absolute_error: 11.7352\n",
      "Epoch 413/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 397.2390 - mean_absolute_error: 11.5543\n",
      "Epoch 414/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.9107 - mean_absolute_error: 12.3116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 423.2494 - mean_absolute_error: 12.2527\n",
      "Epoch 416/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 425.1456 - mean_absolute_error: 12.2311\n",
      "Epoch 417/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 457.9162 - mean_absolute_error: 12.2954\n",
      "Epoch 418/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.6143 - mean_absolute_error: 12.3110\n",
      "Epoch 419/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.6860 - mean_absolute_error: 12.2467\n",
      "Epoch 420/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 426.8720 - mean_absolute_error: 12.0606\n",
      "Epoch 421/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.8332 - mean_absolute_error: 12.1033\n",
      "Epoch 422/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 420.5140 - mean_absolute_error: 12.4310\n",
      "Epoch 423/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.9088 - mean_absolute_error: 12.2580\n",
      "Epoch 424/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.0123 - mean_absolute_error: 12.3013\n",
      "Epoch 425/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 440.4772 - mean_absolute_error: 12.5916\n",
      "Epoch 426/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.9271 - mean_absolute_error: 11.9301\n",
      "Epoch 427/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.7424 - mean_absolute_error: 11.8938\n",
      "Epoch 428/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 416.6106 - mean_absolute_error: 11.8658\n",
      "Epoch 429/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 409.6168 - mean_absolute_error: 11.8845\n",
      "Epoch 430/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.7982 - mean_absolute_error: 11.8924\n",
      "Epoch 431/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.5229 - mean_absolute_error: 11.7448\n",
      "Epoch 432/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.0120 - mean_absolute_error: 11.7992\n",
      "Epoch 433/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 392.9517 - mean_absolute_error: 11.4956\n",
      "Epoch 434/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.6879 - mean_absolute_error: 12.0092\n",
      "Epoch 435/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 408.0634 - mean_absolute_error: 11.6118\n",
      "Epoch 436/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.8329 - mean_absolute_error: 12.0580\n",
      "Epoch 437/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.3454 - mean_absolute_error: 11.9637\n",
      "Epoch 438/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 451.1731 - mean_absolute_error: 12.5346\n",
      "Epoch 439/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.6400 - mean_absolute_error: 11.8719\n",
      "Epoch 440/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 427.5092 - mean_absolute_error: 12.3011\n",
      "Epoch 441/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 431.2466 - mean_absolute_error: 12.3447\n",
      "Epoch 442/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 431.7826 - mean_absolute_error: 12.2379\n",
      "Epoch 443/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 436.2635 - mean_absolute_error: 12.1937\n",
      "Epoch 444/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.2126 - mean_absolute_error: 11.8306\n",
      "Epoch 445/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.0577 - mean_absolute_error: 11.6597\n",
      "Epoch 446/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 420.2716 - mean_absolute_error: 12.2408\n",
      "Epoch 447/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 442.0531 - mean_absolute_error: 12.5884\n",
      "Epoch 448/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 417.6237 - mean_absolute_error: 12.0045\n",
      "Epoch 449/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 432.2526 - mean_absolute_error: 12.2717\n",
      "Epoch 450/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.4839 - mean_absolute_error: 11.5923\n",
      "Epoch 451/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 438.6733 - mean_absolute_error: 12.2935\n",
      "Epoch 452/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.0544 - mean_absolute_error: 12.4208\n",
      "Epoch 453/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 402.9015 - mean_absolute_error: 11.7561\n",
      "Epoch 454/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 446.3654 - mean_absolute_error: 12.5471\n",
      "Epoch 455/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.1263 - mean_absolute_error: 11.7736\n",
      "Epoch 456/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.8590 - mean_absolute_error: 11.9944\n",
      "Epoch 457/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 430.0121 - mean_absolute_error: 12.1402\n",
      "Epoch 458/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.8004 - mean_absolute_error: 11.9408\n",
      "Epoch 459/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.1931 - mean_absolute_error: 11.7747\n",
      "Epoch 460/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 411.0216 - mean_absolute_error: 12.1355\n",
      "Epoch 461/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.9706 - mean_absolute_error: 11.9982\n",
      "Epoch 462/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.6199 - mean_absolute_error: 11.9813\n",
      "Epoch 463/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 405.1838 - mean_absolute_error: 11.6135\n",
      "Epoch 464/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.9617 - mean_absolute_error: 12.2011\n",
      "Epoch 465/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 446.5614 - mean_absolute_error: 12.2435\n",
      "Epoch 466/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.7594 - mean_absolute_error: 12.0170\n",
      "Epoch 467/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 443.2806 - mean_absolute_error: 12.4286\n",
      "Epoch 468/5000\n",
      "344/344 [==============================] - 0s 260us/step - loss: 422.7879 - mean_absolute_error: 12.0944\n",
      "Epoch 469/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 426.7167 - mean_absolute_error: 12.4660\n",
      "Epoch 470/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.6745 - mean_absolute_error: 11.9769\n",
      "Epoch 471/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.2831 - mean_absolute_error: 11.8725\n",
      "Epoch 472/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.1558 - mean_absolute_error: 12.0229\n",
      "Epoch 473/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.1205 - mean_absolute_error: 12.1705\n",
      "Epoch 474/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.2492 - mean_absolute_error: 11.7819\n",
      "Epoch 475/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 426.7036 - mean_absolute_error: 12.3091\n",
      "Epoch 476/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 471.9488 - mean_absolute_error: 12.3554\n",
      "Epoch 477/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 411.9187 - mean_absolute_error: 11.9655\n",
      "Epoch 478/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.9810 - mean_absolute_error: 11.9490\n",
      "Epoch 479/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 445.1093 - mean_absolute_error: 12.7131\n",
      "Epoch 480/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 401.9226 - mean_absolute_error: 11.7333\n",
      "Epoch 481/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 402.3318 - mean_absolute_error: 11.8068\n",
      "Epoch 482/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.4902 - mean_absolute_error: 11.7585\n",
      "Epoch 483/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 447.5605 - mean_absolute_error: 12.6295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 420.9061 - mean_absolute_error: 11.7891\n",
      "Epoch 485/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 416.0618 - mean_absolute_error: 11.9046\n",
      "Epoch 486/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 446.2178 - mean_absolute_error: 12.7521\n",
      "Epoch 487/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.2571 - mean_absolute_error: 11.8593\n",
      "Epoch 488/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.4804 - mean_absolute_error: 11.9806\n",
      "Epoch 489/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 434.3966 - mean_absolute_error: 12.5196\n",
      "Epoch 490/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 422.2097 - mean_absolute_error: 12.3155\n",
      "Epoch 491/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.4072 - mean_absolute_error: 12.0963\n",
      "Epoch 492/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.5803 - mean_absolute_error: 11.8377\n",
      "Epoch 493/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.8987 - mean_absolute_error: 11.9573\n",
      "Epoch 494/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.2712 - mean_absolute_error: 11.7790\n",
      "Epoch 495/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.8250 - mean_absolute_error: 11.3235\n",
      "Epoch 496/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 433.4501 - mean_absolute_error: 12.5438\n",
      "Epoch 497/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 441.9548 - mean_absolute_error: 12.3613\n",
      "Epoch 498/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.1015 - mean_absolute_error: 11.7385\n",
      "Epoch 499/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 422.3995 - mean_absolute_error: 11.9590\n",
      "Epoch 500/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.2264 - mean_absolute_error: 11.7743\n",
      "Epoch 501/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.8380 - mean_absolute_error: 12.0738\n",
      "Epoch 502/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 433.1830 - mean_absolute_error: 12.3463\n",
      "Epoch 503/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 473.0071 - mean_absolute_error: 12.5416\n",
      "Epoch 504/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 418.9258 - mean_absolute_error: 11.8276\n",
      "Epoch 505/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.5745 - mean_absolute_error: 11.9664\n",
      "Epoch 506/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 428.7094 - mean_absolute_error: 12.2073\n",
      "Epoch 507/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.6499 - mean_absolute_error: 11.6862\n",
      "Epoch 508/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.2746 - mean_absolute_error: 11.7871\n",
      "Epoch 509/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 467.1870 - mean_absolute_error: 12.5152\n",
      "Epoch 510/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 443.9947 - mean_absolute_error: 12.7775\n",
      "Epoch 511/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.7842 - mean_absolute_error: 11.9885\n",
      "Epoch 512/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.9765 - mean_absolute_error: 11.7927\n",
      "Epoch 513/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.8740 - mean_absolute_error: 12.2327\n",
      "Epoch 514/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 447.9669 - mean_absolute_error: 12.2692\n",
      "Epoch 515/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 425.2639 - mean_absolute_error: 12.1589\n",
      "Epoch 516/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.5688 - mean_absolute_error: 11.8188\n",
      "Epoch 517/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.3441 - mean_absolute_error: 12.3870\n",
      "Epoch 518/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 472.5773 - mean_absolute_error: 13.0140\n",
      "Epoch 519/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 407.4998 - mean_absolute_error: 11.7420\n",
      "Epoch 520/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 403.7190 - mean_absolute_error: 11.9514\n",
      "Epoch 521/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 424.4518 - mean_absolute_error: 12.1239\n",
      "Epoch 522/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 412.0704 - mean_absolute_error: 11.8856\n",
      "Epoch 523/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.3986 - mean_absolute_error: 12.0055\n",
      "Epoch 524/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 437.0950 - mean_absolute_error: 12.5236\n",
      "Epoch 525/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.4336 - mean_absolute_error: 12.1827\n",
      "Epoch 526/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.7207 - mean_absolute_error: 11.7966\n",
      "Epoch 527/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.6742 - mean_absolute_error: 12.3370\n",
      "Epoch 528/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 443.5585 - mean_absolute_error: 12.4559\n",
      "Epoch 529/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.7179 - mean_absolute_error: 11.8962\n",
      "Epoch 530/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.4596 - mean_absolute_error: 12.3112\n",
      "Epoch 531/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 426.5857 - mean_absolute_error: 12.2489\n",
      "Epoch 532/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 439.9314 - mean_absolute_error: 12.2308\n",
      "Epoch 533/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.1128 - mean_absolute_error: 12.1238\n",
      "Epoch 534/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.0818 - mean_absolute_error: 12.1625\n",
      "Epoch 535/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 404.5956 - mean_absolute_error: 11.7835\n",
      "Epoch 536/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 427.9333 - mean_absolute_error: 12.3978\n",
      "Epoch 537/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.2338 - mean_absolute_error: 11.9794\n",
      "Epoch 538/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.6515 - mean_absolute_error: 12.0059\n",
      "Epoch 539/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 435.4793 - mean_absolute_error: 12.4548\n",
      "Epoch 540/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 420.4577 - mean_absolute_error: 12.2551\n",
      "Epoch 541/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 418.2818 - mean_absolute_error: 11.9313\n",
      "Epoch 542/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 430.8902 - mean_absolute_error: 12.5451\n",
      "Epoch 543/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.0401 - mean_absolute_error: 11.9227\n",
      "Epoch 544/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.5587 - mean_absolute_error: 12.4822\n",
      "Epoch 545/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 423.9613 - mean_absolute_error: 12.0994\n",
      "Epoch 546/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 410.4228 - mean_absolute_error: 11.6251\n",
      "Epoch 547/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 402.8557 - mean_absolute_error: 11.7779\n",
      "Epoch 548/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.1458 - mean_absolute_error: 11.8337\n",
      "Epoch 549/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 432.5829 - mean_absolute_error: 12.1016\n",
      "Epoch 550/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.1440 - mean_absolute_error: 11.6014\n",
      "Epoch 551/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 434.7699 - mean_absolute_error: 12.3180\n",
      "Epoch 552/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.0691 - mean_absolute_error: 12.0890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 402.5362 - mean_absolute_error: 11.5794\n",
      "Epoch 554/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 437.0654 - mean_absolute_error: 12.1978\n",
      "Epoch 555/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.1817 - mean_absolute_error: 11.9289\n",
      "Epoch 556/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.5129 - mean_absolute_error: 12.0445\n",
      "Epoch 557/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 447.6656 - mean_absolute_error: 12.3794\n",
      "Epoch 558/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 423.3280 - mean_absolute_error: 12.1878\n",
      "Epoch 559/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 399.7971 - mean_absolute_error: 11.6254\n",
      "Epoch 560/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 453.1906 - mean_absolute_error: 12.5022\n",
      "Epoch 561/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 443.2939 - mean_absolute_error: 12.4619\n",
      "Epoch 562/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.5999 - mean_absolute_error: 12.2436\n",
      "Epoch 563/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.2514 - mean_absolute_error: 11.6974\n",
      "Epoch 564/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.6348 - mean_absolute_error: 11.7289\n",
      "Epoch 565/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 410.7290 - mean_absolute_error: 11.6219\n",
      "Epoch 566/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 449.7523 - mean_absolute_error: 12.2168\n",
      "Epoch 567/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.8528 - mean_absolute_error: 11.8151\n",
      "Epoch 568/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 413.8830 - mean_absolute_error: 11.8368\n",
      "Epoch 569/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.5982 - mean_absolute_error: 11.6542\n",
      "Epoch 570/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.8598 - mean_absolute_error: 12.2521\n",
      "Epoch 571/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.9345 - mean_absolute_error: 12.1490\n",
      "Epoch 572/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 415.7177 - mean_absolute_error: 12.0997\n",
      "Epoch 573/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 423.0430 - mean_absolute_error: 12.1326\n",
      "Epoch 574/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.7470 - mean_absolute_error: 11.7965\n",
      "Epoch 575/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.0969 - mean_absolute_error: 12.1702\n",
      "Epoch 576/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.8686 - mean_absolute_error: 12.1424\n",
      "Epoch 577/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 471.6205 - mean_absolute_error: 12.4639\n",
      "Epoch 578/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 415.6519 - mean_absolute_error: 11.9498\n",
      "Epoch 579/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 452.5651 - mean_absolute_error: 11.9863\n",
      "Epoch 580/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.0403 - mean_absolute_error: 11.8657\n",
      "Epoch 581/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.2704 - mean_absolute_error: 12.3807\n",
      "Epoch 582/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.9834 - mean_absolute_error: 11.9494\n",
      "Epoch 583/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.0417 - mean_absolute_error: 11.7920\n",
      "Epoch 584/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 421.5269 - mean_absolute_error: 11.9782\n",
      "Epoch 585/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.5895 - mean_absolute_error: 11.9277\n",
      "Epoch 586/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 435.6777 - mean_absolute_error: 12.4012\n",
      "Epoch 587/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.0804 - mean_absolute_error: 12.0129\n",
      "Epoch 588/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 416.5892 - mean_absolute_error: 12.0496\n",
      "Epoch 589/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 435.3171 - mean_absolute_error: 12.3379\n",
      "Epoch 590/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.6461 - mean_absolute_error: 12.1557\n",
      "Epoch 591/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.9241 - mean_absolute_error: 12.1557\n",
      "Epoch 592/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.9424 - mean_absolute_error: 11.7117\n",
      "Epoch 593/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.3315 - mean_absolute_error: 12.1222\n",
      "Epoch 594/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 418.3456 - mean_absolute_error: 12.0545\n",
      "Epoch 595/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.4935 - mean_absolute_error: 11.9382\n",
      "Epoch 596/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 450.9295 - mean_absolute_error: 12.4170\n",
      "Epoch 597/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 411.8399 - mean_absolute_error: 11.8420\n",
      "Epoch 598/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 433.8689 - mean_absolute_error: 12.2233\n",
      "Epoch 599/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.0315 - mean_absolute_error: 12.0275\n",
      "Epoch 600/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.5339 - mean_absolute_error: 11.9082\n",
      "Epoch 601/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.8272 - mean_absolute_error: 11.8245\n",
      "Epoch 602/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 443.0995 - mean_absolute_error: 12.4319\n",
      "Epoch 603/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.9576 - mean_absolute_error: 11.3991\n",
      "Epoch 604/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 434.9998 - mean_absolute_error: 12.1514\n",
      "Epoch 605/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 435.5221 - mean_absolute_error: 12.4039\n",
      "Epoch 606/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.4331 - mean_absolute_error: 12.1413\n",
      "Epoch 607/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.1256 - mean_absolute_error: 11.8792\n",
      "Epoch 608/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 402.7252 - mean_absolute_error: 11.8466\n",
      "Epoch 609/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.3259 - mean_absolute_error: 12.2761\n",
      "Epoch 610/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 409.2937 - mean_absolute_error: 11.7633\n",
      "Epoch 611/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 428.1288 - mean_absolute_error: 12.2027\n",
      "Epoch 612/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 430.3938 - mean_absolute_error: 12.2817\n",
      "Epoch 613/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.6241 - mean_absolute_error: 12.3978\n",
      "Epoch 614/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 406.3948 - mean_absolute_error: 11.6220\n",
      "Epoch 615/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.8982 - mean_absolute_error: 11.5443\n",
      "Epoch 616/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 406.5872 - mean_absolute_error: 12.0784\n",
      "Epoch 617/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.2416 - mean_absolute_error: 11.7640\n",
      "Epoch 618/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.0773 - mean_absolute_error: 11.8632\n",
      "Epoch 619/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 464.7868 - mean_absolute_error: 12.4877\n",
      "Epoch 620/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 416.8573 - mean_absolute_error: 11.9072\n",
      "Epoch 621/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.7872 - mean_absolute_error: 11.9050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 622/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 400.4676 - mean_absolute_error: 11.6693\n",
      "Epoch 623/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 423.5646 - mean_absolute_error: 11.8434\n",
      "Epoch 624/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 421.4331 - mean_absolute_error: 12.2709\n",
      "Epoch 625/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.6169 - mean_absolute_error: 12.3243\n",
      "Epoch 626/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 462.0928 - mean_absolute_error: 12.7749\n",
      "Epoch 627/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.2230 - mean_absolute_error: 11.7483\n",
      "Epoch 628/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.6840 - mean_absolute_error: 12.0033\n",
      "Epoch 629/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 451.8146 - mean_absolute_error: 12.6134\n",
      "Epoch 630/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.7745 - mean_absolute_error: 12.1801\n",
      "Epoch 631/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 427.3586 - mean_absolute_error: 12.1806\n",
      "Epoch 632/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.1691 - mean_absolute_error: 11.7536\n",
      "Epoch 633/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.4086 - mean_absolute_error: 11.9746\n",
      "Epoch 634/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.8385 - mean_absolute_error: 11.9989\n",
      "Epoch 635/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.7296 - mean_absolute_error: 11.9106\n",
      "Epoch 636/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 413.7079 - mean_absolute_error: 11.8184\n",
      "Epoch 637/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.1471 - mean_absolute_error: 11.6582\n",
      "Epoch 638/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.9356 - mean_absolute_error: 12.1090\n",
      "Epoch 639/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.7082 - mean_absolute_error: 11.6586\n",
      "Epoch 640/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.7513 - mean_absolute_error: 11.7797\n",
      "Epoch 641/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 448.3498 - mean_absolute_error: 12.4328\n",
      "Epoch 642/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.5085 - mean_absolute_error: 12.1533\n",
      "Epoch 643/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.8235 - mean_absolute_error: 11.7800\n",
      "Epoch 644/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 440.3681 - mean_absolute_error: 12.4429\n",
      "Epoch 645/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 440.4791 - mean_absolute_error: 12.2163\n",
      "Epoch 646/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.8464 - mean_absolute_error: 12.5324\n",
      "Epoch 647/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.9901 - mean_absolute_error: 11.8091\n",
      "Epoch 648/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.5624 - mean_absolute_error: 11.7716\n",
      "Epoch 649/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.3528 - mean_absolute_error: 12.0699\n",
      "Epoch 650/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.2730 - mean_absolute_error: 11.9469\n",
      "Epoch 651/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.2486 - mean_absolute_error: 11.8760\n",
      "Epoch 652/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.5865 - mean_absolute_error: 11.6363\n",
      "Epoch 653/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 404.9525 - mean_absolute_error: 11.6594\n",
      "Epoch 654/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 425.8907 - mean_absolute_error: 11.9526\n",
      "Epoch 655/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.9851 - mean_absolute_error: 11.7270\n",
      "Epoch 656/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.5890 - mean_absolute_error: 11.8158\n",
      "Epoch 657/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.3775 - mean_absolute_error: 12.4097\n",
      "Epoch 658/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 442.0500 - mean_absolute_error: 12.3914\n",
      "Epoch 659/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 426.6664 - mean_absolute_error: 12.1808\n",
      "Epoch 660/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.2185 - mean_absolute_error: 12.3878\n",
      "Epoch 661/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 425.9395 - mean_absolute_error: 12.1866\n",
      "Epoch 662/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 441.8545 - mean_absolute_error: 12.1536\n",
      "Epoch 663/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.4546 - mean_absolute_error: 12.1683\n",
      "Epoch 664/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.3670 - mean_absolute_error: 11.8156\n",
      "Epoch 665/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 436.7015 - mean_absolute_error: 12.0805\n",
      "Epoch 666/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.7102 - mean_absolute_error: 12.1489\n",
      "Epoch 667/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.2121 - mean_absolute_error: 12.0475\n",
      "Epoch 668/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 434.8568 - mean_absolute_error: 12.3012\n",
      "Epoch 669/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.2131 - mean_absolute_error: 11.8550\n",
      "Epoch 670/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 439.5932 - mean_absolute_error: 12.3052\n",
      "Epoch 671/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 427.0034 - mean_absolute_error: 12.1934\n",
      "Epoch 672/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 409.7378 - mean_absolute_error: 11.7167\n",
      "Epoch 673/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 399.3296 - mean_absolute_error: 11.7840\n",
      "Epoch 674/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 428.5728 - mean_absolute_error: 12.4439\n",
      "Epoch 675/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 439.5687 - mean_absolute_error: 12.1118\n",
      "Epoch 676/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.6715 - mean_absolute_error: 12.0730\n",
      "Epoch 677/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 473.2583 - mean_absolute_error: 12.6125\n",
      "Epoch 678/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 437.4881 - mean_absolute_error: 12.7106\n",
      "Epoch 679/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.6851 - mean_absolute_error: 12.0498\n",
      "Epoch 680/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.6412 - mean_absolute_error: 11.6846\n",
      "Epoch 681/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.4776 - mean_absolute_error: 11.8671\n",
      "Epoch 682/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.3308 - mean_absolute_error: 11.9928\n",
      "Epoch 683/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 430.1638 - mean_absolute_error: 12.2432\n",
      "Epoch 684/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.3290 - mean_absolute_error: 11.8704\n",
      "Epoch 685/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 422.4994 - mean_absolute_error: 11.9255\n",
      "Epoch 686/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 390.7950 - mean_absolute_error: 11.4973\n",
      "Epoch 687/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 396.7356 - mean_absolute_error: 11.5333\n",
      "Epoch 688/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 406.1160 - mean_absolute_error: 11.8492\n",
      "Epoch 689/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 407.2397 - mean_absolute_error: 11.6200\n",
      "Epoch 690/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 431.7865 - mean_absolute_error: 12.2797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 415.1504 - mean_absolute_error: 11.7011\n",
      "Epoch 692/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 428.5431 - mean_absolute_error: 11.7824\n",
      "Epoch 693/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.0512 - mean_absolute_error: 11.9516\n",
      "Epoch 694/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.4356 - mean_absolute_error: 11.9842\n",
      "Epoch 695/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 443.2363 - mean_absolute_error: 12.4237\n",
      "Epoch 696/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.8682 - mean_absolute_error: 12.3098\n",
      "Epoch 697/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.6292 - mean_absolute_error: 11.9391\n",
      "Epoch 698/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.5288 - mean_absolute_error: 12.1660\n",
      "Epoch 699/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 410.0542 - mean_absolute_error: 11.9606\n",
      "Epoch 700/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 432.4442 - mean_absolute_error: 12.2663\n",
      "Epoch 701/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 430.1351 - mean_absolute_error: 12.2574\n",
      "Epoch 702/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.8824 - mean_absolute_error: 12.1204\n",
      "Epoch 703/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 504.9523 - mean_absolute_error: 12.5588\n",
      "Epoch 704/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.7475 - mean_absolute_error: 12.3219\n",
      "Epoch 705/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 421.0029 - mean_absolute_error: 12.1806\n",
      "Epoch 706/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.5862 - mean_absolute_error: 12.2895\n",
      "Epoch 707/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 423.5842 - mean_absolute_error: 12.2209\n",
      "Epoch 708/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 430.9399 - mean_absolute_error: 12.3529\n",
      "Epoch 709/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 427.1472 - mean_absolute_error: 12.2406\n",
      "Epoch 710/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.6991 - mean_absolute_error: 12.1037\n",
      "Epoch 711/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 424.2949 - mean_absolute_error: 12.1755\n",
      "Epoch 712/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.3347 - mean_absolute_error: 11.6401\n",
      "Epoch 713/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.4062 - mean_absolute_error: 11.8177\n",
      "Epoch 714/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 416.8528 - mean_absolute_error: 11.9276\n",
      "Epoch 715/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.2805 - mean_absolute_error: 11.9239\n",
      "Epoch 716/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.7509 - mean_absolute_error: 11.7066\n",
      "Epoch 717/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 435.7687 - mean_absolute_error: 12.1341\n",
      "Epoch 718/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 413.5620 - mean_absolute_error: 11.7377\n",
      "Epoch 719/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 430.4832 - mean_absolute_error: 12.2804\n",
      "Epoch 720/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.8665 - mean_absolute_error: 12.3074\n",
      "Epoch 721/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 422.8170 - mean_absolute_error: 12.1809\n",
      "Epoch 722/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 424.4971 - mean_absolute_error: 12.2753\n",
      "Epoch 723/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.9329 - mean_absolute_error: 12.0202\n",
      "Epoch 724/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 421.7368 - mean_absolute_error: 12.0099\n",
      "Epoch 725/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.9236 - mean_absolute_error: 12.1275\n",
      "Epoch 726/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.0783 - mean_absolute_error: 12.3791\n",
      "Epoch 727/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.7706 - mean_absolute_error: 11.8861\n",
      "Epoch 728/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.5088 - mean_absolute_error: 11.8871\n",
      "Epoch 729/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 393.2822 - mean_absolute_error: 11.5632\n",
      "Epoch 730/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.2492 - mean_absolute_error: 12.2521\n",
      "Epoch 731/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.6092 - mean_absolute_error: 12.1404\n",
      "Epoch 732/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.5359 - mean_absolute_error: 12.0770\n",
      "Epoch 733/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.0842 - mean_absolute_error: 11.8965\n",
      "Epoch 734/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 423.2469 - mean_absolute_error: 11.8850\n",
      "Epoch 735/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.6974 - mean_absolute_error: 12.0759\n",
      "Epoch 736/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.9977 - mean_absolute_error: 11.9702\n",
      "Epoch 737/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 433.6461 - mean_absolute_error: 12.2343\n",
      "Epoch 738/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.3710 - mean_absolute_error: 11.8681\n",
      "Epoch 739/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 435.1166 - mean_absolute_error: 12.3167\n",
      "Epoch 740/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.6011 - mean_absolute_error: 12.1755\n",
      "Epoch 741/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 440.3820 - mean_absolute_error: 12.2357\n",
      "Epoch 742/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 435.2038 - mean_absolute_error: 11.9171\n",
      "Epoch 743/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 430.8091 - mean_absolute_error: 12.3679\n",
      "Epoch 744/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.2540 - mean_absolute_error: 11.7903\n",
      "Epoch 745/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.0963 - mean_absolute_error: 11.9673\n",
      "Epoch 746/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.8871 - mean_absolute_error: 11.4494\n",
      "Epoch 747/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 436.8922 - mean_absolute_error: 11.7271\n",
      "Epoch 748/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 407.6590 - mean_absolute_error: 11.9408\n",
      "Epoch 749/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.0223 - mean_absolute_error: 12.1766\n",
      "Epoch 750/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.0400 - mean_absolute_error: 11.6889\n",
      "Epoch 751/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.5488 - mean_absolute_error: 11.8203\n",
      "Epoch 752/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.3163 - mean_absolute_error: 11.8641\n",
      "Epoch 753/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 413.4122 - mean_absolute_error: 11.8341\n",
      "Epoch 754/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 431.7164 - mean_absolute_error: 12.3021\n",
      "Epoch 755/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 416.5953 - mean_absolute_error: 12.0233\n",
      "Epoch 756/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 436.3115 - mean_absolute_error: 12.2679\n",
      "Epoch 757/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 419.2574 - mean_absolute_error: 12.1013\n",
      "Epoch 758/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.6021 - mean_absolute_error: 11.8257\n",
      "Epoch 759/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 422.8397 - mean_absolute_error: 12.2509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.2235 - mean_absolute_error: 12.2406\n",
      "Epoch 761/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 401.8322 - mean_absolute_error: 11.7265\n",
      "Epoch 762/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 435.1786 - mean_absolute_error: 12.3754\n",
      "Epoch 763/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.3986 - mean_absolute_error: 11.8180\n",
      "Epoch 764/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.7621 - mean_absolute_error: 11.8346\n",
      "Epoch 765/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 429.0229 - mean_absolute_error: 12.4671\n",
      "Epoch 766/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 437.3099 - mean_absolute_error: 12.6127\n",
      "Epoch 767/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.2702 - mean_absolute_error: 11.5714\n",
      "Epoch 768/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 453.8261 - mean_absolute_error: 12.0783\n",
      "Epoch 769/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.2940 - mean_absolute_error: 12.0362\n",
      "Epoch 770/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 431.6842 - mean_absolute_error: 12.4809\n",
      "Epoch 771/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 409.5155 - mean_absolute_error: 11.6883\n",
      "Epoch 772/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.4131 - mean_absolute_error: 11.8529\n",
      "Epoch 773/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 430.6281 - mean_absolute_error: 12.2041\n",
      "Epoch 774/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.2062 - mean_absolute_error: 11.8663\n",
      "Epoch 775/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.6463 - mean_absolute_error: 11.9070\n",
      "Epoch 776/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 432.8004 - mean_absolute_error: 12.1131\n",
      "Epoch 777/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.5714 - mean_absolute_error: 11.9774\n",
      "Epoch 778/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 428.2336 - mean_absolute_error: 12.2211\n",
      "Epoch 779/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 439.3341 - mean_absolute_error: 12.3469\n",
      "Epoch 780/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 422.5919 - mean_absolute_error: 12.0451\n",
      "Epoch 781/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.8136 - mean_absolute_error: 12.0128\n",
      "Epoch 782/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 399.3442 - mean_absolute_error: 11.8113\n",
      "Epoch 783/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 419.3493 - mean_absolute_error: 12.0585\n",
      "Epoch 784/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.8768 - mean_absolute_error: 12.4719\n",
      "Epoch 785/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 430.8405 - mean_absolute_error: 12.2464\n",
      "Epoch 786/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 419.8244 - mean_absolute_error: 11.9289\n",
      "Epoch 787/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 418.8125 - mean_absolute_error: 11.8593\n",
      "Epoch 788/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 415.6323 - mean_absolute_error: 12.0117\n",
      "Epoch 789/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 408.2765 - mean_absolute_error: 11.8214\n",
      "Epoch 790/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.2157 - mean_absolute_error: 12.0097\n",
      "Epoch 791/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 411.0089 - mean_absolute_error: 11.8526\n",
      "Epoch 792/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.1100 - mean_absolute_error: 11.9192\n",
      "Epoch 793/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.0238 - mean_absolute_error: 11.6760\n",
      "Epoch 794/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 400.6954 - mean_absolute_error: 11.5900\n",
      "Epoch 795/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.7677 - mean_absolute_error: 12.1351\n",
      "Epoch 796/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.4350 - mean_absolute_error: 11.5975\n",
      "Epoch 797/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.8950 - mean_absolute_error: 11.8378\n",
      "Epoch 798/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 435.4639 - mean_absolute_error: 12.1798\n",
      "Epoch 799/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 403.0583 - mean_absolute_error: 11.8157\n",
      "Epoch 800/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 397.5250 - mean_absolute_error: 11.5302\n",
      "Epoch 801/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.8862 - mean_absolute_error: 11.5719\n",
      "Epoch 802/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.8754 - mean_absolute_error: 11.9443\n",
      "Epoch 803/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.7566 - mean_absolute_error: 12.1759\n",
      "Epoch 804/5000\n",
      "344/344 [==============================] - 0s 260us/step - loss: 409.0768 - mean_absolute_error: 12.0605\n",
      "Epoch 805/5000\n",
      "344/344 [==============================] - 0s 284us/step - loss: 401.4023 - mean_absolute_error: 11.5597\n",
      "Epoch 806/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 414.7245 - mean_absolute_error: 11.8909\n",
      "Epoch 807/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.3468 - mean_absolute_error: 11.6289\n",
      "Epoch 808/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.1836 - mean_absolute_error: 11.6481\n",
      "Epoch 809/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.0754 - mean_absolute_error: 11.9152\n",
      "Epoch 810/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 428.2119 - mean_absolute_error: 12.1559\n",
      "Epoch 811/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 422.4830 - mean_absolute_error: 12.1749\n",
      "Epoch 812/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.8336 - mean_absolute_error: 11.7154\n",
      "Epoch 813/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.9690 - mean_absolute_error: 12.2287\n",
      "Epoch 814/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 391.4012 - mean_absolute_error: 11.2140\n",
      "Epoch 815/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 444.2243 - mean_absolute_error: 12.3938\n",
      "Epoch 816/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.8802 - mean_absolute_error: 11.7760\n",
      "Epoch 817/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.6079 - mean_absolute_error: 12.1627\n",
      "Epoch 818/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.9280 - mean_absolute_error: 11.5274\n",
      "Epoch 819/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.4037 - mean_absolute_error: 11.8517\n",
      "Epoch 820/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.7778 - mean_absolute_error: 12.5056\n",
      "Epoch 821/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.6438 - mean_absolute_error: 11.9506\n",
      "Epoch 822/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 447.0894 - mean_absolute_error: 12.4906\n",
      "Epoch 823/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 415.8954 - mean_absolute_error: 11.9363\n",
      "Epoch 824/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.2839 - mean_absolute_error: 11.4462\n",
      "Epoch 825/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.5936 - mean_absolute_error: 11.5815\n",
      "Epoch 826/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 397.3745 - mean_absolute_error: 11.5816\n",
      "Epoch 827/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 472.6967 - mean_absolute_error: 13.0493\n",
      "Epoch 828/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 435.8109 - mean_absolute_error: 12.5466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 829/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.1265 - mean_absolute_error: 11.5988\n",
      "Epoch 830/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.4502 - mean_absolute_error: 12.1018\n",
      "Epoch 831/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.4821 - mean_absolute_error: 11.7963\n",
      "Epoch 832/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.0875 - mean_absolute_error: 12.0074\n",
      "Epoch 833/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 417.0078 - mean_absolute_error: 11.6331\n",
      "Epoch 834/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.7285 - mean_absolute_error: 11.8984\n",
      "Epoch 835/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.9399 - mean_absolute_error: 11.7577\n",
      "Epoch 836/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.3640 - mean_absolute_error: 12.3130\n",
      "Epoch 837/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 434.4482 - mean_absolute_error: 12.2798\n",
      "Epoch 838/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 417.5341 - mean_absolute_error: 11.5565\n",
      "Epoch 839/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.6785 - mean_absolute_error: 11.9879\n",
      "Epoch 840/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.6627 - mean_absolute_error: 11.7414\n",
      "Epoch 841/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 428.6866 - mean_absolute_error: 12.3497\n",
      "Epoch 842/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 446.9670 - mean_absolute_error: 12.4053\n",
      "Epoch 843/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 436.7262 - mean_absolute_error: 12.4943\n",
      "Epoch 844/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.5753 - mean_absolute_error: 11.7055\n",
      "Epoch 845/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 395.0910 - mean_absolute_error: 11.5033\n",
      "Epoch 846/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.9215 - mean_absolute_error: 12.2132\n",
      "Epoch 847/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.5687 - mean_absolute_error: 12.0138\n",
      "Epoch 848/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 397.4219 - mean_absolute_error: 11.7131\n",
      "Epoch 849/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.2702 - mean_absolute_error: 11.8336\n",
      "Epoch 850/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 399.5738 - mean_absolute_error: 11.4716\n",
      "Epoch 851/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 441.3278 - mean_absolute_error: 12.7687\n",
      "Epoch 852/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.2388 - mean_absolute_error: 11.9184\n",
      "Epoch 853/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.3855 - mean_absolute_error: 12.1948\n",
      "Epoch 854/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.3462 - mean_absolute_error: 11.9412\n",
      "Epoch 855/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.5246 - mean_absolute_error: 12.0466\n",
      "Epoch 856/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 404.4695 - mean_absolute_error: 11.6442\n",
      "Epoch 857/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 420.4017 - mean_absolute_error: 12.0551\n",
      "Epoch 858/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 406.5619 - mean_absolute_error: 11.6161\n",
      "Epoch 859/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 420.0828 - mean_absolute_error: 12.1382\n",
      "Epoch 860/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 448.9185 - mean_absolute_error: 12.4947\n",
      "Epoch 861/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.3839 - mean_absolute_error: 12.3740\n",
      "Epoch 862/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.8309 - mean_absolute_error: 11.9270\n",
      "Epoch 863/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.3919 - mean_absolute_error: 12.0164\n",
      "Epoch 864/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.3395 - mean_absolute_error: 11.8315\n",
      "Epoch 865/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 425.4085 - mean_absolute_error: 12.1940\n",
      "Epoch 866/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 425.2299 - mean_absolute_error: 12.1211\n",
      "Epoch 867/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.5836 - mean_absolute_error: 11.7993\n",
      "Epoch 868/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 404.1712 - mean_absolute_error: 11.9464\n",
      "Epoch 869/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 431.9586 - mean_absolute_error: 11.8024\n",
      "Epoch 870/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.1549 - mean_absolute_error: 11.9275\n",
      "Epoch 871/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.3193 - mean_absolute_error: 11.6785\n",
      "Epoch 872/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.2556 - mean_absolute_error: 12.1664\n",
      "Epoch 873/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 439.8867 - mean_absolute_error: 12.3438\n",
      "Epoch 874/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 459.8083 - mean_absolute_error: 12.5797\n",
      "Epoch 875/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 460.9398 - mean_absolute_error: 12.0304\n",
      "Epoch 876/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.9432 - mean_absolute_error: 11.7379\n",
      "Epoch 877/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.3289 - mean_absolute_error: 11.9000\n",
      "Epoch 878/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.2615 - mean_absolute_error: 12.2210\n",
      "Epoch 879/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.8687 - mean_absolute_error: 11.9125\n",
      "Epoch 880/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.8335 - mean_absolute_error: 12.0581\n",
      "Epoch 881/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.6439 - mean_absolute_error: 12.0349\n",
      "Epoch 882/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 400.5522 - mean_absolute_error: 11.5739\n",
      "Epoch 883/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 422.3285 - mean_absolute_error: 12.2066\n",
      "Epoch 884/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 396.1750 - mean_absolute_error: 11.4685\n",
      "Epoch 885/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 414.2621 - mean_absolute_error: 12.0308\n",
      "Epoch 886/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.3721 - mean_absolute_error: 11.9227\n",
      "Epoch 887/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.3555 - mean_absolute_error: 11.4329\n",
      "Epoch 888/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 401.1103 - mean_absolute_error: 11.6676\n",
      "Epoch 889/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 398.1169 - mean_absolute_error: 11.6512\n",
      "Epoch 890/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.3720 - mean_absolute_error: 12.1070\n",
      "Epoch 891/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 439.6921 - mean_absolute_error: 12.2628\n",
      "Epoch 892/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 415.0625 - mean_absolute_error: 11.9219\n",
      "Epoch 893/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.8706 - mean_absolute_error: 11.6308\n",
      "Epoch 894/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 396.0566 - mean_absolute_error: 11.5452\n",
      "Epoch 895/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.5905 - mean_absolute_error: 11.6905\n",
      "Epoch 896/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 435.6004 - mean_absolute_error: 12.1712\n",
      "Epoch 897/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 432.9351 - mean_absolute_error: 12.2428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 898/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 415.5122 - mean_absolute_error: 11.9152\n",
      "Epoch 899/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 434.2172 - mean_absolute_error: 12.0961\n",
      "Epoch 900/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.8236 - mean_absolute_error: 12.2582\n",
      "Epoch 901/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.2678 - mean_absolute_error: 12.2500\n",
      "Epoch 902/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 438.8261 - mean_absolute_error: 12.1600\n",
      "Epoch 903/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.5464 - mean_absolute_error: 11.5721\n",
      "Epoch 904/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 398.3610 - mean_absolute_error: 11.6164\n",
      "Epoch 905/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 426.3068 - mean_absolute_error: 12.2098\n",
      "Epoch 906/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.1707 - mean_absolute_error: 11.8840\n",
      "Epoch 907/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.9561 - mean_absolute_error: 11.8477\n",
      "Epoch 908/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.2477 - mean_absolute_error: 11.2893\n",
      "Epoch 909/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.1643 - mean_absolute_error: 12.2880\n",
      "Epoch 910/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 401.8949 - mean_absolute_error: 11.4733\n",
      "Epoch 911/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.1162 - mean_absolute_error: 12.0480\n",
      "Epoch 912/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 404.4995 - mean_absolute_error: 11.6852\n",
      "Epoch 913/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.3316 - mean_absolute_error: 11.4089\n",
      "Epoch 914/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 421.0047 - mean_absolute_error: 12.0970\n",
      "Epoch 915/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 398.4833 - mean_absolute_error: 11.4129\n",
      "Epoch 916/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 435.7695 - mean_absolute_error: 12.7978\n",
      "Epoch 917/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 420.8683 - mean_absolute_error: 12.4236\n",
      "Epoch 918/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 418.0916 - mean_absolute_error: 11.9101\n",
      "Epoch 919/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 418.1758 - mean_absolute_error: 12.2306\n",
      "Epoch 920/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 409.6784 - mean_absolute_error: 11.6585\n",
      "Epoch 921/5000\n",
      "344/344 [==============================] - 0s 265us/step - loss: 434.6871 - mean_absolute_error: 12.1350\n",
      "Epoch 922/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 409.2990 - mean_absolute_error: 11.8255\n",
      "Epoch 923/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 426.5409 - mean_absolute_error: 11.9665\n",
      "Epoch 924/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 435.7181 - mean_absolute_error: 12.3523\n",
      "Epoch 925/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 429.6960 - mean_absolute_error: 12.2310\n",
      "Epoch 926/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.6805 - mean_absolute_error: 11.8182\n",
      "Epoch 927/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 412.2579 - mean_absolute_error: 12.0362\n",
      "Epoch 928/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 436.3180 - mean_absolute_error: 12.3516\n",
      "Epoch 929/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.1900 - mean_absolute_error: 11.8475\n",
      "Epoch 930/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 403.7368 - mean_absolute_error: 11.5873\n",
      "Epoch 931/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 424.1854 - mean_absolute_error: 12.1208\n",
      "Epoch 932/5000\n",
      "344/344 [==============================] - 0s 254us/step - loss: 429.7179 - mean_absolute_error: 12.4648\n",
      "Epoch 933/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.5367 - mean_absolute_error: 11.3763\n",
      "Epoch 934/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 437.1979 - mean_absolute_error: 12.2602\n",
      "Epoch 935/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.1550 - mean_absolute_error: 12.1420\n",
      "Epoch 936/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 423.9044 - mean_absolute_error: 12.2160\n",
      "Epoch 937/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 409.1446 - mean_absolute_error: 12.1183\n",
      "Epoch 938/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 425.1842 - mean_absolute_error: 12.0445\n",
      "Epoch 939/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 437.3167 - mean_absolute_error: 12.1126\n",
      "Epoch 940/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 399.0939 - mean_absolute_error: 11.3294\n",
      "Epoch 941/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.9488 - mean_absolute_error: 12.0847\n",
      "Epoch 942/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.6797 - mean_absolute_error: 11.9028\n",
      "Epoch 943/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.2975 - mean_absolute_error: 12.1595\n",
      "Epoch 944/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 443.8784 - mean_absolute_error: 12.7571\n",
      "Epoch 945/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 439.1247 - mean_absolute_error: 12.4297\n",
      "Epoch 946/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 425.4598 - mean_absolute_error: 11.9509\n",
      "Epoch 947/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.3654 - mean_absolute_error: 12.2246\n",
      "Epoch 948/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 405.3586 - mean_absolute_error: 11.6185\n",
      "Epoch 949/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 403.5493 - mean_absolute_error: 11.7452\n",
      "Epoch 950/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 410.4967 - mean_absolute_error: 11.8155\n",
      "Epoch 951/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.4867 - mean_absolute_error: 12.1242\n",
      "Epoch 952/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.6715 - mean_absolute_error: 11.6376\n",
      "Epoch 953/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 411.3651 - mean_absolute_error: 12.0702\n",
      "Epoch 954/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.9127 - mean_absolute_error: 11.8407\n",
      "Epoch 955/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.0805 - mean_absolute_error: 11.8038\n",
      "Epoch 956/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.1003 - mean_absolute_error: 11.9218\n",
      "Epoch 957/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.2473 - mean_absolute_error: 12.2721\n",
      "Epoch 958/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.5919 - mean_absolute_error: 11.9359\n",
      "Epoch 959/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.6562 - mean_absolute_error: 12.0846\n",
      "Epoch 960/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.4048 - mean_absolute_error: 11.8468\n",
      "Epoch 961/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 433.3858 - mean_absolute_error: 12.1199\n",
      "Epoch 962/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 417.6693 - mean_absolute_error: 12.1071\n",
      "Epoch 963/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 496.9041 - mean_absolute_error: 13.0743\n",
      "Epoch 964/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.9274 - mean_absolute_error: 12.2622\n",
      "Epoch 965/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 426.0623 - mean_absolute_error: 12.0426\n",
      "Epoch 966/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.2203 - mean_absolute_error: 11.6452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 967/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 450.4695 - mean_absolute_error: 12.5764\n",
      "Epoch 968/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 424.0415 - mean_absolute_error: 11.6886\n",
      "Epoch 969/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.2751 - mean_absolute_error: 12.1595\n",
      "Epoch 970/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 454.1584 - mean_absolute_error: 12.7597\n",
      "Epoch 971/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 437.4564 - mean_absolute_error: 12.2199\n",
      "Epoch 972/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.9927 - mean_absolute_error: 12.1284\n",
      "Epoch 973/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 436.5258 - mean_absolute_error: 12.3288\n",
      "Epoch 974/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 435.2963 - mean_absolute_error: 12.1543\n",
      "Epoch 975/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 401.7972 - mean_absolute_error: 11.7269\n",
      "Epoch 976/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.4257 - mean_absolute_error: 11.7141\n",
      "Epoch 977/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.4616 - mean_absolute_error: 11.8756\n",
      "Epoch 978/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 431.4840 - mean_absolute_error: 11.8601\n",
      "Epoch 979/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 442.5236 - mean_absolute_error: 12.2868\n",
      "Epoch 980/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 435.4686 - mean_absolute_error: 12.3755\n",
      "Epoch 981/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 474.3880 - mean_absolute_error: 12.2543\n",
      "Epoch 982/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.6934 - mean_absolute_error: 11.7011\n",
      "Epoch 983/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.7558 - mean_absolute_error: 11.9600\n",
      "Epoch 984/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.1623 - mean_absolute_error: 12.1160\n",
      "Epoch 985/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 435.0074 - mean_absolute_error: 12.2421\n",
      "Epoch 986/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 416.5157 - mean_absolute_error: 11.7351\n",
      "Epoch 987/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 439.0048 - mean_absolute_error: 12.1595\n",
      "Epoch 988/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.8662 - mean_absolute_error: 11.9324\n",
      "Epoch 989/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 430.3750 - mean_absolute_error: 12.2390\n",
      "Epoch 990/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 412.5362 - mean_absolute_error: 12.0403\n",
      "Epoch 991/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 408.2952 - mean_absolute_error: 11.7555\n",
      "Epoch 992/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 420.6382 - mean_absolute_error: 11.9201\n",
      "Epoch 993/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.5898 - mean_absolute_error: 11.9127\n",
      "Epoch 994/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 411.8186 - mean_absolute_error: 11.9260\n",
      "Epoch 995/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.0267 - mean_absolute_error: 11.6835\n",
      "Epoch 996/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.6809 - mean_absolute_error: 12.1199\n",
      "Epoch 997/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.0378 - mean_absolute_error: 11.9305\n",
      "Epoch 998/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.7044 - mean_absolute_error: 12.0962\n",
      "Epoch 999/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.4303 - mean_absolute_error: 11.9462\n",
      "Epoch 1000/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 385.0996 - mean_absolute_error: 11.3557\n",
      "Epoch 1001/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.7555 - mean_absolute_error: 12.0067\n",
      "Epoch 1002/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.9622 - mean_absolute_error: 12.1726\n",
      "Epoch 1003/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 425.3247 - mean_absolute_error: 12.0889\n",
      "Epoch 1004/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 436.0953 - mean_absolute_error: 12.2514\n",
      "Epoch 1005/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.5433 - mean_absolute_error: 12.2228\n",
      "Epoch 1006/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 396.8741 - mean_absolute_error: 11.4798\n",
      "Epoch 1007/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 421.3561 - mean_absolute_error: 12.4145\n",
      "Epoch 1008/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 429.8719 - mean_absolute_error: 12.0135\n",
      "Epoch 1009/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.0211 - mean_absolute_error: 11.5381\n",
      "Epoch 1010/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 428.3336 - mean_absolute_error: 11.8013\n",
      "Epoch 1011/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 429.9514 - mean_absolute_error: 12.0872\n",
      "Epoch 1012/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 419.9478 - mean_absolute_error: 12.1318\n",
      "Epoch 1013/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 428.0382 - mean_absolute_error: 11.7491\n",
      "Epoch 1014/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.1369 - mean_absolute_error: 11.8761\n",
      "Epoch 1015/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 440.9666 - mean_absolute_error: 12.5135\n",
      "Epoch 1016/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.5857 - mean_absolute_error: 11.8480\n",
      "Epoch 1017/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.6483 - mean_absolute_error: 11.6732\n",
      "Epoch 1018/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.2597 - mean_absolute_error: 11.7850\n",
      "Epoch 1019/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.4942 - mean_absolute_error: 12.0462\n",
      "Epoch 1020/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 401.2584 - mean_absolute_error: 11.7621\n",
      "Epoch 1021/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 439.2686 - mean_absolute_error: 12.5438\n",
      "Epoch 1022/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.1479 - mean_absolute_error: 11.7286\n",
      "Epoch 1023/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.8544 - mean_absolute_error: 11.6096\n",
      "Epoch 1024/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 429.4140 - mean_absolute_error: 12.3913\n",
      "Epoch 1025/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.3050 - mean_absolute_error: 12.1740\n",
      "Epoch 1026/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.1065 - mean_absolute_error: 12.0074\n",
      "Epoch 1027/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 442.3259 - mean_absolute_error: 12.3090\n",
      "Epoch 1028/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.6387 - mean_absolute_error: 11.9928\n",
      "Epoch 1029/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 408.9430 - mean_absolute_error: 11.4024\n",
      "Epoch 1030/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 407.8868 - mean_absolute_error: 11.6794\n",
      "Epoch 1031/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.0486 - mean_absolute_error: 12.3184\n",
      "Epoch 1032/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.2560 - mean_absolute_error: 11.7019\n",
      "Epoch 1033/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 394.3734 - mean_absolute_error: 11.6045\n",
      "Epoch 1034/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 422.1530 - mean_absolute_error: 12.3456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1035/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 430.3831 - mean_absolute_error: 12.5973\n",
      "Epoch 1036/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.0665 - mean_absolute_error: 11.9668\n",
      "Epoch 1037/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 439.4797 - mean_absolute_error: 11.8029\n",
      "Epoch 1038/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 422.2569 - mean_absolute_error: 12.0586\n",
      "Epoch 1039/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 437.2977 - mean_absolute_error: 12.2931\n",
      "Epoch 1040/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 421.2660 - mean_absolute_error: 12.4683\n",
      "Epoch 1041/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 434.3073 - mean_absolute_error: 12.0889\n",
      "Epoch 1042/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 396.6160 - mean_absolute_error: 11.5610\n",
      "Epoch 1043/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.9597 - mean_absolute_error: 11.7616\n",
      "Epoch 1044/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.4980 - mean_absolute_error: 12.0213\n",
      "Epoch 1045/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 468.9501 - mean_absolute_error: 12.4967\n",
      "Epoch 1046/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 426.0426 - mean_absolute_error: 12.2398\n",
      "Epoch 1047/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.0128 - mean_absolute_error: 12.0072\n",
      "Epoch 1048/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 451.8275 - mean_absolute_error: 12.2964\n",
      "Epoch 1049/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.2412 - mean_absolute_error: 12.2389\n",
      "Epoch 1050/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.7096 - mean_absolute_error: 11.9998\n",
      "Epoch 1051/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.7066 - mean_absolute_error: 11.6884\n",
      "Epoch 1052/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 427.5453 - mean_absolute_error: 12.0395\n",
      "Epoch 1053/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 439.5316 - mean_absolute_error: 12.2870\n",
      "Epoch 1054/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 439.2144 - mean_absolute_error: 12.2956\n",
      "Epoch 1055/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.5680 - mean_absolute_error: 12.3420\n",
      "Epoch 1056/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.5176 - mean_absolute_error: 11.8533\n",
      "Epoch 1057/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.3647 - mean_absolute_error: 11.8921\n",
      "Epoch 1058/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.5420 - mean_absolute_error: 11.7967\n",
      "Epoch 1059/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.6419 - mean_absolute_error: 11.8615\n",
      "Epoch 1060/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 442.6852 - mean_absolute_error: 12.3960\n",
      "Epoch 1061/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.3065 - mean_absolute_error: 12.1050\n",
      "Epoch 1062/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.2399 - mean_absolute_error: 11.8586\n",
      "Epoch 1063/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 418.6692 - mean_absolute_error: 12.2350\n",
      "Epoch 1064/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.5951 - mean_absolute_error: 11.8851\n",
      "Epoch 1065/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 431.6069 - mean_absolute_error: 12.0953\n",
      "Epoch 1066/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.6915 - mean_absolute_error: 11.7916\n",
      "Epoch 1067/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.6856 - mean_absolute_error: 11.6499\n",
      "Epoch 1068/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.6474 - mean_absolute_error: 12.0550\n",
      "Epoch 1069/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 419.4098 - mean_absolute_error: 12.2803\n",
      "Epoch 1070/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.0580 - mean_absolute_error: 12.0529\n",
      "Epoch 1071/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 408.1812 - mean_absolute_error: 11.7274\n",
      "Epoch 1072/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.7063 - mean_absolute_error: 12.1135\n",
      "Epoch 1073/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 434.1675 - mean_absolute_error: 11.9800\n",
      "Epoch 1074/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 411.1381 - mean_absolute_error: 12.0412\n",
      "Epoch 1075/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 430.7731 - mean_absolute_error: 12.1792\n",
      "Epoch 1076/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 416.6977 - mean_absolute_error: 12.0973\n",
      "Epoch 1077/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 434.3538 - mean_absolute_error: 12.2586\n",
      "Epoch 1078/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 433.7653 - mean_absolute_error: 12.5517\n",
      "Epoch 1079/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 435.0342 - mean_absolute_error: 12.2344\n",
      "Epoch 1080/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.1864 - mean_absolute_error: 11.6261\n",
      "Epoch 1081/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.3777 - mean_absolute_error: 11.6151\n",
      "Epoch 1082/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 423.7032 - mean_absolute_error: 12.2088\n",
      "Epoch 1083/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 421.9279 - mean_absolute_error: 12.1570\n",
      "Epoch 1084/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 430.9883 - mean_absolute_error: 12.0233\n",
      "Epoch 1085/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.6462 - mean_absolute_error: 11.8598\n",
      "Epoch 1086/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 454.1007 - mean_absolute_error: 12.6513\n",
      "Epoch 1087/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.2913 - mean_absolute_error: 11.8043\n",
      "Epoch 1088/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.5439 - mean_absolute_error: 11.9031\n",
      "Epoch 1089/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.3641 - mean_absolute_error: 11.9075\n",
      "Epoch 1090/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.1673 - mean_absolute_error: 11.8780\n",
      "Epoch 1091/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.9984 - mean_absolute_error: 12.1085\n",
      "Epoch 1092/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 419.5272 - mean_absolute_error: 11.8435\n",
      "Epoch 1093/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.3804 - mean_absolute_error: 11.9810\n",
      "Epoch 1094/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 405.8676 - mean_absolute_error: 11.9424\n",
      "Epoch 1095/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 432.7873 - mean_absolute_error: 11.7790\n",
      "Epoch 1096/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.6682 - mean_absolute_error: 12.0074\n",
      "Epoch 1097/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 433.5466 - mean_absolute_error: 12.2726\n",
      "Epoch 1098/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.0298 - mean_absolute_error: 12.0247\n",
      "Epoch 1099/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 400.7094 - mean_absolute_error: 11.9346\n",
      "Epoch 1100/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.4464 - mean_absolute_error: 11.8495\n",
      "Epoch 1101/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.5829 - mean_absolute_error: 11.8178\n",
      "Epoch 1102/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.0571 - mean_absolute_error: 12.0524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1103/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.8560 - mean_absolute_error: 11.7084\n",
      "Epoch 1104/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.6479 - mean_absolute_error: 12.0709\n",
      "Epoch 1105/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.3263 - mean_absolute_error: 12.0043\n",
      "Epoch 1106/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.0521 - mean_absolute_error: 12.0608\n",
      "Epoch 1107/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 405.8585 - mean_absolute_error: 11.7012\n",
      "Epoch 1108/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.8604 - mean_absolute_error: 11.9703\n",
      "Epoch 1109/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.9549 - mean_absolute_error: 11.8844\n",
      "Epoch 1110/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 451.4256 - mean_absolute_error: 12.7188\n",
      "Epoch 1111/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 444.9336 - mean_absolute_error: 11.9897\n",
      "Epoch 1112/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.5274 - mean_absolute_error: 11.5339\n",
      "Epoch 1113/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.1022 - mean_absolute_error: 11.8888\n",
      "Epoch 1114/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 399.8778 - mean_absolute_error: 11.6135\n",
      "Epoch 1115/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.9070 - mean_absolute_error: 11.6003\n",
      "Epoch 1116/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 426.7918 - mean_absolute_error: 12.2623\n",
      "Epoch 1117/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 422.7129 - mean_absolute_error: 12.3071\n",
      "Epoch 1118/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 424.2193 - mean_absolute_error: 11.8253\n",
      "Epoch 1119/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 404.9729 - mean_absolute_error: 11.6450\n",
      "Epoch 1120/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 409.8082 - mean_absolute_error: 11.7596\n",
      "Epoch 1121/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 424.0773 - mean_absolute_error: 11.9462\n",
      "Epoch 1122/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.0832 - mean_absolute_error: 11.9319\n",
      "Epoch 1123/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 432.7744 - mean_absolute_error: 12.1451\n",
      "Epoch 1124/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 416.8078 - mean_absolute_error: 11.7287\n",
      "Epoch 1125/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.3912 - mean_absolute_error: 12.1032\n",
      "Epoch 1126/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 408.6847 - mean_absolute_error: 11.8738\n",
      "Epoch 1127/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 424.6803 - mean_absolute_error: 12.2856\n",
      "Epoch 1128/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 437.3387 - mean_absolute_error: 12.5804\n",
      "Epoch 1129/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.5592 - mean_absolute_error: 11.9182\n",
      "Epoch 1130/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 424.2024 - mean_absolute_error: 12.0669\n",
      "Epoch 1131/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.8345 - mean_absolute_error: 11.8799\n",
      "Epoch 1132/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 412.9194 - mean_absolute_error: 11.7525\n",
      "Epoch 1133/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 424.1018 - mean_absolute_error: 12.1511\n",
      "Epoch 1134/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 440.0629 - mean_absolute_error: 12.5507\n",
      "Epoch 1135/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 408.8638 - mean_absolute_error: 11.6778\n",
      "Epoch 1136/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.0533 - mean_absolute_error: 12.0556\n",
      "Epoch 1137/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 407.9657 - mean_absolute_error: 11.8801\n",
      "Epoch 1138/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 429.9991 - mean_absolute_error: 12.0932\n",
      "Epoch 1139/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 470.7491 - mean_absolute_error: 12.7362\n",
      "Epoch 1140/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.4618 - mean_absolute_error: 11.2998\n",
      "Epoch 1141/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 425.0505 - mean_absolute_error: 12.3211\n",
      "Epoch 1142/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 414.2174 - mean_absolute_error: 11.8610\n",
      "Epoch 1143/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 427.8071 - mean_absolute_error: 12.1202\n",
      "Epoch 1144/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 419.7263 - mean_absolute_error: 11.9846\n",
      "Epoch 1145/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 392.1618 - mean_absolute_error: 11.6599\n",
      "Epoch 1146/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.3215 - mean_absolute_error: 11.9700\n",
      "Epoch 1147/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 424.5050 - mean_absolute_error: 12.1608\n",
      "Epoch 1148/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 420.4597 - mean_absolute_error: 12.1103\n",
      "Epoch 1149/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.1549 - mean_absolute_error: 11.9053\n",
      "Epoch 1150/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 432.7802 - mean_absolute_error: 12.3676\n",
      "Epoch 1151/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 402.8062 - mean_absolute_error: 11.4759\n",
      "Epoch 1152/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.3661 - mean_absolute_error: 11.7941\n",
      "Epoch 1153/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 435.5880 - mean_absolute_error: 12.3702\n",
      "Epoch 1154/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 433.0080 - mean_absolute_error: 12.2652\n",
      "Epoch 1155/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 425.7042 - mean_absolute_error: 12.0917\n",
      "Epoch 1156/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 442.3190 - mean_absolute_error: 12.4468\n",
      "Epoch 1157/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 426.9543 - mean_absolute_error: 12.2691\n",
      "Epoch 1158/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.3509 - mean_absolute_error: 11.6636\n",
      "Epoch 1159/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 416.3825 - mean_absolute_error: 11.7147\n",
      "Epoch 1160/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 405.1360 - mean_absolute_error: 11.3641\n",
      "Epoch 1161/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.0610 - mean_absolute_error: 11.5834\n",
      "Epoch 1162/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 435.5347 - mean_absolute_error: 12.2690\n",
      "Epoch 1163/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 438.9529 - mean_absolute_error: 12.1731\n",
      "Epoch 1164/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.3664 - mean_absolute_error: 11.8330\n",
      "Epoch 1165/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 419.1354 - mean_absolute_error: 11.7080\n",
      "Epoch 1166/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.9576 - mean_absolute_error: 11.9057\n",
      "Epoch 1167/5000\n",
      "344/344 [==============================] - 0s 287us/step - loss: 426.5443 - mean_absolute_error: 12.0093\n",
      "Epoch 1168/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 427.7509 - mean_absolute_error: 12.0986\n",
      "Epoch 1169/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 432.1429 - mean_absolute_error: 12.2777\n",
      "Epoch 1170/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 418.2656 - mean_absolute_error: 11.8078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1171/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 454.3473 - mean_absolute_error: 12.6527\n",
      "Epoch 1172/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.9940 - mean_absolute_error: 11.9712\n",
      "Epoch 1173/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 413.1568 - mean_absolute_error: 11.8895\n",
      "Epoch 1174/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 398.0971 - mean_absolute_error: 11.5979\n",
      "Epoch 1175/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.3306 - mean_absolute_error: 12.2729\n",
      "Epoch 1176/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 412.0698 - mean_absolute_error: 11.6664\n",
      "Epoch 1177/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.0542 - mean_absolute_error: 12.1755\n",
      "Epoch 1178/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.7333 - mean_absolute_error: 11.9053\n",
      "Epoch 1179/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 409.6341 - mean_absolute_error: 11.6220\n",
      "Epoch 1180/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 418.3148 - mean_absolute_error: 11.9313\n",
      "Epoch 1181/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.1341 - mean_absolute_error: 11.8573\n",
      "Epoch 1182/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 403.5355 - mean_absolute_error: 11.5958\n",
      "Epoch 1183/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.9919 - mean_absolute_error: 11.9262\n",
      "Epoch 1184/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 436.5048 - mean_absolute_error: 12.3306\n",
      "Epoch 1185/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 413.4521 - mean_absolute_error: 11.8619\n",
      "Epoch 1186/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.4674 - mean_absolute_error: 11.9737\n",
      "Epoch 1187/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 438.3268 - mean_absolute_error: 12.1837\n",
      "Epoch 1188/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.0564 - mean_absolute_error: 12.0025\n",
      "Epoch 1189/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 415.9179 - mean_absolute_error: 11.8142\n",
      "Epoch 1190/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.8378 - mean_absolute_error: 11.9462\n",
      "Epoch 1191/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.4295 - mean_absolute_error: 11.5925\n",
      "Epoch 1192/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 407.9694 - mean_absolute_error: 11.8690\n",
      "Epoch 1193/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 452.4887 - mean_absolute_error: 12.1907\n",
      "Epoch 1194/5000\n",
      "344/344 [==============================] - 0s 262us/step - loss: 421.8262 - mean_absolute_error: 12.1113\n",
      "Epoch 1195/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 412.4117 - mean_absolute_error: 11.8655\n",
      "Epoch 1196/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 423.8466 - mean_absolute_error: 12.1475\n",
      "Epoch 1197/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 438.3077 - mean_absolute_error: 12.4351\n",
      "Epoch 1198/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.8524 - mean_absolute_error: 12.0679\n",
      "Epoch 1199/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.5847 - mean_absolute_error: 11.7924\n",
      "Epoch 1200/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 437.0749 - mean_absolute_error: 12.2126\n",
      "Epoch 1201/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.1661 - mean_absolute_error: 12.0725\n",
      "Epoch 1202/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.6763 - mean_absolute_error: 11.7176\n",
      "Epoch 1203/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.1443 - mean_absolute_error: 11.7122\n",
      "Epoch 1204/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.3188 - mean_absolute_error: 11.9171\n",
      "Epoch 1205/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 394.6924 - mean_absolute_error: 11.3589\n",
      "Epoch 1206/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 399.1085 - mean_absolute_error: 11.7131\n",
      "Epoch 1207/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.8973 - mean_absolute_error: 11.9250\n",
      "Epoch 1208/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.3610 - mean_absolute_error: 11.8805\n",
      "Epoch 1209/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.1759 - mean_absolute_error: 11.6815\n",
      "Epoch 1210/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 431.6710 - mean_absolute_error: 12.1586\n",
      "Epoch 1211/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.4106 - mean_absolute_error: 11.7703\n",
      "Epoch 1212/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.5456 - mean_absolute_error: 11.8457\n",
      "Epoch 1213/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 411.3115 - mean_absolute_error: 11.7428\n",
      "Epoch 1214/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 390.1806 - mean_absolute_error: 11.3856\n",
      "Epoch 1215/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 393.5609 - mean_absolute_error: 11.2239\n",
      "Epoch 1216/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.7101 - mean_absolute_error: 11.9870\n",
      "Epoch 1217/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 398.8633 - mean_absolute_error: 11.4727\n",
      "Epoch 1218/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 401.5109 - mean_absolute_error: 11.8601\n",
      "Epoch 1219/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 407.3133 - mean_absolute_error: 11.6140\n",
      "Epoch 1220/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 415.4955 - mean_absolute_error: 11.9110\n",
      "Epoch 1221/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 434.6099 - mean_absolute_error: 12.2636\n",
      "Epoch 1222/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.7122 - mean_absolute_error: 12.1265\n",
      "Epoch 1223/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 432.8509 - mean_absolute_error: 12.7042\n",
      "Epoch 1224/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 410.5699 - mean_absolute_error: 11.7869\n",
      "Epoch 1225/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 390.2066 - mean_absolute_error: 11.1509\n",
      "Epoch 1226/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 424.3792 - mean_absolute_error: 12.2580\n",
      "Epoch 1227/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 435.2851 - mean_absolute_error: 12.2755\n",
      "Epoch 1228/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.6219 - mean_absolute_error: 11.6233\n",
      "Epoch 1229/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 437.3881 - mean_absolute_error: 12.5306\n",
      "Epoch 1230/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.6723 - mean_absolute_error: 11.6769\n",
      "Epoch 1231/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 415.5991 - mean_absolute_error: 12.0395\n",
      "Epoch 1232/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 425.6787 - mean_absolute_error: 11.8999\n",
      "Epoch 1233/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.1775 - mean_absolute_error: 11.5229\n",
      "Epoch 1234/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.5263 - mean_absolute_error: 11.9604\n",
      "Epoch 1235/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.7696 - mean_absolute_error: 11.9816\n",
      "Epoch 1236/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 415.8442 - mean_absolute_error: 11.8367\n",
      "Epoch 1237/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.3571 - mean_absolute_error: 11.9987\n",
      "Epoch 1238/5000\n",
      "344/344 [==============================] - 0s 222us/step - loss: 422.8271 - mean_absolute_error: 12.1083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1239/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 428.0703 - mean_absolute_error: 12.1740\n",
      "Epoch 1240/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 445.8247 - mean_absolute_error: 12.3689\n",
      "Epoch 1241/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.4689 - mean_absolute_error: 11.9884\n",
      "Epoch 1242/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 430.9729 - mean_absolute_error: 12.4117\n",
      "Epoch 1243/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 413.7054 - mean_absolute_error: 12.2555\n",
      "Epoch 1244/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 424.8549 - mean_absolute_error: 12.2005\n",
      "Epoch 1245/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 409.4443 - mean_absolute_error: 11.6473\n",
      "Epoch 1246/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 497.3250 - mean_absolute_error: 12.0781\n",
      "Epoch 1247/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 442.7446 - mean_absolute_error: 12.2888\n",
      "Epoch 1248/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.7533 - mean_absolute_error: 12.3764\n",
      "Epoch 1249/5000\n",
      "344/344 [==============================] - 0s 224us/step - loss: 436.8036 - mean_absolute_error: 12.3651\n",
      "Epoch 1250/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 413.3960 - mean_absolute_error: 11.8346\n",
      "Epoch 1251/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.4375 - mean_absolute_error: 12.0868\n",
      "Epoch 1252/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.5434 - mean_absolute_error: 11.6756\n",
      "Epoch 1253/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 487.8372 - mean_absolute_error: 12.5141\n",
      "Epoch 1254/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.6920 - mean_absolute_error: 12.1694\n",
      "Epoch 1255/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 441.2525 - mean_absolute_error: 12.4324\n",
      "Epoch 1256/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.5942 - mean_absolute_error: 11.8914\n",
      "Epoch 1257/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.0037 - mean_absolute_error: 11.8666\n",
      "Epoch 1258/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 403.4681 - mean_absolute_error: 11.7710\n",
      "Epoch 1259/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.3014 - mean_absolute_error: 11.8175\n",
      "Epoch 1260/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.6804 - mean_absolute_error: 11.9701\n",
      "Epoch 1261/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 421.0883 - mean_absolute_error: 12.1022\n",
      "Epoch 1262/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 392.6902 - mean_absolute_error: 11.2183\n",
      "Epoch 1263/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 424.8539 - mean_absolute_error: 11.6337\n",
      "Epoch 1264/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 447.5129 - mean_absolute_error: 12.4959\n",
      "Epoch 1265/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 419.6489 - mean_absolute_error: 12.0225\n",
      "Epoch 1266/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 419.6172 - mean_absolute_error: 12.1217\n",
      "Epoch 1267/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 437.2601 - mean_absolute_error: 12.4797\n",
      "Epoch 1268/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 436.7967 - mean_absolute_error: 12.2351\n",
      "Epoch 1269/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.2487 - mean_absolute_error: 11.8143\n",
      "Epoch 1270/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.6529 - mean_absolute_error: 11.7302\n",
      "Epoch 1271/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 440.8913 - mean_absolute_error: 12.3016\n",
      "Epoch 1272/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 432.0057 - mean_absolute_error: 12.0648\n",
      "Epoch 1273/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 422.1341 - mean_absolute_error: 12.0712\n",
      "Epoch 1274/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 442.2669 - mean_absolute_error: 12.3528\n",
      "Epoch 1275/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 410.4656 - mean_absolute_error: 11.8111\n",
      "Epoch 1276/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.8106 - mean_absolute_error: 12.5629\n",
      "Epoch 1277/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 412.5580 - mean_absolute_error: 11.7921\n",
      "Epoch 1278/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.9149 - mean_absolute_error: 11.8245\n",
      "Epoch 1279/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 421.1817 - mean_absolute_error: 12.1279\n",
      "Epoch 1280/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 411.3230 - mean_absolute_error: 11.7765\n",
      "Epoch 1281/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.8203 - mean_absolute_error: 11.7508\n",
      "Epoch 1282/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.6106 - mean_absolute_error: 12.2925\n",
      "Epoch 1283/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.7201 - mean_absolute_error: 11.8844\n",
      "Epoch 1284/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 407.3595 - mean_absolute_error: 11.7662\n",
      "Epoch 1285/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 407.0371 - mean_absolute_error: 11.9406\n",
      "Epoch 1286/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.1781 - mean_absolute_error: 11.8758\n",
      "Epoch 1287/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 441.8129 - mean_absolute_error: 12.2879\n",
      "Epoch 1288/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.1748 - mean_absolute_error: 12.1963\n",
      "Epoch 1289/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.0471 - mean_absolute_error: 11.6699\n",
      "Epoch 1290/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 408.7408 - mean_absolute_error: 11.9890\n",
      "Epoch 1291/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 431.9638 - mean_absolute_error: 12.1616\n",
      "Epoch 1292/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 426.0769 - mean_absolute_error: 11.8646\n",
      "Epoch 1293/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 422.2303 - mean_absolute_error: 12.1176\n",
      "Epoch 1294/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.1855 - mean_absolute_error: 11.9012\n",
      "Epoch 1295/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.8807 - mean_absolute_error: 11.6488\n",
      "Epoch 1296/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 422.0942 - mean_absolute_error: 12.0730\n",
      "Epoch 1297/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 403.2801 - mean_absolute_error: 11.4078\n",
      "Epoch 1298/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 397.1846 - mean_absolute_error: 11.3847\n",
      "Epoch 1299/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 428.0129 - mean_absolute_error: 12.2038\n",
      "Epoch 1300/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.1759 - mean_absolute_error: 11.6776\n",
      "Epoch 1301/5000\n",
      "344/344 [==============================] - 0s 221us/step - loss: 438.4872 - mean_absolute_error: 12.5309\n",
      "Epoch 1302/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 398.0641 - mean_absolute_error: 11.7069\n",
      "Epoch 1303/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 437.9182 - mean_absolute_error: 12.3804\n",
      "Epoch 1304/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 429.6209 - mean_absolute_error: 12.2176\n",
      "Epoch 1305/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 393.1105 - mean_absolute_error: 11.6251\n",
      "Epoch 1306/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.2251 - mean_absolute_error: 11.8337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1307/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 442.5269 - mean_absolute_error: 11.9812\n",
      "Epoch 1308/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 426.0379 - mean_absolute_error: 12.2531\n",
      "Epoch 1309/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 439.7336 - mean_absolute_error: 12.1415\n",
      "Epoch 1310/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.5633 - mean_absolute_error: 11.7249\n",
      "Epoch 1311/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.4047 - mean_absolute_error: 11.7793\n",
      "Epoch 1312/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.8180 - mean_absolute_error: 11.8352\n",
      "Epoch 1313/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.7910 - mean_absolute_error: 12.2040\n",
      "Epoch 1314/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.6511 - mean_absolute_error: 11.6964\n",
      "Epoch 1315/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.5820 - mean_absolute_error: 12.1232\n",
      "Epoch 1316/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 411.9047 - mean_absolute_error: 11.6727\n",
      "Epoch 1317/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 437.8891 - mean_absolute_error: 12.4481\n",
      "Epoch 1318/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.0507 - mean_absolute_error: 11.6406\n",
      "Epoch 1319/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 571.2938 - mean_absolute_error: 12.5786\n",
      "Epoch 1320/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 402.8688 - mean_absolute_error: 11.5377\n",
      "Epoch 1321/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 435.1465 - mean_absolute_error: 12.2985\n",
      "Epoch 1322/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 437.7190 - mean_absolute_error: 12.5077\n",
      "Epoch 1323/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.3716 - mean_absolute_error: 11.4143\n",
      "Epoch 1324/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 463.6450 - mean_absolute_error: 12.4971\n",
      "Epoch 1325/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.4256 - mean_absolute_error: 11.9118\n",
      "Epoch 1326/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 397.4023 - mean_absolute_error: 11.4832\n",
      "Epoch 1327/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 436.0709 - mean_absolute_error: 11.8521\n",
      "Epoch 1328/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.8720 - mean_absolute_error: 12.2963\n",
      "Epoch 1329/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 412.6418 - mean_absolute_error: 12.0181\n",
      "Epoch 1330/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 431.2343 - mean_absolute_error: 12.4031\n",
      "Epoch 1331/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.1229 - mean_absolute_error: 12.3348\n",
      "Epoch 1332/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.0903 - mean_absolute_error: 11.5484\n",
      "Epoch 1333/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 396.5179 - mean_absolute_error: 11.5517\n",
      "Epoch 1334/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 406.0685 - mean_absolute_error: 11.6754\n",
      "Epoch 1335/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 398.7463 - mean_absolute_error: 11.5750\n",
      "Epoch 1336/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.2820 - mean_absolute_error: 11.9989\n",
      "Epoch 1337/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.4127 - mean_absolute_error: 11.9136\n",
      "Epoch 1338/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 536.8717 - mean_absolute_error: 12.9175\n",
      "Epoch 1339/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.4281 - mean_absolute_error: 11.7794\n",
      "Epoch 1340/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.9196 - mean_absolute_error: 12.2148\n",
      "Epoch 1341/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 419.9423 - mean_absolute_error: 11.9880\n",
      "Epoch 1342/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 430.2068 - mean_absolute_error: 12.2531\n",
      "Epoch 1343/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 436.2518 - mean_absolute_error: 12.3314\n",
      "Epoch 1344/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 384.7094 - mean_absolute_error: 11.2591\n",
      "Epoch 1345/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 432.7312 - mean_absolute_error: 12.5116\n",
      "Epoch 1346/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.4789 - mean_absolute_error: 12.1578\n",
      "Epoch 1347/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.3946 - mean_absolute_error: 12.1833\n",
      "Epoch 1348/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.2072 - mean_absolute_error: 12.1795\n",
      "Epoch 1349/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 415.5502 - mean_absolute_error: 11.9169\n",
      "Epoch 1350/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 411.8690 - mean_absolute_error: 11.9714\n",
      "Epoch 1351/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 434.3417 - mean_absolute_error: 11.9235\n",
      "Epoch 1352/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 427.1975 - mean_absolute_error: 12.2633\n",
      "Epoch 1353/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.8537 - mean_absolute_error: 12.1703\n",
      "Epoch 1354/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.3318 - mean_absolute_error: 11.7284\n",
      "Epoch 1355/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.9247 - mean_absolute_error: 12.1476\n",
      "Epoch 1356/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 399.9985 - mean_absolute_error: 11.8815\n",
      "Epoch 1357/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.1410 - mean_absolute_error: 12.0214\n",
      "Epoch 1358/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.5366 - mean_absolute_error: 12.1652\n",
      "Epoch 1359/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.7317 - mean_absolute_error: 12.4165\n",
      "Epoch 1360/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.1714 - mean_absolute_error: 12.3215\n",
      "Epoch 1361/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 445.0860 - mean_absolute_error: 12.6853\n",
      "Epoch 1362/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.7527 - mean_absolute_error: 11.8002\n",
      "Epoch 1363/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.6309 - mean_absolute_error: 12.2106\n",
      "Epoch 1364/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.1474 - mean_absolute_error: 11.8314\n",
      "Epoch 1365/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 434.4700 - mean_absolute_error: 12.1405\n",
      "Epoch 1366/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.5715 - mean_absolute_error: 12.1167\n",
      "Epoch 1367/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.2917 - mean_absolute_error: 11.1732\n",
      "Epoch 1368/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.4973 - mean_absolute_error: 12.0217\n",
      "Epoch 1369/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.0917 - mean_absolute_error: 11.9179\n",
      "Epoch 1370/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.6726 - mean_absolute_error: 12.4580\n",
      "Epoch 1371/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 447.1356 - mean_absolute_error: 12.5762\n",
      "Epoch 1372/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 455.3174 - mean_absolute_error: 12.7227\n",
      "Epoch 1373/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 403.6111 - mean_absolute_error: 11.7061\n",
      "Epoch 1374/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.0003 - mean_absolute_error: 11.4387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1375/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 399.5031 - mean_absolute_error: 11.7396\n",
      "Epoch 1376/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 423.7992 - mean_absolute_error: 12.1728\n",
      "Epoch 1377/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.3742 - mean_absolute_error: 11.6976\n",
      "Epoch 1378/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.4035 - mean_absolute_error: 12.1219\n",
      "Epoch 1379/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.0286 - mean_absolute_error: 12.1465\n",
      "Epoch 1380/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 397.0692 - mean_absolute_error: 11.5238\n",
      "Epoch 1381/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.5204 - mean_absolute_error: 11.8793\n",
      "Epoch 1382/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.2757 - mean_absolute_error: 11.7561\n",
      "Epoch 1383/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.8490 - mean_absolute_error: 11.9624\n",
      "Epoch 1384/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.0476 - mean_absolute_error: 11.8124\n",
      "Epoch 1385/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.7367 - mean_absolute_error: 11.7704\n",
      "Epoch 1386/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.5274 - mean_absolute_error: 11.7009\n",
      "Epoch 1387/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.1735 - mean_absolute_error: 11.8528\n",
      "Epoch 1388/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 422.8849 - mean_absolute_error: 12.3337\n",
      "Epoch 1389/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.9874 - mean_absolute_error: 11.5628\n",
      "Epoch 1390/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.7723 - mean_absolute_error: 11.5788\n",
      "Epoch 1391/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.0727 - mean_absolute_error: 12.1389\n",
      "Epoch 1392/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 437.4139 - mean_absolute_error: 12.1504\n",
      "Epoch 1393/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.5889 - mean_absolute_error: 12.2766\n",
      "Epoch 1394/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.8083 - mean_absolute_error: 12.1223\n",
      "Epoch 1395/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 435.8353 - mean_absolute_error: 12.0966\n",
      "Epoch 1396/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.8818 - mean_absolute_error: 11.9114\n",
      "Epoch 1397/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.2195 - mean_absolute_error: 11.6083\n",
      "Epoch 1398/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.6687 - mean_absolute_error: 12.1380\n",
      "Epoch 1399/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.3634 - mean_absolute_error: 12.1601\n",
      "Epoch 1400/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.3622 - mean_absolute_error: 11.7291\n",
      "Epoch 1401/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.9336 - mean_absolute_error: 12.0960\n",
      "Epoch 1402/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.9116 - mean_absolute_error: 11.8597\n",
      "Epoch 1403/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.3788 - mean_absolute_error: 11.9079\n",
      "Epoch 1404/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.7482 - mean_absolute_error: 12.0326\n",
      "Epoch 1405/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 423.3268 - mean_absolute_error: 12.2174\n",
      "Epoch 1406/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 422.7548 - mean_absolute_error: 12.0418\n",
      "Epoch 1407/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.6118 - mean_absolute_error: 11.7614\n",
      "Epoch 1408/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 438.7320 - mean_absolute_error: 12.5296\n",
      "Epoch 1409/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 441.4342 - mean_absolute_error: 12.1650\n",
      "Epoch 1410/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 435.6235 - mean_absolute_error: 12.3636\n",
      "Epoch 1411/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.1166 - mean_absolute_error: 12.1836\n",
      "Epoch 1412/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.8309 - mean_absolute_error: 11.9718\n",
      "Epoch 1413/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.7792 - mean_absolute_error: 11.9035\n",
      "Epoch 1414/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 430.3485 - mean_absolute_error: 12.2353\n",
      "Epoch 1415/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 403.4604 - mean_absolute_error: 11.2860\n",
      "Epoch 1416/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 415.6387 - mean_absolute_error: 11.9146\n",
      "Epoch 1417/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.8032 - mean_absolute_error: 11.6851\n",
      "Epoch 1418/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.4259 - mean_absolute_error: 11.7407\n",
      "Epoch 1419/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 436.1010 - mean_absolute_error: 12.3837\n",
      "Epoch 1420/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.6607 - mean_absolute_error: 12.0512\n",
      "Epoch 1421/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.1911 - mean_absolute_error: 12.0081\n",
      "Epoch 1422/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.3239 - mean_absolute_error: 11.9298\n",
      "Epoch 1423/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 416.7406 - mean_absolute_error: 12.0709\n",
      "Epoch 1424/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.2473 - mean_absolute_error: 12.0764\n",
      "Epoch 1425/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 422.9298 - mean_absolute_error: 12.0189\n",
      "Epoch 1426/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 419.4959 - mean_absolute_error: 11.6568\n",
      "Epoch 1427/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 395.3000 - mean_absolute_error: 11.5370\n",
      "Epoch 1428/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 435.0358 - mean_absolute_error: 12.0425\n",
      "Epoch 1429/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.8516 - mean_absolute_error: 11.7597\n",
      "Epoch 1430/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.2213 - mean_absolute_error: 12.0968\n",
      "Epoch 1431/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.9484 - mean_absolute_error: 12.0499\n",
      "Epoch 1432/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 440.5056 - mean_absolute_error: 12.4146\n",
      "Epoch 1433/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 434.1902 - mean_absolute_error: 12.5111\n",
      "Epoch 1434/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.8862 - mean_absolute_error: 12.0673\n",
      "Epoch 1435/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.1552 - mean_absolute_error: 12.2045\n",
      "Epoch 1436/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 436.4473 - mean_absolute_error: 12.1158\n",
      "Epoch 1437/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.0329 - mean_absolute_error: 11.5920\n",
      "Epoch 1438/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.9717 - mean_absolute_error: 11.7101\n",
      "Epoch 1439/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 431.5415 - mean_absolute_error: 12.3595\n",
      "Epoch 1440/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.5015 - mean_absolute_error: 12.0203\n",
      "Epoch 1441/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 428.5484 - mean_absolute_error: 12.0916\n",
      "Epoch 1442/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.8833 - mean_absolute_error: 11.9229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1443/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 428.3508 - mean_absolute_error: 12.1587\n",
      "Epoch 1444/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 432.3954 - mean_absolute_error: 12.3692\n",
      "Epoch 1445/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.1206 - mean_absolute_error: 12.0666\n",
      "Epoch 1446/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 396.1141 - mean_absolute_error: 11.3896\n",
      "Epoch 1447/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.3543 - mean_absolute_error: 12.2054\n",
      "Epoch 1448/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.9742 - mean_absolute_error: 12.0601\n",
      "Epoch 1449/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.2341 - mean_absolute_error: 11.4137\n",
      "Epoch 1450/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 425.6624 - mean_absolute_error: 12.1628\n",
      "Epoch 1451/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.3762 - mean_absolute_error: 11.7352\n",
      "Epoch 1452/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.3958 - mean_absolute_error: 12.1095\n",
      "Epoch 1453/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.8528 - mean_absolute_error: 11.7739\n",
      "Epoch 1454/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 470.6000 - mean_absolute_error: 12.1261\n",
      "Epoch 1455/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.9077 - mean_absolute_error: 12.4252\n",
      "Epoch 1456/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 425.3517 - mean_absolute_error: 12.1234\n",
      "Epoch 1457/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 394.4158 - mean_absolute_error: 11.4866\n",
      "Epoch 1458/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.0723 - mean_absolute_error: 12.0528\n",
      "Epoch 1459/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.5025 - mean_absolute_error: 11.9055\n",
      "Epoch 1460/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 414.4136 - mean_absolute_error: 11.8022\n",
      "Epoch 1461/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 415.6010 - mean_absolute_error: 12.1885\n",
      "Epoch 1462/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 421.8867 - mean_absolute_error: 12.1757\n",
      "Epoch 1463/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.6487 - mean_absolute_error: 12.2863\n",
      "Epoch 1464/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 436.0678 - mean_absolute_error: 12.2973\n",
      "Epoch 1465/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.4850 - mean_absolute_error: 11.7234\n",
      "Epoch 1466/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.3200 - mean_absolute_error: 11.4598\n",
      "Epoch 1467/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 423.5838 - mean_absolute_error: 11.7131\n",
      "Epoch 1468/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.6345 - mean_absolute_error: 11.8320\n",
      "Epoch 1469/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.4158 - mean_absolute_error: 11.6792\n",
      "Epoch 1470/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.0836 - mean_absolute_error: 11.9180\n",
      "Epoch 1471/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.9353 - mean_absolute_error: 11.7132\n",
      "Epoch 1472/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.1400 - mean_absolute_error: 12.0172\n",
      "Epoch 1473/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 447.8947 - mean_absolute_error: 12.4479\n",
      "Epoch 1474/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 414.2582 - mean_absolute_error: 12.0246\n",
      "Epoch 1475/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 426.4992 - mean_absolute_error: 12.0987\n",
      "Epoch 1476/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.6772 - mean_absolute_error: 12.0004\n",
      "Epoch 1477/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 422.9898 - mean_absolute_error: 12.2196\n",
      "Epoch 1478/5000\n",
      "344/344 [==============================] - 0s 250us/step - loss: 409.6469 - mean_absolute_error: 11.8860\n",
      "Epoch 1479/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 436.0955 - mean_absolute_error: 12.2727\n",
      "Epoch 1480/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.6378 - mean_absolute_error: 11.9353\n",
      "Epoch 1481/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 418.5842 - mean_absolute_error: 11.9466\n",
      "Epoch 1482/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.8048 - mean_absolute_error: 11.9174\n",
      "Epoch 1483/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.7898 - mean_absolute_error: 11.8368\n",
      "Epoch 1484/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 393.2891 - mean_absolute_error: 11.5200\n",
      "Epoch 1485/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.9612 - mean_absolute_error: 11.7374\n",
      "Epoch 1486/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.1467 - mean_absolute_error: 12.1650\n",
      "Epoch 1487/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.1258 - mean_absolute_error: 12.0823\n",
      "Epoch 1488/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 432.6095 - mean_absolute_error: 12.2770\n",
      "Epoch 1489/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 458.5821 - mean_absolute_error: 12.8821\n",
      "Epoch 1490/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.5826 - mean_absolute_error: 12.0736\n",
      "Epoch 1491/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 409.8707 - mean_absolute_error: 11.8564\n",
      "Epoch 1492/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.2936 - mean_absolute_error: 12.2487\n",
      "Epoch 1493/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.2719 - mean_absolute_error: 11.7116\n",
      "Epoch 1494/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.2651 - mean_absolute_error: 11.8845\n",
      "Epoch 1495/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 415.0114 - mean_absolute_error: 11.9010\n",
      "Epoch 1496/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.0860 - mean_absolute_error: 11.8337\n",
      "Epoch 1497/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 394.1149 - mean_absolute_error: 11.8349\n",
      "Epoch 1498/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 424.0550 - mean_absolute_error: 12.2852\n",
      "Epoch 1499/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.4630 - mean_absolute_error: 11.7674\n",
      "Epoch 1500/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.4123 - mean_absolute_error: 12.2131\n",
      "Epoch 1501/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 394.4824 - mean_absolute_error: 11.4678\n",
      "Epoch 1502/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.7223 - mean_absolute_error: 11.9895\n",
      "Epoch 1503/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.0634 - mean_absolute_error: 12.3031\n",
      "Epoch 1504/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 404.5612 - mean_absolute_error: 11.6552\n",
      "Epoch 1505/5000\n",
      "344/344 [==============================] - 0s 256us/step - loss: 427.1152 - mean_absolute_error: 12.3766\n",
      "Epoch 1506/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 409.8059 - mean_absolute_error: 12.2089\n",
      "Epoch 1507/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 463.5804 - mean_absolute_error: 12.4222\n",
      "Epoch 1508/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.5217 - mean_absolute_error: 12.0224\n",
      "Epoch 1509/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.7619 - mean_absolute_error: 11.7913\n",
      "Epoch 1510/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.7892 - mean_absolute_error: 12.0980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1511/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 454.9517 - mean_absolute_error: 12.8944\n",
      "Epoch 1512/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 410.7257 - mean_absolute_error: 12.0477\n",
      "Epoch 1513/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.7303 - mean_absolute_error: 11.8042\n",
      "Epoch 1514/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 430.8533 - mean_absolute_error: 12.2753\n",
      "Epoch 1515/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 408.6645 - mean_absolute_error: 11.9579\n",
      "Epoch 1516/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.1647 - mean_absolute_error: 12.0826\n",
      "Epoch 1517/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 460.6375 - mean_absolute_error: 12.8022\n",
      "Epoch 1518/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.5695 - mean_absolute_error: 11.5870\n",
      "Epoch 1519/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 420.2739 - mean_absolute_error: 11.9895\n",
      "Epoch 1520/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.6140 - mean_absolute_error: 11.6009\n",
      "Epoch 1521/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 427.0040 - mean_absolute_error: 12.0980\n",
      "Epoch 1522/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.9543 - mean_absolute_error: 11.9209\n",
      "Epoch 1523/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.3111 - mean_absolute_error: 12.0498\n",
      "Epoch 1524/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.9402 - mean_absolute_error: 12.1122\n",
      "Epoch 1525/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 397.0959 - mean_absolute_error: 11.7519\n",
      "Epoch 1526/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.0311 - mean_absolute_error: 11.7746\n",
      "Epoch 1527/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.7825 - mean_absolute_error: 11.9349\n",
      "Epoch 1528/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 432.2558 - mean_absolute_error: 12.1698\n",
      "Epoch 1529/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.4106 - mean_absolute_error: 11.8504\n",
      "Epoch 1530/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 437.7424 - mean_absolute_error: 12.4677\n",
      "Epoch 1531/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.9621 - mean_absolute_error: 11.8872\n",
      "Epoch 1532/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 425.4421 - mean_absolute_error: 12.2211\n",
      "Epoch 1533/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.6900 - mean_absolute_error: 12.0552\n",
      "Epoch 1534/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.9389 - mean_absolute_error: 12.0415\n",
      "Epoch 1535/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 449.6049 - mean_absolute_error: 12.2469\n",
      "Epoch 1536/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 493.1050 - mean_absolute_error: 12.5722\n",
      "Epoch 1537/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 413.2918 - mean_absolute_error: 11.9611\n",
      "Epoch 1538/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.1169 - mean_absolute_error: 11.6945\n",
      "Epoch 1539/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 398.0862 - mean_absolute_error: 11.4224\n",
      "Epoch 1540/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 423.6737 - mean_absolute_error: 12.2876\n",
      "Epoch 1541/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 437.3710 - mean_absolute_error: 12.3151\n",
      "Epoch 1542/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.2146 - mean_absolute_error: 12.0890\n",
      "Epoch 1543/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 422.8273 - mean_absolute_error: 12.3219\n",
      "Epoch 1544/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 425.9861 - mean_absolute_error: 12.5671\n",
      "Epoch 1545/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.1942 - mean_absolute_error: 11.6825\n",
      "Epoch 1546/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 438.1393 - mean_absolute_error: 12.3425\n",
      "Epoch 1547/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 426.1244 - mean_absolute_error: 12.0869\n",
      "Epoch 1548/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 416.4380 - mean_absolute_error: 11.9200\n",
      "Epoch 1549/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.6585 - mean_absolute_error: 11.8097\n",
      "Epoch 1550/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.5269 - mean_absolute_error: 12.1846\n",
      "Epoch 1551/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.4573 - mean_absolute_error: 11.8396\n",
      "Epoch 1552/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.0529 - mean_absolute_error: 11.7220\n",
      "Epoch 1553/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 405.2434 - mean_absolute_error: 11.5943\n",
      "Epoch 1554/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.0515 - mean_absolute_error: 11.8722\n",
      "Epoch 1555/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.3995 - mean_absolute_error: 11.3423\n",
      "Epoch 1556/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.4610 - mean_absolute_error: 12.4156\n",
      "Epoch 1557/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.3474 - mean_absolute_error: 12.0999\n",
      "Epoch 1558/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 411.0415 - mean_absolute_error: 11.6817\n",
      "Epoch 1559/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.7326 - mean_absolute_error: 12.0815\n",
      "Epoch 1560/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.7972 - mean_absolute_error: 12.2218\n",
      "Epoch 1561/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.1026 - mean_absolute_error: 11.7357\n",
      "Epoch 1562/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.5163 - mean_absolute_error: 11.7576\n",
      "Epoch 1563/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.4899 - mean_absolute_error: 12.2582\n",
      "Epoch 1564/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.0876 - mean_absolute_error: 12.1551\n",
      "Epoch 1565/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 422.2639 - mean_absolute_error: 11.9534\n",
      "Epoch 1566/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.1856 - mean_absolute_error: 11.9267\n",
      "Epoch 1567/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 445.1945 - mean_absolute_error: 11.8869\n",
      "Epoch 1568/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.6261 - mean_absolute_error: 12.2625\n",
      "Epoch 1569/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.9925 - mean_absolute_error: 11.6463\n",
      "Epoch 1570/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.3612 - mean_absolute_error: 11.7544\n",
      "Epoch 1571/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.3229 - mean_absolute_error: 12.1741\n",
      "Epoch 1572/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.4286 - mean_absolute_error: 11.8363\n",
      "Epoch 1573/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 416.2492 - mean_absolute_error: 11.8662\n",
      "Epoch 1574/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 435.3441 - mean_absolute_error: 12.1739\n",
      "Epoch 1575/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 432.6504 - mean_absolute_error: 12.2885\n",
      "Epoch 1576/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.9892 - mean_absolute_error: 11.6930\n",
      "Epoch 1577/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.4709 - mean_absolute_error: 12.0937\n",
      "Epoch 1578/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 422.2292 - mean_absolute_error: 12.1052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1579/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 406.7825 - mean_absolute_error: 11.5060\n",
      "Epoch 1580/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.3539 - mean_absolute_error: 11.7169\n",
      "Epoch 1581/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.3676 - mean_absolute_error: 12.0118\n",
      "Epoch 1582/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 412.6723 - mean_absolute_error: 11.9113\n",
      "Epoch 1583/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.6372 - mean_absolute_error: 11.9982\n",
      "Epoch 1584/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 412.9975 - mean_absolute_error: 12.0308\n",
      "Epoch 1585/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.7927 - mean_absolute_error: 12.3010\n",
      "Epoch 1586/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.1773 - mean_absolute_error: 11.9566\n",
      "Epoch 1587/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.9726 - mean_absolute_error: 12.3210\n",
      "Epoch 1588/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 422.7971 - mean_absolute_error: 12.1599\n",
      "Epoch 1589/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.5038 - mean_absolute_error: 11.6456\n",
      "Epoch 1590/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 404.4383 - mean_absolute_error: 11.9325\n",
      "Epoch 1591/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 421.2484 - mean_absolute_error: 12.0092\n",
      "Epoch 1592/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 413.5191 - mean_absolute_error: 11.6606\n",
      "Epoch 1593/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.6080 - mean_absolute_error: 12.1880\n",
      "Epoch 1594/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 463.0421 - mean_absolute_error: 12.6550\n",
      "Epoch 1595/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 436.3252 - mean_absolute_error: 12.2374\n",
      "Epoch 1596/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.7249 - mean_absolute_error: 11.4268\n",
      "Epoch 1597/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.8117 - mean_absolute_error: 11.9771\n",
      "Epoch 1598/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 409.6056 - mean_absolute_error: 11.8064\n",
      "Epoch 1599/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 408.5239 - mean_absolute_error: 12.0136\n",
      "Epoch 1600/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 426.6198 - mean_absolute_error: 11.7603\n",
      "Epoch 1601/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 430.9442 - mean_absolute_error: 12.0249\n",
      "Epoch 1602/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 425.4274 - mean_absolute_error: 12.0295\n",
      "Epoch 1603/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 408.4972 - mean_absolute_error: 11.8318\n",
      "Epoch 1604/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.2242 - mean_absolute_error: 12.0105\n",
      "Epoch 1605/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.5641 - mean_absolute_error: 11.5879\n",
      "Epoch 1606/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.6144 - mean_absolute_error: 12.1189\n",
      "Epoch 1607/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 392.8869 - mean_absolute_error: 11.4714\n",
      "Epoch 1608/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.1288 - mean_absolute_error: 11.6660\n",
      "Epoch 1609/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 399.5636 - mean_absolute_error: 11.6129\n",
      "Epoch 1610/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 404.9387 - mean_absolute_error: 11.5754\n",
      "Epoch 1611/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 395.5717 - mean_absolute_error: 11.4461\n",
      "Epoch 1612/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.3701 - mean_absolute_error: 12.1581\n",
      "Epoch 1613/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 401.2996 - mean_absolute_error: 11.6313\n",
      "Epoch 1614/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 402.7996 - mean_absolute_error: 11.5348\n",
      "Epoch 1615/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.5171 - mean_absolute_error: 11.9130\n",
      "Epoch 1616/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 407.1634 - mean_absolute_error: 11.7705\n",
      "Epoch 1617/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.5685 - mean_absolute_error: 11.9711\n",
      "Epoch 1618/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.7833 - mean_absolute_error: 11.9600\n",
      "Epoch 1619/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 400.8021 - mean_absolute_error: 11.5904\n",
      "Epoch 1620/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.8555 - mean_absolute_error: 11.7511\n",
      "Epoch 1621/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.5432 - mean_absolute_error: 12.0704\n",
      "Epoch 1622/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 424.8773 - mean_absolute_error: 12.2009\n",
      "Epoch 1623/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 411.2887 - mean_absolute_error: 12.1152\n",
      "Epoch 1624/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.0608 - mean_absolute_error: 11.8440\n",
      "Epoch 1625/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.5563 - mean_absolute_error: 12.0228\n",
      "Epoch 1626/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.2753 - mean_absolute_error: 11.9747\n",
      "Epoch 1627/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 425.7409 - mean_absolute_error: 12.0552\n",
      "Epoch 1628/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 391.4716 - mean_absolute_error: 11.3417\n",
      "Epoch 1629/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.6132 - mean_absolute_error: 12.0156\n",
      "Epoch 1630/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.7079 - mean_absolute_error: 11.5780\n",
      "Epoch 1631/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.2072 - mean_absolute_error: 11.9027\n",
      "Epoch 1632/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.9773 - mean_absolute_error: 12.1806\n",
      "Epoch 1633/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 433.5925 - mean_absolute_error: 12.4356\n",
      "Epoch 1634/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 401.4208 - mean_absolute_error: 11.5635\n",
      "Epoch 1635/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 413.8667 - mean_absolute_error: 11.8666\n",
      "Epoch 1636/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 408.1301 - mean_absolute_error: 11.7883\n",
      "Epoch 1637/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 405.6814 - mean_absolute_error: 11.8003\n",
      "Epoch 1638/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 429.6306 - mean_absolute_error: 11.9913\n",
      "Epoch 1639/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.6304 - mean_absolute_error: 12.0804\n",
      "Epoch 1640/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 431.7851 - mean_absolute_error: 12.0523\n",
      "Epoch 1641/5000\n",
      "344/344 [==============================] - 0s 254us/step - loss: 429.8767 - mean_absolute_error: 12.3393\n",
      "Epoch 1642/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 431.0801 - mean_absolute_error: 12.4198\n",
      "Epoch 1643/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.8208 - mean_absolute_error: 12.0447\n",
      "Epoch 1644/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.7769 - mean_absolute_error: 11.8081\n",
      "Epoch 1645/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.4289 - mean_absolute_error: 11.9966\n",
      "Epoch 1646/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 410.7431 - mean_absolute_error: 11.7118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1647/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 391.6367 - mean_absolute_error: 11.5127\n",
      "Epoch 1648/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 429.4397 - mean_absolute_error: 12.1627\n",
      "Epoch 1649/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.8615 - mean_absolute_error: 11.9966\n",
      "Epoch 1650/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 449.2342 - mean_absolute_error: 11.9337\n",
      "Epoch 1651/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.2987 - mean_absolute_error: 12.2479\n",
      "Epoch 1652/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 411.0107 - mean_absolute_error: 11.9276\n",
      "Epoch 1653/5000\n",
      "344/344 [==============================] - 0s 250us/step - loss: 431.4070 - mean_absolute_error: 12.2600\n",
      "Epoch 1654/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.3966 - mean_absolute_error: 12.0831\n",
      "Epoch 1655/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 395.7506 - mean_absolute_error: 11.9579\n",
      "Epoch 1656/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.1999 - mean_absolute_error: 12.2928\n",
      "Epoch 1657/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.5660 - mean_absolute_error: 12.2726\n",
      "Epoch 1658/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.7059 - mean_absolute_error: 11.6717\n",
      "Epoch 1659/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.7975 - mean_absolute_error: 11.8250\n",
      "Epoch 1660/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 443.6766 - mean_absolute_error: 12.6029\n",
      "Epoch 1661/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.3719 - mean_absolute_error: 11.8392\n",
      "Epoch 1662/5000\n",
      "344/344 [==============================] - 0s 260us/step - loss: 445.2982 - mean_absolute_error: 12.5459\n",
      "Epoch 1663/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 430.8444 - mean_absolute_error: 12.3166\n",
      "Epoch 1664/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 398.3212 - mean_absolute_error: 11.5301\n",
      "Epoch 1665/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 436.7321 - mean_absolute_error: 12.2778\n",
      "Epoch 1666/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.3182 - mean_absolute_error: 12.0088\n",
      "Epoch 1667/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.2449 - mean_absolute_error: 11.6821\n",
      "Epoch 1668/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 433.8918 - mean_absolute_error: 12.1674\n",
      "Epoch 1669/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 430.9504 - mean_absolute_error: 12.4085\n",
      "Epoch 1670/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.6936 - mean_absolute_error: 12.1205\n",
      "Epoch 1671/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.5912 - mean_absolute_error: 11.7088\n",
      "Epoch 1672/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 398.0237 - mean_absolute_error: 11.5628\n",
      "Epoch 1673/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.0695 - mean_absolute_error: 12.0865\n",
      "Epoch 1674/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.1611 - mean_absolute_error: 11.8657\n",
      "Epoch 1675/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 421.0047 - mean_absolute_error: 11.7513\n",
      "Epoch 1676/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.5454 - mean_absolute_error: 11.9202\n",
      "Epoch 1677/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 441.0767 - mean_absolute_error: 12.5005\n",
      "Epoch 1678/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.1844 - mean_absolute_error: 11.8470\n",
      "Epoch 1679/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 390.9072 - mean_absolute_error: 11.5148\n",
      "Epoch 1680/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 434.3221 - mean_absolute_error: 12.5182\n",
      "Epoch 1681/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.1096 - mean_absolute_error: 11.8153\n",
      "Epoch 1682/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 437.5634 - mean_absolute_error: 12.3698\n",
      "Epoch 1683/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.4197 - mean_absolute_error: 11.6516\n",
      "Epoch 1684/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.0754 - mean_absolute_error: 12.0264\n",
      "Epoch 1685/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 441.1351 - mean_absolute_error: 12.4019\n",
      "Epoch 1686/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 448.9861 - mean_absolute_error: 12.7190\n",
      "Epoch 1687/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 400.2881 - mean_absolute_error: 11.6120\n",
      "Epoch 1688/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 418.6084 - mean_absolute_error: 11.9848\n",
      "Epoch 1689/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 423.6678 - mean_absolute_error: 12.0600\n",
      "Epoch 1690/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.4732 - mean_absolute_error: 11.5299\n",
      "Epoch 1691/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 458.3592 - mean_absolute_error: 12.4682\n",
      "Epoch 1692/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 411.7390 - mean_absolute_error: 11.8316\n",
      "Epoch 1693/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.9871 - mean_absolute_error: 12.4834\n",
      "Epoch 1694/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 421.8370 - mean_absolute_error: 12.1472\n",
      "Epoch 1695/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.9922 - mean_absolute_error: 11.8900\n",
      "Epoch 1696/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.4286 - mean_absolute_error: 12.1588\n",
      "Epoch 1697/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.4155 - mean_absolute_error: 11.5661\n",
      "Epoch 1698/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.2113 - mean_absolute_error: 12.1116\n",
      "Epoch 1699/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 434.3783 - mean_absolute_error: 12.4160\n",
      "Epoch 1700/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.6271 - mean_absolute_error: 11.9881\n",
      "Epoch 1701/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.8829 - mean_absolute_error: 11.7328\n",
      "Epoch 1702/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.8650 - mean_absolute_error: 11.9380\n",
      "Epoch 1703/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 423.6279 - mean_absolute_error: 12.0241\n",
      "Epoch 1704/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 416.0518 - mean_absolute_error: 12.1849\n",
      "Epoch 1705/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 411.3407 - mean_absolute_error: 11.9270\n",
      "Epoch 1706/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.4277 - mean_absolute_error: 11.7784\n",
      "Epoch 1707/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.7957 - mean_absolute_error: 12.2633\n",
      "Epoch 1708/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.3223 - mean_absolute_error: 11.9898\n",
      "Epoch 1709/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.3168 - mean_absolute_error: 11.7650\n",
      "Epoch 1710/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 409.9945 - mean_absolute_error: 11.9735\n",
      "Epoch 1711/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.2172 - mean_absolute_error: 11.5712\n",
      "Epoch 1712/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 433.1189 - mean_absolute_error: 12.4387\n",
      "Epoch 1713/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 407.6754 - mean_absolute_error: 11.5180\n",
      "Epoch 1714/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 393.1744 - mean_absolute_error: 11.7388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1715/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.1794 - mean_absolute_error: 11.8398\n",
      "Epoch 1716/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 423.1624 - mean_absolute_error: 11.7901\n",
      "Epoch 1717/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 405.4581 - mean_absolute_error: 11.6453\n",
      "Epoch 1718/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 416.4280 - mean_absolute_error: 11.7069\n",
      "Epoch 1719/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 410.0131 - mean_absolute_error: 11.5679\n",
      "Epoch 1720/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 414.0708 - mean_absolute_error: 11.9136\n",
      "Epoch 1721/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 422.3228 - mean_absolute_error: 11.9699\n",
      "Epoch 1722/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 421.1156 - mean_absolute_error: 11.9873\n",
      "Epoch 1723/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 439.3417 - mean_absolute_error: 11.9442\n",
      "Epoch 1724/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.5431 - mean_absolute_error: 12.1039\n",
      "Epoch 1725/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 425.2654 - mean_absolute_error: 11.8027\n",
      "Epoch 1726/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 417.7226 - mean_absolute_error: 12.1320\n",
      "Epoch 1727/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.6830 - mean_absolute_error: 11.7140\n",
      "Epoch 1728/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 423.3085 - mean_absolute_error: 12.3482\n",
      "Epoch 1729/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.4950 - mean_absolute_error: 12.2307\n",
      "Epoch 1730/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.1664 - mean_absolute_error: 12.0840\n",
      "Epoch 1731/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.6600 - mean_absolute_error: 11.9329\n",
      "Epoch 1732/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 395.9302 - mean_absolute_error: 11.2842\n",
      "Epoch 1733/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 407.7112 - mean_absolute_error: 11.7984\n",
      "Epoch 1734/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 412.9969 - mean_absolute_error: 11.6797\n",
      "Epoch 1735/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 436.0768 - mean_absolute_error: 12.4601\n",
      "Epoch 1736/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.5638 - mean_absolute_error: 11.8962\n",
      "Epoch 1737/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.6584 - mean_absolute_error: 11.8248\n",
      "Epoch 1738/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 397.3571 - mean_absolute_error: 11.3809\n",
      "Epoch 1739/5000\n",
      "344/344 [==============================] - 0s 260us/step - loss: 417.2710 - mean_absolute_error: 12.2527\n",
      "Epoch 1740/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 403.3773 - mean_absolute_error: 11.6084\n",
      "Epoch 1741/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 431.7282 - mean_absolute_error: 12.3571\n",
      "Epoch 1742/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 425.8020 - mean_absolute_error: 12.4236\n",
      "Epoch 1743/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 409.1956 - mean_absolute_error: 11.3494\n",
      "Epoch 1744/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 404.0898 - mean_absolute_error: 11.8256\n",
      "Epoch 1745/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 416.5392 - mean_absolute_error: 11.9623\n",
      "Epoch 1746/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 398.4732 - mean_absolute_error: 11.5263\n",
      "Epoch 1747/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.5869 - mean_absolute_error: 11.9042\n",
      "Epoch 1748/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.3320 - mean_absolute_error: 11.9986\n",
      "Epoch 1749/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.7886 - mean_absolute_error: 11.5918\n",
      "Epoch 1750/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.4373 - mean_absolute_error: 12.0665\n",
      "Epoch 1751/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 432.9438 - mean_absolute_error: 12.2510\n",
      "Epoch 1752/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.0815 - mean_absolute_error: 11.6498\n",
      "Epoch 1753/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 430.5779 - mean_absolute_error: 12.0686\n",
      "Epoch 1754/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.1523 - mean_absolute_error: 12.1750\n",
      "Epoch 1755/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.5577 - mean_absolute_error: 11.8176\n",
      "Epoch 1756/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 425.8770 - mean_absolute_error: 12.0329\n",
      "Epoch 1757/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 406.3915 - mean_absolute_error: 11.7302\n",
      "Epoch 1758/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.4277 - mean_absolute_error: 12.0806\n",
      "Epoch 1759/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 439.2407 - mean_absolute_error: 12.4326\n",
      "Epoch 1760/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 435.9966 - mean_absolute_error: 12.6718\n",
      "Epoch 1761/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.2187 - mean_absolute_error: 11.8685\n",
      "Epoch 1762/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 441.0109 - mean_absolute_error: 12.4474\n",
      "Epoch 1763/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.4462 - mean_absolute_error: 12.0113\n",
      "Epoch 1764/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 415.9540 - mean_absolute_error: 11.9211\n",
      "Epoch 1765/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 413.6343 - mean_absolute_error: 11.6861\n",
      "Epoch 1766/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.5577 - mean_absolute_error: 11.7614\n",
      "Epoch 1767/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.8157 - mean_absolute_error: 11.9819\n",
      "Epoch 1768/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.8516 - mean_absolute_error: 11.6880\n",
      "Epoch 1769/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.3064 - mean_absolute_error: 11.9433\n",
      "Epoch 1770/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.2256 - mean_absolute_error: 12.1771\n",
      "Epoch 1771/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 397.4210 - mean_absolute_error: 11.4388\n",
      "Epoch 1772/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 435.3765 - mean_absolute_error: 12.2264\n",
      "Epoch 1773/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 439.0669 - mean_absolute_error: 12.2428\n",
      "Epoch 1774/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.3142 - mean_absolute_error: 11.7806\n",
      "Epoch 1775/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.3408 - mean_absolute_error: 12.0858\n",
      "Epoch 1776/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 445.3870 - mean_absolute_error: 12.6668\n",
      "Epoch 1777/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.6324 - mean_absolute_error: 12.1531\n",
      "Epoch 1778/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.3997 - mean_absolute_error: 11.8141\n",
      "Epoch 1779/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.2371 - mean_absolute_error: 11.8148\n",
      "Epoch 1780/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 396.5869 - mean_absolute_error: 11.6046\n",
      "Epoch 1781/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 462.7102 - mean_absolute_error: 12.5223\n",
      "Epoch 1782/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.3166 - mean_absolute_error: 11.9872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1783/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.3245 - mean_absolute_error: 11.9115\n",
      "Epoch 1784/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 411.3787 - mean_absolute_error: 11.7001\n",
      "Epoch 1785/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 416.2936 - mean_absolute_error: 11.7871\n",
      "Epoch 1786/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.9648 - mean_absolute_error: 11.9138\n",
      "Epoch 1787/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.4141 - mean_absolute_error: 11.9137\n",
      "Epoch 1788/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.0238 - mean_absolute_error: 11.7515\n",
      "Epoch 1789/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.2378 - mean_absolute_error: 11.8796\n",
      "Epoch 1790/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 438.7883 - mean_absolute_error: 12.4257\n",
      "Epoch 1791/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.6732 - mean_absolute_error: 12.1571\n",
      "Epoch 1792/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 405.2114 - mean_absolute_error: 11.7622\n",
      "Epoch 1793/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.3032 - mean_absolute_error: 12.0349\n",
      "Epoch 1794/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 427.1678 - mean_absolute_error: 12.3417\n",
      "Epoch 1795/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.8252 - mean_absolute_error: 12.1814\n",
      "Epoch 1796/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 433.9528 - mean_absolute_error: 12.3812\n",
      "Epoch 1797/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 421.0256 - mean_absolute_error: 12.0814\n",
      "Epoch 1798/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.8844 - mean_absolute_error: 11.5916\n",
      "Epoch 1799/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 416.6272 - mean_absolute_error: 11.8918\n",
      "Epoch 1800/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.5457 - mean_absolute_error: 11.8926\n",
      "Epoch 1801/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 405.5688 - mean_absolute_error: 11.7295\n",
      "Epoch 1802/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 437.3244 - mean_absolute_error: 12.4078\n",
      "Epoch 1803/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.2265 - mean_absolute_error: 11.5755\n",
      "Epoch 1804/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.8196 - mean_absolute_error: 11.9665\n",
      "Epoch 1805/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.5583 - mean_absolute_error: 12.0524\n",
      "Epoch 1806/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 437.1047 - mean_absolute_error: 12.3675\n",
      "Epoch 1807/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.1006 - mean_absolute_error: 11.7797\n",
      "Epoch 1808/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.9116 - mean_absolute_error: 11.9403\n",
      "Epoch 1809/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.9164 - mean_absolute_error: 11.5784\n",
      "Epoch 1810/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 432.1607 - mean_absolute_error: 12.4603\n",
      "Epoch 1811/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 411.6384 - mean_absolute_error: 12.0415\n",
      "Epoch 1812/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.1523 - mean_absolute_error: 11.9349\n",
      "Epoch 1813/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.3031 - mean_absolute_error: 11.9347\n",
      "Epoch 1814/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 400.7937 - mean_absolute_error: 11.5574\n",
      "Epoch 1815/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 398.5068 - mean_absolute_error: 11.5622\n",
      "Epoch 1816/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.2943 - mean_absolute_error: 12.0246\n",
      "Epoch 1817/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 427.3200 - mean_absolute_error: 12.3486\n",
      "Epoch 1818/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.9130 - mean_absolute_error: 11.9006\n",
      "Epoch 1819/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.3118 - mean_absolute_error: 12.1834\n",
      "Epoch 1820/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.0578 - mean_absolute_error: 11.4842\n",
      "Epoch 1821/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.2316 - mean_absolute_error: 11.6746\n",
      "Epoch 1822/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 391.7275 - mean_absolute_error: 11.3980\n",
      "Epoch 1823/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 394.4987 - mean_absolute_error: 11.4582\n",
      "Epoch 1824/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 424.5910 - mean_absolute_error: 11.9452\n",
      "Epoch 1825/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 403.5481 - mean_absolute_error: 11.6525\n",
      "Epoch 1826/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 427.2586 - mean_absolute_error: 12.4584\n",
      "Epoch 1827/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 415.2541 - mean_absolute_error: 11.9072\n",
      "Epoch 1828/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 399.5870 - mean_absolute_error: 11.5952\n",
      "Epoch 1829/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 427.7769 - mean_absolute_error: 12.3536\n",
      "Epoch 1830/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 419.7717 - mean_absolute_error: 12.0845\n",
      "Epoch 1831/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.3393 - mean_absolute_error: 12.3097\n",
      "Epoch 1832/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 425.6404 - mean_absolute_error: 12.2150\n",
      "Epoch 1833/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.3479 - mean_absolute_error: 11.8012\n",
      "Epoch 1834/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 425.6031 - mean_absolute_error: 11.8840\n",
      "Epoch 1835/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 452.2488 - mean_absolute_error: 12.3921\n",
      "Epoch 1836/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.1242 - mean_absolute_error: 12.1060\n",
      "Epoch 1837/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 437.1117 - mean_absolute_error: 12.2611\n",
      "Epoch 1838/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.7101 - mean_absolute_error: 11.8521\n",
      "Epoch 1839/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 402.9841 - mean_absolute_error: 11.5817\n",
      "Epoch 1840/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.9169 - mean_absolute_error: 12.0812\n",
      "Epoch 1841/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 409.1025 - mean_absolute_error: 11.7859\n",
      "Epoch 1842/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 522.3338 - mean_absolute_error: 12.4785\n",
      "Epoch 1843/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 423.0824 - mean_absolute_error: 11.9348\n",
      "Epoch 1844/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 410.2762 - mean_absolute_error: 11.7620\n",
      "Epoch 1845/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 391.5914 - mean_absolute_error: 11.3745\n",
      "Epoch 1846/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.9947 - mean_absolute_error: 12.0966\n",
      "Epoch 1847/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 441.0598 - mean_absolute_error: 12.1607\n",
      "Epoch 1848/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 423.5431 - mean_absolute_error: 11.4925\n",
      "Epoch 1849/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 422.5157 - mean_absolute_error: 12.1297\n",
      "Epoch 1850/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.7204 - mean_absolute_error: 11.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1851/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.8871 - mean_absolute_error: 11.5925\n",
      "Epoch 1852/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 403.5530 - mean_absolute_error: 11.5356\n",
      "Epoch 1853/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 427.1334 - mean_absolute_error: 12.0261\n",
      "Epoch 1854/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.3193 - mean_absolute_error: 11.7924\n",
      "Epoch 1855/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 405.4757 - mean_absolute_error: 11.8142\n",
      "Epoch 1856/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.8911 - mean_absolute_error: 11.5930\n",
      "Epoch 1857/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.0471 - mean_absolute_error: 12.1500\n",
      "Epoch 1858/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 434.4778 - mean_absolute_error: 11.8958\n",
      "Epoch 1859/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 426.7245 - mean_absolute_error: 11.9381\n",
      "Epoch 1860/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 433.5975 - mean_absolute_error: 12.2498\n",
      "Epoch 1861/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.8066 - mean_absolute_error: 11.4510\n",
      "Epoch 1862/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 403.6413 - mean_absolute_error: 11.6949\n",
      "Epoch 1863/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 394.0671 - mean_absolute_error: 11.4922\n",
      "Epoch 1864/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 433.3384 - mean_absolute_error: 11.9928\n",
      "Epoch 1865/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.8757 - mean_absolute_error: 11.8945\n",
      "Epoch 1866/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.7417 - mean_absolute_error: 11.9322\n",
      "Epoch 1867/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 419.8711 - mean_absolute_error: 11.9839\n",
      "Epoch 1868/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.7111 - mean_absolute_error: 11.9870\n",
      "Epoch 1869/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 410.1514 - mean_absolute_error: 11.6890\n",
      "Epoch 1870/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 402.8885 - mean_absolute_error: 11.6056\n",
      "Epoch 1871/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 411.5138 - mean_absolute_error: 11.6398\n",
      "Epoch 1872/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 394.9748 - mean_absolute_error: 11.4781\n",
      "Epoch 1873/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.6368 - mean_absolute_error: 11.9464\n",
      "Epoch 1874/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.7017 - mean_absolute_error: 12.1194\n",
      "Epoch 1875/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 443.2423 - mean_absolute_error: 12.5425\n",
      "Epoch 1876/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.8426 - mean_absolute_error: 12.0542\n",
      "Epoch 1877/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 421.4015 - mean_absolute_error: 11.9761\n",
      "Epoch 1878/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.5249 - mean_absolute_error: 11.9488\n",
      "Epoch 1879/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.9736 - mean_absolute_error: 11.8536\n",
      "Epoch 1880/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.3976 - mean_absolute_error: 11.6152\n",
      "Epoch 1881/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.6512 - mean_absolute_error: 11.8589\n",
      "Epoch 1882/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 432.3083 - mean_absolute_error: 12.4883\n",
      "Epoch 1883/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 429.9283 - mean_absolute_error: 12.2300\n",
      "Epoch 1884/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.7303 - mean_absolute_error: 11.9411\n",
      "Epoch 1885/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 425.4665 - mean_absolute_error: 11.9843\n",
      "Epoch 1886/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 436.1472 - mean_absolute_error: 12.3747\n",
      "Epoch 1887/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.6686 - mean_absolute_error: 11.9994\n",
      "Epoch 1888/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.2318 - mean_absolute_error: 11.6518\n",
      "Epoch 1889/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.2974 - mean_absolute_error: 12.3333\n",
      "Epoch 1890/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.4019 - mean_absolute_error: 11.6269\n",
      "Epoch 1891/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.9562 - mean_absolute_error: 11.8834\n",
      "Epoch 1892/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.8804 - mean_absolute_error: 11.9789\n",
      "Epoch 1893/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 403.7173 - mean_absolute_error: 11.9012\n",
      "Epoch 1894/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 411.4229 - mean_absolute_error: 11.5051\n",
      "Epoch 1895/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 403.7030 - mean_absolute_error: 11.7681\n",
      "Epoch 1896/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 420.9030 - mean_absolute_error: 12.1734\n",
      "Epoch 1897/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.1591 - mean_absolute_error: 11.6690\n",
      "Epoch 1898/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 432.7275 - mean_absolute_error: 12.2448\n",
      "Epoch 1899/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 436.1306 - mean_absolute_error: 12.4626\n",
      "Epoch 1900/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 387.9351 - mean_absolute_error: 11.4882\n",
      "Epoch 1901/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 410.7551 - mean_absolute_error: 12.2349\n",
      "Epoch 1902/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 421.4513 - mean_absolute_error: 12.1144\n",
      "Epoch 1903/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 404.4324 - mean_absolute_error: 11.7985\n",
      "Epoch 1904/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.5066 - mean_absolute_error: 11.8746\n",
      "Epoch 1905/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 400.9030 - mean_absolute_error: 11.7285\n",
      "Epoch 1906/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 409.5093 - mean_absolute_error: 11.5898\n",
      "Epoch 1907/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 390.3807 - mean_absolute_error: 11.6437\n",
      "Epoch 1908/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.2438 - mean_absolute_error: 11.8398\n",
      "Epoch 1909/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 423.1733 - mean_absolute_error: 11.9620\n",
      "Epoch 1910/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 400.6744 - mean_absolute_error: 11.6878\n",
      "Epoch 1911/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 410.0880 - mean_absolute_error: 11.6929\n",
      "Epoch 1912/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 435.8180 - mean_absolute_error: 12.2674\n",
      "Epoch 1913/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 411.4641 - mean_absolute_error: 12.0807\n",
      "Epoch 1914/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 388.8564 - mean_absolute_error: 11.1742\n",
      "Epoch 1915/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 418.7020 - mean_absolute_error: 12.1179\n",
      "Epoch 1916/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.9956 - mean_absolute_error: 12.1860\n",
      "Epoch 1917/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.9048 - mean_absolute_error: 12.0222\n",
      "Epoch 1918/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.8123 - mean_absolute_error: 12.2560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1919/5000\n",
      "344/344 [==============================] - 0s 268us/step - loss: 415.2766 - mean_absolute_error: 11.8689\n",
      "Epoch 1920/5000\n",
      "344/344 [==============================] - 0s 281us/step - loss: 404.1195 - mean_absolute_error: 11.7152\n",
      "Epoch 1921/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 422.0597 - mean_absolute_error: 12.1655\n",
      "Epoch 1922/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 400.7287 - mean_absolute_error: 11.6187\n",
      "Epoch 1923/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.3424 - mean_absolute_error: 11.4829\n",
      "Epoch 1924/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.8863 - mean_absolute_error: 11.7321\n",
      "Epoch 1925/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 416.3690 - mean_absolute_error: 11.9284\n",
      "Epoch 1926/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 401.8596 - mean_absolute_error: 11.6862\n",
      "Epoch 1927/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 429.5814 - mean_absolute_error: 11.9696\n",
      "Epoch 1928/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 399.4733 - mean_absolute_error: 11.6068\n",
      "Epoch 1929/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.6594 - mean_absolute_error: 12.3296\n",
      "Epoch 1930/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 406.9747 - mean_absolute_error: 11.3104\n",
      "Epoch 1931/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 414.9675 - mean_absolute_error: 11.7139\n",
      "Epoch 1932/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 407.1495 - mean_absolute_error: 11.6144\n",
      "Epoch 1933/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 410.4326 - mean_absolute_error: 11.9673\n",
      "Epoch 1934/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 412.7102 - mean_absolute_error: 11.7094\n",
      "Epoch 1935/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.9754 - mean_absolute_error: 11.8174\n",
      "Epoch 1936/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.4206 - mean_absolute_error: 11.8348\n",
      "Epoch 1937/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 433.6598 - mean_absolute_error: 12.2971\n",
      "Epoch 1938/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.5608 - mean_absolute_error: 11.8082\n",
      "Epoch 1939/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 433.4302 - mean_absolute_error: 12.2776\n",
      "Epoch 1940/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 420.5811 - mean_absolute_error: 12.1251\n",
      "Epoch 1941/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 403.3870 - mean_absolute_error: 11.4792\n",
      "Epoch 1942/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 411.2365 - mean_absolute_error: 11.8544\n",
      "Epoch 1943/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 429.9576 - mean_absolute_error: 12.0646\n",
      "Epoch 1944/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.9811 - mean_absolute_error: 11.6386\n",
      "Epoch 1945/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 422.4213 - mean_absolute_error: 12.0283\n",
      "Epoch 1946/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 419.3690 - mean_absolute_error: 11.8664\n",
      "Epoch 1947/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 420.7641 - mean_absolute_error: 11.9371\n",
      "Epoch 1948/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 400.3345 - mean_absolute_error: 11.8023\n",
      "Epoch 1949/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 428.8229 - mean_absolute_error: 11.8406\n",
      "Epoch 1950/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 419.6125 - mean_absolute_error: 11.6943\n",
      "Epoch 1951/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 421.9388 - mean_absolute_error: 11.8986\n",
      "Epoch 1952/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.6407 - mean_absolute_error: 11.6685\n",
      "Epoch 1953/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.7846 - mean_absolute_error: 12.0136\n",
      "Epoch 1954/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 424.9314 - mean_absolute_error: 12.0515\n",
      "Epoch 1955/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 400.1513 - mean_absolute_error: 11.5491\n",
      "Epoch 1956/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 429.9600 - mean_absolute_error: 12.1778\n",
      "Epoch 1957/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 392.4541 - mean_absolute_error: 11.4142\n",
      "Epoch 1958/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 403.9807 - mean_absolute_error: 11.6581\n",
      "Epoch 1959/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.9104 - mean_absolute_error: 12.1083\n",
      "Epoch 1960/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 430.9391 - mean_absolute_error: 12.3636\n",
      "Epoch 1961/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 425.0585 - mean_absolute_error: 11.9650\n",
      "Epoch 1962/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 429.6239 - mean_absolute_error: 12.7611\n",
      "Epoch 1963/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 412.5317 - mean_absolute_error: 11.8373\n",
      "Epoch 1964/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.0129 - mean_absolute_error: 11.7080\n",
      "Epoch 1965/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.0124 - mean_absolute_error: 11.6869\n",
      "Epoch 1966/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 404.1911 - mean_absolute_error: 11.9024\n",
      "Epoch 1967/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.4122 - mean_absolute_error: 11.8626\n",
      "Epoch 1968/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.9556 - mean_absolute_error: 12.0377\n",
      "Epoch 1969/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 397.4998 - mean_absolute_error: 11.5972\n",
      "Epoch 1970/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 432.5347 - mean_absolute_error: 12.4615\n",
      "Epoch 1971/5000\n",
      "344/344 [==============================] - 0s 250us/step - loss: 455.9984 - mean_absolute_error: 12.3193\n",
      "Epoch 1972/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.5435 - mean_absolute_error: 11.9451\n",
      "Epoch 1973/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 424.5437 - mean_absolute_error: 12.0967\n",
      "Epoch 1974/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 425.7563 - mean_absolute_error: 12.2243\n",
      "Epoch 1975/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 444.6317 - mean_absolute_error: 12.2119\n",
      "Epoch 1976/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.0540 - mean_absolute_error: 11.6882\n",
      "Epoch 1977/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 416.0374 - mean_absolute_error: 11.8984\n",
      "Epoch 1978/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 401.2776 - mean_absolute_error: 11.7015\n",
      "Epoch 1979/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.4420 - mean_absolute_error: 11.9404\n",
      "Epoch 1980/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.0402 - mean_absolute_error: 11.4036\n",
      "Epoch 1981/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 489.3191 - mean_absolute_error: 12.2722\n",
      "Epoch 1982/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.9762 - mean_absolute_error: 11.7121\n",
      "Epoch 1983/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.3582 - mean_absolute_error: 12.0268\n",
      "Epoch 1984/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.7953 - mean_absolute_error: 11.7026\n",
      "Epoch 1985/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 399.8307 - mean_absolute_error: 11.1274\n",
      "Epoch 1986/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 424.2884 - mean_absolute_error: 12.1918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1987/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.6624 - mean_absolute_error: 12.0115\n",
      "Epoch 1988/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 427.7576 - mean_absolute_error: 12.1031\n",
      "Epoch 1989/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 412.8476 - mean_absolute_error: 11.9946\n",
      "Epoch 1990/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.6395 - mean_absolute_error: 12.0167\n",
      "Epoch 1991/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.5668 - mean_absolute_error: 11.5549\n",
      "Epoch 1992/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.9998 - mean_absolute_error: 11.9226\n",
      "Epoch 1993/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 423.4087 - mean_absolute_error: 12.3202\n",
      "Epoch 1994/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 429.7599 - mean_absolute_error: 12.2859\n",
      "Epoch 1995/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.4401 - mean_absolute_error: 11.8402\n",
      "Epoch 1996/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 428.3134 - mean_absolute_error: 12.1298\n",
      "Epoch 1997/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 438.2211 - mean_absolute_error: 12.3894\n",
      "Epoch 1998/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.4892 - mean_absolute_error: 11.7829\n",
      "Epoch 1999/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.8276 - mean_absolute_error: 11.7633\n",
      "Epoch 2000/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 437.2821 - mean_absolute_error: 12.0498\n",
      "Epoch 2001/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.0718 - mean_absolute_error: 12.3040\n",
      "Epoch 2002/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.1847 - mean_absolute_error: 11.7796\n",
      "Epoch 2003/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.9972 - mean_absolute_error: 12.2280\n",
      "Epoch 2004/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.0275 - mean_absolute_error: 11.8460\n",
      "Epoch 2005/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.5080 - mean_absolute_error: 11.7401\n",
      "Epoch 2006/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.1627 - mean_absolute_error: 11.8627\n",
      "Epoch 2007/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.4333 - mean_absolute_error: 12.0062\n",
      "Epoch 2008/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 408.4239 - mean_absolute_error: 11.6167\n",
      "Epoch 2009/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 398.7911 - mean_absolute_error: 11.3508\n",
      "Epoch 2010/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 417.8682 - mean_absolute_error: 12.2119\n",
      "Epoch 2011/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 399.6252 - mean_absolute_error: 11.6797\n",
      "Epoch 2012/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.4208 - mean_absolute_error: 11.6674\n",
      "Epoch 2013/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 399.9494 - mean_absolute_error: 11.3271\n",
      "Epoch 2014/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 411.7834 - mean_absolute_error: 11.8010\n",
      "Epoch 2015/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.8056 - mean_absolute_error: 12.0746\n",
      "Epoch 2016/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 398.8637 - mean_absolute_error: 11.5135\n",
      "Epoch 2017/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.0021 - mean_absolute_error: 12.4185\n",
      "Epoch 2018/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.7098 - mean_absolute_error: 12.0331\n",
      "Epoch 2019/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.0813 - mean_absolute_error: 12.0976\n",
      "Epoch 2020/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 442.9610 - mean_absolute_error: 12.4614\n",
      "Epoch 2021/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.4496 - mean_absolute_error: 12.1955\n",
      "Epoch 2022/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.8712 - mean_absolute_error: 12.2318\n",
      "Epoch 2023/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 405.0748 - mean_absolute_error: 11.7242\n",
      "Epoch 2024/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 430.5961 - mean_absolute_error: 11.8781\n",
      "Epoch 2025/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 420.6833 - mean_absolute_error: 11.9024\n",
      "Epoch 2026/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 406.1901 - mean_absolute_error: 11.6571\n",
      "Epoch 2027/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.6756 - mean_absolute_error: 11.6121\n",
      "Epoch 2028/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.1484 - mean_absolute_error: 11.9116\n",
      "Epoch 2029/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 413.7128 - mean_absolute_error: 11.9049\n",
      "Epoch 2030/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 424.1476 - mean_absolute_error: 12.1035\n",
      "Epoch 2031/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 418.9822 - mean_absolute_error: 11.8803\n",
      "Epoch 2032/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 407.6781 - mean_absolute_error: 11.6228\n",
      "Epoch 2033/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 408.2990 - mean_absolute_error: 11.6530\n",
      "Epoch 2034/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.4591 - mean_absolute_error: 11.8769\n",
      "Epoch 2035/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.0480 - mean_absolute_error: 12.2781\n",
      "Epoch 2036/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.6906 - mean_absolute_error: 11.9611\n",
      "Epoch 2037/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 431.5412 - mean_absolute_error: 12.3214\n",
      "Epoch 2038/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 393.0038 - mean_absolute_error: 11.5392\n",
      "Epoch 2039/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.8827 - mean_absolute_error: 12.0152\n",
      "Epoch 2040/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.1936 - mean_absolute_error: 12.1289\n",
      "Epoch 2041/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 415.6729 - mean_absolute_error: 11.7253\n",
      "Epoch 2042/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.2831 - mean_absolute_error: 11.4779\n",
      "Epoch 2043/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 412.4504 - mean_absolute_error: 11.7855\n",
      "Epoch 2044/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 395.7069 - mean_absolute_error: 11.6743\n",
      "Epoch 2045/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 424.9306 - mean_absolute_error: 11.9601\n",
      "Epoch 2046/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.9083 - mean_absolute_error: 11.7175\n",
      "Epoch 2047/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.1100 - mean_absolute_error: 12.2714\n",
      "Epoch 2048/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 402.0388 - mean_absolute_error: 11.5892\n",
      "Epoch 2049/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 426.4206 - mean_absolute_error: 12.0182\n",
      "Epoch 2050/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.0681 - mean_absolute_error: 12.0366\n",
      "Epoch 2051/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.9986 - mean_absolute_error: 11.9892\n",
      "Epoch 2052/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.9191 - mean_absolute_error: 11.6266\n",
      "Epoch 2053/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 430.6609 - mean_absolute_error: 11.8206\n",
      "Epoch 2054/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.3280 - mean_absolute_error: 11.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2055/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.6151 - mean_absolute_error: 12.2516\n",
      "Epoch 2056/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 405.3133 - mean_absolute_error: 11.7832\n",
      "Epoch 2057/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.8985 - mean_absolute_error: 12.0145\n",
      "Epoch 2058/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 427.0388 - mean_absolute_error: 12.3841\n",
      "Epoch 2059/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 433.0381 - mean_absolute_error: 12.3022\n",
      "Epoch 2060/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 402.3070 - mean_absolute_error: 11.7697\n",
      "Epoch 2061/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 412.4790 - mean_absolute_error: 11.9537\n",
      "Epoch 2062/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.1541 - mean_absolute_error: 11.9584\n",
      "Epoch 2063/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.0602 - mean_absolute_error: 11.8257\n",
      "Epoch 2064/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.4984 - mean_absolute_error: 11.7603\n",
      "Epoch 2065/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.1846 - mean_absolute_error: 11.7907\n",
      "Epoch 2066/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 415.5450 - mean_absolute_error: 11.9345\n",
      "Epoch 2067/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.9007 - mean_absolute_error: 11.8954\n",
      "Epoch 2068/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 419.2798 - mean_absolute_error: 12.3728\n",
      "Epoch 2069/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.0324 - mean_absolute_error: 12.0614\n",
      "Epoch 2070/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.0094 - mean_absolute_error: 11.6748\n",
      "Epoch 2071/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.7647 - mean_absolute_error: 11.7138\n",
      "Epoch 2072/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 417.7833 - mean_absolute_error: 12.2232\n",
      "Epoch 2073/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 452.1574 - mean_absolute_error: 12.6313\n",
      "Epoch 2074/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 398.7510 - mean_absolute_error: 11.7913\n",
      "Epoch 2075/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 406.9025 - mean_absolute_error: 11.8226\n",
      "Epoch 2076/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.5136 - mean_absolute_error: 12.3747\n",
      "Epoch 2077/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 420.6121 - mean_absolute_error: 12.1206\n",
      "Epoch 2078/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 401.4902 - mean_absolute_error: 11.7545\n",
      "Epoch 2079/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.0422 - mean_absolute_error: 11.9467\n",
      "Epoch 2080/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.5941 - mean_absolute_error: 11.8355\n",
      "Epoch 2081/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 437.1787 - mean_absolute_error: 12.3007\n",
      "Epoch 2082/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 492.2675 - mean_absolute_error: 12.5369\n",
      "Epoch 2083/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.5507 - mean_absolute_error: 12.0499\n",
      "Epoch 2084/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.0131 - mean_absolute_error: 12.0556\n",
      "Epoch 2085/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 412.9366 - mean_absolute_error: 12.0630\n",
      "Epoch 2086/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.4063 - mean_absolute_error: 11.6979\n",
      "Epoch 2087/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 419.7101 - mean_absolute_error: 12.2587\n",
      "Epoch 2088/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 408.2475 - mean_absolute_error: 11.4565\n",
      "Epoch 2089/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 415.0022 - mean_absolute_error: 12.2856\n",
      "Epoch 2090/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.0408 - mean_absolute_error: 11.7989\n",
      "Epoch 2091/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.8031 - mean_absolute_error: 11.5920\n",
      "Epoch 2092/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.1985 - mean_absolute_error: 11.8928\n",
      "Epoch 2093/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 422.6110 - mean_absolute_error: 12.0492\n",
      "Epoch 2094/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 431.3936 - mean_absolute_error: 12.3860\n",
      "Epoch 2095/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 394.0672 - mean_absolute_error: 11.5903\n",
      "Epoch 2096/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 416.2181 - mean_absolute_error: 11.8934\n",
      "Epoch 2097/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.5909 - mean_absolute_error: 11.8948\n",
      "Epoch 2098/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 392.9329 - mean_absolute_error: 11.1419\n",
      "Epoch 2099/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.9866 - mean_absolute_error: 11.8816\n",
      "Epoch 2100/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 399.2420 - mean_absolute_error: 11.5578\n",
      "Epoch 2101/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.2137 - mean_absolute_error: 11.8914\n",
      "Epoch 2102/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 405.1602 - mean_absolute_error: 11.8302\n",
      "Epoch 2103/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.3902 - mean_absolute_error: 11.8021\n",
      "Epoch 2104/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 427.5689 - mean_absolute_error: 12.2364\n",
      "Epoch 2105/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 391.0972 - mean_absolute_error: 11.6950\n",
      "Epoch 2106/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 389.9411 - mean_absolute_error: 11.3384\n",
      "Epoch 2107/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 433.2706 - mean_absolute_error: 12.5457\n",
      "Epoch 2108/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 439.7191 - mean_absolute_error: 12.2688\n",
      "Epoch 2109/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 401.2282 - mean_absolute_error: 11.9186\n",
      "Epoch 2110/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 430.5904 - mean_absolute_error: 11.9222\n",
      "Epoch 2111/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.1765 - mean_absolute_error: 12.0615\n",
      "Epoch 2112/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.5329 - mean_absolute_error: 11.9171\n",
      "Epoch 2113/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 415.8857 - mean_absolute_error: 11.6958\n",
      "Epoch 2114/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.3256 - mean_absolute_error: 11.8449\n",
      "Epoch 2115/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 427.8990 - mean_absolute_error: 12.3428\n",
      "Epoch 2116/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.6357 - mean_absolute_error: 11.6170\n",
      "Epoch 2117/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.4403 - mean_absolute_error: 12.0480\n",
      "Epoch 2118/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.4603 - mean_absolute_error: 11.8979\n",
      "Epoch 2119/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.5319 - mean_absolute_error: 11.6571\n",
      "Epoch 2120/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.9149 - mean_absolute_error: 11.5343\n",
      "Epoch 2121/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 399.4677 - mean_absolute_error: 11.5640\n",
      "Epoch 2122/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 423.1791 - mean_absolute_error: 12.2724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2123/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 507.9707 - mean_absolute_error: 12.5132\n",
      "Epoch 2124/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 392.1841 - mean_absolute_error: 11.4993\n",
      "Epoch 2125/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.9521 - mean_absolute_error: 11.7674\n",
      "Epoch 2126/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 432.1015 - mean_absolute_error: 12.1436\n",
      "Epoch 2127/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 408.3653 - mean_absolute_error: 11.7771\n",
      "Epoch 2128/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.5880 - mean_absolute_error: 11.7046\n",
      "Epoch 2129/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 403.9837 - mean_absolute_error: 11.5275\n",
      "Epoch 2130/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.7419 - mean_absolute_error: 12.0788\n",
      "Epoch 2131/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 423.6675 - mean_absolute_error: 12.2483\n",
      "Epoch 2132/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 449.5520 - mean_absolute_error: 12.3323\n",
      "Epoch 2133/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 410.8136 - mean_absolute_error: 11.8959\n",
      "Epoch 2134/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 411.6982 - mean_absolute_error: 12.0604\n",
      "Epoch 2135/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.3106 - mean_absolute_error: 11.9544\n",
      "Epoch 2136/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 446.9429 - mean_absolute_error: 12.2678\n",
      "Epoch 2137/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.5045 - mean_absolute_error: 12.1237\n",
      "Epoch 2138/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.9336 - mean_absolute_error: 11.9758\n",
      "Epoch 2139/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 405.7252 - mean_absolute_error: 11.5786\n",
      "Epoch 2140/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 393.6193 - mean_absolute_error: 11.5838\n",
      "Epoch 2141/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 402.9470 - mean_absolute_error: 11.8760\n",
      "Epoch 2142/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.4432 - mean_absolute_error: 12.0665\n",
      "Epoch 2143/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.4809 - mean_absolute_error: 11.6233\n",
      "Epoch 2144/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.2076 - mean_absolute_error: 12.2316\n",
      "Epoch 2145/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 407.0366 - mean_absolute_error: 11.8489\n",
      "Epoch 2146/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 409.0750 - mean_absolute_error: 12.1641\n",
      "Epoch 2147/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.6328 - mean_absolute_error: 12.0486\n",
      "Epoch 2148/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.9494 - mean_absolute_error: 11.6409\n",
      "Epoch 2149/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.2386 - mean_absolute_error: 11.8752\n",
      "Epoch 2150/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 418.8408 - mean_absolute_error: 12.0252\n",
      "Epoch 2151/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 422.5164 - mean_absolute_error: 12.0695\n",
      "Epoch 2152/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 435.1243 - mean_absolute_error: 12.0426\n",
      "Epoch 2153/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 432.6414 - mean_absolute_error: 12.1094\n",
      "Epoch 2154/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 406.8924 - mean_absolute_error: 11.8481\n",
      "Epoch 2155/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.3855 - mean_absolute_error: 11.8970\n",
      "Epoch 2156/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.6107 - mean_absolute_error: 11.9584\n",
      "Epoch 2157/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.3940 - mean_absolute_error: 11.9525\n",
      "Epoch 2158/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.9761 - mean_absolute_error: 11.9042\n",
      "Epoch 2159/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.6848 - mean_absolute_error: 11.6786\n",
      "Epoch 2160/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.4235 - mean_absolute_error: 11.9263\n",
      "Epoch 2161/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.3757 - mean_absolute_error: 11.8615\n",
      "Epoch 2162/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.6377 - mean_absolute_error: 11.2831\n",
      "Epoch 2163/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.2994 - mean_absolute_error: 12.1873\n",
      "Epoch 2164/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 415.3813 - mean_absolute_error: 12.1458\n",
      "Epoch 2165/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 388.8615 - mean_absolute_error: 11.3278\n",
      "Epoch 2166/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 434.6168 - mean_absolute_error: 12.1270\n",
      "Epoch 2167/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.7181 - mean_absolute_error: 12.0798\n",
      "Epoch 2168/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 412.0761 - mean_absolute_error: 11.8169\n",
      "Epoch 2169/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.6385 - mean_absolute_error: 12.0198\n",
      "Epoch 2170/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.5096 - mean_absolute_error: 12.3427\n",
      "Epoch 2171/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.3344 - mean_absolute_error: 11.9661\n",
      "Epoch 2172/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 406.2285 - mean_absolute_error: 11.5674\n",
      "Epoch 2173/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.2664 - mean_absolute_error: 11.9820\n",
      "Epoch 2174/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.2991 - mean_absolute_error: 12.1381\n",
      "Epoch 2175/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 403.6769 - mean_absolute_error: 11.5643\n",
      "Epoch 2176/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.6601 - mean_absolute_error: 12.1555\n",
      "Epoch 2177/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.7332 - mean_absolute_error: 12.1595\n",
      "Epoch 2178/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.3481 - mean_absolute_error: 12.0601\n",
      "Epoch 2179/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.7789 - mean_absolute_error: 11.6420\n",
      "Epoch 2180/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 409.6717 - mean_absolute_error: 11.7449\n",
      "Epoch 2181/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.1115 - mean_absolute_error: 11.8100\n",
      "Epoch 2182/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 406.1096 - mean_absolute_error: 11.6696\n",
      "Epoch 2183/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.2675 - mean_absolute_error: 11.9882\n",
      "Epoch 2184/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 424.5675 - mean_absolute_error: 12.3672\n",
      "Epoch 2185/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.8949 - mean_absolute_error: 12.2004\n",
      "Epoch 2186/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 389.4423 - mean_absolute_error: 11.2443\n",
      "Epoch 2187/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 447.5299 - mean_absolute_error: 12.2938\n",
      "Epoch 2188/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 440.9103 - mean_absolute_error: 12.6315\n",
      "Epoch 2189/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.3747 - mean_absolute_error: 11.8634\n",
      "Epoch 2190/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.4261 - mean_absolute_error: 12.0147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2191/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 414.7072 - mean_absolute_error: 11.6201\n",
      "Epoch 2192/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.2279 - mean_absolute_error: 11.8237\n",
      "Epoch 2193/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 414.9826 - mean_absolute_error: 11.8795\n",
      "Epoch 2194/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 396.4214 - mean_absolute_error: 11.4503\n",
      "Epoch 2195/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 401.3907 - mean_absolute_error: 11.8043\n",
      "Epoch 2196/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.9078 - mean_absolute_error: 11.6616\n",
      "Epoch 2197/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 429.4080 - mean_absolute_error: 11.9899\n",
      "Epoch 2198/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.4810 - mean_absolute_error: 11.9396\n",
      "Epoch 2199/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 419.5310 - mean_absolute_error: 11.9179\n",
      "Epoch 2200/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 413.3409 - mean_absolute_error: 11.5540\n",
      "Epoch 2201/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.5301 - mean_absolute_error: 12.1065\n",
      "Epoch 2202/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 431.5099 - mean_absolute_error: 12.1648\n",
      "Epoch 2203/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 410.5175 - mean_absolute_error: 12.0929\n",
      "Epoch 2204/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.2946 - mean_absolute_error: 11.7207\n",
      "Epoch 2205/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.1451 - mean_absolute_error: 12.0838\n",
      "Epoch 2206/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.4208 - mean_absolute_error: 12.1434\n",
      "Epoch 2207/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 505.7199 - mean_absolute_error: 12.9020\n",
      "Epoch 2208/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.7254 - mean_absolute_error: 11.8447\n",
      "Epoch 2209/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 416.1112 - mean_absolute_error: 12.0713\n",
      "Epoch 2210/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.5712 - mean_absolute_error: 11.6795\n",
      "Epoch 2211/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.8274 - mean_absolute_error: 12.0155\n",
      "Epoch 2212/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 405.1277 - mean_absolute_error: 11.8815\n",
      "Epoch 2213/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 434.2988 - mean_absolute_error: 11.8946\n",
      "Epoch 2214/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.4568 - mean_absolute_error: 11.9479\n",
      "Epoch 2215/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 458.9639 - mean_absolute_error: 12.3676\n",
      "Epoch 2216/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 426.7313 - mean_absolute_error: 12.2190\n",
      "Epoch 2217/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 400.9927 - mean_absolute_error: 11.3478\n",
      "Epoch 2218/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.7022 - mean_absolute_error: 11.7949\n",
      "Epoch 2219/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 422.5636 - mean_absolute_error: 12.1920\n",
      "Epoch 2220/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.6956 - mean_absolute_error: 11.6618\n",
      "Epoch 2221/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 428.4858 - mean_absolute_error: 12.3154\n",
      "Epoch 2222/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 429.0056 - mean_absolute_error: 12.1759\n",
      "Epoch 2223/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.8168 - mean_absolute_error: 11.8533\n",
      "Epoch 2224/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.6232 - mean_absolute_error: 11.7841\n",
      "Epoch 2225/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.2661 - mean_absolute_error: 11.9616\n",
      "Epoch 2226/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 405.7698 - mean_absolute_error: 11.5264\n",
      "Epoch 2227/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.3585 - mean_absolute_error: 12.1956\n",
      "Epoch 2228/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 410.3304 - mean_absolute_error: 11.6685\n",
      "Epoch 2229/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.1955 - mean_absolute_error: 12.2178\n",
      "Epoch 2230/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 440.2150 - mean_absolute_error: 12.4718\n",
      "Epoch 2231/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 411.2830 - mean_absolute_error: 11.6897\n",
      "Epoch 2232/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 428.4074 - mean_absolute_error: 12.1102\n",
      "Epoch 2233/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 403.9209 - mean_absolute_error: 11.6990\n",
      "Epoch 2234/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 438.7913 - mean_absolute_error: 12.3914\n",
      "Epoch 2235/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 409.3208 - mean_absolute_error: 11.7715\n",
      "Epoch 2236/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 423.2291 - mean_absolute_error: 11.9619\n",
      "Epoch 2237/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 431.9233 - mean_absolute_error: 12.3117\n",
      "Epoch 2238/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.2759 - mean_absolute_error: 11.8802\n",
      "Epoch 2239/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.0090 - mean_absolute_error: 11.2952\n",
      "Epoch 2240/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 460.1093 - mean_absolute_error: 12.1785\n",
      "Epoch 2241/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.6736 - mean_absolute_error: 11.8481\n",
      "Epoch 2242/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 413.4998 - mean_absolute_error: 11.9614\n",
      "Epoch 2243/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 399.1294 - mean_absolute_error: 11.3257\n",
      "Epoch 2244/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 445.5216 - mean_absolute_error: 12.3143\n",
      "Epoch 2245/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.2423 - mean_absolute_error: 11.9680\n",
      "Epoch 2246/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.2228 - mean_absolute_error: 12.0837\n",
      "Epoch 2247/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 472.9378 - mean_absolute_error: 12.5651\n",
      "Epoch 2248/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 411.4317 - mean_absolute_error: 12.0647\n",
      "Epoch 2249/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.0335 - mean_absolute_error: 11.7644\n",
      "Epoch 2250/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 425.6592 - mean_absolute_error: 12.0772\n",
      "Epoch 2251/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.6967 - mean_absolute_error: 11.6164\n",
      "Epoch 2252/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.7805 - mean_absolute_error: 11.6103\n",
      "Epoch 2253/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 440.3787 - mean_absolute_error: 12.6108\n",
      "Epoch 2254/5000\n",
      "344/344 [==============================] - 0s 224us/step - loss: 420.4745 - mean_absolute_error: 11.9236\n",
      "Epoch 2255/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.7766 - mean_absolute_error: 11.8173\n",
      "Epoch 2256/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 428.4635 - mean_absolute_error: 12.0940\n",
      "Epoch 2257/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 427.1588 - mean_absolute_error: 12.0872\n",
      "Epoch 2258/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 463.3374 - mean_absolute_error: 12.5489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2259/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.9598 - mean_absolute_error: 12.0676\n",
      "Epoch 2260/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.0590 - mean_absolute_error: 11.7220\n",
      "Epoch 2261/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 394.8851 - mean_absolute_error: 11.3827\n",
      "Epoch 2262/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.0488 - mean_absolute_error: 11.8601\n",
      "Epoch 2263/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.2003 - mean_absolute_error: 11.7397\n",
      "Epoch 2264/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.5869 - mean_absolute_error: 11.7987\n",
      "Epoch 2265/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.2802 - mean_absolute_error: 11.9968\n",
      "Epoch 2266/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.6885 - mean_absolute_error: 12.1930\n",
      "Epoch 2267/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.3841 - mean_absolute_error: 12.2398\n",
      "Epoch 2268/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.2616 - mean_absolute_error: 11.5299\n",
      "Epoch 2269/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 391.4769 - mean_absolute_error: 11.6894\n",
      "Epoch 2270/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.0512 - mean_absolute_error: 11.7163\n",
      "Epoch 2271/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 409.3318 - mean_absolute_error: 11.5974\n",
      "Epoch 2272/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 386.0394 - mean_absolute_error: 11.3089\n",
      "Epoch 2273/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 410.4098 - mean_absolute_error: 11.8353\n",
      "Epoch 2274/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.0947 - mean_absolute_error: 11.8729\n",
      "Epoch 2275/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 400.6630 - mean_absolute_error: 11.7067\n",
      "Epoch 2276/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.4379 - mean_absolute_error: 12.1671\n",
      "Epoch 2277/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 406.0601 - mean_absolute_error: 11.7855\n",
      "Epoch 2278/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 416.0081 - mean_absolute_error: 11.9738\n",
      "Epoch 2279/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.4533 - mean_absolute_error: 11.7648\n",
      "Epoch 2280/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 460.5400 - mean_absolute_error: 12.2771\n",
      "Epoch 2281/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.0259 - mean_absolute_error: 11.6550\n",
      "Epoch 2282/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.2711 - mean_absolute_error: 11.9994\n",
      "Epoch 2283/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.9829 - mean_absolute_error: 12.0745\n",
      "Epoch 2284/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 422.8027 - mean_absolute_error: 12.0861\n",
      "Epoch 2285/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 395.6927 - mean_absolute_error: 11.1047\n",
      "Epoch 2286/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 427.1428 - mean_absolute_error: 12.0825\n",
      "Epoch 2287/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 395.7931 - mean_absolute_error: 11.3575\n",
      "Epoch 2288/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.8767 - mean_absolute_error: 11.9329\n",
      "Epoch 2289/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.7662 - mean_absolute_error: 11.8068\n",
      "Epoch 2290/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 413.4809 - mean_absolute_error: 11.9251\n",
      "Epoch 2291/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 417.4977 - mean_absolute_error: 12.0270\n",
      "Epoch 2292/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 447.3826 - mean_absolute_error: 12.3697\n",
      "Epoch 2293/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.0307 - mean_absolute_error: 11.8131\n",
      "Epoch 2294/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.9439 - mean_absolute_error: 11.9970\n",
      "Epoch 2295/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.9581 - mean_absolute_error: 11.7999\n",
      "Epoch 2296/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.1797 - mean_absolute_error: 11.8647\n",
      "Epoch 2297/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.2150 - mean_absolute_error: 11.9621\n",
      "Epoch 2298/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 394.7852 - mean_absolute_error: 11.5250\n",
      "Epoch 2299/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 404.8214 - mean_absolute_error: 11.6501\n",
      "Epoch 2300/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 429.1387 - mean_absolute_error: 12.2297\n",
      "Epoch 2301/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.7597 - mean_absolute_error: 11.3204\n",
      "Epoch 2302/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 430.3289 - mean_absolute_error: 12.3371\n",
      "Epoch 2303/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 422.1642 - mean_absolute_error: 12.1993\n",
      "Epoch 2304/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.7181 - mean_absolute_error: 11.5673\n",
      "Epoch 2305/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.2780 - mean_absolute_error: 11.9275\n",
      "Epoch 2306/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.3408 - mean_absolute_error: 11.8150\n",
      "Epoch 2307/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.6395 - mean_absolute_error: 12.3329\n",
      "Epoch 2308/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.0570 - mean_absolute_error: 11.7306\n",
      "Epoch 2309/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.2231 - mean_absolute_error: 11.7271\n",
      "Epoch 2310/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 412.8328 - mean_absolute_error: 11.6432\n",
      "Epoch 2311/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 431.9072 - mean_absolute_error: 12.4880\n",
      "Epoch 2312/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 402.8025 - mean_absolute_error: 11.7872\n",
      "Epoch 2313/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 397.5996 - mean_absolute_error: 11.5697\n",
      "Epoch 2314/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 405.8618 - mean_absolute_error: 11.4769\n",
      "Epoch 2315/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 399.7297 - mean_absolute_error: 11.3331\n",
      "Epoch 2316/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 415.5850 - mean_absolute_error: 11.7942\n",
      "Epoch 2317/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.9541 - mean_absolute_error: 11.7792\n",
      "Epoch 2318/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.3507 - mean_absolute_error: 11.7720\n",
      "Epoch 2319/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.6422 - mean_absolute_error: 11.7806\n",
      "Epoch 2320/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.4749 - mean_absolute_error: 11.8015\n",
      "Epoch 2321/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.8993 - mean_absolute_error: 11.7131\n",
      "Epoch 2322/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.2258 - mean_absolute_error: 11.8252\n",
      "Epoch 2323/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.2852 - mean_absolute_error: 11.6652\n",
      "Epoch 2324/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.4386 - mean_absolute_error: 12.1265\n",
      "Epoch 2325/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 423.7421 - mean_absolute_error: 12.2003\n",
      "Epoch 2326/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 414.2747 - mean_absolute_error: 11.7980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2327/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 407.7476 - mean_absolute_error: 11.7548\n",
      "Epoch 2328/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 398.8015 - mean_absolute_error: 11.5567\n",
      "Epoch 2329/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.5283 - mean_absolute_error: 12.0957\n",
      "Epoch 2330/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.6641 - mean_absolute_error: 12.0021\n",
      "Epoch 2331/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 400.8684 - mean_absolute_error: 11.4533\n",
      "Epoch 2332/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 425.8064 - mean_absolute_error: 12.2182\n",
      "Epoch 2333/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.3509 - mean_absolute_error: 11.4446\n",
      "Epoch 2334/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.4606 - mean_absolute_error: 11.9815\n",
      "Epoch 2335/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.1419 - mean_absolute_error: 12.0985\n",
      "Epoch 2336/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 428.5469 - mean_absolute_error: 12.2014\n",
      "Epoch 2337/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 427.5375 - mean_absolute_error: 12.1926\n",
      "Epoch 2338/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 403.6483 - mean_absolute_error: 11.7699\n",
      "Epoch 2339/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.1131 - mean_absolute_error: 12.1292\n",
      "Epoch 2340/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 403.8677 - mean_absolute_error: 11.6598\n",
      "Epoch 2341/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 441.9878 - mean_absolute_error: 12.0821\n",
      "Epoch 2342/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 438.4449 - mean_absolute_error: 12.5177\n",
      "Epoch 2343/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 432.5736 - mean_absolute_error: 12.0648\n",
      "Epoch 2344/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 411.8862 - mean_absolute_error: 11.7309\n",
      "Epoch 2345/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.9852 - mean_absolute_error: 11.8140\n",
      "Epoch 2346/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.4229 - mean_absolute_error: 12.2092\n",
      "Epoch 2347/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.7546 - mean_absolute_error: 12.1295\n",
      "Epoch 2348/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.6408 - mean_absolute_error: 11.5109\n",
      "Epoch 2349/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 427.6130 - mean_absolute_error: 12.1979\n",
      "Epoch 2350/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 398.8347 - mean_absolute_error: 11.8737\n",
      "Epoch 2351/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 405.3080 - mean_absolute_error: 11.8700\n",
      "Epoch 2352/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.1997 - mean_absolute_error: 12.0254\n",
      "Epoch 2353/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 395.1718 - mean_absolute_error: 11.4516\n",
      "Epoch 2354/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.3275 - mean_absolute_error: 11.8144\n",
      "Epoch 2355/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 394.3277 - mean_absolute_error: 11.5470\n",
      "Epoch 2356/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.3139 - mean_absolute_error: 11.8695\n",
      "Epoch 2357/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 422.5030 - mean_absolute_error: 11.8020\n",
      "Epoch 2358/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.7587 - mean_absolute_error: 11.9254\n",
      "Epoch 2359/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 392.5634 - mean_absolute_error: 11.3346\n",
      "Epoch 2360/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 383.6731 - mean_absolute_error: 11.1715\n",
      "Epoch 2361/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 420.2596 - mean_absolute_error: 12.2679\n",
      "Epoch 2362/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 398.1321 - mean_absolute_error: 11.7910\n",
      "Epoch 2363/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.6168 - mean_absolute_error: 11.8796\n",
      "Epoch 2364/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.2951 - mean_absolute_error: 11.9324\n",
      "Epoch 2365/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.1118 - mean_absolute_error: 11.8740\n",
      "Epoch 2366/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 408.8725 - mean_absolute_error: 11.8457\n",
      "Epoch 2367/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.9655 - mean_absolute_error: 12.3164\n",
      "Epoch 2368/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 394.9160 - mean_absolute_error: 11.4208\n",
      "Epoch 2369/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.6627 - mean_absolute_error: 12.2849\n",
      "Epoch 2370/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 444.7805 - mean_absolute_error: 12.4751\n",
      "Epoch 2371/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 417.3126 - mean_absolute_error: 11.9114\n",
      "Epoch 2372/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 412.9160 - mean_absolute_error: 11.9381\n",
      "Epoch 2373/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 426.6407 - mean_absolute_error: 11.8588\n",
      "Epoch 2374/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 453.9696 - mean_absolute_error: 12.1252\n",
      "Epoch 2375/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 406.4227 - mean_absolute_error: 11.7475\n",
      "Epoch 2376/5000\n",
      "344/344 [==============================] - 0s 217us/step - loss: 412.4231 - mean_absolute_error: 11.9408\n",
      "Epoch 2377/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.4387 - mean_absolute_error: 12.1924\n",
      "Epoch 2378/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 431.2436 - mean_absolute_error: 12.1045\n",
      "Epoch 2379/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.2296 - mean_absolute_error: 11.8076\n",
      "Epoch 2380/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.0226 - mean_absolute_error: 12.3518\n",
      "Epoch 2381/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.0675 - mean_absolute_error: 12.0525\n",
      "Epoch 2382/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 431.2014 - mean_absolute_error: 12.5330\n",
      "Epoch 2383/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.0327 - mean_absolute_error: 12.1869\n",
      "Epoch 2384/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 396.4575 - mean_absolute_error: 11.5704\n",
      "Epoch 2385/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 413.4028 - mean_absolute_error: 12.3294\n",
      "Epoch 2386/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.5659 - mean_absolute_error: 12.0359\n",
      "Epoch 2387/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 410.9124 - mean_absolute_error: 11.8021\n",
      "Epoch 2388/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 431.0192 - mean_absolute_error: 12.3702\n",
      "Epoch 2389/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.3410 - mean_absolute_error: 12.1397\n",
      "Epoch 2390/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 424.9944 - mean_absolute_error: 12.1049\n",
      "Epoch 2391/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.5941 - mean_absolute_error: 12.1893\n",
      "Epoch 2392/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.6262 - mean_absolute_error: 11.5810\n",
      "Epoch 2393/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 417.9016 - mean_absolute_error: 11.8252\n",
      "Epoch 2394/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.7446 - mean_absolute_error: 12.0999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2395/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.5890 - mean_absolute_error: 11.8333\n",
      "Epoch 2396/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.4810 - mean_absolute_error: 11.5322\n",
      "Epoch 2397/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.5455 - mean_absolute_error: 12.1601\n",
      "Epoch 2398/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 404.6846 - mean_absolute_error: 11.6449\n",
      "Epoch 2399/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.2698 - mean_absolute_error: 12.2423\n",
      "Epoch 2400/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.2040 - mean_absolute_error: 12.2891\n",
      "Epoch 2401/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.2098 - mean_absolute_error: 11.8242\n",
      "Epoch 2402/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 408.5308 - mean_absolute_error: 11.9867\n",
      "Epoch 2403/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.8856 - mean_absolute_error: 11.7650\n",
      "Epoch 2404/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 405.7567 - mean_absolute_error: 11.8148\n",
      "Epoch 2405/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.3684 - mean_absolute_error: 11.5868\n",
      "Epoch 2406/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.5146 - mean_absolute_error: 12.0066\n",
      "Epoch 2407/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 435.2539 - mean_absolute_error: 12.2335\n",
      "Epoch 2408/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.3513 - mean_absolute_error: 12.1924\n",
      "Epoch 2409/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 403.4333 - mean_absolute_error: 11.5732\n",
      "Epoch 2410/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.2919 - mean_absolute_error: 11.9810\n",
      "Epoch 2411/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.9311 - mean_absolute_error: 12.2409\n",
      "Epoch 2412/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.9559 - mean_absolute_error: 12.0975\n",
      "Epoch 2413/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 407.1428 - mean_absolute_error: 11.8349\n",
      "Epoch 2414/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 428.5234 - mean_absolute_error: 12.0954\n",
      "Epoch 2415/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 396.2618 - mean_absolute_error: 11.3963\n",
      "Epoch 2416/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.9160 - mean_absolute_error: 11.7103\n",
      "Epoch 2417/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 425.4745 - mean_absolute_error: 12.2604\n",
      "Epoch 2418/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.1809 - mean_absolute_error: 11.8098\n",
      "Epoch 2419/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 396.8493 - mean_absolute_error: 11.3826\n",
      "Epoch 2420/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 442.0501 - mean_absolute_error: 12.6319\n",
      "Epoch 2421/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.7257 - mean_absolute_error: 11.9916\n",
      "Epoch 2422/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.5518 - mean_absolute_error: 12.2356\n",
      "Epoch 2423/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.3100 - mean_absolute_error: 12.0080\n",
      "Epoch 2424/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.2939 - mean_absolute_error: 11.7259\n",
      "Epoch 2425/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.5473 - mean_absolute_error: 11.8737\n",
      "Epoch 2426/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 398.8566 - mean_absolute_error: 11.5605\n",
      "Epoch 2427/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.5823 - mean_absolute_error: 11.9358\n",
      "Epoch 2428/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 403.2487 - mean_absolute_error: 11.5113\n",
      "Epoch 2429/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.6610 - mean_absolute_error: 11.9513\n",
      "Epoch 2430/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.3703 - mean_absolute_error: 11.5881\n",
      "Epoch 2431/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 378.6446 - mean_absolute_error: 11.0529\n",
      "Epoch 2432/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.9387 - mean_absolute_error: 12.2215\n",
      "Epoch 2433/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.9908 - mean_absolute_error: 11.6787\n",
      "Epoch 2434/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 395.9707 - mean_absolute_error: 11.6249\n",
      "Epoch 2435/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 403.4857 - mean_absolute_error: 11.8859\n",
      "Epoch 2436/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 410.7509 - mean_absolute_error: 11.8568\n",
      "Epoch 2437/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.9784 - mean_absolute_error: 11.9141\n",
      "Epoch 2438/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 405.3732 - mean_absolute_error: 11.7840\n",
      "Epoch 2439/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.9607 - mean_absolute_error: 12.2728\n",
      "Epoch 2440/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 400.7967 - mean_absolute_error: 11.6867\n",
      "Epoch 2441/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.8756 - mean_absolute_error: 11.6736\n",
      "Epoch 2442/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 391.3300 - mean_absolute_error: 11.5446\n",
      "Epoch 2443/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 398.0249 - mean_absolute_error: 11.4418\n",
      "Epoch 2444/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 392.9540 - mean_absolute_error: 11.5780\n",
      "Epoch 2445/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 426.8550 - mean_absolute_error: 12.0164\n",
      "Epoch 2446/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.8430 - mean_absolute_error: 11.9996\n",
      "Epoch 2447/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.2057 - mean_absolute_error: 11.8022\n",
      "Epoch 2448/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 418.6580 - mean_absolute_error: 12.0689\n",
      "Epoch 2449/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 399.9069 - mean_absolute_error: 11.5847\n",
      "Epoch 2450/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.8655 - mean_absolute_error: 12.2426\n",
      "Epoch 2451/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 427.5307 - mean_absolute_error: 12.0714\n",
      "Epoch 2452/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.1516 - mean_absolute_error: 11.6312\n",
      "Epoch 2453/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.1454 - mean_absolute_error: 12.0668\n",
      "Epoch 2454/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.2484 - mean_absolute_error: 11.9955\n",
      "Epoch 2455/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 389.8977 - mean_absolute_error: 11.3578\n",
      "Epoch 2456/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 427.3510 - mean_absolute_error: 12.5089\n",
      "Epoch 2457/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.9104 - mean_absolute_error: 11.7467\n",
      "Epoch 2458/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 411.7535 - mean_absolute_error: 11.9869\n",
      "Epoch 2459/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.4551 - mean_absolute_error: 12.0005\n",
      "Epoch 2460/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 403.8899 - mean_absolute_error: 11.5421\n",
      "Epoch 2461/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.0809 - mean_absolute_error: 11.7990\n",
      "Epoch 2462/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.1158 - mean_absolute_error: 11.6388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2463/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.1927 - mean_absolute_error: 11.7369\n",
      "Epoch 2464/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.1444 - mean_absolute_error: 12.0394\n",
      "Epoch 2465/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 407.7560 - mean_absolute_error: 11.6653\n",
      "Epoch 2466/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 438.9664 - mean_absolute_error: 12.5285\n",
      "Epoch 2467/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.4904 - mean_absolute_error: 11.4906\n",
      "Epoch 2468/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.3906 - mean_absolute_error: 11.8931\n",
      "Epoch 2469/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.9270 - mean_absolute_error: 12.1351\n",
      "Epoch 2470/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.4084 - mean_absolute_error: 11.7496\n",
      "Epoch 2471/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.1151 - mean_absolute_error: 12.0226\n",
      "Epoch 2472/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 396.1445 - mean_absolute_error: 11.5716\n",
      "Epoch 2473/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.6026 - mean_absolute_error: 11.8602\n",
      "Epoch 2474/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.7219 - mean_absolute_error: 11.8349\n",
      "Epoch 2475/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 414.2403 - mean_absolute_error: 11.6688\n",
      "Epoch 2476/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.4858 - mean_absolute_error: 11.6231\n",
      "Epoch 2477/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 399.4033 - mean_absolute_error: 11.3952\n",
      "Epoch 2478/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.2350 - mean_absolute_error: 12.2048\n",
      "Epoch 2479/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.7351 - mean_absolute_error: 11.7370\n",
      "Epoch 2480/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.6919 - mean_absolute_error: 11.8342\n",
      "Epoch 2481/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.3856 - mean_absolute_error: 11.7442\n",
      "Epoch 2482/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.5638 - mean_absolute_error: 11.8418\n",
      "Epoch 2483/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.6748 - mean_absolute_error: 12.0475\n",
      "Epoch 2484/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 411.1324 - mean_absolute_error: 11.8251\n",
      "Epoch 2485/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.8293 - mean_absolute_error: 11.6953\n",
      "Epoch 2486/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.7566 - mean_absolute_error: 11.9554\n",
      "Epoch 2487/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.5130 - mean_absolute_error: 12.1584\n",
      "Epoch 2488/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.2406 - mean_absolute_error: 11.9014\n",
      "Epoch 2489/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 397.7950 - mean_absolute_error: 11.6186\n",
      "Epoch 2490/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 412.6099 - mean_absolute_error: 11.5500\n",
      "Epoch 2491/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 436.4896 - mean_absolute_error: 12.2683\n",
      "Epoch 2492/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.6549 - mean_absolute_error: 11.9633\n",
      "Epoch 2493/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 428.8541 - mean_absolute_error: 12.1137\n",
      "Epoch 2494/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 427.4190 - mean_absolute_error: 11.9438\n",
      "Epoch 2495/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 393.2010 - mean_absolute_error: 11.5757\n",
      "Epoch 2496/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 434.8007 - mean_absolute_error: 12.3089\n",
      "Epoch 2497/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.7159 - mean_absolute_error: 11.9958\n",
      "Epoch 2498/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.7779 - mean_absolute_error: 11.8970\n",
      "Epoch 2499/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.9172 - mean_absolute_error: 11.9451\n",
      "Epoch 2500/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 419.3976 - mean_absolute_error: 12.3459\n",
      "Epoch 2501/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.5364 - mean_absolute_error: 11.6907\n",
      "Epoch 2502/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 437.8544 - mean_absolute_error: 12.2589\n",
      "Epoch 2503/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.4857 - mean_absolute_error: 11.8502\n",
      "Epoch 2504/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 430.8712 - mean_absolute_error: 12.1618\n",
      "Epoch 2505/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 432.3433 - mean_absolute_error: 12.0425\n",
      "Epoch 2506/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.9506 - mean_absolute_error: 11.7299\n",
      "Epoch 2507/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 433.9308 - mean_absolute_error: 12.5111\n",
      "Epoch 2508/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 420.5192 - mean_absolute_error: 12.1413\n",
      "Epoch 2509/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.4484 - mean_absolute_error: 11.7955\n",
      "Epoch 2510/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 395.3202 - mean_absolute_error: 11.2329\n",
      "Epoch 2511/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.7743 - mean_absolute_error: 11.9818\n",
      "Epoch 2512/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 419.0362 - mean_absolute_error: 12.3382\n",
      "Epoch 2513/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 396.4171 - mean_absolute_error: 11.4446\n",
      "Epoch 2514/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 423.6144 - mean_absolute_error: 11.9592\n",
      "Epoch 2515/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 406.8065 - mean_absolute_error: 11.6596\n",
      "Epoch 2516/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.6100 - mean_absolute_error: 12.0009\n",
      "Epoch 2517/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.3831 - mean_absolute_error: 11.7664\n",
      "Epoch 2518/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.4249 - mean_absolute_error: 11.6573\n",
      "Epoch 2519/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 389.3159 - mean_absolute_error: 11.4272\n",
      "Epoch 2520/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 397.4080 - mean_absolute_error: 11.5325\n",
      "Epoch 2521/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 432.0452 - mean_absolute_error: 11.9929\n",
      "Epoch 2522/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.5800 - mean_absolute_error: 12.1385\n",
      "Epoch 2523/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.3196 - mean_absolute_error: 11.7795\n",
      "Epoch 2524/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 433.1050 - mean_absolute_error: 12.1818\n",
      "Epoch 2525/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 436.4765 - mean_absolute_error: 12.4787\n",
      "Epoch 2526/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 416.0207 - mean_absolute_error: 11.9883\n",
      "Epoch 2527/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.7417 - mean_absolute_error: 11.7923\n",
      "Epoch 2528/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.7081 - mean_absolute_error: 11.7606\n",
      "Epoch 2529/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 393.0359 - mean_absolute_error: 11.4485\n",
      "Epoch 2530/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 407.2477 - mean_absolute_error: 11.5373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2531/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 401.2948 - mean_absolute_error: 11.6671\n",
      "Epoch 2532/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 432.4515 - mean_absolute_error: 12.2856\n",
      "Epoch 2533/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 408.5565 - mean_absolute_error: 12.0736\n",
      "Epoch 2534/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 410.9394 - mean_absolute_error: 11.8107\n",
      "Epoch 2535/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 407.1556 - mean_absolute_error: 11.7391\n",
      "Epoch 2536/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.5822 - mean_absolute_error: 11.9605\n",
      "Epoch 2537/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.8816 - mean_absolute_error: 11.6189\n",
      "Epoch 2538/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.8843 - mean_absolute_error: 11.9398\n",
      "Epoch 2539/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 438.7271 - mean_absolute_error: 12.2891\n",
      "Epoch 2540/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 422.0282 - mean_absolute_error: 11.7129\n",
      "Epoch 2541/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.5317 - mean_absolute_error: 11.6240\n",
      "Epoch 2542/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.2482 - mean_absolute_error: 11.6000\n",
      "Epoch 2543/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.1444 - mean_absolute_error: 12.1222\n",
      "Epoch 2544/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.4161 - mean_absolute_error: 11.6579\n",
      "Epoch 2545/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.0118 - mean_absolute_error: 12.0893\n",
      "Epoch 2546/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.5699 - mean_absolute_error: 12.0945\n",
      "Epoch 2547/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.3150 - mean_absolute_error: 12.1700\n",
      "Epoch 2548/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.2575 - mean_absolute_error: 11.7770\n",
      "Epoch 2549/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.0914 - mean_absolute_error: 11.9379\n",
      "Epoch 2550/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.6596 - mean_absolute_error: 12.0359\n",
      "Epoch 2551/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 392.5962 - mean_absolute_error: 11.3862\n",
      "Epoch 2552/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 394.9214 - mean_absolute_error: 11.4608\n",
      "Epoch 2553/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.9763 - mean_absolute_error: 11.6393\n",
      "Epoch 2554/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.0846 - mean_absolute_error: 12.1191\n",
      "Epoch 2555/5000\n",
      "344/344 [==============================] - 0s 254us/step - loss: 412.5415 - mean_absolute_error: 11.7936\n",
      "Epoch 2556/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.1322 - mean_absolute_error: 11.7850\n",
      "Epoch 2557/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 379.4780 - mean_absolute_error: 11.2441\n",
      "Epoch 2558/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 472.0308 - mean_absolute_error: 12.6777\n",
      "Epoch 2559/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 396.6922 - mean_absolute_error: 11.6416\n",
      "Epoch 2560/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.4867 - mean_absolute_error: 12.1234\n",
      "Epoch 2561/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.6427 - mean_absolute_error: 11.6931\n",
      "Epoch 2562/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.8292 - mean_absolute_error: 11.6540\n",
      "Epoch 2563/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 392.6577 - mean_absolute_error: 11.5400\n",
      "Epoch 2564/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.3169 - mean_absolute_error: 11.9660\n",
      "Epoch 2565/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 420.7569 - mean_absolute_error: 12.0436\n",
      "Epoch 2566/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 502.8643 - mean_absolute_error: 12.3792\n",
      "Epoch 2567/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.7433 - mean_absolute_error: 12.0755\n",
      "Epoch 2568/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.3836 - mean_absolute_error: 11.8910\n",
      "Epoch 2569/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 514.7194 - mean_absolute_error: 12.4378\n",
      "Epoch 2570/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.9211 - mean_absolute_error: 12.0370\n",
      "Epoch 2571/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.0126 - mean_absolute_error: 12.0081\n",
      "Epoch 2572/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 408.5366 - mean_absolute_error: 11.8724\n",
      "Epoch 2573/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.0049 - mean_absolute_error: 11.7817\n",
      "Epoch 2574/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.3763 - mean_absolute_error: 11.9997\n",
      "Epoch 2575/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 403.5164 - mean_absolute_error: 11.6156\n",
      "Epoch 2576/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 397.6242 - mean_absolute_error: 11.4345\n",
      "Epoch 2577/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.1483 - mean_absolute_error: 11.9688\n",
      "Epoch 2578/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.7441 - mean_absolute_error: 11.5657\n",
      "Epoch 2579/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.6862 - mean_absolute_error: 11.5457\n",
      "Epoch 2580/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 392.7969 - mean_absolute_error: 11.3758\n",
      "Epoch 2581/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.7859 - mean_absolute_error: 12.0941\n",
      "Epoch 2582/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.6921 - mean_absolute_error: 11.6912\n",
      "Epoch 2583/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 405.0980 - mean_absolute_error: 11.5242\n",
      "Epoch 2584/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 460.2092 - mean_absolute_error: 12.7541\n",
      "Epoch 2585/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.3982 - mean_absolute_error: 11.8719\n",
      "Epoch 2586/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.9207 - mean_absolute_error: 12.0351\n",
      "Epoch 2587/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.5294 - mean_absolute_error: 11.5666\n",
      "Epoch 2588/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.7132 - mean_absolute_error: 11.9143\n",
      "Epoch 2589/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 432.1440 - mean_absolute_error: 12.0622\n",
      "Epoch 2590/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 401.6588 - mean_absolute_error: 11.4633\n",
      "Epoch 2591/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 398.8215 - mean_absolute_error: 11.4636\n",
      "Epoch 2592/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.4235 - mean_absolute_error: 11.9803\n",
      "Epoch 2593/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 408.3856 - mean_absolute_error: 11.7770\n",
      "Epoch 2594/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 419.1306 - mean_absolute_error: 12.0480\n",
      "Epoch 2595/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.3394 - mean_absolute_error: 11.8008\n",
      "Epoch 2596/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.6375 - mean_absolute_error: 12.1990\n",
      "Epoch 2597/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 423.3773 - mean_absolute_error: 12.0092\n",
      "Epoch 2598/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 400.3533 - mean_absolute_error: 11.7730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2599/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 432.3763 - mean_absolute_error: 12.3438\n",
      "Epoch 2600/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 432.6939 - mean_absolute_error: 12.2509\n",
      "Epoch 2601/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 411.9276 - mean_absolute_error: 12.2600\n",
      "Epoch 2602/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 572.6448 - mean_absolute_error: 12.5488\n",
      "Epoch 2603/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 424.3998 - mean_absolute_error: 11.9805\n",
      "Epoch 2604/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.3300 - mean_absolute_error: 12.3472\n",
      "Epoch 2605/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.8927 - mean_absolute_error: 12.0225\n",
      "Epoch 2606/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 396.0479 - mean_absolute_error: 11.2919\n",
      "Epoch 2607/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.5992 - mean_absolute_error: 11.9844\n",
      "Epoch 2608/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.7641 - mean_absolute_error: 11.9009\n",
      "Epoch 2609/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 389.0824 - mean_absolute_error: 11.3854\n",
      "Epoch 2610/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 395.4352 - mean_absolute_error: 11.7689\n",
      "Epoch 2611/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.7051 - mean_absolute_error: 11.9376\n",
      "Epoch 2612/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.9724 - mean_absolute_error: 12.0672\n",
      "Epoch 2613/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.5930 - mean_absolute_error: 11.4673\n",
      "Epoch 2614/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 403.4707 - mean_absolute_error: 11.6761\n",
      "Epoch 2615/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 431.1732 - mean_absolute_error: 12.1273\n",
      "Epoch 2616/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.2328 - mean_absolute_error: 11.8889\n",
      "Epoch 2617/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.0505 - mean_absolute_error: 11.8473\n",
      "Epoch 2618/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.5451 - mean_absolute_error: 11.7340\n",
      "Epoch 2619/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.0227 - mean_absolute_error: 12.0875\n",
      "Epoch 2620/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 404.6315 - mean_absolute_error: 11.7808\n",
      "Epoch 2621/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.0883 - mean_absolute_error: 11.9813\n",
      "Epoch 2622/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 422.2602 - mean_absolute_error: 11.8356\n",
      "Epoch 2623/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 409.5106 - mean_absolute_error: 11.7996\n",
      "Epoch 2624/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 412.6890 - mean_absolute_error: 11.9567\n",
      "Epoch 2625/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.5648 - mean_absolute_error: 11.7134\n",
      "Epoch 2626/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 421.6880 - mean_absolute_error: 12.0460\n",
      "Epoch 2627/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 441.4816 - mean_absolute_error: 12.3668\n",
      "Epoch 2628/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.1816 - mean_absolute_error: 11.3500\n",
      "Epoch 2629/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 448.4877 - mean_absolute_error: 11.6038\n",
      "Epoch 2630/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.6295 - mean_absolute_error: 11.6416\n",
      "Epoch 2631/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 406.1294 - mean_absolute_error: 11.6984\n",
      "Epoch 2632/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 399.2188 - mean_absolute_error: 11.6556\n",
      "Epoch 2633/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 430.6842 - mean_absolute_error: 12.3520\n",
      "Epoch 2634/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 389.9190 - mean_absolute_error: 11.0536\n",
      "Epoch 2635/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.1254 - mean_absolute_error: 11.9004\n",
      "Epoch 2636/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 399.6792 - mean_absolute_error: 11.6083\n",
      "Epoch 2637/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 409.5213 - mean_absolute_error: 11.5984\n",
      "Epoch 2638/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 426.3792 - mean_absolute_error: 11.7530\n",
      "Epoch 2639/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 419.6668 - mean_absolute_error: 11.7245\n",
      "Epoch 2640/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.0749 - mean_absolute_error: 12.0428\n",
      "Epoch 2641/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 418.9570 - mean_absolute_error: 11.6135\n",
      "Epoch 2642/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 413.5686 - mean_absolute_error: 11.8005\n",
      "Epoch 2643/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.5852 - mean_absolute_error: 11.6306\n",
      "Epoch 2644/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.7368 - mean_absolute_error: 12.2256\n",
      "Epoch 2645/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 399.5022 - mean_absolute_error: 11.8543\n",
      "Epoch 2646/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.5754 - mean_absolute_error: 12.0682\n",
      "Epoch 2647/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.4955 - mean_absolute_error: 12.0629\n",
      "Epoch 2648/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 416.7253 - mean_absolute_error: 11.6072\n",
      "Epoch 2649/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 417.2939 - mean_absolute_error: 12.1134\n",
      "Epoch 2650/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.3114 - mean_absolute_error: 12.2848\n",
      "Epoch 2651/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.8042 - mean_absolute_error: 12.2123\n",
      "Epoch 2652/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.5202 - mean_absolute_error: 11.7074\n",
      "Epoch 2653/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.4204 - mean_absolute_error: 12.1014\n",
      "Epoch 2654/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 407.0589 - mean_absolute_error: 11.7261\n",
      "Epoch 2655/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.2398 - mean_absolute_error: 11.8093\n",
      "Epoch 2656/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 391.0461 - mean_absolute_error: 11.5222\n",
      "Epoch 2657/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 420.6458 - mean_absolute_error: 12.1205\n",
      "Epoch 2658/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 436.8421 - mean_absolute_error: 12.4217\n",
      "Epoch 2659/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 446.2385 - mean_absolute_error: 12.4483\n",
      "Epoch 2660/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.5865 - mean_absolute_error: 12.0478\n",
      "Epoch 2661/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.5621 - mean_absolute_error: 11.9266\n",
      "Epoch 2662/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.3101 - mean_absolute_error: 11.5736\n",
      "Epoch 2663/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.9304 - mean_absolute_error: 11.6818\n",
      "Epoch 2664/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.3985 - mean_absolute_error: 11.7051\n",
      "Epoch 2665/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 404.5125 - mean_absolute_error: 11.5646\n",
      "Epoch 2666/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 437.4803 - mean_absolute_error: 12.2437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2667/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.5213 - mean_absolute_error: 12.0788\n",
      "Epoch 2668/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.1401 - mean_absolute_error: 11.7162\n",
      "Epoch 2669/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 424.8051 - mean_absolute_error: 12.1370\n",
      "Epoch 2670/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 406.2231 - mean_absolute_error: 11.7096\n",
      "Epoch 2671/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 425.1284 - mean_absolute_error: 11.9605\n",
      "Epoch 2672/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 439.6522 - mean_absolute_error: 12.4812\n",
      "Epoch 2673/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.9956 - mean_absolute_error: 11.7583\n",
      "Epoch 2674/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 418.8721 - mean_absolute_error: 11.8452\n",
      "Epoch 2675/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.2635 - mean_absolute_error: 12.0481\n",
      "Epoch 2676/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.4534 - mean_absolute_error: 11.5348\n",
      "Epoch 2677/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.8164 - mean_absolute_error: 11.9267\n",
      "Epoch 2678/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 425.8927 - mean_absolute_error: 12.2851\n",
      "Epoch 2679/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 429.5704 - mean_absolute_error: 12.1827\n",
      "Epoch 2680/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.2109 - mean_absolute_error: 11.9307\n",
      "Epoch 2681/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 427.6683 - mean_absolute_error: 12.2475\n",
      "Epoch 2682/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.5191 - mean_absolute_error: 12.2845\n",
      "Epoch 2683/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.3839 - mean_absolute_error: 11.7301\n",
      "Epoch 2684/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.7362 - mean_absolute_error: 11.7867\n",
      "Epoch 2685/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 398.1716 - mean_absolute_error: 11.4321\n",
      "Epoch 2686/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 398.0142 - mean_absolute_error: 11.2344\n",
      "Epoch 2687/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.8193 - mean_absolute_error: 12.0060\n",
      "Epoch 2688/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.5224 - mean_absolute_error: 12.1337\n",
      "Epoch 2689/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.3581 - mean_absolute_error: 12.1286\n",
      "Epoch 2690/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.4337 - mean_absolute_error: 11.8757\n",
      "Epoch 2691/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.8088 - mean_absolute_error: 11.9655\n",
      "Epoch 2692/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.9984 - mean_absolute_error: 12.1406\n",
      "Epoch 2693/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.4446 - mean_absolute_error: 12.0576\n",
      "Epoch 2694/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.1878 - mean_absolute_error: 11.6076\n",
      "Epoch 2695/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.6284 - mean_absolute_error: 12.0441\n",
      "Epoch 2696/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.2777 - mean_absolute_error: 11.7203\n",
      "Epoch 2697/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 424.6282 - mean_absolute_error: 12.3165\n",
      "Epoch 2698/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 387.2528 - mean_absolute_error: 11.2700\n",
      "Epoch 2699/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 383.8146 - mean_absolute_error: 11.2706\n",
      "Epoch 2700/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.1414 - mean_absolute_error: 12.0552\n",
      "Epoch 2701/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 410.2199 - mean_absolute_error: 11.9364\n",
      "Epoch 2702/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 400.0561 - mean_absolute_error: 11.3567\n",
      "Epoch 2703/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 434.4019 - mean_absolute_error: 12.5312\n",
      "Epoch 2704/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 421.5786 - mean_absolute_error: 12.4578\n",
      "Epoch 2705/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 410.3183 - mean_absolute_error: 11.7702\n",
      "Epoch 2706/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.9900 - mean_absolute_error: 11.8406\n",
      "Epoch 2707/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.5630 - mean_absolute_error: 11.9952\n",
      "Epoch 2708/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 428.6833 - mean_absolute_error: 12.3045\n",
      "Epoch 2709/5000\n",
      "344/344 [==============================] - 0s 287us/step - loss: 403.1159 - mean_absolute_error: 11.5155\n",
      "Epoch 2710/5000\n",
      "344/344 [==============================] - 0s 281us/step - loss: 426.0132 - mean_absolute_error: 12.2830\n",
      "Epoch 2711/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 400.2119 - mean_absolute_error: 11.5808\n",
      "Epoch 2712/5000\n",
      "344/344 [==============================] - 0s 287us/step - loss: 421.6362 - mean_absolute_error: 12.0285\n",
      "Epoch 2713/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 417.2625 - mean_absolute_error: 11.7138\n",
      "Epoch 2714/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 401.7464 - mean_absolute_error: 11.6815\n",
      "Epoch 2715/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 423.3105 - mean_absolute_error: 11.9275\n",
      "Epoch 2716/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 412.2740 - mean_absolute_error: 12.2273\n",
      "Epoch 2717/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 427.2731 - mean_absolute_error: 12.3315\n",
      "Epoch 2718/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 398.0728 - mean_absolute_error: 11.3413\n",
      "Epoch 2719/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 428.4305 - mean_absolute_error: 12.0874\n",
      "Epoch 2720/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 412.3929 - mean_absolute_error: 11.7024\n",
      "Epoch 2721/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 425.7659 - mean_absolute_error: 11.9922\n",
      "Epoch 2722/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 418.1676 - mean_absolute_error: 11.8103\n",
      "Epoch 2723/5000\n",
      "344/344 [==============================] - 0s 262us/step - loss: 402.7385 - mean_absolute_error: 11.5962\n",
      "Epoch 2724/5000\n",
      "344/344 [==============================] - 0s 286us/step - loss: 394.2685 - mean_absolute_error: 11.4893\n",
      "Epoch 2725/5000\n",
      "344/344 [==============================] - 0s 284us/step - loss: 397.9530 - mean_absolute_error: 11.3145\n",
      "Epoch 2726/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 414.2248 - mean_absolute_error: 12.0352\n",
      "Epoch 2727/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 420.2209 - mean_absolute_error: 11.9710\n",
      "Epoch 2728/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 409.6773 - mean_absolute_error: 11.8810\n",
      "Epoch 2729/5000\n",
      "344/344 [==============================] - 0s 274us/step - loss: 443.3599 - mean_absolute_error: 12.2489\n",
      "Epoch 2730/5000\n",
      "344/344 [==============================] - 0s 287us/step - loss: 435.1216 - mean_absolute_error: 12.0724\n",
      "Epoch 2731/5000\n",
      "344/344 [==============================] - 0s 323us/step - loss: 429.7695 - mean_absolute_error: 12.2702\n",
      "Epoch 2732/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 423.1504 - mean_absolute_error: 11.8170\n",
      "Epoch 2733/5000\n",
      "344/344 [==============================] - 0s 294us/step - loss: 408.8352 - mean_absolute_error: 11.8466\n",
      "Epoch 2734/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 484.8631 - mean_absolute_error: 12.5822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2735/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 438.7556 - mean_absolute_error: 11.9281\n",
      "Epoch 2736/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 414.7952 - mean_absolute_error: 11.7554\n",
      "Epoch 2737/5000\n",
      "344/344 [==============================] - 0s 293us/step - loss: 411.3915 - mean_absolute_error: 11.6926\n",
      "Epoch 2738/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 424.3683 - mean_absolute_error: 11.9325\n",
      "Epoch 2739/5000\n",
      "344/344 [==============================] - 0s 257us/step - loss: 404.5515 - mean_absolute_error: 11.8240\n",
      "Epoch 2740/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 446.3940 - mean_absolute_error: 12.3582\n",
      "Epoch 2741/5000\n",
      "344/344 [==============================] - 0s 217us/step - loss: 421.8780 - mean_absolute_error: 12.1187\n",
      "Epoch 2742/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 398.6372 - mean_absolute_error: 11.4556\n",
      "Epoch 2743/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.4042 - mean_absolute_error: 11.5104\n",
      "Epoch 2744/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 401.2791 - mean_absolute_error: 11.3682\n",
      "Epoch 2745/5000\n",
      "344/344 [==============================] - 0s 302us/step - loss: 417.8232 - mean_absolute_error: 12.0883\n",
      "Epoch 2746/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 419.3849 - mean_absolute_error: 12.0880\n",
      "Epoch 2747/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 420.9432 - mean_absolute_error: 11.8436\n",
      "Epoch 2748/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 409.4130 - mean_absolute_error: 11.4899\n",
      "Epoch 2749/5000\n",
      "344/344 [==============================] - 0s 250us/step - loss: 411.6797 - mean_absolute_error: 11.8898\n",
      "Epoch 2750/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 412.1378 - mean_absolute_error: 12.0712\n",
      "Epoch 2751/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 419.8269 - mean_absolute_error: 11.9202\n",
      "Epoch 2752/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 395.6510 - mean_absolute_error: 11.2867\n",
      "Epoch 2753/5000\n",
      "344/344 [==============================] - 0s 287us/step - loss: 424.0695 - mean_absolute_error: 12.2691\n",
      "Epoch 2754/5000\n",
      "344/344 [==============================] - 0s 262us/step - loss: 441.3594 - mean_absolute_error: 12.4915\n",
      "Epoch 2755/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 430.1049 - mean_absolute_error: 12.3179\n",
      "Epoch 2756/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 410.8082 - mean_absolute_error: 11.7009\n",
      "Epoch 2757/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 410.2208 - mean_absolute_error: 12.0655\n",
      "Epoch 2758/5000\n",
      "344/344 [==============================] - 0s 284us/step - loss: 424.2356 - mean_absolute_error: 11.7871\n",
      "Epoch 2759/5000\n",
      "344/344 [==============================] - 0s 284us/step - loss: 426.4550 - mean_absolute_error: 12.0250\n",
      "Epoch 2760/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 422.3417 - mean_absolute_error: 12.3901\n",
      "Epoch 2761/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.6331 - mean_absolute_error: 11.8116\n",
      "Epoch 2762/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.6996 - mean_absolute_error: 12.0204\n",
      "Epoch 2763/5000\n",
      "344/344 [==============================] - 0s 217us/step - loss: 414.9191 - mean_absolute_error: 11.8869\n",
      "Epoch 2764/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.0243 - mean_absolute_error: 12.1390\n",
      "Epoch 2765/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 400.8939 - mean_absolute_error: 11.7900\n",
      "Epoch 2766/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 434.6595 - mean_absolute_error: 12.2066\n",
      "Epoch 2767/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 401.2929 - mean_absolute_error: 11.8123\n",
      "Epoch 2768/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 426.0741 - mean_absolute_error: 12.3340\n",
      "Epoch 2769/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 407.3759 - mean_absolute_error: 11.6997\n",
      "Epoch 2770/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 418.3041 - mean_absolute_error: 11.9561\n",
      "Epoch 2771/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 432.8874 - mean_absolute_error: 12.3037\n",
      "Epoch 2772/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 411.7840 - mean_absolute_error: 11.9796\n",
      "Epoch 2773/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 418.8706 - mean_absolute_error: 12.0573\n",
      "Epoch 2774/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.3796 - mean_absolute_error: 11.5994\n",
      "Epoch 2775/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 407.8918 - mean_absolute_error: 11.4375\n",
      "Epoch 2776/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 407.9827 - mean_absolute_error: 11.6046\n",
      "Epoch 2777/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 424.9037 - mean_absolute_error: 12.0410\n",
      "Epoch 2778/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 406.0269 - mean_absolute_error: 11.6629\n",
      "Epoch 2779/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 410.6306 - mean_absolute_error: 11.9179\n",
      "Epoch 2780/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 410.2042 - mean_absolute_error: 11.6420\n",
      "Epoch 2781/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.6947 - mean_absolute_error: 12.1236\n",
      "Epoch 2782/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 409.4427 - mean_absolute_error: 11.6846\n",
      "Epoch 2783/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 397.9710 - mean_absolute_error: 11.7380\n",
      "Epoch 2784/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 406.2560 - mean_absolute_error: 11.8730\n",
      "Epoch 2785/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 423.7844 - mean_absolute_error: 12.2753\n",
      "Epoch 2786/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 387.7406 - mean_absolute_error: 11.6106\n",
      "Epoch 2787/5000\n",
      "344/344 [==============================] - 0s 298us/step - loss: 406.0951 - mean_absolute_error: 11.9325\n",
      "Epoch 2788/5000\n",
      "344/344 [==============================] - 0s 262us/step - loss: 413.4277 - mean_absolute_error: 11.8824\n",
      "Epoch 2789/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 413.6737 - mean_absolute_error: 11.8233\n",
      "Epoch 2790/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 420.3278 - mean_absolute_error: 12.1242\n",
      "Epoch 2791/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.6917 - mean_absolute_error: 11.9671\n",
      "Epoch 2792/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 400.4353 - mean_absolute_error: 11.7899\n",
      "Epoch 2793/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.2253 - mean_absolute_error: 11.8527\n",
      "Epoch 2794/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.1515 - mean_absolute_error: 11.9058\n",
      "Epoch 2795/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.9229 - mean_absolute_error: 12.1072\n",
      "Epoch 2796/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 394.3049 - mean_absolute_error: 11.3999\n",
      "Epoch 2797/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 425.6484 - mean_absolute_error: 11.8198\n",
      "Epoch 2798/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.5966 - mean_absolute_error: 11.8540\n",
      "Epoch 2799/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 459.1499 - mean_absolute_error: 12.4021\n",
      "Epoch 2800/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 430.3969 - mean_absolute_error: 12.0635\n",
      "Epoch 2801/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 484.4891 - mean_absolute_error: 12.2067\n",
      "Epoch 2802/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.8803 - mean_absolute_error: 11.8368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2803/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 406.4667 - mean_absolute_error: 11.6440\n",
      "Epoch 2804/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.9792 - mean_absolute_error: 11.4854\n",
      "Epoch 2805/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 409.2686 - mean_absolute_error: 11.8747\n",
      "Epoch 2806/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 417.7125 - mean_absolute_error: 12.0577\n",
      "Epoch 2807/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 422.4525 - mean_absolute_error: 11.9902\n",
      "Epoch 2808/5000\n",
      "344/344 [==============================] - 0s 272us/step - loss: 418.8445 - mean_absolute_error: 11.7713\n",
      "Epoch 2809/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 422.5867 - mean_absolute_error: 11.9873\n",
      "Epoch 2810/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 422.1659 - mean_absolute_error: 12.0388\n",
      "Epoch 2811/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.4236 - mean_absolute_error: 11.9008\n",
      "Epoch 2812/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 401.7674 - mean_absolute_error: 12.0653\n",
      "Epoch 2813/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 406.3686 - mean_absolute_error: 11.3106\n",
      "Epoch 2814/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 392.3317 - mean_absolute_error: 11.4138\n",
      "Epoch 2815/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 401.9624 - mean_absolute_error: 11.5380\n",
      "Epoch 2816/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 419.4430 - mean_absolute_error: 12.1624\n",
      "Epoch 2817/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 403.0866 - mean_absolute_error: 11.6995\n",
      "Epoch 2818/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 401.2266 - mean_absolute_error: 11.7236\n",
      "Epoch 2819/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 423.0680 - mean_absolute_error: 12.1908\n",
      "Epoch 2820/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 416.5901 - mean_absolute_error: 12.2763\n",
      "Epoch 2821/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 410.5023 - mean_absolute_error: 11.7052\n",
      "Epoch 2822/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 407.8217 - mean_absolute_error: 11.7867\n",
      "Epoch 2823/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 441.5785 - mean_absolute_error: 12.4350\n",
      "Epoch 2824/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 415.7219 - mean_absolute_error: 11.6891\n",
      "Epoch 2825/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 429.8113 - mean_absolute_error: 12.3959\n",
      "Epoch 2826/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 399.0458 - mean_absolute_error: 11.4250\n",
      "Epoch 2827/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.3582 - mean_absolute_error: 11.7293\n",
      "Epoch 2828/5000\n",
      "344/344 [==============================] - 0s 272us/step - loss: 416.9260 - mean_absolute_error: 11.8193\n",
      "Epoch 2829/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.8773 - mean_absolute_error: 11.6546\n",
      "Epoch 2830/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 410.9500 - mean_absolute_error: 11.8404\n",
      "Epoch 2831/5000\n",
      "344/344 [==============================] - 0s 259us/step - loss: 416.1390 - mean_absolute_error: 12.1542\n",
      "Epoch 2832/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 417.6931 - mean_absolute_error: 11.9178\n",
      "Epoch 2833/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 402.5015 - mean_absolute_error: 11.6793\n",
      "Epoch 2834/5000\n",
      "344/344 [==============================] - 0s 263us/step - loss: 402.0908 - mean_absolute_error: 11.8887\n",
      "Epoch 2835/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 408.0210 - mean_absolute_error: 12.0057\n",
      "Epoch 2836/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 426.3845 - mean_absolute_error: 12.0353\n",
      "Epoch 2837/5000\n",
      "344/344 [==============================] - 0s 274us/step - loss: 411.1178 - mean_absolute_error: 11.6110\n",
      "Epoch 2838/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 392.3564 - mean_absolute_error: 11.5355\n",
      "Epoch 2839/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 420.2606 - mean_absolute_error: 12.1171\n",
      "Epoch 2840/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 412.6464 - mean_absolute_error: 11.6823\n",
      "Epoch 2841/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 399.8250 - mean_absolute_error: 11.6895\n",
      "Epoch 2842/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 413.8207 - mean_absolute_error: 12.0011\n",
      "Epoch 2843/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 414.3929 - mean_absolute_error: 11.9051\n",
      "Epoch 2844/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.0830 - mean_absolute_error: 12.0590\n",
      "Epoch 2845/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 417.8708 - mean_absolute_error: 12.1368\n",
      "Epoch 2846/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 416.7054 - mean_absolute_error: 12.1241\n",
      "Epoch 2847/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 403.9125 - mean_absolute_error: 11.6120\n",
      "Epoch 2848/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 412.0494 - mean_absolute_error: 11.7177\n",
      "Epoch 2849/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 416.9774 - mean_absolute_error: 11.7319\n",
      "Epoch 2850/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 428.3404 - mean_absolute_error: 12.3574\n",
      "Epoch 2851/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 409.5816 - mean_absolute_error: 11.6137\n",
      "Epoch 2852/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 416.2038 - mean_absolute_error: 11.9743\n",
      "Epoch 2853/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.6246 - mean_absolute_error: 11.8973\n",
      "Epoch 2854/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 469.8189 - mean_absolute_error: 12.8947\n",
      "Epoch 2855/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.5326 - mean_absolute_error: 12.3870\n",
      "Epoch 2856/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 408.6187 - mean_absolute_error: 11.7796\n",
      "Epoch 2857/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 438.5990 - mean_absolute_error: 12.3619\n",
      "Epoch 2858/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 425.9906 - mean_absolute_error: 11.8757\n",
      "Epoch 2859/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.4174 - mean_absolute_error: 11.7561\n",
      "Epoch 2860/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.7388 - mean_absolute_error: 12.2413\n",
      "Epoch 2861/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 387.8482 - mean_absolute_error: 11.4160\n",
      "Epoch 2862/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 428.0062 - mean_absolute_error: 12.2595\n",
      "Epoch 2863/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 405.9858 - mean_absolute_error: 11.7631\n",
      "Epoch 2864/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 427.7482 - mean_absolute_error: 12.1957\n",
      "Epoch 2865/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 433.5684 - mean_absolute_error: 11.6932\n",
      "Epoch 2866/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 396.9092 - mean_absolute_error: 11.5897\n",
      "Epoch 2867/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 432.1555 - mean_absolute_error: 12.4218\n",
      "Epoch 2868/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 427.4478 - mean_absolute_error: 12.2058\n",
      "Epoch 2869/5000\n",
      "344/344 [==============================] - 0s 271us/step - loss: 398.3984 - mean_absolute_error: 11.3590\n",
      "Epoch 2870/5000\n",
      "344/344 [==============================] - 0s 268us/step - loss: 418.5976 - mean_absolute_error: 11.8883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2871/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 415.2327 - mean_absolute_error: 11.7369\n",
      "Epoch 2872/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 415.3670 - mean_absolute_error: 12.0754\n",
      "Epoch 2873/5000\n",
      "344/344 [==============================] - 0s 380us/step - loss: 419.0692 - mean_absolute_error: 11.8401\n",
      "Epoch 2874/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 395.9311 - mean_absolute_error: 11.7543\n",
      "Epoch 2875/5000\n",
      "344/344 [==============================] - 0s 257us/step - loss: 401.8457 - mean_absolute_error: 11.7505\n",
      "Epoch 2876/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 399.5994 - mean_absolute_error: 11.6196\n",
      "Epoch 2877/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.5203 - mean_absolute_error: 11.9359\n",
      "Epoch 2878/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 417.5591 - mean_absolute_error: 12.0230\n",
      "Epoch 2879/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.9340 - mean_absolute_error: 11.8248\n",
      "Epoch 2880/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 404.7854 - mean_absolute_error: 11.8176\n",
      "Epoch 2881/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.0774 - mean_absolute_error: 12.0657\n",
      "Epoch 2882/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.2429 - mean_absolute_error: 11.9839\n",
      "Epoch 2883/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.6452 - mean_absolute_error: 11.8970\n",
      "Epoch 2884/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 402.3397 - mean_absolute_error: 11.7146\n",
      "Epoch 2885/5000\n",
      "344/344 [==============================] - 0s 281us/step - loss: 402.0164 - mean_absolute_error: 11.4987\n",
      "Epoch 2886/5000\n",
      "344/344 [==============================] - 0s 287us/step - loss: 421.2357 - mean_absolute_error: 12.1150\n",
      "Epoch 2887/5000\n",
      "344/344 [==============================] - 0s 265us/step - loss: 402.7415 - mean_absolute_error: 11.6426\n",
      "Epoch 2888/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 423.5879 - mean_absolute_error: 11.9999\n",
      "Epoch 2889/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 416.5550 - mean_absolute_error: 11.9681\n",
      "Epoch 2890/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 433.6385 - mean_absolute_error: 12.3412\n",
      "Epoch 2891/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 405.8277 - mean_absolute_error: 11.7065\n",
      "Epoch 2892/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.1484 - mean_absolute_error: 11.8321\n",
      "Epoch 2893/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.6120 - mean_absolute_error: 12.1231\n",
      "Epoch 2894/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 422.6310 - mean_absolute_error: 12.1582\n",
      "Epoch 2895/5000\n",
      "344/344 [==============================] - 0s 253us/step - loss: 408.1400 - mean_absolute_error: 11.9837\n",
      "Epoch 2896/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 429.4329 - mean_absolute_error: 12.0550\n",
      "Epoch 2897/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.5336 - mean_absolute_error: 11.6145\n",
      "Epoch 2898/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 407.9379 - mean_absolute_error: 11.7595\n",
      "Epoch 2899/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.3787 - mean_absolute_error: 11.9210\n",
      "Epoch 2900/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.3022 - mean_absolute_error: 11.9886\n",
      "Epoch 2901/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 396.8368 - mean_absolute_error: 11.5190\n",
      "Epoch 2902/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 404.1696 - mean_absolute_error: 11.9980\n",
      "Epoch 2903/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.4571 - mean_absolute_error: 11.6494\n",
      "Epoch 2904/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 403.6169 - mean_absolute_error: 11.4774\n",
      "Epoch 2905/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.2039 - mean_absolute_error: 11.5818\n",
      "Epoch 2906/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 403.7667 - mean_absolute_error: 11.6810\n",
      "Epoch 2907/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 487.7132 - mean_absolute_error: 11.8539\n",
      "Epoch 2908/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.8895 - mean_absolute_error: 12.0283\n",
      "Epoch 2909/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 447.0414 - mean_absolute_error: 12.4026\n",
      "Epoch 2910/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 404.3509 - mean_absolute_error: 11.9120\n",
      "Epoch 2911/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 405.6165 - mean_absolute_error: 11.8333\n",
      "Epoch 2912/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 416.0097 - mean_absolute_error: 11.9489\n",
      "Epoch 2913/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 409.2403 - mean_absolute_error: 11.6519\n",
      "Epoch 2914/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 431.2997 - mean_absolute_error: 12.3894\n",
      "Epoch 2915/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.1117 - mean_absolute_error: 11.7078\n",
      "Epoch 2916/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 407.8073 - mean_absolute_error: 11.9371\n",
      "Epoch 2917/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 426.8751 - mean_absolute_error: 12.2843\n",
      "Epoch 2918/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.3350 - mean_absolute_error: 11.6661\n",
      "Epoch 2919/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 417.3303 - mean_absolute_error: 11.7513\n",
      "Epoch 2920/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 397.2897 - mean_absolute_error: 11.4480\n",
      "Epoch 2921/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 401.4865 - mean_absolute_error: 11.5889\n",
      "Epoch 2922/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 419.1513 - mean_absolute_error: 12.0052\n",
      "Epoch 2923/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.3435 - mean_absolute_error: 12.0914\n",
      "Epoch 2924/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 416.5838 - mean_absolute_error: 12.0330\n",
      "Epoch 2925/5000\n",
      "344/344 [==============================] - 0s 290us/step - loss: 424.9323 - mean_absolute_error: 12.3499\n",
      "Epoch 2926/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.5715 - mean_absolute_error: 12.0182\n",
      "Epoch 2927/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 415.3309 - mean_absolute_error: 11.8986\n",
      "Epoch 2928/5000\n",
      "344/344 [==============================] - 0s 281us/step - loss: 413.2612 - mean_absolute_error: 11.8600\n",
      "Epoch 2929/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 413.2737 - mean_absolute_error: 11.7846\n",
      "Epoch 2930/5000\n",
      "344/344 [==============================] - 0s 276us/step - loss: 395.3845 - mean_absolute_error: 11.5607\n",
      "Epoch 2931/5000\n",
      "344/344 [==============================] - 0s 284us/step - loss: 415.5725 - mean_absolute_error: 11.9052\n",
      "Epoch 2932/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 395.1697 - mean_absolute_error: 11.5618\n",
      "Epoch 2933/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 414.1916 - mean_absolute_error: 11.9193\n",
      "Epoch 2934/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 403.3250 - mean_absolute_error: 11.6499\n",
      "Epoch 2935/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 435.0393 - mean_absolute_error: 12.3260\n",
      "Epoch 2936/5000\n",
      "344/344 [==============================] - 0s 263us/step - loss: 449.0699 - mean_absolute_error: 12.3589\n",
      "Epoch 2937/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 418.0374 - mean_absolute_error: 11.8317\n",
      "Epoch 2938/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 435.5385 - mean_absolute_error: 12.4597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2939/5000\n",
      "344/344 [==============================] - 0s 263us/step - loss: 424.3805 - mean_absolute_error: 12.3475\n",
      "Epoch 2940/5000\n",
      "344/344 [==============================] - 0s 257us/step - loss: 398.0693 - mean_absolute_error: 11.4392\n",
      "Epoch 2941/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.7772 - mean_absolute_error: 12.1923\n",
      "Epoch 2942/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 406.9256 - mean_absolute_error: 11.7433\n",
      "Epoch 2943/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.4531 - mean_absolute_error: 11.9061\n",
      "Epoch 2944/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 396.5225 - mean_absolute_error: 11.3772\n",
      "Epoch 2945/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 415.1456 - mean_absolute_error: 11.9432\n",
      "Epoch 2946/5000\n",
      "344/344 [==============================] - 0s 286us/step - loss: 438.8845 - mean_absolute_error: 12.6116\n",
      "Epoch 2947/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.2984 - mean_absolute_error: 11.8604\n",
      "Epoch 2948/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 446.8655 - mean_absolute_error: 12.6104\n",
      "Epoch 2949/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 391.7577 - mean_absolute_error: 11.3791\n",
      "Epoch 2950/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.4862 - mean_absolute_error: 11.9652\n",
      "Epoch 2951/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.9310 - mean_absolute_error: 11.7033\n",
      "Epoch 2952/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 394.9905 - mean_absolute_error: 11.7118\n",
      "Epoch 2953/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 412.6646 - mean_absolute_error: 11.9705\n",
      "Epoch 2954/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 426.1513 - mean_absolute_error: 12.2278\n",
      "Epoch 2955/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 424.2349 - mean_absolute_error: 11.4710\n",
      "Epoch 2956/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 393.4926 - mean_absolute_error: 11.3498\n",
      "Epoch 2957/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 403.4099 - mean_absolute_error: 11.5055\n",
      "Epoch 2958/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 398.0422 - mean_absolute_error: 11.3502\n",
      "Epoch 2959/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 403.5272 - mean_absolute_error: 11.6883\n",
      "Epoch 2960/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 406.9405 - mean_absolute_error: 11.6958\n",
      "Epoch 2961/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 413.5575 - mean_absolute_error: 11.7577\n",
      "Epoch 2962/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 413.4946 - mean_absolute_error: 11.8750\n",
      "Epoch 2963/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 429.9007 - mean_absolute_error: 12.2352\n",
      "Epoch 2964/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 409.5683 - mean_absolute_error: 11.7901\n",
      "Epoch 2965/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 426.2247 - mean_absolute_error: 12.0366\n",
      "Epoch 2966/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.7551 - mean_absolute_error: 12.2195\n",
      "Epoch 2967/5000\n",
      "344/344 [==============================] - 0s 256us/step - loss: 432.9013 - mean_absolute_error: 12.0905\n",
      "Epoch 2968/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 417.5128 - mean_absolute_error: 11.8042\n",
      "Epoch 2969/5000\n",
      "344/344 [==============================] - 0s 304us/step - loss: 399.4501 - mean_absolute_error: 11.6513\n",
      "Epoch 2970/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 413.3556 - mean_absolute_error: 11.8524\n",
      "Epoch 2971/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 445.1280 - mean_absolute_error: 12.1899\n",
      "Epoch 2972/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 428.7580 - mean_absolute_error: 12.4549\n",
      "Epoch 2973/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 431.9237 - mean_absolute_error: 11.9395\n",
      "Epoch 2974/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 408.8927 - mean_absolute_error: 11.7866\n",
      "Epoch 2975/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 418.9105 - mean_absolute_error: 11.6579\n",
      "Epoch 2976/5000\n",
      "344/344 [==============================] - 0s 271us/step - loss: 413.7080 - mean_absolute_error: 11.6741\n",
      "Epoch 2977/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 422.6201 - mean_absolute_error: 11.8766\n",
      "Epoch 2978/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 409.3985 - mean_absolute_error: 11.6248\n",
      "Epoch 2979/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 412.6175 - mean_absolute_error: 12.0045\n",
      "Epoch 2980/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 410.6652 - mean_absolute_error: 11.8279\n",
      "Epoch 2981/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 410.8162 - mean_absolute_error: 11.5900\n",
      "Epoch 2982/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 483.0588 - mean_absolute_error: 13.0774\n",
      "Epoch 2983/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 401.6138 - mean_absolute_error: 11.6702\n",
      "Epoch 2984/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 421.6974 - mean_absolute_error: 11.8352\n",
      "Epoch 2985/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.2503 - mean_absolute_error: 11.7492\n",
      "Epoch 2986/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 414.8098 - mean_absolute_error: 11.8924\n",
      "Epoch 2987/5000\n",
      "344/344 [==============================] - 0s 253us/step - loss: 430.4782 - mean_absolute_error: 12.2430\n",
      "Epoch 2988/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 400.9538 - mean_absolute_error: 11.5410\n",
      "Epoch 2989/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 403.6467 - mean_absolute_error: 11.6426\n",
      "Epoch 2990/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 413.0357 - mean_absolute_error: 11.8749\n",
      "Epoch 2991/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 405.4849 - mean_absolute_error: 11.5221\n",
      "Epoch 2992/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 417.8592 - mean_absolute_error: 12.2012\n",
      "Epoch 2993/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 424.0048 - mean_absolute_error: 12.1977\n",
      "Epoch 2994/5000\n",
      "344/344 [==============================] - 0s 262us/step - loss: 430.9357 - mean_absolute_error: 12.0953\n",
      "Epoch 2995/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.0197 - mean_absolute_error: 11.7940\n",
      "Epoch 2996/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.1432 - mean_absolute_error: 12.1384\n",
      "Epoch 2997/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 390.3477 - mean_absolute_error: 11.6641\n",
      "Epoch 2998/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 397.8796 - mean_absolute_error: 11.5292\n",
      "Epoch 2999/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 410.5428 - mean_absolute_error: 12.0832\n",
      "Epoch 3000/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 403.6017 - mean_absolute_error: 11.5661\n",
      "Epoch 3001/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.9301 - mean_absolute_error: 12.3105\n",
      "Epoch 3002/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 412.3437 - mean_absolute_error: 11.9235\n",
      "Epoch 3003/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 427.5255 - mean_absolute_error: 12.1999\n",
      "Epoch 3004/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 423.6432 - mean_absolute_error: 12.0459\n",
      "Epoch 3005/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 422.4969 - mean_absolute_error: 12.0516\n",
      "Epoch 3006/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 436.1594 - mean_absolute_error: 12.3406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3007/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 416.5319 - mean_absolute_error: 11.8654\n",
      "Epoch 3008/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 414.2683 - mean_absolute_error: 12.1875\n",
      "Epoch 3009/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 405.5201 - mean_absolute_error: 12.1558\n",
      "Epoch 3010/5000\n",
      "344/344 [==============================] - 0s 268us/step - loss: 411.7769 - mean_absolute_error: 11.6401\n",
      "Epoch 3011/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 410.8878 - mean_absolute_error: 12.1429\n",
      "Epoch 3012/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.8074 - mean_absolute_error: 12.0896\n",
      "Epoch 3013/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 425.1263 - mean_absolute_error: 12.0068\n",
      "Epoch 3014/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 415.4088 - mean_absolute_error: 11.6682\n",
      "Epoch 3015/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 407.2037 - mean_absolute_error: 12.0110\n",
      "Epoch 3016/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 415.1167 - mean_absolute_error: 12.2716\n",
      "Epoch 3017/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 407.5147 - mean_absolute_error: 11.8464\n",
      "Epoch 3018/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 458.5581 - mean_absolute_error: 12.5397\n",
      "Epoch 3019/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 434.0042 - mean_absolute_error: 12.2156\n",
      "Epoch 3020/5000\n",
      "344/344 [==============================] - 0s 262us/step - loss: 415.8359 - mean_absolute_error: 11.3728\n",
      "Epoch 3021/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 400.8660 - mean_absolute_error: 11.9043\n",
      "Epoch 3022/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 402.9638 - mean_absolute_error: 11.6716\n",
      "Epoch 3023/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 389.5740 - mean_absolute_error: 11.4412\n",
      "Epoch 3024/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 429.8955 - mean_absolute_error: 12.3218\n",
      "Epoch 3025/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 418.3075 - mean_absolute_error: 11.7118\n",
      "Epoch 3026/5000\n",
      "344/344 [==============================] - 0s 262us/step - loss: 406.8275 - mean_absolute_error: 11.5959\n",
      "Epoch 3027/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 412.3126 - mean_absolute_error: 11.9996\n",
      "Epoch 3028/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 414.7738 - mean_absolute_error: 11.9099\n",
      "Epoch 3029/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 410.0815 - mean_absolute_error: 11.6962\n",
      "Epoch 3030/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 415.9977 - mean_absolute_error: 11.8208\n",
      "Epoch 3031/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 419.9186 - mean_absolute_error: 11.9080\n",
      "Epoch 3032/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 424.0312 - mean_absolute_error: 11.9975\n",
      "Epoch 3033/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 405.3660 - mean_absolute_error: 11.8024\n",
      "Epoch 3034/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 436.2132 - mean_absolute_error: 12.4034\n",
      "Epoch 3035/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.8998 - mean_absolute_error: 11.8558\n",
      "Epoch 3036/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.5137 - mean_absolute_error: 11.7243\n",
      "Epoch 3037/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 407.7166 - mean_absolute_error: 11.6647\n",
      "Epoch 3038/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 416.4682 - mean_absolute_error: 11.8203\n",
      "Epoch 3039/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 406.4199 - mean_absolute_error: 11.7476\n",
      "Epoch 3040/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 414.0396 - mean_absolute_error: 11.9168\n",
      "Epoch 3041/5000\n",
      "344/344 [==============================] - 0s 268us/step - loss: 414.2594 - mean_absolute_error: 11.8734\n",
      "Epoch 3042/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 430.5938 - mean_absolute_error: 11.9636\n",
      "Epoch 3043/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.6718 - mean_absolute_error: 12.3045\n",
      "Epoch 3044/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 401.4502 - mean_absolute_error: 11.7420\n",
      "Epoch 3045/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.3329 - mean_absolute_error: 11.9988\n",
      "Epoch 3046/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 408.6058 - mean_absolute_error: 11.7490\n",
      "Epoch 3047/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 395.5342 - mean_absolute_error: 11.5878\n",
      "Epoch 3048/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 404.7257 - mean_absolute_error: 11.6881\n",
      "Epoch 3049/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 418.7752 - mean_absolute_error: 12.2019\n",
      "Epoch 3050/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 419.7484 - mean_absolute_error: 12.0486\n",
      "Epoch 3051/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 395.8403 - mean_absolute_error: 11.4543\n",
      "Epoch 3052/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 422.4236 - mean_absolute_error: 11.8407\n",
      "Epoch 3053/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 412.1620 - mean_absolute_error: 11.9135\n",
      "Epoch 3054/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 426.4155 - mean_absolute_error: 12.2260\n",
      "Epoch 3055/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 412.4825 - mean_absolute_error: 11.8023\n",
      "Epoch 3056/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 428.2005 - mean_absolute_error: 12.3134\n",
      "Epoch 3057/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 430.7928 - mean_absolute_error: 12.2513\n",
      "Epoch 3058/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 400.0624 - mean_absolute_error: 11.4029\n",
      "Epoch 3059/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.4987 - mean_absolute_error: 12.0851\n",
      "Epoch 3060/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 438.2359 - mean_absolute_error: 12.5211\n",
      "Epoch 3061/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.0538 - mean_absolute_error: 11.8267\n",
      "Epoch 3062/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 422.3932 - mean_absolute_error: 12.1610\n",
      "Epoch 3063/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 400.6717 - mean_absolute_error: 11.6307\n",
      "Epoch 3064/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 413.7317 - mean_absolute_error: 11.6378\n",
      "Epoch 3065/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 394.7004 - mean_absolute_error: 11.2599\n",
      "Epoch 3066/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 418.0396 - mean_absolute_error: 12.0020\n",
      "Epoch 3067/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 440.9891 - mean_absolute_error: 12.2285\n",
      "Epoch 3068/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 419.9612 - mean_absolute_error: 11.8483\n",
      "Epoch 3069/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 415.8783 - mean_absolute_error: 11.8211\n",
      "Epoch 3070/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 396.4332 - mean_absolute_error: 11.5387\n",
      "Epoch 3071/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.6126 - mean_absolute_error: 12.1341\n",
      "Epoch 3072/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 412.4941 - mean_absolute_error: 12.1546\n",
      "Epoch 3073/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 402.5700 - mean_absolute_error: 11.7183\n",
      "Epoch 3074/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 424.8018 - mean_absolute_error: 12.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3075/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 399.8815 - mean_absolute_error: 11.3226\n",
      "Epoch 3076/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.7212 - mean_absolute_error: 12.3948\n",
      "Epoch 3077/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 422.5262 - mean_absolute_error: 11.8850\n",
      "Epoch 3078/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 415.6115 - mean_absolute_error: 11.7999\n",
      "Epoch 3079/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 398.2234 - mean_absolute_error: 11.4162\n",
      "Epoch 3080/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 401.4487 - mean_absolute_error: 11.5968\n",
      "Epoch 3081/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 416.8879 - mean_absolute_error: 12.3188\n",
      "Epoch 3082/5000\n",
      "344/344 [==============================] - 0s 293us/step - loss: 409.7905 - mean_absolute_error: 11.3384\n",
      "Epoch 3083/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.2573 - mean_absolute_error: 11.9268\n",
      "Epoch 3084/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 395.8543 - mean_absolute_error: 11.2530\n",
      "Epoch 3085/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 404.1600 - mean_absolute_error: 11.7491\n",
      "Epoch 3086/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 428.8222 - mean_absolute_error: 11.9486\n",
      "Epoch 3087/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 402.7146 - mean_absolute_error: 11.5132\n",
      "Epoch 3088/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 401.3679 - mean_absolute_error: 11.4353\n",
      "Epoch 3089/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.5378 - mean_absolute_error: 12.0435\n",
      "Epoch 3090/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 427.5248 - mean_absolute_error: 12.1971\n",
      "Epoch 3091/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 400.7958 - mean_absolute_error: 11.2837\n",
      "Epoch 3092/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 396.1613 - mean_absolute_error: 11.5224\n",
      "Epoch 3093/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 413.9930 - mean_absolute_error: 11.9906\n",
      "Epoch 3094/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 432.9297 - mean_absolute_error: 12.1602\n",
      "Epoch 3095/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 396.8813 - mean_absolute_error: 11.5087\n",
      "Epoch 3096/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.7726 - mean_absolute_error: 11.8691\n",
      "Epoch 3097/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 411.3161 - mean_absolute_error: 12.1542\n",
      "Epoch 3098/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 424.5237 - mean_absolute_error: 12.1630\n",
      "Epoch 3099/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 415.9695 - mean_absolute_error: 11.8527\n",
      "Epoch 3100/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 426.2963 - mean_absolute_error: 11.8614\n",
      "Epoch 3101/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 436.3474 - mean_absolute_error: 12.1591\n",
      "Epoch 3102/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 428.9766 - mean_absolute_error: 12.2856\n",
      "Epoch 3103/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 499.4037 - mean_absolute_error: 12.3349\n",
      "Epoch 3104/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 398.3130 - mean_absolute_error: 11.5582\n",
      "Epoch 3105/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 419.7618 - mean_absolute_error: 12.0976\n",
      "Epoch 3106/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 401.9424 - mean_absolute_error: 11.7313\n",
      "Epoch 3107/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 409.0892 - mean_absolute_error: 11.8828\n",
      "Epoch 3108/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 428.2437 - mean_absolute_error: 12.2190\n",
      "Epoch 3109/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 449.4102 - mean_absolute_error: 12.5145\n",
      "Epoch 3110/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 405.5055 - mean_absolute_error: 11.8506\n",
      "Epoch 3111/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.4830 - mean_absolute_error: 11.3558\n",
      "Epoch 3112/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 423.6068 - mean_absolute_error: 12.1007\n",
      "Epoch 3113/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.0937 - mean_absolute_error: 11.7828\n",
      "Epoch 3114/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 383.4611 - mean_absolute_error: 11.2668\n",
      "Epoch 3115/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 409.3578 - mean_absolute_error: 11.8592\n",
      "Epoch 3116/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 401.7637 - mean_absolute_error: 11.6337\n",
      "Epoch 3117/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 411.7439 - mean_absolute_error: 11.7201\n",
      "Epoch 3118/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 444.9189 - mean_absolute_error: 12.3914\n",
      "Epoch 3119/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 404.2053 - mean_absolute_error: 11.3089\n",
      "Epoch 3120/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 406.8882 - mean_absolute_error: 11.6896\n",
      "Epoch 3121/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 399.1830 - mean_absolute_error: 11.7159\n",
      "Epoch 3122/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.0804 - mean_absolute_error: 11.8598\n",
      "Epoch 3123/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 397.3442 - mean_absolute_error: 11.5355\n",
      "Epoch 3124/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.9691 - mean_absolute_error: 11.9369\n",
      "Epoch 3125/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 398.1169 - mean_absolute_error: 11.7482\n",
      "Epoch 3126/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 399.8380 - mean_absolute_error: 11.5426\n",
      "Epoch 3127/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 424.3460 - mean_absolute_error: 12.0658\n",
      "Epoch 3128/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 424.5175 - mean_absolute_error: 12.3829\n",
      "Epoch 3129/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.8216 - mean_absolute_error: 11.8495\n",
      "Epoch 3130/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 407.4898 - mean_absolute_error: 11.5961\n",
      "Epoch 3131/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.7951 - mean_absolute_error: 12.0289\n",
      "Epoch 3132/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 397.9130 - mean_absolute_error: 11.6405\n",
      "Epoch 3133/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 432.3905 - mean_absolute_error: 12.3179\n",
      "Epoch 3134/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.1994 - mean_absolute_error: 11.8134\n",
      "Epoch 3135/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 401.4117 - mean_absolute_error: 11.5260\n",
      "Epoch 3136/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 415.6199 - mean_absolute_error: 12.0697\n",
      "Epoch 3137/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 409.2048 - mean_absolute_error: 11.8365\n",
      "Epoch 3138/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 398.3026 - mean_absolute_error: 11.4104\n",
      "Epoch 3139/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.6162 - mean_absolute_error: 12.0592\n",
      "Epoch 3140/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 420.9261 - mean_absolute_error: 12.0569\n",
      "Epoch 3141/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 408.1410 - mean_absolute_error: 11.6322\n",
      "Epoch 3142/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 419.2915 - mean_absolute_error: 11.8563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3143/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.9078 - mean_absolute_error: 11.7808\n",
      "Epoch 3144/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.5352 - mean_absolute_error: 12.1173\n",
      "Epoch 3145/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 404.1944 - mean_absolute_error: 11.6155\n",
      "Epoch 3146/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 400.2938 - mean_absolute_error: 11.4975\n",
      "Epoch 3147/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 433.8731 - mean_absolute_error: 12.1451\n",
      "Epoch 3148/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 422.1895 - mean_absolute_error: 12.1081\n",
      "Epoch 3149/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 456.2545 - mean_absolute_error: 12.9132\n",
      "Epoch 3150/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 425.4387 - mean_absolute_error: 12.1742\n",
      "Epoch 3151/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 409.8921 - mean_absolute_error: 11.4333\n",
      "Epoch 3152/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 409.6322 - mean_absolute_error: 11.5799\n",
      "Epoch 3153/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 415.3021 - mean_absolute_error: 12.1750\n",
      "Epoch 3154/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.0240 - mean_absolute_error: 12.1564\n",
      "Epoch 3155/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.3143 - mean_absolute_error: 11.8324\n",
      "Epoch 3156/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 435.5788 - mean_absolute_error: 12.3452\n",
      "Epoch 3157/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 425.5278 - mean_absolute_error: 11.9921\n",
      "Epoch 3158/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 428.0183 - mean_absolute_error: 12.1844\n",
      "Epoch 3159/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 409.7209 - mean_absolute_error: 11.7617\n",
      "Epoch 3160/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 399.1498 - mean_absolute_error: 11.4680\n",
      "Epoch 3161/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 400.1198 - mean_absolute_error: 11.5891\n",
      "Epoch 3162/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 425.6111 - mean_absolute_error: 12.3228\n",
      "Epoch 3163/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 405.5273 - mean_absolute_error: 11.7054\n",
      "Epoch 3164/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 390.7299 - mean_absolute_error: 11.3793\n",
      "Epoch 3165/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 406.9041 - mean_absolute_error: 11.5146\n",
      "Epoch 3166/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 391.1987 - mean_absolute_error: 11.6412\n",
      "Epoch 3167/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 428.8460 - mean_absolute_error: 12.1585\n",
      "Epoch 3168/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 401.0140 - mean_absolute_error: 11.8269\n",
      "Epoch 3169/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.7744 - mean_absolute_error: 12.1870\n",
      "Epoch 3170/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.4417 - mean_absolute_error: 12.0807\n",
      "Epoch 3171/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 398.7675 - mean_absolute_error: 11.5394\n",
      "Epoch 3172/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 425.2845 - mean_absolute_error: 11.9771\n",
      "Epoch 3173/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 401.5260 - mean_absolute_error: 11.7214\n",
      "Epoch 3174/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.3352 - mean_absolute_error: 12.0490\n",
      "Epoch 3175/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 411.5259 - mean_absolute_error: 11.8191\n",
      "Epoch 3176/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.6789 - mean_absolute_error: 11.9867\n",
      "Epoch 3177/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.5992 - mean_absolute_error: 11.9556\n",
      "Epoch 3178/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 395.4384 - mean_absolute_error: 11.5826\n",
      "Epoch 3179/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 404.3384 - mean_absolute_error: 11.7104\n",
      "Epoch 3180/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 414.8274 - mean_absolute_error: 11.9944\n",
      "Epoch 3181/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 410.4980 - mean_absolute_error: 11.8208\n",
      "Epoch 3182/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.4426 - mean_absolute_error: 11.6981\n",
      "Epoch 3183/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.7148 - mean_absolute_error: 11.9553\n",
      "Epoch 3184/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 407.0610 - mean_absolute_error: 11.7556\n",
      "Epoch 3185/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 428.1493 - mean_absolute_error: 12.1532\n",
      "Epoch 3186/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 392.6685 - mean_absolute_error: 11.5158\n",
      "Epoch 3187/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 445.6858 - mean_absolute_error: 12.0351\n",
      "Epoch 3188/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 406.6387 - mean_absolute_error: 11.7771\n",
      "Epoch 3189/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 416.2178 - mean_absolute_error: 12.1812\n",
      "Epoch 3190/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 425.4145 - mean_absolute_error: 12.0340\n",
      "Epoch 3191/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 429.8402 - mean_absolute_error: 12.1706\n",
      "Epoch 3192/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 418.7994 - mean_absolute_error: 12.2158\n",
      "Epoch 3193/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 410.5978 - mean_absolute_error: 12.0631\n",
      "Epoch 3194/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 423.0141 - mean_absolute_error: 12.1908\n",
      "Epoch 3195/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 388.9642 - mean_absolute_error: 11.2636\n",
      "Epoch 3196/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 401.8131 - mean_absolute_error: 11.5623\n",
      "Epoch 3197/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 425.6363 - mean_absolute_error: 12.1539\n",
      "Epoch 3198/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 411.0635 - mean_absolute_error: 11.7143\n",
      "Epoch 3199/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 396.1682 - mean_absolute_error: 11.5603\n",
      "Epoch 3200/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 402.6245 - mean_absolute_error: 11.6029\n",
      "Epoch 3201/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 405.4948 - mean_absolute_error: 11.5229\n",
      "Epoch 3202/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 400.9619 - mean_absolute_error: 11.4714\n",
      "Epoch 3203/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.9553 - mean_absolute_error: 11.8820\n",
      "Epoch 3204/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 427.6976 - mean_absolute_error: 12.1745\n",
      "Epoch 3205/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.4955 - mean_absolute_error: 12.0721\n",
      "Epoch 3206/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.4432 - mean_absolute_error: 12.0481\n",
      "Epoch 3207/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.3631 - mean_absolute_error: 12.0102\n",
      "Epoch 3208/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 433.9079 - mean_absolute_error: 12.2920\n",
      "Epoch 3209/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 408.5239 - mean_absolute_error: 11.9181\n",
      "Epoch 3210/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 394.2661 - mean_absolute_error: 11.5162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3211/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.8206 - mean_absolute_error: 12.0256\n",
      "Epoch 3212/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 401.2122 - mean_absolute_error: 11.1383\n",
      "Epoch 3213/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 415.5157 - mean_absolute_error: 11.7659\n",
      "Epoch 3214/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 395.6942 - mean_absolute_error: 11.3526\n",
      "Epoch 3215/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 391.0841 - mean_absolute_error: 11.4815\n",
      "Epoch 3216/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.3561 - mean_absolute_error: 12.0872\n",
      "Epoch 3217/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 420.1141 - mean_absolute_error: 11.7261\n",
      "Epoch 3218/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 500.2036 - mean_absolute_error: 12.8136\n",
      "Epoch 3219/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 380.2039 - mean_absolute_error: 11.2057\n",
      "Epoch 3220/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 397.4962 - mean_absolute_error: 11.5870\n",
      "Epoch 3221/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.7834 - mean_absolute_error: 11.7553\n",
      "Epoch 3222/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 419.0650 - mean_absolute_error: 12.1159\n",
      "Epoch 3223/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 391.4207 - mean_absolute_error: 11.6323\n",
      "Epoch 3224/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 397.1385 - mean_absolute_error: 11.4412\n",
      "Epoch 3225/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 394.4383 - mean_absolute_error: 11.5280\n",
      "Epoch 3226/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 421.8642 - mean_absolute_error: 12.1134\n",
      "Epoch 3227/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 390.7879 - mean_absolute_error: 11.5816\n",
      "Epoch 3228/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 431.1872 - mean_absolute_error: 12.3892\n",
      "Epoch 3229/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.5442 - mean_absolute_error: 12.0034\n",
      "Epoch 3230/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 395.1108 - mean_absolute_error: 11.6012\n",
      "Epoch 3231/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 395.2404 - mean_absolute_error: 11.5763\n",
      "Epoch 3232/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 412.8959 - mean_absolute_error: 11.8270\n",
      "Epoch 3233/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.0908 - mean_absolute_error: 11.6005\n",
      "Epoch 3234/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 409.8693 - mean_absolute_error: 11.7178\n",
      "Epoch 3235/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 385.5528 - mean_absolute_error: 11.4398\n",
      "Epoch 3236/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 406.8477 - mean_absolute_error: 11.8320\n",
      "Epoch 3237/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 422.1261 - mean_absolute_error: 11.8616\n",
      "Epoch 3238/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.2960 - mean_absolute_error: 11.9684\n",
      "Epoch 3239/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.9525 - mean_absolute_error: 12.3122\n",
      "Epoch 3240/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 422.4570 - mean_absolute_error: 12.0669\n",
      "Epoch 3241/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 401.8277 - mean_absolute_error: 12.0856\n",
      "Epoch 3242/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 386.5017 - mean_absolute_error: 11.2149\n",
      "Epoch 3243/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 426.7292 - mean_absolute_error: 12.0237\n",
      "Epoch 3244/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 408.1387 - mean_absolute_error: 11.6729\n",
      "Epoch 3245/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 414.5151 - mean_absolute_error: 11.8927\n",
      "Epoch 3246/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 430.0859 - mean_absolute_error: 12.3459\n",
      "Epoch 3247/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.2137 - mean_absolute_error: 11.6195\n",
      "Epoch 3248/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.5566 - mean_absolute_error: 11.4412\n",
      "Epoch 3249/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.5054 - mean_absolute_error: 11.8401\n",
      "Epoch 3250/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 395.8246 - mean_absolute_error: 11.4072\n",
      "Epoch 3251/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 388.0988 - mean_absolute_error: 11.3555\n",
      "Epoch 3252/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 415.5794 - mean_absolute_error: 12.1612\n",
      "Epoch 3253/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 400.7256 - mean_absolute_error: 11.4040\n",
      "Epoch 3254/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 396.6868 - mean_absolute_error: 11.7734\n",
      "Epoch 3255/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.1322 - mean_absolute_error: 11.6079\n",
      "Epoch 3256/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 405.3688 - mean_absolute_error: 11.9005\n",
      "Epoch 3257/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 413.7430 - mean_absolute_error: 11.8495\n",
      "Epoch 3258/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 428.3541 - mean_absolute_error: 11.8393\n",
      "Epoch 3259/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 407.1505 - mean_absolute_error: 11.8233\n",
      "Epoch 3260/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.1017 - mean_absolute_error: 11.9548\n",
      "Epoch 3261/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 395.2537 - mean_absolute_error: 11.3740\n",
      "Epoch 3262/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 429.6185 - mean_absolute_error: 12.2061\n",
      "Epoch 3263/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 428.8271 - mean_absolute_error: 12.2229\n",
      "Epoch 3264/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.1880 - mean_absolute_error: 11.8177\n",
      "Epoch 3265/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.3794 - mean_absolute_error: 11.8371\n",
      "Epoch 3266/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 434.5935 - mean_absolute_error: 11.8849\n",
      "Epoch 3267/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 427.8069 - mean_absolute_error: 12.4768\n",
      "Epoch 3268/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 443.5356 - mean_absolute_error: 12.4906\n",
      "Epoch 3269/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.4176 - mean_absolute_error: 11.6738\n",
      "Epoch 3270/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.8547 - mean_absolute_error: 11.6725\n",
      "Epoch 3271/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.6728 - mean_absolute_error: 11.7677\n",
      "Epoch 3272/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 411.4446 - mean_absolute_error: 12.0447\n",
      "Epoch 3273/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 412.5989 - mean_absolute_error: 11.7754\n",
      "Epoch 3274/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 388.8599 - mean_absolute_error: 11.4315\n",
      "Epoch 3275/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 460.0808 - mean_absolute_error: 12.4466\n",
      "Epoch 3276/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.1843 - mean_absolute_error: 11.8581\n",
      "Epoch 3277/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 402.5811 - mean_absolute_error: 11.8001\n",
      "Epoch 3278/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.9010 - mean_absolute_error: 12.4084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3279/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 417.3100 - mean_absolute_error: 12.1490\n",
      "Epoch 3280/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.6011 - mean_absolute_error: 11.9041\n",
      "Epoch 3281/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 399.9854 - mean_absolute_error: 11.8861\n",
      "Epoch 3282/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 401.8810 - mean_absolute_error: 11.6401\n",
      "Epoch 3283/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.4168 - mean_absolute_error: 11.8842\n",
      "Epoch 3284/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 436.4194 - mean_absolute_error: 11.9295\n",
      "Epoch 3285/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 401.4846 - mean_absolute_error: 11.7911\n",
      "Epoch 3286/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 451.2306 - mean_absolute_error: 11.7355\n",
      "Epoch 3287/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 416.7370 - mean_absolute_error: 11.8001\n",
      "Epoch 3288/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 387.6824 - mean_absolute_error: 11.2008\n",
      "Epoch 3289/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 387.5160 - mean_absolute_error: 11.4716\n",
      "Epoch 3290/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 393.9609 - mean_absolute_error: 11.3538\n",
      "Epoch 3291/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 404.3963 - mean_absolute_error: 11.6125\n",
      "Epoch 3292/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 403.7944 - mean_absolute_error: 11.9653\n",
      "Epoch 3293/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 433.7519 - mean_absolute_error: 12.1974\n",
      "Epoch 3294/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 388.7675 - mean_absolute_error: 11.1795\n",
      "Epoch 3295/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.1447 - mean_absolute_error: 11.8466\n",
      "Epoch 3296/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 405.0068 - mean_absolute_error: 11.5342\n",
      "Epoch 3297/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 403.2891 - mean_absolute_error: 11.5725\n",
      "Epoch 3298/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 425.9435 - mean_absolute_error: 11.9935\n",
      "Epoch 3299/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.7062 - mean_absolute_error: 11.9509\n",
      "Epoch 3300/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 403.9071 - mean_absolute_error: 11.6023\n",
      "Epoch 3301/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 443.7915 - mean_absolute_error: 12.7883\n",
      "Epoch 3302/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 411.0825 - mean_absolute_error: 12.1632\n",
      "Epoch 3303/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 400.2018 - mean_absolute_error: 11.8019\n",
      "Epoch 3304/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 410.0254 - mean_absolute_error: 12.0666\n",
      "Epoch 3305/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.1581 - mean_absolute_error: 11.7511\n",
      "Epoch 3306/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 407.5349 - mean_absolute_error: 11.6550\n",
      "Epoch 3307/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.7051 - mean_absolute_error: 11.7727\n",
      "Epoch 3308/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.7450 - mean_absolute_error: 12.2789\n",
      "Epoch 3309/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.4895 - mean_absolute_error: 11.5844\n",
      "Epoch 3310/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 420.2973 - mean_absolute_error: 12.0314\n",
      "Epoch 3311/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 405.6263 - mean_absolute_error: 11.7645\n",
      "Epoch 3312/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 436.6805 - mean_absolute_error: 12.0768\n",
      "Epoch 3313/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 389.8262 - mean_absolute_error: 11.3464\n",
      "Epoch 3314/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 449.5056 - mean_absolute_error: 12.3717\n",
      "Epoch 3315/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 413.9041 - mean_absolute_error: 12.0855\n",
      "Epoch 3316/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 433.5905 - mean_absolute_error: 12.4700\n",
      "Epoch 3317/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.8505 - mean_absolute_error: 11.9034\n",
      "Epoch 3318/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 395.6646 - mean_absolute_error: 11.3491\n",
      "Epoch 3319/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 423.6210 - mean_absolute_error: 12.0896\n",
      "Epoch 3320/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 394.8079 - mean_absolute_error: 11.3405\n",
      "Epoch 3321/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 427.3864 - mean_absolute_error: 12.1470\n",
      "Epoch 3322/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 399.1013 - mean_absolute_error: 11.6944\n",
      "Epoch 3323/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.0077 - mean_absolute_error: 12.2919\n",
      "Epoch 3324/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.5528 - mean_absolute_error: 11.8254\n",
      "Epoch 3325/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 423.0206 - mean_absolute_error: 11.9894\n",
      "Epoch 3326/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 401.7610 - mean_absolute_error: 11.6555\n",
      "Epoch 3327/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 428.9541 - mean_absolute_error: 11.8321\n",
      "Epoch 3328/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.5683 - mean_absolute_error: 12.0631\n",
      "Epoch 3329/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 465.6995 - mean_absolute_error: 12.5069\n",
      "Epoch 3330/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 411.8291 - mean_absolute_error: 11.8880\n",
      "Epoch 3331/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 411.5258 - mean_absolute_error: 11.8362\n",
      "Epoch 3332/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.7426 - mean_absolute_error: 11.7902\n",
      "Epoch 3333/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.5113 - mean_absolute_error: 11.4987\n",
      "Epoch 3334/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 402.2787 - mean_absolute_error: 11.6645\n",
      "Epoch 3335/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 419.4156 - mean_absolute_error: 11.8134\n",
      "Epoch 3336/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 401.9750 - mean_absolute_error: 11.8330\n",
      "Epoch 3337/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 388.7414 - mean_absolute_error: 11.4988\n",
      "Epoch 3338/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.9063 - mean_absolute_error: 12.0652\n",
      "Epoch 3339/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.8271 - mean_absolute_error: 12.1848\n",
      "Epoch 3340/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 410.9950 - mean_absolute_error: 11.7398\n",
      "Epoch 3341/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 413.3009 - mean_absolute_error: 12.0904\n",
      "Epoch 3342/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 417.8009 - mean_absolute_error: 11.8546\n",
      "Epoch 3343/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 405.6232 - mean_absolute_error: 11.7106\n",
      "Epoch 3344/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 416.0444 - mean_absolute_error: 11.9315\n",
      "Epoch 3345/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 408.4280 - mean_absolute_error: 11.7793\n",
      "Epoch 3346/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.6101 - mean_absolute_error: 11.9522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3347/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.1649 - mean_absolute_error: 11.7612\n",
      "Epoch 3348/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 427.7352 - mean_absolute_error: 12.0546\n",
      "Epoch 3349/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 418.6196 - mean_absolute_error: 12.0418\n",
      "Epoch 3350/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 410.6078 - mean_absolute_error: 11.7133\n",
      "Epoch 3351/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 440.0784 - mean_absolute_error: 12.3459\n",
      "Epoch 3352/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 435.2625 - mean_absolute_error: 12.3656\n",
      "Epoch 3353/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 410.3612 - mean_absolute_error: 11.5870\n",
      "Epoch 3354/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.8832 - mean_absolute_error: 11.9048\n",
      "Epoch 3355/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 395.1505 - mean_absolute_error: 11.4390\n",
      "Epoch 3356/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 399.9381 - mean_absolute_error: 11.2518\n",
      "Epoch 3357/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 420.7709 - mean_absolute_error: 12.2866\n",
      "Epoch 3358/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 408.4097 - mean_absolute_error: 11.9826\n",
      "Epoch 3359/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 416.5995 - mean_absolute_error: 11.9565\n",
      "Epoch 3360/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 405.6237 - mean_absolute_error: 11.6635\n",
      "Epoch 3361/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 415.4340 - mean_absolute_error: 11.9431\n",
      "Epoch 3362/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.5388 - mean_absolute_error: 12.0084\n",
      "Epoch 3363/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 414.2049 - mean_absolute_error: 11.8767\n",
      "Epoch 3364/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 408.6615 - mean_absolute_error: 11.8956\n",
      "Epoch 3365/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.3256 - mean_absolute_error: 11.7175\n",
      "Epoch 3366/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.6907 - mean_absolute_error: 12.2189\n",
      "Epoch 3367/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 417.0517 - mean_absolute_error: 12.0319\n",
      "Epoch 3368/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 415.0707 - mean_absolute_error: 12.1349\n",
      "Epoch 3369/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 425.9682 - mean_absolute_error: 12.1786\n",
      "Epoch 3370/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 428.9628 - mean_absolute_error: 12.4101\n",
      "Epoch 3371/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 417.3062 - mean_absolute_error: 11.9043\n",
      "Epoch 3372/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 407.8668 - mean_absolute_error: 11.5851\n",
      "Epoch 3373/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 408.3680 - mean_absolute_error: 11.7123\n",
      "Epoch 3374/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 421.8884 - mean_absolute_error: 12.2514\n",
      "Epoch 3375/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 399.7529 - mean_absolute_error: 11.6545\n",
      "Epoch 3376/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.2312 - mean_absolute_error: 11.9991\n",
      "Epoch 3377/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 405.8438 - mean_absolute_error: 11.6603\n",
      "Epoch 3378/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 410.9658 - mean_absolute_error: 11.8839\n",
      "Epoch 3379/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.5462 - mean_absolute_error: 11.8326\n",
      "Epoch 3380/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.2997 - mean_absolute_error: 11.8766\n",
      "Epoch 3381/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.3360 - mean_absolute_error: 12.3874\n",
      "Epoch 3382/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 403.6469 - mean_absolute_error: 11.8977\n",
      "Epoch 3383/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 390.9603 - mean_absolute_error: 11.6070\n",
      "Epoch 3384/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 406.0885 - mean_absolute_error: 11.9193\n",
      "Epoch 3385/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 403.2475 - mean_absolute_error: 11.6481\n",
      "Epoch 3386/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 392.4303 - mean_absolute_error: 11.2937\n",
      "Epoch 3387/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 426.3855 - mean_absolute_error: 12.1319\n",
      "Epoch 3388/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 418.4699 - mean_absolute_error: 11.5569\n",
      "Epoch 3389/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 429.4882 - mean_absolute_error: 12.0966\n",
      "Epoch 3390/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.0523 - mean_absolute_error: 11.8146\n",
      "Epoch 3391/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.9974 - mean_absolute_error: 11.6778\n",
      "Epoch 3392/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 418.2704 - mean_absolute_error: 12.2862\n",
      "Epoch 3393/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 394.4025 - mean_absolute_error: 11.4877\n",
      "Epoch 3394/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.6211 - mean_absolute_error: 12.0806\n",
      "Epoch 3395/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 386.2310 - mean_absolute_error: 11.1901\n",
      "Epoch 3396/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 404.1562 - mean_absolute_error: 11.3288\n",
      "Epoch 3397/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.8743 - mean_absolute_error: 11.7241\n",
      "Epoch 3398/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 410.2766 - mean_absolute_error: 12.1687\n",
      "Epoch 3399/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 410.1970 - mean_absolute_error: 11.8387\n",
      "Epoch 3400/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 403.4501 - mean_absolute_error: 11.6026\n",
      "Epoch 3401/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 418.5351 - mean_absolute_error: 11.9756\n",
      "Epoch 3402/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.9251 - mean_absolute_error: 11.3658\n",
      "Epoch 3403/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.1034 - mean_absolute_error: 11.9035\n",
      "Epoch 3404/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 444.8552 - mean_absolute_error: 12.0131\n",
      "Epoch 3405/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 410.0745 - mean_absolute_error: 11.6070\n",
      "Epoch 3406/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 416.9105 - mean_absolute_error: 12.0894\n",
      "Epoch 3407/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.7791 - mean_absolute_error: 11.9412\n",
      "Epoch 3408/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 423.6313 - mean_absolute_error: 12.4168\n",
      "Epoch 3409/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 422.0273 - mean_absolute_error: 11.9530\n",
      "Epoch 3410/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 407.3259 - mean_absolute_error: 11.7590\n",
      "Epoch 3411/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 411.9549 - mean_absolute_error: 11.6083\n",
      "Epoch 3412/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 401.8589 - mean_absolute_error: 11.3818\n",
      "Epoch 3413/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.7294 - mean_absolute_error: 12.2018\n",
      "Epoch 3414/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 428.3700 - mean_absolute_error: 12.0382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3415/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 417.2539 - mean_absolute_error: 11.6510\n",
      "Epoch 3416/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 421.0672 - mean_absolute_error: 11.6385\n",
      "Epoch 3417/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 417.9446 - mean_absolute_error: 11.7284\n",
      "Epoch 3418/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 400.8115 - mean_absolute_error: 11.7315\n",
      "Epoch 3419/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.3253 - mean_absolute_error: 12.1921\n",
      "Epoch 3420/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.0596 - mean_absolute_error: 12.0133\n",
      "Epoch 3421/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 426.2384 - mean_absolute_error: 12.0552\n",
      "Epoch 3422/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 406.6282 - mean_absolute_error: 11.9287\n",
      "Epoch 3423/5000\n",
      "344/344 [==============================] - 0s 302us/step - loss: 411.3674 - mean_absolute_error: 11.7609\n",
      "Epoch 3424/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 423.2870 - mean_absolute_error: 12.2002\n",
      "Epoch 3425/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 430.7245 - mean_absolute_error: 12.2539\n",
      "Epoch 3426/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 390.7156 - mean_absolute_error: 11.3928\n",
      "Epoch 3427/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.3199 - mean_absolute_error: 11.7312\n",
      "Epoch 3428/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 412.2846 - mean_absolute_error: 11.8463\n",
      "Epoch 3429/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 422.7637 - mean_absolute_error: 11.8297\n",
      "Epoch 3430/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 422.0276 - mean_absolute_error: 12.0819\n",
      "Epoch 3431/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 411.7801 - mean_absolute_error: 11.7109\n",
      "Epoch 3432/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 410.6244 - mean_absolute_error: 11.7639\n",
      "Epoch 3433/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 413.3010 - mean_absolute_error: 11.7170\n",
      "Epoch 3434/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.2382 - mean_absolute_error: 11.9871\n",
      "Epoch 3435/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 409.5476 - mean_absolute_error: 11.8674\n",
      "Epoch 3436/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 413.4312 - mean_absolute_error: 12.1815\n",
      "Epoch 3437/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 418.9034 - mean_absolute_error: 12.1308\n",
      "Epoch 3438/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.4216 - mean_absolute_error: 11.8542\n",
      "Epoch 3439/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 418.7588 - mean_absolute_error: 11.8679\n",
      "Epoch 3440/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.5059 - mean_absolute_error: 11.8857\n",
      "Epoch 3441/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 420.3902 - mean_absolute_error: 12.1775\n",
      "Epoch 3442/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 423.8815 - mean_absolute_error: 11.9130\n",
      "Epoch 3443/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 416.6142 - mean_absolute_error: 11.9527\n",
      "Epoch 3444/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.8990 - mean_absolute_error: 11.6603\n",
      "Epoch 3445/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 406.3013 - mean_absolute_error: 12.0559\n",
      "Epoch 3446/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 406.8159 - mean_absolute_error: 11.8875\n",
      "Epoch 3447/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 420.4716 - mean_absolute_error: 12.0375\n",
      "Epoch 3448/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 411.4148 - mean_absolute_error: 11.8247\n",
      "Epoch 3449/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 411.4365 - mean_absolute_error: 11.9237\n",
      "Epoch 3450/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 405.8023 - mean_absolute_error: 11.7894\n",
      "Epoch 3451/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 403.5132 - mean_absolute_error: 11.6363\n",
      "Epoch 3452/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 406.3546 - mean_absolute_error: 11.9523\n",
      "Epoch 3453/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 422.8876 - mean_absolute_error: 12.0360\n",
      "Epoch 3454/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 425.2373 - mean_absolute_error: 12.2083\n",
      "Epoch 3455/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 407.1882 - mean_absolute_error: 11.6028\n",
      "Epoch 3456/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.6469 - mean_absolute_error: 12.0194\n",
      "Epoch 3457/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 414.0401 - mean_absolute_error: 12.1169\n",
      "Epoch 3458/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 431.7387 - mean_absolute_error: 12.3986\n",
      "Epoch 3459/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 428.3172 - mean_absolute_error: 12.3198\n",
      "Epoch 3460/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.6994 - mean_absolute_error: 12.0620\n",
      "Epoch 3461/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.2614 - mean_absolute_error: 11.5070\n",
      "Epoch 3462/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 408.0098 - mean_absolute_error: 11.6942\n",
      "Epoch 3463/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.7210 - mean_absolute_error: 11.9590\n",
      "Epoch 3464/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.6701 - mean_absolute_error: 12.0277\n",
      "Epoch 3465/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 402.5662 - mean_absolute_error: 11.8103\n",
      "Epoch 3466/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 419.9911 - mean_absolute_error: 12.0184\n",
      "Epoch 3467/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 397.7310 - mean_absolute_error: 11.3385\n",
      "Epoch 3468/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 495.0377 - mean_absolute_error: 12.5132\n",
      "Epoch 3469/5000\n",
      "344/344 [==============================] - 0s 293us/step - loss: 390.4502 - mean_absolute_error: 11.6459\n",
      "Epoch 3470/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 399.2254 - mean_absolute_error: 11.6997\n",
      "Epoch 3471/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 420.4152 - mean_absolute_error: 11.9078\n",
      "Epoch 3472/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 397.0694 - mean_absolute_error: 11.7545\n",
      "Epoch 3473/5000\n",
      "344/344 [==============================] - 0s 281us/step - loss: 395.1286 - mean_absolute_error: 11.2622\n",
      "Epoch 3474/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 389.8538 - mean_absolute_error: 11.7002\n",
      "Epoch 3475/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 414.5165 - mean_absolute_error: 11.7150\n",
      "Epoch 3476/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 405.4800 - mean_absolute_error: 11.8690\n",
      "Epoch 3477/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 408.8143 - mean_absolute_error: 11.5815\n",
      "Epoch 3478/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 410.1232 - mean_absolute_error: 11.5091\n",
      "Epoch 3479/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 416.6816 - mean_absolute_error: 11.9031\n",
      "Epoch 3480/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 426.3049 - mean_absolute_error: 12.0036\n",
      "Epoch 3481/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 407.8088 - mean_absolute_error: 11.5692\n",
      "Epoch 3482/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.7575 - mean_absolute_error: 11.7022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3483/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.0841 - mean_absolute_error: 11.9652\n",
      "Epoch 3484/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 410.0292 - mean_absolute_error: 11.6196\n",
      "Epoch 3485/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 402.6375 - mean_absolute_error: 11.6591\n",
      "Epoch 3486/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 397.0791 - mean_absolute_error: 11.3706\n",
      "Epoch 3487/5000\n",
      "344/344 [==============================] - 0s 293us/step - loss: 402.8483 - mean_absolute_error: 11.5873\n",
      "Epoch 3488/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 415.7023 - mean_absolute_error: 12.0081\n",
      "Epoch 3489/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 398.7877 - mean_absolute_error: 11.5181\n",
      "Epoch 3490/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 382.6317 - mean_absolute_error: 11.3392\n",
      "Epoch 3491/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 431.9181 - mean_absolute_error: 12.2963\n",
      "Epoch 3492/5000\n",
      "344/344 [==============================] - 0s 316us/step - loss: 410.2784 - mean_absolute_error: 11.9778\n",
      "Epoch 3493/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 399.3415 - mean_absolute_error: 11.7621\n",
      "Epoch 3494/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 410.2637 - mean_absolute_error: 12.0800\n",
      "Epoch 3495/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.0500 - mean_absolute_error: 11.8397\n",
      "Epoch 3496/5000\n",
      "344/344 [==============================] - 0s 212us/step - loss: 418.1527 - mean_absolute_error: 11.8131\n",
      "Epoch 3497/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 423.6337 - mean_absolute_error: 12.3009\n",
      "Epoch 3498/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 402.9655 - mean_absolute_error: 11.4342\n",
      "Epoch 3499/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 411.7878 - mean_absolute_error: 11.6019\n",
      "Epoch 3500/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 399.8055 - mean_absolute_error: 11.3913\n",
      "Epoch 3501/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 419.5341 - mean_absolute_error: 12.0420\n",
      "Epoch 3502/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 437.8254 - mean_absolute_error: 12.4447\n",
      "Epoch 3503/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 418.7310 - mean_absolute_error: 11.8436\n",
      "Epoch 3504/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 407.8292 - mean_absolute_error: 11.5981\n",
      "Epoch 3505/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 425.3491 - mean_absolute_error: 12.1730\n",
      "Epoch 3506/5000\n",
      "344/344 [==============================] - 0s 256us/step - loss: 400.2000 - mean_absolute_error: 11.7978\n",
      "Epoch 3507/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 424.6281 - mean_absolute_error: 12.1777\n",
      "Epoch 3508/5000\n",
      "344/344 [==============================] - 0s 169us/step - loss: 427.2105 - mean_absolute_error: 11.9857\n",
      "Epoch 3509/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 416.6425 - mean_absolute_error: 12.0432\n",
      "Epoch 3510/5000\n",
      "344/344 [==============================] - 0s 257us/step - loss: 408.6844 - mean_absolute_error: 11.6034\n",
      "Epoch 3511/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 448.5148 - mean_absolute_error: 12.4029\n",
      "Epoch 3512/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 438.4934 - mean_absolute_error: 12.2244\n",
      "Epoch 3513/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 398.7671 - mean_absolute_error: 11.6529\n",
      "Epoch 3514/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 430.6425 - mean_absolute_error: 12.1504\n",
      "Epoch 3515/5000\n",
      "344/344 [==============================] - 0s 210us/step - loss: 399.0096 - mean_absolute_error: 11.3945\n",
      "Epoch 3516/5000\n",
      "344/344 [==============================] - 0s 276us/step - loss: 407.9736 - mean_absolute_error: 11.7325\n",
      "Epoch 3517/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 398.1773 - mean_absolute_error: 11.4711\n",
      "Epoch 3518/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.7118 - mean_absolute_error: 11.8330\n",
      "Epoch 3519/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 421.2818 - mean_absolute_error: 11.9359\n",
      "Epoch 3520/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 414.6651 - mean_absolute_error: 12.1090\n",
      "Epoch 3521/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.7946 - mean_absolute_error: 11.7453\n",
      "Epoch 3522/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.2295 - mean_absolute_error: 11.4892\n",
      "Epoch 3523/5000\n",
      "344/344 [==============================] - 0s 215us/step - loss: 425.1382 - mean_absolute_error: 12.0706\n",
      "Epoch 3524/5000\n",
      "344/344 [==============================] - 0s 214us/step - loss: 407.3671 - mean_absolute_error: 12.0827\n",
      "Epoch 3525/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 406.0428 - mean_absolute_error: 11.7403\n",
      "Epoch 3526/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 431.7109 - mean_absolute_error: 11.9387\n",
      "Epoch 3527/5000\n",
      "344/344 [==============================] - 0s 195us/step - loss: 400.1113 - mean_absolute_error: 11.7420\n",
      "Epoch 3528/5000\n",
      "344/344 [==============================] - 0s 202us/step - loss: 407.2554 - mean_absolute_error: 11.6712\n",
      "Epoch 3529/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 404.9903 - mean_absolute_error: 11.6321\n",
      "Epoch 3530/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 415.5817 - mean_absolute_error: 12.1421\n",
      "Epoch 3531/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 416.1185 - mean_absolute_error: 11.7542\n",
      "Epoch 3532/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.7117 - mean_absolute_error: 11.6825\n",
      "Epoch 3533/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.7913 - mean_absolute_error: 11.7323\n",
      "Epoch 3534/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.3249 - mean_absolute_error: 11.9377\n",
      "Epoch 3535/5000\n",
      "344/344 [==============================] - 0s 219us/step - loss: 432.6822 - mean_absolute_error: 12.5780\n",
      "Epoch 3536/5000\n",
      "344/344 [==============================] - 0s 182us/step - loss: 415.5640 - mean_absolute_error: 11.9191\n",
      "Epoch 3537/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 416.2346 - mean_absolute_error: 11.6799\n",
      "Epoch 3538/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 421.2750 - mean_absolute_error: 11.9544\n",
      "Epoch 3539/5000\n",
      "344/344 [==============================] - 0s 281us/step - loss: 429.0547 - mean_absolute_error: 12.1120\n",
      "Epoch 3540/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 398.0715 - mean_absolute_error: 11.7444\n",
      "Epoch 3541/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.0551 - mean_absolute_error: 11.8958\n",
      "Epoch 3542/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 403.9798 - mean_absolute_error: 11.8047\n",
      "Epoch 3543/5000\n",
      "344/344 [==============================] - 0s 195us/step - loss: 430.1213 - mean_absolute_error: 12.1962\n",
      "Epoch 3544/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.5704 - mean_absolute_error: 11.9678\n",
      "Epoch 3545/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 416.2626 - mean_absolute_error: 12.1117\n",
      "Epoch 3546/5000\n",
      "344/344 [==============================] - 0s 254us/step - loss: 417.2377 - mean_absolute_error: 12.2392\n",
      "Epoch 3547/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 432.1699 - mean_absolute_error: 12.1193\n",
      "Epoch 3548/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 403.9594 - mean_absolute_error: 11.7591\n",
      "Epoch 3549/5000\n",
      "344/344 [==============================] - 0s 212us/step - loss: 410.1225 - mean_absolute_error: 11.5954\n",
      "Epoch 3550/5000\n",
      "344/344 [==============================] - 0s 182us/step - loss: 406.0521 - mean_absolute_error: 11.6574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3551/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 420.7057 - mean_absolute_error: 11.8943\n",
      "Epoch 3552/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 415.4759 - mean_absolute_error: 11.9569\n",
      "Epoch 3553/5000\n",
      "344/344 [==============================] - 0s 284us/step - loss: 411.1916 - mean_absolute_error: 12.1750\n",
      "Epoch 3554/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 411.2649 - mean_absolute_error: 11.9361\n",
      "Epoch 3555/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 402.0937 - mean_absolute_error: 11.6133\n",
      "Epoch 3556/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 394.6636 - mean_absolute_error: 11.3467\n",
      "Epoch 3557/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.8692 - mean_absolute_error: 11.8452\n",
      "Epoch 3558/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 432.3731 - mean_absolute_error: 12.1010\n",
      "Epoch 3559/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 417.3755 - mean_absolute_error: 12.2012\n",
      "Epoch 3560/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 410.4217 - mean_absolute_error: 11.8015\n",
      "Epoch 3561/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 395.4755 - mean_absolute_error: 11.3051\n",
      "Epoch 3562/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 400.1585 - mean_absolute_error: 11.4674\n",
      "Epoch 3563/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 409.5000 - mean_absolute_error: 11.7721\n",
      "Epoch 3564/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 406.4044 - mean_absolute_error: 11.5814\n",
      "Epoch 3565/5000\n",
      "344/344 [==============================] - 0s 179us/step - loss: 410.4801 - mean_absolute_error: 11.9191\n",
      "Epoch 3566/5000\n",
      "344/344 [==============================] - 0s 196us/step - loss: 431.0029 - mean_absolute_error: 11.9732\n",
      "Epoch 3567/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 420.5626 - mean_absolute_error: 12.1066\n",
      "Epoch 3568/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 397.1753 - mean_absolute_error: 11.4748\n",
      "Epoch 3569/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 403.3646 - mean_absolute_error: 11.6745\n",
      "Epoch 3570/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.4604 - mean_absolute_error: 12.0528\n",
      "Epoch 3571/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.9990 - mean_absolute_error: 11.7956\n",
      "Epoch 3572/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 424.7589 - mean_absolute_error: 12.2134\n",
      "Epoch 3573/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.4791 - mean_absolute_error: 11.5276\n",
      "Epoch 3574/5000\n",
      "344/344 [==============================] - 0s 175us/step - loss: 405.2835 - mean_absolute_error: 11.6785\n",
      "Epoch 3575/5000\n",
      "344/344 [==============================] - 0s 218us/step - loss: 400.8073 - mean_absolute_error: 11.4643\n",
      "Epoch 3576/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 411.7948 - mean_absolute_error: 11.7769\n",
      "Epoch 3577/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 411.4909 - mean_absolute_error: 11.6463\n",
      "Epoch 3578/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.6887 - mean_absolute_error: 11.7144\n",
      "Epoch 3579/5000\n",
      "344/344 [==============================] - 0s 208us/step - loss: 417.5129 - mean_absolute_error: 12.1365\n",
      "Epoch 3580/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 425.3670 - mean_absolute_error: 12.0189\n",
      "Epoch 3581/5000\n",
      "344/344 [==============================] - 0s 221us/step - loss: 419.3846 - mean_absolute_error: 11.8838\n",
      "Epoch 3582/5000\n",
      "344/344 [==============================] - 0s 212us/step - loss: 399.1642 - mean_absolute_error: 11.9630\n",
      "Epoch 3583/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 408.8358 - mean_absolute_error: 11.4764\n",
      "Epoch 3584/5000\n",
      "344/344 [==============================] - 0s 182us/step - loss: 395.1823 - mean_absolute_error: 11.5103\n",
      "Epoch 3585/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 426.7782 - mean_absolute_error: 12.0199\n",
      "Epoch 3586/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 416.0701 - mean_absolute_error: 11.9414\n",
      "Epoch 3587/5000\n",
      "344/344 [==============================] - 0s 181us/step - loss: 423.8194 - mean_absolute_error: 12.0734\n",
      "Epoch 3588/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 416.9178 - mean_absolute_error: 12.0589\n",
      "Epoch 3589/5000\n",
      "344/344 [==============================] - 0s 211us/step - loss: 416.3176 - mean_absolute_error: 11.9449\n",
      "Epoch 3590/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.9820 - mean_absolute_error: 11.9466\n",
      "Epoch 3591/5000\n",
      "344/344 [==============================] - 0s 193us/step - loss: 395.0281 - mean_absolute_error: 11.5818\n",
      "Epoch 3592/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 412.1967 - mean_absolute_error: 11.6836\n",
      "Epoch 3593/5000\n",
      "344/344 [==============================] - 0s 186us/step - loss: 397.3408 - mean_absolute_error: 11.3276\n",
      "Epoch 3594/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 418.9005 - mean_absolute_error: 12.0825\n",
      "Epoch 3595/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 424.2767 - mean_absolute_error: 12.0511\n",
      "Epoch 3596/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 423.0564 - mean_absolute_error: 12.2358\n",
      "Epoch 3597/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 415.3114 - mean_absolute_error: 11.9213\n",
      "Epoch 3598/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 393.1918 - mean_absolute_error: 11.3216\n",
      "Epoch 3599/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 423.9164 - mean_absolute_error: 11.9052\n",
      "Epoch 3600/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 408.3641 - mean_absolute_error: 11.6399\n",
      "Epoch 3601/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 409.4768 - mean_absolute_error: 11.5623\n",
      "Epoch 3602/5000\n",
      "344/344 [==============================] - 0s 212us/step - loss: 410.4252 - mean_absolute_error: 11.7743\n",
      "Epoch 3603/5000\n",
      "344/344 [==============================] - 0s 215us/step - loss: 391.7885 - mean_absolute_error: 11.2128\n",
      "Epoch 3604/5000\n",
      "344/344 [==============================] - 0s 204us/step - loss: 432.4178 - mean_absolute_error: 12.3074\n",
      "Epoch 3605/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 413.6511 - mean_absolute_error: 11.8513\n",
      "Epoch 3606/5000\n",
      "344/344 [==============================] - 0s 182us/step - loss: 421.8028 - mean_absolute_error: 12.2075\n",
      "Epoch 3607/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 421.1905 - mean_absolute_error: 12.0222\n",
      "Epoch 3608/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 402.3896 - mean_absolute_error: 11.8146\n",
      "Epoch 3609/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 428.0743 - mean_absolute_error: 12.0054\n",
      "Epoch 3610/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 425.6069 - mean_absolute_error: 11.8198\n",
      "Epoch 3611/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 415.7447 - mean_absolute_error: 11.6286\n",
      "Epoch 3612/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 399.2811 - mean_absolute_error: 11.5808\n",
      "Epoch 3613/5000\n",
      "344/344 [==============================] - 0s 316us/step - loss: 418.1773 - mean_absolute_error: 12.0431\n",
      "Epoch 3614/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 404.5504 - mean_absolute_error: 11.6556\n",
      "Epoch 3615/5000\n",
      "344/344 [==============================] - 0s 203us/step - loss: 437.7495 - mean_absolute_error: 12.3102\n",
      "Epoch 3616/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 401.9828 - mean_absolute_error: 11.5975\n",
      "Epoch 3617/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 429.0068 - mean_absolute_error: 12.4534\n",
      "Epoch 3618/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 428.6302 - mean_absolute_error: 12.1916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3619/5000\n",
      "344/344 [==============================] - 0s 209us/step - loss: 455.1089 - mean_absolute_error: 12.8836\n",
      "Epoch 3620/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 405.6612 - mean_absolute_error: 11.6606\n",
      "Epoch 3621/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 437.3566 - mean_absolute_error: 12.0385\n",
      "Epoch 3622/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 409.7198 - mean_absolute_error: 11.7860\n",
      "Epoch 3623/5000\n",
      "344/344 [==============================] - 0s 200us/step - loss: 389.3176 - mean_absolute_error: 11.4490\n",
      "Epoch 3624/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 403.7509 - mean_absolute_error: 11.8582\n",
      "Epoch 3625/5000\n",
      "344/344 [==============================] - 0s 187us/step - loss: 418.9292 - mean_absolute_error: 11.7072\n",
      "Epoch 3626/5000\n",
      "344/344 [==============================] - 0s 214us/step - loss: 427.1368 - mean_absolute_error: 12.2145\n",
      "Epoch 3627/5000\n",
      "344/344 [==============================] - 0s 221us/step - loss: 420.5967 - mean_absolute_error: 12.0962\n",
      "Epoch 3628/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 412.0266 - mean_absolute_error: 11.9284\n",
      "Epoch 3629/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 416.5742 - mean_absolute_error: 12.0550\n",
      "Epoch 3630/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 393.1768 - mean_absolute_error: 11.2545\n",
      "Epoch 3631/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 411.6326 - mean_absolute_error: 11.4523\n",
      "Epoch 3632/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 410.3595 - mean_absolute_error: 11.8894\n",
      "Epoch 3633/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 410.4430 - mean_absolute_error: 11.7475\n",
      "Epoch 3634/5000\n",
      "344/344 [==============================] - 0s 284us/step - loss: 412.9218 - mean_absolute_error: 11.8494\n",
      "Epoch 3635/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 407.1348 - mean_absolute_error: 11.7731\n",
      "Epoch 3636/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 410.2074 - mean_absolute_error: 11.7653\n",
      "Epoch 3637/5000\n",
      "344/344 [==============================] - 0s 204us/step - loss: 387.9428 - mean_absolute_error: 11.3927\n",
      "Epoch 3638/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 400.3589 - mean_absolute_error: 11.4917\n",
      "Epoch 3639/5000\n",
      "344/344 [==============================] - 0s 182us/step - loss: 395.9021 - mean_absolute_error: 11.5469\n",
      "Epoch 3640/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 409.5977 - mean_absolute_error: 11.6303\n",
      "Epoch 3641/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 411.9643 - mean_absolute_error: 11.7664\n",
      "Epoch 3642/5000\n",
      "344/344 [==============================] - 0s 280us/step - loss: 424.2318 - mean_absolute_error: 11.8257\n",
      "Epoch 3643/5000\n",
      "344/344 [==============================] - 0s 281us/step - loss: 398.8113 - mean_absolute_error: 11.6923\n",
      "Epoch 3644/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 425.7870 - mean_absolute_error: 12.1240\n",
      "Epoch 3645/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.6879 - mean_absolute_error: 11.8256\n",
      "Epoch 3646/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 412.6699 - mean_absolute_error: 11.7795\n",
      "Epoch 3647/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.7709 - mean_absolute_error: 11.8564\n",
      "Epoch 3648/5000\n",
      "344/344 [==============================] - 0s 186us/step - loss: 420.0907 - mean_absolute_error: 11.8402\n",
      "Epoch 3649/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 411.9200 - mean_absolute_error: 11.8279\n",
      "Epoch 3650/5000\n",
      "344/344 [==============================] - 0s 213us/step - loss: 404.6830 - mean_absolute_error: 11.8355\n",
      "Epoch 3651/5000\n",
      "344/344 [==============================] - 0s 181us/step - loss: 407.6552 - mean_absolute_error: 11.9025\n",
      "Epoch 3652/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 412.1771 - mean_absolute_error: 11.8368\n",
      "Epoch 3653/5000\n",
      "344/344 [==============================] - 0s 182us/step - loss: 421.2319 - mean_absolute_error: 12.3106\n",
      "Epoch 3654/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 414.4111 - mean_absolute_error: 11.9466\n",
      "Epoch 3655/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 412.3234 - mean_absolute_error: 11.5417\n",
      "Epoch 3656/5000\n",
      "344/344 [==============================] - 0s 200us/step - loss: 408.8302 - mean_absolute_error: 11.7534\n",
      "Epoch 3657/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 404.9342 - mean_absolute_error: 11.5339\n",
      "Epoch 3658/5000\n",
      "344/344 [==============================] - 0s 199us/step - loss: 395.4869 - mean_absolute_error: 11.4615\n",
      "Epoch 3659/5000\n",
      "344/344 [==============================] - 0s 212us/step - loss: 405.0916 - mean_absolute_error: 11.5716\n",
      "Epoch 3660/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 411.7567 - mean_absolute_error: 11.6275\n",
      "Epoch 3661/5000\n",
      "344/344 [==============================] - 0s 182us/step - loss: 402.7529 - mean_absolute_error: 11.8822\n",
      "Epoch 3662/5000\n",
      "344/344 [==============================] - 0s 217us/step - loss: 410.2137 - mean_absolute_error: 12.0759\n",
      "Epoch 3663/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.9644 - mean_absolute_error: 12.2594\n",
      "Epoch 3664/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 418.0182 - mean_absolute_error: 11.8324\n",
      "Epoch 3665/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 432.9827 - mean_absolute_error: 12.4535\n",
      "Epoch 3666/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.2716 - mean_absolute_error: 12.4027\n",
      "Epoch 3667/5000\n",
      "344/344 [==============================] - 0s 191us/step - loss: 422.4651 - mean_absolute_error: 12.1925\n",
      "Epoch 3668/5000\n",
      "344/344 [==============================] - 0s 274us/step - loss: 399.9973 - mean_absolute_error: 11.3719\n",
      "Epoch 3669/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 378.7837 - mean_absolute_error: 11.2443\n",
      "Epoch 3670/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 402.6781 - mean_absolute_error: 11.4426\n",
      "Epoch 3671/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 416.9311 - mean_absolute_error: 11.9128\n",
      "Epoch 3672/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.9923 - mean_absolute_error: 12.2311\n",
      "Epoch 3673/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 400.1555 - mean_absolute_error: 11.5372\n",
      "Epoch 3674/5000\n",
      "344/344 [==============================] - 0s 207us/step - loss: 403.9469 - mean_absolute_error: 11.8480\n",
      "Epoch 3675/5000\n",
      "344/344 [==============================] - 0s 195us/step - loss: 418.6282 - mean_absolute_error: 11.9197\n",
      "Epoch 3676/5000\n",
      "344/344 [==============================] - 0s 201us/step - loss: 440.4283 - mean_absolute_error: 12.1355\n",
      "Epoch 3677/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 425.1814 - mean_absolute_error: 12.1346\n",
      "Epoch 3678/5000\n",
      "344/344 [==============================] - 0s 202us/step - loss: 407.9184 - mean_absolute_error: 11.3250\n",
      "Epoch 3679/5000\n",
      "344/344 [==============================] - 0s 256us/step - loss: 421.4725 - mean_absolute_error: 11.7511\n",
      "Epoch 3680/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 416.7295 - mean_absolute_error: 12.0058\n",
      "Epoch 3681/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 407.6983 - mean_absolute_error: 12.1594\n",
      "Epoch 3682/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 412.3711 - mean_absolute_error: 12.0612\n",
      "Epoch 3683/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.6400 - mean_absolute_error: 11.9445\n",
      "Epoch 3684/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 393.6871 - mean_absolute_error: 11.7964\n",
      "Epoch 3685/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 403.5661 - mean_absolute_error: 11.6391\n",
      "Epoch 3686/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 414.1367 - mean_absolute_error: 11.5037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3687/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.1811 - mean_absolute_error: 11.9436\n",
      "Epoch 3688/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.9810 - mean_absolute_error: 11.9229\n",
      "Epoch 3689/5000\n",
      "344/344 [==============================] - 0s 211us/step - loss: 402.7065 - mean_absolute_error: 11.8088\n",
      "Epoch 3690/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 398.1434 - mean_absolute_error: 11.6888\n",
      "Epoch 3691/5000\n",
      "344/344 [==============================] - 0s 211us/step - loss: 416.3491 - mean_absolute_error: 11.9992\n",
      "Epoch 3692/5000\n",
      "344/344 [==============================] - 0s 250us/step - loss: 427.9876 - mean_absolute_error: 11.7177\n",
      "Epoch 3693/5000\n",
      "344/344 [==============================] - 0s 310us/step - loss: 403.8307 - mean_absolute_error: 11.9113\n",
      "Epoch 3694/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 401.4942 - mean_absolute_error: 11.2523\n",
      "Epoch 3695/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.8834 - mean_absolute_error: 11.4783\n",
      "Epoch 3696/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 426.8922 - mean_absolute_error: 12.2140\n",
      "Epoch 3697/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.9200 - mean_absolute_error: 11.3872\n",
      "Epoch 3698/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 401.4493 - mean_absolute_error: 11.7603\n",
      "Epoch 3699/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 397.3004 - mean_absolute_error: 11.6939\n",
      "Epoch 3700/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 381.3388 - mean_absolute_error: 11.3632\n",
      "Epoch 3701/5000\n",
      "344/344 [==============================] - 0s 200us/step - loss: 440.9046 - mean_absolute_error: 12.4796\n",
      "Epoch 3702/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 403.4203 - mean_absolute_error: 11.6533\n",
      "Epoch 3703/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.5224 - mean_absolute_error: 11.7367\n",
      "Epoch 3704/5000\n",
      "344/344 [==============================] - 0s 209us/step - loss: 399.0051 - mean_absolute_error: 11.6921\n",
      "Epoch 3705/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 415.9558 - mean_absolute_error: 11.6225\n",
      "Epoch 3706/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 396.2521 - mean_absolute_error: 11.4423\n",
      "Epoch 3707/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 404.6018 - mean_absolute_error: 11.6519\n",
      "Epoch 3708/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 413.0361 - mean_absolute_error: 11.9767\n",
      "Epoch 3709/5000\n",
      "344/344 [==============================] - 0s 296us/step - loss: 417.6573 - mean_absolute_error: 11.6595\n",
      "Epoch 3710/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 406.0255 - mean_absolute_error: 11.6892\n",
      "Epoch 3711/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.1769 - mean_absolute_error: 11.8874\n",
      "Epoch 3712/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 429.0691 - mean_absolute_error: 12.0977\n",
      "Epoch 3713/5000\n",
      "344/344 [==============================] - 0s 218us/step - loss: 409.5647 - mean_absolute_error: 11.7068\n",
      "Epoch 3714/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 419.8071 - mean_absolute_error: 11.9907\n",
      "Epoch 3715/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.2644 - mean_absolute_error: 12.1545\n",
      "Epoch 3716/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.6223 - mean_absolute_error: 11.9286\n",
      "Epoch 3717/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 408.0977 - mean_absolute_error: 11.8673\n",
      "Epoch 3718/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 428.0087 - mean_absolute_error: 12.0591\n",
      "Epoch 3719/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 410.4211 - mean_absolute_error: 12.0671\n",
      "Epoch 3720/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 407.8827 - mean_absolute_error: 12.2500\n",
      "Epoch 3721/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 405.6162 - mean_absolute_error: 11.8125\n",
      "Epoch 3722/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 402.4331 - mean_absolute_error: 11.6006\n",
      "Epoch 3723/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 400.4134 - mean_absolute_error: 11.6251\n",
      "Epoch 3724/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.7307 - mean_absolute_error: 11.5719\n",
      "Epoch 3725/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 411.7953 - mean_absolute_error: 12.0066\n",
      "Epoch 3726/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.3932 - mean_absolute_error: 12.1970\n",
      "Epoch 3727/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 405.0495 - mean_absolute_error: 11.8627\n",
      "Epoch 3728/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 407.5369 - mean_absolute_error: 11.7792\n",
      "Epoch 3729/5000\n",
      "344/344 [==============================] - 0s 271us/step - loss: 422.5104 - mean_absolute_error: 11.9347\n",
      "Epoch 3730/5000\n",
      "344/344 [==============================] - 0s 254us/step - loss: 417.0156 - mean_absolute_error: 11.8233\n",
      "Epoch 3731/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 416.6999 - mean_absolute_error: 11.9632\n",
      "Epoch 3732/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 408.8665 - mean_absolute_error: 11.6885\n",
      "Epoch 3733/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 433.8727 - mean_absolute_error: 12.1561\n",
      "Epoch 3734/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 418.2329 - mean_absolute_error: 12.3413\n",
      "Epoch 3735/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 417.4649 - mean_absolute_error: 12.2388\n",
      "Epoch 3736/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 462.4460 - mean_absolute_error: 12.4691\n",
      "Epoch 3737/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 408.0719 - mean_absolute_error: 11.7164\n",
      "Epoch 3738/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 402.4266 - mean_absolute_error: 11.3472\n",
      "Epoch 3739/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 428.0598 - mean_absolute_error: 12.1952\n",
      "Epoch 3740/5000\n",
      "344/344 [==============================] - 0s 297us/step - loss: 391.0707 - mean_absolute_error: 11.4524\n",
      "Epoch 3741/5000\n",
      "344/344 [==============================] - 0s 274us/step - loss: 415.9395 - mean_absolute_error: 11.8301\n",
      "Epoch 3742/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 412.9451 - mean_absolute_error: 11.9158\n",
      "Epoch 3743/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 403.0884 - mean_absolute_error: 11.7516\n",
      "Epoch 3744/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 404.4784 - mean_absolute_error: 11.6646\n",
      "Epoch 3745/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 423.5478 - mean_absolute_error: 12.3029\n",
      "Epoch 3746/5000\n",
      "344/344 [==============================] - 0s 219us/step - loss: 411.3874 - mean_absolute_error: 11.8425\n",
      "Epoch 3747/5000\n",
      "344/344 [==============================] - 0s 216us/step - loss: 421.6842 - mean_absolute_error: 11.8480\n",
      "Epoch 3748/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.1631 - mean_absolute_error: 12.2899\n",
      "Epoch 3749/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.2136 - mean_absolute_error: 11.7271\n",
      "Epoch 3750/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 423.7039 - mean_absolute_error: 12.0184\n",
      "Epoch 3751/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 415.9987 - mean_absolute_error: 12.1125\n",
      "Epoch 3752/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.4706 - mean_absolute_error: 11.7874\n",
      "Epoch 3753/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 418.2035 - mean_absolute_error: 12.0809\n",
      "Epoch 3754/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 426.2611 - mean_absolute_error: 12.1079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3755/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 412.4438 - mean_absolute_error: 11.6078\n",
      "Epoch 3756/5000\n",
      "344/344 [==============================] - 0s 218us/step - loss: 416.0483 - mean_absolute_error: 12.0459\n",
      "Epoch 3757/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 400.1570 - mean_absolute_error: 11.5392\n",
      "Epoch 3758/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 406.4781 - mean_absolute_error: 11.8279\n",
      "Epoch 3759/5000\n",
      "344/344 [==============================] - 0s 215us/step - loss: 406.7022 - mean_absolute_error: 11.7468\n",
      "Epoch 3760/5000\n",
      "344/344 [==============================] - 0s 215us/step - loss: 402.6464 - mean_absolute_error: 11.6732\n",
      "Epoch 3761/5000\n",
      "344/344 [==============================] - 0s 215us/step - loss: 412.6017 - mean_absolute_error: 11.5707\n",
      "Epoch 3762/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 385.5466 - mean_absolute_error: 11.2286\n",
      "Epoch 3763/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.6870 - mean_absolute_error: 11.9549\n",
      "Epoch 3764/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.0167 - mean_absolute_error: 12.1125\n",
      "Epoch 3765/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 397.1160 - mean_absolute_error: 11.7784\n",
      "Epoch 3766/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 409.9737 - mean_absolute_error: 11.7803\n",
      "Epoch 3767/5000\n",
      "344/344 [==============================] - 0s 219us/step - loss: 394.2899 - mean_absolute_error: 11.3739\n",
      "Epoch 3768/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 430.5072 - mean_absolute_error: 12.4173\n",
      "Epoch 3769/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 437.1518 - mean_absolute_error: 12.1572\n",
      "Epoch 3770/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 407.0837 - mean_absolute_error: 11.6201\n",
      "Epoch 3771/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 386.5956 - mean_absolute_error: 11.3890\n",
      "Epoch 3772/5000\n",
      "344/344 [==============================] - 0s 215us/step - loss: 427.1801 - mean_absolute_error: 12.3283\n",
      "Epoch 3773/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 428.9037 - mean_absolute_error: 12.2409\n",
      "Epoch 3774/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 415.4363 - mean_absolute_error: 12.1533\n",
      "Epoch 3775/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.0443 - mean_absolute_error: 11.9576\n",
      "Epoch 3776/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 400.0161 - mean_absolute_error: 11.5439\n",
      "Epoch 3777/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 400.1202 - mean_absolute_error: 11.4398\n",
      "Epoch 3778/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 412.9664 - mean_absolute_error: 12.0181\n",
      "Epoch 3779/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 415.0248 - mean_absolute_error: 11.6754\n",
      "Epoch 3780/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 397.4701 - mean_absolute_error: 11.5084\n",
      "Epoch 3781/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.2675 - mean_absolute_error: 11.8698\n",
      "Epoch 3782/5000\n",
      "344/344 [==============================] - 0s 222us/step - loss: 414.8455 - mean_absolute_error: 11.8885\n",
      "Epoch 3783/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 384.5798 - mean_absolute_error: 11.3989\n",
      "Epoch 3784/5000\n",
      "344/344 [==============================] - 0s 222us/step - loss: 410.5521 - mean_absolute_error: 11.9981\n",
      "Epoch 3785/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 405.5292 - mean_absolute_error: 11.6672\n",
      "Epoch 3786/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 527.9738 - mean_absolute_error: 12.5803\n",
      "Epoch 3787/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 424.5070 - mean_absolute_error: 11.9278\n",
      "Epoch 3788/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 418.3732 - mean_absolute_error: 12.1933\n",
      "Epoch 3789/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 395.7255 - mean_absolute_error: 11.3749\n",
      "Epoch 3790/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 401.2828 - mean_absolute_error: 11.6426\n",
      "Epoch 3791/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 417.6765 - mean_absolute_error: 11.9191\n",
      "Epoch 3792/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 423.0287 - mean_absolute_error: 11.9429\n",
      "Epoch 3793/5000\n",
      "344/344 [==============================] - 0s 299us/step - loss: 428.1610 - mean_absolute_error: 11.8800\n",
      "Epoch 3794/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 416.6233 - mean_absolute_error: 12.0932\n",
      "Epoch 3795/5000\n",
      "344/344 [==============================] - 0s 213us/step - loss: 411.9841 - mean_absolute_error: 11.8416\n",
      "Epoch 3796/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 398.4151 - mean_absolute_error: 11.5433\n",
      "Epoch 3797/5000\n",
      "344/344 [==============================] - 0s 217us/step - loss: 385.4590 - mean_absolute_error: 11.5017\n",
      "Epoch 3798/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.5451 - mean_absolute_error: 11.6984\n",
      "Epoch 3799/5000\n",
      "344/344 [==============================] - 0s 217us/step - loss: 395.5679 - mean_absolute_error: 11.5758\n",
      "Epoch 3800/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.8335 - mean_absolute_error: 11.8557\n",
      "Epoch 3801/5000\n",
      "344/344 [==============================] - 0s 332us/step - loss: 425.6108 - mean_absolute_error: 12.2451\n",
      "Epoch 3802/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 397.4141 - mean_absolute_error: 11.4551\n",
      "Epoch 3803/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 414.7032 - mean_absolute_error: 11.9927\n",
      "Epoch 3804/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 399.8857 - mean_absolute_error: 11.4424\n",
      "Epoch 3805/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 430.5581 - mean_absolute_error: 12.3313\n",
      "Epoch 3806/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 419.6574 - mean_absolute_error: 12.1357\n",
      "Epoch 3807/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 412.3040 - mean_absolute_error: 11.7897\n",
      "Epoch 3808/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 409.4962 - mean_absolute_error: 12.0053\n",
      "Epoch 3809/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 400.4042 - mean_absolute_error: 11.7039\n",
      "Epoch 3810/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 425.9642 - mean_absolute_error: 12.1796\n",
      "Epoch 3811/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 393.9238 - mean_absolute_error: 11.6462\n",
      "Epoch 3812/5000\n",
      "344/344 [==============================] - 0s 218us/step - loss: 401.8159 - mean_absolute_error: 11.8443\n",
      "Epoch 3813/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 387.1123 - mean_absolute_error: 11.2740\n",
      "Epoch 3814/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.3351 - mean_absolute_error: 11.7298\n",
      "Epoch 3815/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.6721 - mean_absolute_error: 12.1773\n",
      "Epoch 3816/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.6271 - mean_absolute_error: 11.7505\n",
      "Epoch 3817/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 404.1307 - mean_absolute_error: 11.4409\n",
      "Epoch 3818/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 419.0818 - mean_absolute_error: 11.9559\n",
      "Epoch 3819/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.8353 - mean_absolute_error: 12.1532\n",
      "Epoch 3820/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.1491 - mean_absolute_error: 11.5955\n",
      "Epoch 3821/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 411.7047 - mean_absolute_error: 11.5768\n",
      "Epoch 3822/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 401.7727 - mean_absolute_error: 11.7872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3823/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 401.6923 - mean_absolute_error: 11.5903\n",
      "Epoch 3824/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 403.4412 - mean_absolute_error: 11.7292\n",
      "Epoch 3825/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 398.6582 - mean_absolute_error: 11.4819\n",
      "Epoch 3826/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 423.8557 - mean_absolute_error: 11.9533\n",
      "Epoch 3827/5000\n",
      "344/344 [==============================] - 0s 309us/step - loss: 418.2232 - mean_absolute_error: 11.6459\n",
      "Epoch 3828/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 403.6788 - mean_absolute_error: 11.8707\n",
      "Epoch 3829/5000\n",
      "344/344 [==============================] - 0s 271us/step - loss: 401.0312 - mean_absolute_error: 11.7329\n",
      "Epoch 3830/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 398.4183 - mean_absolute_error: 11.4898\n",
      "Epoch 3831/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 435.5818 - mean_absolute_error: 12.2658\n",
      "Epoch 3832/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.1071 - mean_absolute_error: 11.7747\n",
      "Epoch 3833/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 431.4511 - mean_absolute_error: 12.2949\n",
      "Epoch 3834/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.6667 - mean_absolute_error: 12.0692\n",
      "Epoch 3835/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 401.2997 - mean_absolute_error: 11.2026\n",
      "Epoch 3836/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.2065 - mean_absolute_error: 12.3058\n",
      "Epoch 3837/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 397.1491 - mean_absolute_error: 11.5633\n",
      "Epoch 3838/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 408.1584 - mean_absolute_error: 11.7448\n",
      "Epoch 3839/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 398.7127 - mean_absolute_error: 11.7654\n",
      "Epoch 3840/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 428.9926 - mean_absolute_error: 12.1226\n",
      "Epoch 3841/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 406.1795 - mean_absolute_error: 11.5620\n",
      "Epoch 3842/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 432.2074 - mean_absolute_error: 12.4288\n",
      "Epoch 3843/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 426.3843 - mean_absolute_error: 11.8883\n",
      "Epoch 3844/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.2805 - mean_absolute_error: 11.7980\n",
      "Epoch 3845/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 404.9504 - mean_absolute_error: 11.9196\n",
      "Epoch 3846/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 399.4217 - mean_absolute_error: 11.5398\n",
      "Epoch 3847/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 415.4248 - mean_absolute_error: 11.8830\n",
      "Epoch 3848/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 421.2855 - mean_absolute_error: 11.8740\n",
      "Epoch 3849/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 408.4304 - mean_absolute_error: 11.7833\n",
      "Epoch 3850/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 441.5140 - mean_absolute_error: 12.0907\n",
      "Epoch 3851/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.1716 - mean_absolute_error: 12.3320\n",
      "Epoch 3852/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 406.3510 - mean_absolute_error: 11.7063\n",
      "Epoch 3853/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.1711 - mean_absolute_error: 11.9041\n",
      "Epoch 3854/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.1671 - mean_absolute_error: 11.5954\n",
      "Epoch 3855/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 398.4369 - mean_absolute_error: 11.4191\n",
      "Epoch 3856/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 393.2770 - mean_absolute_error: 11.3853\n",
      "Epoch 3857/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.3654 - mean_absolute_error: 12.2284\n",
      "Epoch 3858/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 393.9792 - mean_absolute_error: 11.4050\n",
      "Epoch 3859/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 399.9056 - mean_absolute_error: 11.4318\n",
      "Epoch 3860/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 393.0972 - mean_absolute_error: 11.3835\n",
      "Epoch 3861/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 401.3210 - mean_absolute_error: 11.4724\n",
      "Epoch 3862/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.5309 - mean_absolute_error: 11.7738\n",
      "Epoch 3863/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 399.9383 - mean_absolute_error: 11.6674\n",
      "Epoch 3864/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.2132 - mean_absolute_error: 12.1806\n",
      "Epoch 3865/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.8748 - mean_absolute_error: 12.0617\n",
      "Epoch 3866/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 424.0104 - mean_absolute_error: 11.9547\n",
      "Epoch 3867/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.9888 - mean_absolute_error: 11.9845\n",
      "Epoch 3868/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 411.1931 - mean_absolute_error: 11.7949\n",
      "Epoch 3869/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 422.8184 - mean_absolute_error: 12.0430\n",
      "Epoch 3870/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 429.2739 - mean_absolute_error: 12.3188\n",
      "Epoch 3871/5000\n",
      "344/344 [==============================] - 0s 222us/step - loss: 400.3575 - mean_absolute_error: 11.6809\n",
      "Epoch 3872/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.9786 - mean_absolute_error: 11.9389\n",
      "Epoch 3873/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.1965 - mean_absolute_error: 12.1456\n",
      "Epoch 3874/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.1928 - mean_absolute_error: 11.9237\n",
      "Epoch 3875/5000\n",
      "344/344 [==============================] - 0s 224us/step - loss: 413.1616 - mean_absolute_error: 11.9757\n",
      "Epoch 3876/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 408.7951 - mean_absolute_error: 12.1029\n",
      "Epoch 3877/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 395.5954 - mean_absolute_error: 11.5653\n",
      "Epoch 3878/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.9326 - mean_absolute_error: 12.0726\n",
      "Epoch 3879/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 404.3233 - mean_absolute_error: 11.5537\n",
      "Epoch 3880/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.0215 - mean_absolute_error: 11.8061\n",
      "Epoch 3881/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.3527 - mean_absolute_error: 11.9874\n",
      "Epoch 3882/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 410.3129 - mean_absolute_error: 11.7816\n",
      "Epoch 3883/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 419.3814 - mean_absolute_error: 12.0288\n",
      "Epoch 3884/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 395.3175 - mean_absolute_error: 11.8405\n",
      "Epoch 3885/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 398.9752 - mean_absolute_error: 11.7035\n",
      "Epoch 3886/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 434.6361 - mean_absolute_error: 12.3775\n",
      "Epoch 3887/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 428.8369 - mean_absolute_error: 12.1796\n",
      "Epoch 3888/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.7609 - mean_absolute_error: 11.4667\n",
      "Epoch 3889/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 406.7246 - mean_absolute_error: 11.6127\n",
      "Epoch 3890/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.7658 - mean_absolute_error: 11.8883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3891/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.6545 - mean_absolute_error: 11.5917\n",
      "Epoch 3892/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 412.3662 - mean_absolute_error: 12.0534\n",
      "Epoch 3893/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.7413 - mean_absolute_error: 11.6117\n",
      "Epoch 3894/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.6289 - mean_absolute_error: 11.9541\n",
      "Epoch 3895/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 415.4592 - mean_absolute_error: 12.0582\n",
      "Epoch 3896/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.8553 - mean_absolute_error: 11.4840\n",
      "Epoch 3897/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 395.1511 - mean_absolute_error: 11.2682\n",
      "Epoch 3898/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 415.0951 - mean_absolute_error: 12.1011\n",
      "Epoch 3899/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.7560 - mean_absolute_error: 11.6611\n",
      "Epoch 3900/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.4262 - mean_absolute_error: 11.6310\n",
      "Epoch 3901/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.0776 - mean_absolute_error: 11.8771\n",
      "Epoch 3902/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.5261 - mean_absolute_error: 12.2902\n",
      "Epoch 3903/5000\n",
      "344/344 [==============================] - 0s 299us/step - loss: 418.1154 - mean_absolute_error: 11.7531\n",
      "Epoch 3904/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 391.8272 - mean_absolute_error: 11.3706\n",
      "Epoch 3905/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 416.8368 - mean_absolute_error: 12.1930\n",
      "Epoch 3906/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 401.7765 - mean_absolute_error: 11.5421\n",
      "Epoch 3907/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 412.6929 - mean_absolute_error: 11.8879\n",
      "Epoch 3908/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 409.3189 - mean_absolute_error: 11.9413\n",
      "Epoch 3909/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 418.6141 - mean_absolute_error: 12.0584\n",
      "Epoch 3910/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 424.0351 - mean_absolute_error: 12.1270\n",
      "Epoch 3911/5000\n",
      "344/344 [==============================] - 0s 271us/step - loss: 436.6394 - mean_absolute_error: 12.0744\n",
      "Epoch 3912/5000\n",
      "344/344 [==============================] - 0s 260us/step - loss: 410.2781 - mean_absolute_error: 11.8811\n",
      "Epoch 3913/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.7701 - mean_absolute_error: 11.7687\n",
      "Epoch 3914/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 393.8938 - mean_absolute_error: 11.5901\n",
      "Epoch 3915/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 398.2340 - mean_absolute_error: 11.6498\n",
      "Epoch 3916/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 383.2485 - mean_absolute_error: 11.0425\n",
      "Epoch 3917/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.4411 - mean_absolute_error: 12.0874\n",
      "Epoch 3918/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.9561 - mean_absolute_error: 11.9777\n",
      "Epoch 3919/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.5638 - mean_absolute_error: 11.8248\n",
      "Epoch 3920/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 427.5430 - mean_absolute_error: 11.9802\n",
      "Epoch 3921/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 414.7067 - mean_absolute_error: 11.8317\n",
      "Epoch 3922/5000\n",
      "344/344 [==============================] - 0s 274us/step - loss: 420.9138 - mean_absolute_error: 12.2679\n",
      "Epoch 3923/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 418.5654 - mean_absolute_error: 11.8817\n",
      "Epoch 3924/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 407.7010 - mean_absolute_error: 11.8419\n",
      "Epoch 3925/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 423.0612 - mean_absolute_error: 12.2748\n",
      "Epoch 3926/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 428.4277 - mean_absolute_error: 11.8887\n",
      "Epoch 3927/5000\n",
      "344/344 [==============================] - 0s 281us/step - loss: 393.3076 - mean_absolute_error: 11.6012\n",
      "Epoch 3928/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 400.3195 - mean_absolute_error: 11.5504\n",
      "Epoch 3929/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 416.8298 - mean_absolute_error: 11.6840\n",
      "Epoch 3930/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 384.7093 - mean_absolute_error: 11.4259\n",
      "Epoch 3931/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 424.3549 - mean_absolute_error: 11.8787\n",
      "Epoch 3932/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 408.1300 - mean_absolute_error: 11.7143\n",
      "Epoch 3933/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 404.7285 - mean_absolute_error: 11.6923\n",
      "Epoch 3934/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 424.6307 - mean_absolute_error: 11.8708\n",
      "Epoch 3935/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 415.9232 - mean_absolute_error: 11.7234\n",
      "Epoch 3936/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 414.1996 - mean_absolute_error: 11.6444\n",
      "Epoch 3937/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 421.2972 - mean_absolute_error: 11.6843\n",
      "Epoch 3938/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 405.1766 - mean_absolute_error: 11.8194\n",
      "Epoch 3939/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.1098 - mean_absolute_error: 11.8724\n",
      "Epoch 3940/5000\n",
      "344/344 [==============================] - 0s 267us/step - loss: 414.3058 - mean_absolute_error: 11.9643\n",
      "Epoch 3941/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 419.6458 - mean_absolute_error: 12.1830\n",
      "Epoch 3942/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 397.2072 - mean_absolute_error: 11.6206\n",
      "Epoch 3943/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 415.1987 - mean_absolute_error: 11.9758\n",
      "Epoch 3944/5000\n",
      "344/344 [==============================] - 0s 271us/step - loss: 419.1337 - mean_absolute_error: 12.0506\n",
      "Epoch 3945/5000\n",
      "344/344 [==============================] - 0s 279us/step - loss: 398.9610 - mean_absolute_error: 11.6093\n",
      "Epoch 3946/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.7678 - mean_absolute_error: 11.9877\n",
      "Epoch 3947/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 398.2448 - mean_absolute_error: 11.5085\n",
      "Epoch 3948/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 417.3434 - mean_absolute_error: 12.2576\n",
      "Epoch 3949/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 396.6536 - mean_absolute_error: 11.3995\n",
      "Epoch 3950/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 400.8924 - mean_absolute_error: 11.9271\n",
      "Epoch 3951/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 407.7420 - mean_absolute_error: 11.9670\n",
      "Epoch 3952/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 404.5082 - mean_absolute_error: 11.7316\n",
      "Epoch 3953/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 422.5212 - mean_absolute_error: 12.0178\n",
      "Epoch 3954/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 423.3081 - mean_absolute_error: 11.9654\n",
      "Epoch 3955/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.0280 - mean_absolute_error: 11.4766\n",
      "Epoch 3956/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 418.9601 - mean_absolute_error: 11.8640\n",
      "Epoch 3957/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 428.7648 - mean_absolute_error: 12.2671\n",
      "Epoch 3958/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.0904 - mean_absolute_error: 11.9593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3959/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 426.2949 - mean_absolute_error: 11.9808\n",
      "Epoch 3960/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 411.7200 - mean_absolute_error: 11.7930\n",
      "Epoch 3961/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 401.7069 - mean_absolute_error: 11.2870\n",
      "Epoch 3962/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 412.8448 - mean_absolute_error: 12.1146\n",
      "Epoch 3963/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 404.8841 - mean_absolute_error: 11.7326\n",
      "Epoch 3964/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 405.3811 - mean_absolute_error: 11.8244\n",
      "Epoch 3965/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 411.7157 - mean_absolute_error: 11.8921\n",
      "Epoch 3966/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 401.5948 - mean_absolute_error: 11.4215\n",
      "Epoch 3967/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 413.4767 - mean_absolute_error: 12.0415\n",
      "Epoch 3968/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.6756 - mean_absolute_error: 11.8590\n",
      "Epoch 3969/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 386.0182 - mean_absolute_error: 11.3813\n",
      "Epoch 3970/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 420.3891 - mean_absolute_error: 12.2943\n",
      "Epoch 3971/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 402.7266 - mean_absolute_error: 11.6242\n",
      "Epoch 3972/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 402.1440 - mean_absolute_error: 11.6476\n",
      "Epoch 3973/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 394.9861 - mean_absolute_error: 11.5828\n",
      "Epoch 3974/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.4388 - mean_absolute_error: 11.9611\n",
      "Epoch 3975/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.0529 - mean_absolute_error: 11.5113\n",
      "Epoch 3976/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 418.3060 - mean_absolute_error: 12.1659\n",
      "Epoch 3977/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.6845 - mean_absolute_error: 11.9265\n",
      "Epoch 3978/5000\n",
      "344/344 [==============================] - 0s 256us/step - loss: 401.4822 - mean_absolute_error: 11.5438\n",
      "Epoch 3979/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 396.7567 - mean_absolute_error: 11.6902\n",
      "Epoch 3980/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 415.4650 - mean_absolute_error: 11.7995\n",
      "Epoch 3981/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 404.3408 - mean_absolute_error: 11.6478\n",
      "Epoch 3982/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 413.4641 - mean_absolute_error: 11.8461\n",
      "Epoch 3983/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 424.2578 - mean_absolute_error: 11.9176\n",
      "Epoch 3984/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 424.2492 - mean_absolute_error: 12.2337\n",
      "Epoch 3985/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 400.9344 - mean_absolute_error: 11.6857\n",
      "Epoch 3986/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 408.3903 - mean_absolute_error: 11.9631\n",
      "Epoch 3987/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 394.6172 - mean_absolute_error: 11.7547\n",
      "Epoch 3988/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 420.2045 - mean_absolute_error: 12.0536\n",
      "Epoch 3989/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 415.5007 - mean_absolute_error: 11.7623\n",
      "Epoch 3990/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 419.0159 - mean_absolute_error: 12.0741\n",
      "Epoch 3991/5000\n",
      "344/344 [==============================] - 0s 262us/step - loss: 439.2999 - mean_absolute_error: 12.2765\n",
      "Epoch 3992/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 431.6525 - mean_absolute_error: 12.1531\n",
      "Epoch 3993/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.8642 - mean_absolute_error: 11.7570\n",
      "Epoch 3994/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.0735 - mean_absolute_error: 11.7611\n",
      "Epoch 3995/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 400.7235 - mean_absolute_error: 11.8498\n",
      "Epoch 3996/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.7389 - mean_absolute_error: 11.7378\n",
      "Epoch 3997/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 400.2816 - mean_absolute_error: 11.4684\n",
      "Epoch 3998/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.8311 - mean_absolute_error: 12.2341\n",
      "Epoch 3999/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.9012 - mean_absolute_error: 11.8561\n",
      "Epoch 4000/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 446.6849 - mean_absolute_error: 12.5882\n",
      "Epoch 4001/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 424.0445 - mean_absolute_error: 12.0008\n",
      "Epoch 4002/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 411.6249 - mean_absolute_error: 11.8583\n",
      "Epoch 4003/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 406.5822 - mean_absolute_error: 11.6393\n",
      "Epoch 4004/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.5783 - mean_absolute_error: 12.2306\n",
      "Epoch 4005/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.3859 - mean_absolute_error: 12.2523\n",
      "Epoch 4006/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.3665 - mean_absolute_error: 12.0262\n",
      "Epoch 4007/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 400.1528 - mean_absolute_error: 11.5013\n",
      "Epoch 4008/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 393.6499 - mean_absolute_error: 11.4168\n",
      "Epoch 4009/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 404.0432 - mean_absolute_error: 11.8046\n",
      "Epoch 4010/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 419.4644 - mean_absolute_error: 12.0329\n",
      "Epoch 4011/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.9280 - mean_absolute_error: 11.6952\n",
      "Epoch 4012/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 404.2515 - mean_absolute_error: 11.6256\n",
      "Epoch 4013/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 392.0076 - mean_absolute_error: 11.6177\n",
      "Epoch 4014/5000\n",
      "344/344 [==============================] - 0s 273us/step - loss: 419.4105 - mean_absolute_error: 12.2148\n",
      "Epoch 4015/5000\n",
      "344/344 [==============================] - 0s 281us/step - loss: 413.3336 - mean_absolute_error: 12.0932\n",
      "Epoch 4016/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 418.1240 - mean_absolute_error: 11.9033\n",
      "Epoch 4017/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 411.7355 - mean_absolute_error: 11.6421\n",
      "Epoch 4018/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 409.3532 - mean_absolute_error: 11.5591\n",
      "Epoch 4019/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.7502 - mean_absolute_error: 11.8224\n",
      "Epoch 4020/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 406.4902 - mean_absolute_error: 11.8003\n",
      "Epoch 4021/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 421.8868 - mean_absolute_error: 12.1280\n",
      "Epoch 4022/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.1663 - mean_absolute_error: 12.0204\n",
      "Epoch 4023/5000\n",
      "344/344 [==============================] - 0s 254us/step - loss: 429.3273 - mean_absolute_error: 12.1219\n",
      "Epoch 4024/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 418.7906 - mean_absolute_error: 12.1106\n",
      "Epoch 4025/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 422.0209 - mean_absolute_error: 12.0421\n",
      "Epoch 4026/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 402.7167 - mean_absolute_error: 11.7516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4027/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 410.9423 - mean_absolute_error: 11.6624\n",
      "Epoch 4028/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 423.3038 - mean_absolute_error: 12.0086\n",
      "Epoch 4029/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 408.3171 - mean_absolute_error: 11.7447\n",
      "Epoch 4030/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 457.7243 - mean_absolute_error: 12.2396\n",
      "Epoch 4031/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.5499 - mean_absolute_error: 11.7428\n",
      "Epoch 4032/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 401.7551 - mean_absolute_error: 11.3982\n",
      "Epoch 4033/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.8922 - mean_absolute_error: 12.0531\n",
      "Epoch 4034/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 397.4524 - mean_absolute_error: 11.3791\n",
      "Epoch 4035/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 395.2992 - mean_absolute_error: 11.5804\n",
      "Epoch 4036/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 419.2632 - mean_absolute_error: 12.0319\n",
      "Epoch 4037/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 405.9173 - mean_absolute_error: 11.8606\n",
      "Epoch 4038/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 401.4186 - mean_absolute_error: 11.7068\n",
      "Epoch 4039/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 422.1227 - mean_absolute_error: 12.1570\n",
      "Epoch 4040/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 382.1109 - mean_absolute_error: 11.2425\n",
      "Epoch 4041/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 416.4503 - mean_absolute_error: 11.7531\n",
      "Epoch 4042/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.7706 - mean_absolute_error: 11.6736\n",
      "Epoch 4043/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 393.4641 - mean_absolute_error: 11.3715\n",
      "Epoch 4044/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 408.8479 - mean_absolute_error: 11.6179\n",
      "Epoch 4045/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.7690 - mean_absolute_error: 11.6121\n",
      "Epoch 4046/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 440.5168 - mean_absolute_error: 12.0771\n",
      "Epoch 4047/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 406.9105 - mean_absolute_error: 11.8929\n",
      "Epoch 4048/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 446.3516 - mean_absolute_error: 12.0244\n",
      "Epoch 4049/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 410.4743 - mean_absolute_error: 11.9629\n",
      "Epoch 4050/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 416.3893 - mean_absolute_error: 11.6742\n",
      "Epoch 4051/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 423.7643 - mean_absolute_error: 12.0385\n",
      "Epoch 4052/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 405.3848 - mean_absolute_error: 11.4892\n",
      "Epoch 4053/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 413.0093 - mean_absolute_error: 11.6465\n",
      "Epoch 4054/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 423.1146 - mean_absolute_error: 12.0190\n",
      "Epoch 4055/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 396.4418 - mean_absolute_error: 11.3061\n",
      "Epoch 4056/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 418.2143 - mean_absolute_error: 11.8500\n",
      "Epoch 4057/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 409.2314 - mean_absolute_error: 11.7025\n",
      "Epoch 4058/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 417.4332 - mean_absolute_error: 11.9081\n",
      "Epoch 4059/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 425.3799 - mean_absolute_error: 12.1080\n",
      "Epoch 4060/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 410.6255 - mean_absolute_error: 12.0612\n",
      "Epoch 4061/5000\n",
      "344/344 [==============================] - 0s 257us/step - loss: 410.5741 - mean_absolute_error: 11.8354\n",
      "Epoch 4062/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 401.6938 - mean_absolute_error: 11.8580\n",
      "Epoch 4063/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 421.9866 - mean_absolute_error: 12.0867\n",
      "Epoch 4064/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 419.4923 - mean_absolute_error: 12.0666\n",
      "Epoch 4065/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 419.0196 - mean_absolute_error: 12.0684\n",
      "Epoch 4066/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 424.5263 - mean_absolute_error: 11.9733\n",
      "Epoch 4067/5000\n",
      "344/344 [==============================] - 0s 257us/step - loss: 470.1071 - mean_absolute_error: 12.7094\n",
      "Epoch 4068/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 442.0650 - mean_absolute_error: 12.4648\n",
      "Epoch 4069/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 406.4572 - mean_absolute_error: 11.5960\n",
      "Epoch 4070/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 413.9428 - mean_absolute_error: 11.7561\n",
      "Epoch 4071/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 427.2196 - mean_absolute_error: 11.9802\n",
      "Epoch 4072/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.7553 - mean_absolute_error: 12.1243\n",
      "Epoch 4073/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 404.7608 - mean_absolute_error: 11.8109\n",
      "Epoch 4074/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.9750 - mean_absolute_error: 11.4417\n",
      "Epoch 4075/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 413.6249 - mean_absolute_error: 11.7889\n",
      "Epoch 4076/5000\n",
      "344/344 [==============================] - 0s 325us/step - loss: 417.7179 - mean_absolute_error: 11.8374\n",
      "Epoch 4077/5000\n",
      "344/344 [==============================] - 0s 319us/step - loss: 415.2519 - mean_absolute_error: 11.7043\n",
      "Epoch 4078/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 421.0628 - mean_absolute_error: 11.9051\n",
      "Epoch 4079/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 416.7264 - mean_absolute_error: 12.1934\n",
      "Epoch 4080/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 398.6917 - mean_absolute_error: 11.1989\n",
      "Epoch 4081/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 390.6148 - mean_absolute_error: 11.4935\n",
      "Epoch 4082/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.9958 - mean_absolute_error: 11.8167\n",
      "Epoch 4083/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 400.1958 - mean_absolute_error: 11.7694\n",
      "Epoch 4084/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 402.1096 - mean_absolute_error: 11.6752\n",
      "Epoch 4085/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 416.5033 - mean_absolute_error: 11.8065\n",
      "Epoch 4086/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 427.0278 - mean_absolute_error: 12.0758\n",
      "Epoch 4087/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.4857 - mean_absolute_error: 11.7694\n",
      "Epoch 4088/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 394.1207 - mean_absolute_error: 11.6250\n",
      "Epoch 4089/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.9919 - mean_absolute_error: 11.6270\n",
      "Epoch 4090/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 424.3561 - mean_absolute_error: 11.7442\n",
      "Epoch 4091/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 400.8760 - mean_absolute_error: 11.5347\n",
      "Epoch 4092/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 415.0292 - mean_absolute_error: 12.0353\n",
      "Epoch 4093/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.8144 - mean_absolute_error: 11.7832\n",
      "Epoch 4094/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 413.2530 - mean_absolute_error: 11.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4095/5000\n",
      "344/344 [==============================] - 0s 296us/step - loss: 420.3957 - mean_absolute_error: 12.0397\n",
      "Epoch 4096/5000\n",
      "344/344 [==============================] - 0s 290us/step - loss: 389.9829 - mean_absolute_error: 11.2151\n",
      "Epoch 4097/5000\n",
      "344/344 [==============================] - 0s 275us/step - loss: 402.0867 - mean_absolute_error: 11.8157\n",
      "Epoch 4098/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 412.9880 - mean_absolute_error: 11.7308\n",
      "Epoch 4099/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 396.8926 - mean_absolute_error: 11.4268\n",
      "Epoch 4100/5000\n",
      "344/344 [==============================] - 0s 296us/step - loss: 398.1580 - mean_absolute_error: 11.5287\n",
      "Epoch 4101/5000\n",
      "344/344 [==============================] - 0s 325us/step - loss: 399.5778 - mean_absolute_error: 11.5974\n",
      "Epoch 4102/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 394.7020 - mean_absolute_error: 11.3729\n",
      "Epoch 4103/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 429.7147 - mean_absolute_error: 12.0480\n",
      "Epoch 4104/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 404.8006 - mean_absolute_error: 11.6824\n",
      "Epoch 4105/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 422.2497 - mean_absolute_error: 11.5704\n",
      "Epoch 4106/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.5032 - mean_absolute_error: 11.9343\n",
      "Epoch 4107/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.3548 - mean_absolute_error: 12.0430\n",
      "Epoch 4108/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.5666 - mean_absolute_error: 11.6366\n",
      "Epoch 4109/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 436.8297 - mean_absolute_error: 12.0979\n",
      "Epoch 4110/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.0582 - mean_absolute_error: 11.9510\n",
      "Epoch 4111/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 398.9846 - mean_absolute_error: 11.4232\n",
      "Epoch 4112/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.7012 - mean_absolute_error: 11.8863\n",
      "Epoch 4113/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 422.9885 - mean_absolute_error: 12.0275\n",
      "Epoch 4114/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 400.0947 - mean_absolute_error: 11.5034\n",
      "Epoch 4115/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 396.6538 - mean_absolute_error: 11.6684\n",
      "Epoch 4116/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 412.1571 - mean_absolute_error: 12.0281\n",
      "Epoch 4117/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.2612 - mean_absolute_error: 11.8879\n",
      "Epoch 4118/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.4909 - mean_absolute_error: 11.8225\n",
      "Epoch 4119/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 412.4786 - mean_absolute_error: 11.8710\n",
      "Epoch 4120/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 401.5365 - mean_absolute_error: 11.7636\n",
      "Epoch 4121/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.1677 - mean_absolute_error: 11.8640\n",
      "Epoch 4122/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 425.0562 - mean_absolute_error: 12.2400\n",
      "Epoch 4123/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 398.9113 - mean_absolute_error: 11.5751\n",
      "Epoch 4124/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.0427 - mean_absolute_error: 12.3665\n",
      "Epoch 4125/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.9236 - mean_absolute_error: 12.1858\n",
      "Epoch 4126/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.5344 - mean_absolute_error: 11.6657\n",
      "Epoch 4127/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 398.0467 - mean_absolute_error: 11.6066\n",
      "Epoch 4128/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.8700 - mean_absolute_error: 11.9995\n",
      "Epoch 4129/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 431.0814 - mean_absolute_error: 12.1580\n",
      "Epoch 4130/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 406.6913 - mean_absolute_error: 11.7053\n",
      "Epoch 4131/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 423.1427 - mean_absolute_error: 12.3618\n",
      "Epoch 4132/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 429.2515 - mean_absolute_error: 11.8595\n",
      "Epoch 4133/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 400.8455 - mean_absolute_error: 11.6766\n",
      "Epoch 4134/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 408.7826 - mean_absolute_error: 11.7438\n",
      "Epoch 4135/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.3010 - mean_absolute_error: 11.7048\n",
      "Epoch 4136/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 394.4929 - mean_absolute_error: 11.5859\n",
      "Epoch 4137/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 432.1075 - mean_absolute_error: 12.1690\n",
      "Epoch 4138/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 433.9771 - mean_absolute_error: 12.3512\n",
      "Epoch 4139/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.5002 - mean_absolute_error: 11.9151\n",
      "Epoch 4140/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 400.6946 - mean_absolute_error: 11.7804\n",
      "Epoch 4141/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 409.2581 - mean_absolute_error: 11.8239\n",
      "Epoch 4142/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 390.0766 - mean_absolute_error: 11.4435\n",
      "Epoch 4143/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 404.2128 - mean_absolute_error: 11.6955\n",
      "Epoch 4144/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.7166 - mean_absolute_error: 11.7305\n",
      "Epoch 4145/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.4324 - mean_absolute_error: 11.9310\n",
      "Epoch 4146/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 396.5025 - mean_absolute_error: 11.6290\n",
      "Epoch 4147/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 423.2302 - mean_absolute_error: 12.1466\n",
      "Epoch 4148/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.6027 - mean_absolute_error: 11.8970\n",
      "Epoch 4149/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 398.8122 - mean_absolute_error: 11.3224\n",
      "Epoch 4150/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.9657 - mean_absolute_error: 12.0217\n",
      "Epoch 4151/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.9483 - mean_absolute_error: 11.9020\n",
      "Epoch 4152/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 418.6563 - mean_absolute_error: 12.3066\n",
      "Epoch 4153/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.4068 - mean_absolute_error: 11.8062\n",
      "Epoch 4154/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.4447 - mean_absolute_error: 11.8522\n",
      "Epoch 4155/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 417.3725 - mean_absolute_error: 12.0920\n",
      "Epoch 4156/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.5518 - mean_absolute_error: 11.8555\n",
      "Epoch 4157/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.1150 - mean_absolute_error: 12.3011\n",
      "Epoch 4158/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 425.8315 - mean_absolute_error: 12.0775\n",
      "Epoch 4159/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 397.3282 - mean_absolute_error: 11.6211\n",
      "Epoch 4160/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.5488 - mean_absolute_error: 12.2168\n",
      "Epoch 4161/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 430.2068 - mean_absolute_error: 12.4328\n",
      "Epoch 4162/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.8562 - mean_absolute_error: 11.7251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4163/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.3237 - mean_absolute_error: 12.0142\n",
      "Epoch 4164/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.9631 - mean_absolute_error: 12.1966\n",
      "Epoch 4165/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 422.4737 - mean_absolute_error: 12.0977\n",
      "Epoch 4166/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.9717 - mean_absolute_error: 11.7658\n",
      "Epoch 4167/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 433.2692 - mean_absolute_error: 11.8632\n",
      "Epoch 4168/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 396.6845 - mean_absolute_error: 11.2405\n",
      "Epoch 4169/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 421.3063 - mean_absolute_error: 12.2898\n",
      "Epoch 4170/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 395.1438 - mean_absolute_error: 11.6818\n",
      "Epoch 4171/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.2077 - mean_absolute_error: 11.6506\n",
      "Epoch 4172/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.5045 - mean_absolute_error: 11.8845\n",
      "Epoch 4173/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.6285 - mean_absolute_error: 12.0793\n",
      "Epoch 4174/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.2812 - mean_absolute_error: 12.0436\n",
      "Epoch 4175/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.7864 - mean_absolute_error: 11.6572\n",
      "Epoch 4176/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.7675 - mean_absolute_error: 12.1179\n",
      "Epoch 4177/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 403.0762 - mean_absolute_error: 11.5044\n",
      "Epoch 4178/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.2173 - mean_absolute_error: 11.8274\n",
      "Epoch 4179/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 383.5588 - mean_absolute_error: 11.2030\n",
      "Epoch 4180/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.0356 - mean_absolute_error: 12.0139\n",
      "Epoch 4181/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 394.0076 - mean_absolute_error: 11.5929\n",
      "Epoch 4182/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.3061 - mean_absolute_error: 11.7026\n",
      "Epoch 4183/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 382.1114 - mean_absolute_error: 11.1810\n",
      "Epoch 4184/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 399.1522 - mean_absolute_error: 11.5608\n",
      "Epoch 4185/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 427.6949 - mean_absolute_error: 12.1268\n",
      "Epoch 4186/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 419.3038 - mean_absolute_error: 11.8455\n",
      "Epoch 4187/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.3859 - mean_absolute_error: 11.4973\n",
      "Epoch 4188/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.8845 - mean_absolute_error: 12.0068\n",
      "Epoch 4189/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 379.0966 - mean_absolute_error: 11.2752\n",
      "Epoch 4190/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.1815 - mean_absolute_error: 11.8997\n",
      "Epoch 4191/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 415.6612 - mean_absolute_error: 12.0861\n",
      "Epoch 4192/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 424.1110 - mean_absolute_error: 12.1206\n",
      "Epoch 4193/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 419.7914 - mean_absolute_error: 11.7751\n",
      "Epoch 4194/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 394.2655 - mean_absolute_error: 11.4094\n",
      "Epoch 4195/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.9786 - mean_absolute_error: 12.1614\n",
      "Epoch 4196/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.6711 - mean_absolute_error: 11.5701\n",
      "Epoch 4197/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.9471 - mean_absolute_error: 11.8183\n",
      "Epoch 4198/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 422.6366 - mean_absolute_error: 11.9890\n",
      "Epoch 4199/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.2767 - mean_absolute_error: 12.0915\n",
      "Epoch 4200/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 390.1762 - mean_absolute_error: 11.3118\n",
      "Epoch 4201/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 402.9217 - mean_absolute_error: 11.7593\n",
      "Epoch 4202/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 413.3397 - mean_absolute_error: 11.8488\n",
      "Epoch 4203/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 398.1493 - mean_absolute_error: 11.6289\n",
      "Epoch 4204/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 395.6438 - mean_absolute_error: 11.5691\n",
      "Epoch 4205/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 381.8067 - mean_absolute_error: 11.1432\n",
      "Epoch 4206/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.1727 - mean_absolute_error: 11.9922\n",
      "Epoch 4207/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 421.1034 - mean_absolute_error: 12.0818\n",
      "Epoch 4208/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.8967 - mean_absolute_error: 12.1095\n",
      "Epoch 4209/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.3254 - mean_absolute_error: 11.8478\n",
      "Epoch 4210/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 447.8375 - mean_absolute_error: 11.8880\n",
      "Epoch 4211/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 432.8579 - mean_absolute_error: 12.0941\n",
      "Epoch 4212/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 411.8419 - mean_absolute_error: 11.7634\n",
      "Epoch 4213/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.1848 - mean_absolute_error: 11.9438\n",
      "Epoch 4214/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.8887 - mean_absolute_error: 11.6696\n",
      "Epoch 4215/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.5726 - mean_absolute_error: 12.0509\n",
      "Epoch 4216/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.4317 - mean_absolute_error: 11.7798\n",
      "Epoch 4217/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 402.2643 - mean_absolute_error: 11.5743\n",
      "Epoch 4218/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 420.8717 - mean_absolute_error: 11.8755\n",
      "Epoch 4219/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.0964 - mean_absolute_error: 11.7083\n",
      "Epoch 4220/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 419.1706 - mean_absolute_error: 11.8479\n",
      "Epoch 4221/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 416.2629 - mean_absolute_error: 11.9735\n",
      "Epoch 4222/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 417.9998 - mean_absolute_error: 11.9455\n",
      "Epoch 4223/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 419.0703 - mean_absolute_error: 12.0217\n",
      "Epoch 4224/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 403.7616 - mean_absolute_error: 11.5051\n",
      "Epoch 4225/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.1402 - mean_absolute_error: 11.6433\n",
      "Epoch 4226/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 496.3340 - mean_absolute_error: 12.8866\n",
      "Epoch 4227/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.4631 - mean_absolute_error: 12.0501\n",
      "Epoch 4228/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 390.8718 - mean_absolute_error: 11.2347\n",
      "Epoch 4229/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 403.5526 - mean_absolute_error: 11.5381\n",
      "Epoch 4230/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 387.5858 - mean_absolute_error: 11.5089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4231/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 397.2072 - mean_absolute_error: 11.6511\n",
      "Epoch 4232/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.8285 - mean_absolute_error: 12.0353\n",
      "Epoch 4233/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 407.1282 - mean_absolute_error: 11.8505\n",
      "Epoch 4234/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 387.6794 - mean_absolute_error: 11.1403\n",
      "Epoch 4235/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.7157 - mean_absolute_error: 12.0181\n",
      "Epoch 4236/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.0436 - mean_absolute_error: 11.9305\n",
      "Epoch 4237/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.5592 - mean_absolute_error: 11.5611\n",
      "Epoch 4238/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 404.7671 - mean_absolute_error: 11.8084\n",
      "Epoch 4239/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 411.0802 - mean_absolute_error: 11.7226\n",
      "Epoch 4240/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 402.4435 - mean_absolute_error: 11.8383\n",
      "Epoch 4241/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 399.5742 - mean_absolute_error: 11.2943\n",
      "Epoch 4242/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 390.2863 - mean_absolute_error: 11.5492\n",
      "Epoch 4243/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 426.1744 - mean_absolute_error: 12.1947\n",
      "Epoch 4244/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 415.0100 - mean_absolute_error: 12.0970\n",
      "Epoch 4245/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 401.3880 - mean_absolute_error: 11.7600\n",
      "Epoch 4246/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 402.7710 - mean_absolute_error: 11.7829\n",
      "Epoch 4247/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 395.1396 - mean_absolute_error: 11.4509\n",
      "Epoch 4248/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 411.1778 - mean_absolute_error: 11.9162\n",
      "Epoch 4249/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 390.7826 - mean_absolute_error: 11.4794\n",
      "Epoch 4250/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 419.6315 - mean_absolute_error: 11.8536\n",
      "Epoch 4251/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 389.7227 - mean_absolute_error: 11.2213\n",
      "Epoch 4252/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 398.8790 - mean_absolute_error: 11.5045\n",
      "Epoch 4253/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 436.7407 - mean_absolute_error: 12.2061\n",
      "Epoch 4254/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 381.4946 - mean_absolute_error: 11.2138\n",
      "Epoch 4255/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.7257 - mean_absolute_error: 12.2989\n",
      "Epoch 4256/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 414.8865 - mean_absolute_error: 11.7991\n",
      "Epoch 4257/5000\n",
      "344/344 [==============================] - 0s 257us/step - loss: 415.5456 - mean_absolute_error: 11.8793\n",
      "Epoch 4258/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.6617 - mean_absolute_error: 11.6374\n",
      "Epoch 4259/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 404.4753 - mean_absolute_error: 11.5462\n",
      "Epoch 4260/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.1692 - mean_absolute_error: 12.1380\n",
      "Epoch 4261/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.9745 - mean_absolute_error: 11.9408\n",
      "Epoch 4262/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 407.6542 - mean_absolute_error: 11.7297\n",
      "Epoch 4263/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 403.8394 - mean_absolute_error: 11.4126\n",
      "Epoch 4264/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 406.7199 - mean_absolute_error: 11.5393\n",
      "Epoch 4265/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.5234 - mean_absolute_error: 11.8989\n",
      "Epoch 4266/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 406.3441 - mean_absolute_error: 11.7149\n",
      "Epoch 4267/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 428.8768 - mean_absolute_error: 12.4332\n",
      "Epoch 4268/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 411.0654 - mean_absolute_error: 11.7418\n",
      "Epoch 4269/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 410.1469 - mean_absolute_error: 11.6919\n",
      "Epoch 4270/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 387.4275 - mean_absolute_error: 11.1483\n",
      "Epoch 4271/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 403.1012 - mean_absolute_error: 11.5355\n",
      "Epoch 4272/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 398.0537 - mean_absolute_error: 11.4721\n",
      "Epoch 4273/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 432.0272 - mean_absolute_error: 12.1199\n",
      "Epoch 4274/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.5912 - mean_absolute_error: 11.9452\n",
      "Epoch 4275/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 401.0742 - mean_absolute_error: 11.3502\n",
      "Epoch 4276/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.1477 - mean_absolute_error: 11.8948\n",
      "Epoch 4277/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 409.0704 - mean_absolute_error: 11.6916\n",
      "Epoch 4278/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 398.1068 - mean_absolute_error: 11.2923\n",
      "Epoch 4279/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 415.7004 - mean_absolute_error: 12.2027\n",
      "Epoch 4280/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 423.4108 - mean_absolute_error: 12.1752\n",
      "Epoch 4281/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 408.1408 - mean_absolute_error: 11.7713\n",
      "Epoch 4282/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 408.2207 - mean_absolute_error: 11.9396\n",
      "Epoch 4283/5000\n",
      "344/344 [==============================] - 0s 302us/step - loss: 416.2020 - mean_absolute_error: 11.9231\n",
      "Epoch 4284/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 403.3463 - mean_absolute_error: 11.4155\n",
      "Epoch 4285/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.1993 - mean_absolute_error: 11.9811\n",
      "Epoch 4286/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 419.2177 - mean_absolute_error: 12.0919\n",
      "Epoch 4287/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 419.0066 - mean_absolute_error: 11.7307\n",
      "Epoch 4288/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 406.7648 - mean_absolute_error: 11.9798\n",
      "Epoch 4289/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 410.3242 - mean_absolute_error: 11.9542\n",
      "Epoch 4290/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 429.9609 - mean_absolute_error: 12.3587\n",
      "Epoch 4291/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 425.7859 - mean_absolute_error: 11.9898\n",
      "Epoch 4292/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 409.0733 - mean_absolute_error: 11.7369\n",
      "Epoch 4293/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 426.1195 - mean_absolute_error: 11.9047\n",
      "Epoch 4294/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 415.7325 - mean_absolute_error: 11.8853\n",
      "Epoch 4295/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 410.1505 - mean_absolute_error: 11.8738\n",
      "Epoch 4296/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 411.7097 - mean_absolute_error: 12.2786\n",
      "Epoch 4297/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 399.9383 - mean_absolute_error: 11.7015\n",
      "Epoch 4298/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 411.4491 - mean_absolute_error: 11.5919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4299/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 392.7023 - mean_absolute_error: 11.5492\n",
      "Epoch 4300/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.8340 - mean_absolute_error: 11.7314\n",
      "Epoch 4301/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.5898 - mean_absolute_error: 11.5635\n",
      "Epoch 4302/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.9562 - mean_absolute_error: 11.8329\n",
      "Epoch 4303/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 411.2639 - mean_absolute_error: 11.7222\n",
      "Epoch 4304/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.4106 - mean_absolute_error: 12.0234\n",
      "Epoch 4305/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 404.6318 - mean_absolute_error: 11.5856\n",
      "Epoch 4306/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.8024 - mean_absolute_error: 12.0375\n",
      "Epoch 4307/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 398.3172 - mean_absolute_error: 11.7088\n",
      "Epoch 4308/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 399.2052 - mean_absolute_error: 11.5732\n",
      "Epoch 4309/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 403.3266 - mean_absolute_error: 11.7302\n",
      "Epoch 4310/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 392.1821 - mean_absolute_error: 11.3091\n",
      "Epoch 4311/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.1127 - mean_absolute_error: 12.3714\n",
      "Epoch 4312/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 402.9440 - mean_absolute_error: 11.3660\n",
      "Epoch 4313/5000\n",
      "344/344 [==============================] - 0s 222us/step - loss: 404.1147 - mean_absolute_error: 11.6564\n",
      "Epoch 4314/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.9840 - mean_absolute_error: 11.9935\n",
      "Epoch 4315/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.5602 - mean_absolute_error: 11.6509\n",
      "Epoch 4316/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 418.1666 - mean_absolute_error: 12.2244\n",
      "Epoch 4317/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 409.4854 - mean_absolute_error: 12.1339\n",
      "Epoch 4318/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.0115 - mean_absolute_error: 11.8691\n",
      "Epoch 4319/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 402.4400 - mean_absolute_error: 11.8207\n",
      "Epoch 4320/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.6620 - mean_absolute_error: 11.9890\n",
      "Epoch 4321/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 394.2392 - mean_absolute_error: 11.3869\n",
      "Epoch 4322/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 396.6581 - mean_absolute_error: 11.5349\n",
      "Epoch 4323/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.4630 - mean_absolute_error: 12.1266\n",
      "Epoch 4324/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.6258 - mean_absolute_error: 11.6057\n",
      "Epoch 4325/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 403.6052 - mean_absolute_error: 11.9281\n",
      "Epoch 4326/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.1339 - mean_absolute_error: 12.1038\n",
      "Epoch 4327/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.7896 - mean_absolute_error: 11.5927\n",
      "Epoch 4328/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 430.6123 - mean_absolute_error: 12.1771\n",
      "Epoch 4329/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.0006 - mean_absolute_error: 12.1565\n",
      "Epoch 4330/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.5746 - mean_absolute_error: 11.7578\n",
      "Epoch 4331/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.4181 - mean_absolute_error: 11.8406\n",
      "Epoch 4332/5000\n",
      "344/344 [==============================] - 0s 287us/step - loss: 405.3705 - mean_absolute_error: 11.6610\n",
      "Epoch 4333/5000\n",
      "344/344 [==============================] - 0s 257us/step - loss: 418.2501 - mean_absolute_error: 11.5719\n",
      "Epoch 4334/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 523.1507 - mean_absolute_error: 12.3938\n",
      "Epoch 4335/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.2690 - mean_absolute_error: 12.0408\n",
      "Epoch 4336/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 423.2372 - mean_absolute_error: 11.8553\n",
      "Epoch 4337/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.0448 - mean_absolute_error: 11.9974\n",
      "Epoch 4338/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 401.1096 - mean_absolute_error: 11.7694\n",
      "Epoch 4339/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 402.8419 - mean_absolute_error: 11.5929\n",
      "Epoch 4340/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.8841 - mean_absolute_error: 11.7692\n",
      "Epoch 4341/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.2722 - mean_absolute_error: 12.0343\n",
      "Epoch 4342/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 395.1040 - mean_absolute_error: 11.6787\n",
      "Epoch 4343/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 395.1148 - mean_absolute_error: 11.6374\n",
      "Epoch 4344/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.8440 - mean_absolute_error: 11.9489\n",
      "Epoch 4345/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.4460 - mean_absolute_error: 11.8901\n",
      "Epoch 4346/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.2078 - mean_absolute_error: 11.8675\n",
      "Epoch 4347/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.6598 - mean_absolute_error: 12.2993\n",
      "Epoch 4348/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 403.2917 - mean_absolute_error: 11.8088\n",
      "Epoch 4349/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.8380 - mean_absolute_error: 12.2080\n",
      "Epoch 4350/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.9140 - mean_absolute_error: 11.6148\n",
      "Epoch 4351/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 422.2731 - mean_absolute_error: 12.0041\n",
      "Epoch 4352/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.5165 - mean_absolute_error: 11.6257\n",
      "Epoch 4353/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.7305 - mean_absolute_error: 12.0602\n",
      "Epoch 4354/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.2206 - mean_absolute_error: 12.0216\n",
      "Epoch 4355/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 429.6877 - mean_absolute_error: 12.4888\n",
      "Epoch 4356/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 424.6057 - mean_absolute_error: 12.1937\n",
      "Epoch 4357/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.8645 - mean_absolute_error: 11.9284\n",
      "Epoch 4358/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 393.7657 - mean_absolute_error: 11.3857\n",
      "Epoch 4359/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 410.5541 - mean_absolute_error: 11.8014\n",
      "Epoch 4360/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.1453 - mean_absolute_error: 12.2439\n",
      "Epoch 4361/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.9373 - mean_absolute_error: 12.2347\n",
      "Epoch 4362/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 419.9669 - mean_absolute_error: 12.0344\n",
      "Epoch 4363/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 411.6612 - mean_absolute_error: 11.7925\n",
      "Epoch 4364/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.8641 - mean_absolute_error: 11.6223\n",
      "Epoch 4365/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 398.2865 - mean_absolute_error: 11.4392\n",
      "Epoch 4366/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.7784 - mean_absolute_error: 11.8742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4367/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 386.6788 - mean_absolute_error: 11.2199\n",
      "Epoch 4368/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 393.5038 - mean_absolute_error: 11.5388\n",
      "Epoch 4369/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 412.9896 - mean_absolute_error: 11.9633\n",
      "Epoch 4370/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 430.3865 - mean_absolute_error: 12.2190\n",
      "Epoch 4371/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 412.3540 - mean_absolute_error: 11.7929\n",
      "Epoch 4372/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.7477 - mean_absolute_error: 12.3656\n",
      "Epoch 4373/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 402.7473 - mean_absolute_error: 11.4407\n",
      "Epoch 4374/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 416.0819 - mean_absolute_error: 12.0586\n",
      "Epoch 4375/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.7549 - mean_absolute_error: 11.9910\n",
      "Epoch 4376/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 408.1276 - mean_absolute_error: 11.8259\n",
      "Epoch 4377/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 397.0627 - mean_absolute_error: 11.4838\n",
      "Epoch 4378/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.5103 - mean_absolute_error: 11.8066\n",
      "Epoch 4379/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 398.7237 - mean_absolute_error: 11.4403\n",
      "Epoch 4380/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 393.1999 - mean_absolute_error: 11.4623\n",
      "Epoch 4381/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 440.1941 - mean_absolute_error: 12.1756\n",
      "Epoch 4382/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.8802 - mean_absolute_error: 11.8398\n",
      "Epoch 4383/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 418.9709 - mean_absolute_error: 11.9587\n",
      "Epoch 4384/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 446.9252 - mean_absolute_error: 12.8611\n",
      "Epoch 4385/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 408.2927 - mean_absolute_error: 11.6913\n",
      "Epoch 4386/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 425.0580 - mean_absolute_error: 12.2088\n",
      "Epoch 4387/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.7469 - mean_absolute_error: 11.8354\n",
      "Epoch 4388/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.1041 - mean_absolute_error: 12.1908\n",
      "Epoch 4389/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 407.9494 - mean_absolute_error: 11.5677\n",
      "Epoch 4390/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 410.5011 - mean_absolute_error: 11.7225\n",
      "Epoch 4391/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.9012 - mean_absolute_error: 12.2487\n",
      "Epoch 4392/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 446.1791 - mean_absolute_error: 11.9215\n",
      "Epoch 4393/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.6549 - mean_absolute_error: 11.6980\n",
      "Epoch 4394/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 442.9748 - mean_absolute_error: 12.5183\n",
      "Epoch 4395/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 398.6414 - mean_absolute_error: 11.5852\n",
      "Epoch 4396/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 385.2478 - mean_absolute_error: 11.3797\n",
      "Epoch 4397/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.0976 - mean_absolute_error: 12.0879\n",
      "Epoch 4398/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 397.0971 - mean_absolute_error: 11.5919\n",
      "Epoch 4399/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.9286 - mean_absolute_error: 11.9662\n",
      "Epoch 4400/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.0582 - mean_absolute_error: 11.7747\n",
      "Epoch 4401/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.6391 - mean_absolute_error: 12.3099\n",
      "Epoch 4402/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.6468 - mean_absolute_error: 11.8063\n",
      "Epoch 4403/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 415.8512 - mean_absolute_error: 12.0574\n",
      "Epoch 4404/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.3645 - mean_absolute_error: 12.2350\n",
      "Epoch 4405/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.1338 - mean_absolute_error: 11.6791\n",
      "Epoch 4406/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 412.0275 - mean_absolute_error: 11.6240\n",
      "Epoch 4407/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.8390 - mean_absolute_error: 12.0036\n",
      "Epoch 4408/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 416.3231 - mean_absolute_error: 11.9174\n",
      "Epoch 4409/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 405.2458 - mean_absolute_error: 11.7380\n",
      "Epoch 4410/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.9189 - mean_absolute_error: 11.8648\n",
      "Epoch 4411/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 406.8139 - mean_absolute_error: 11.8530\n",
      "Epoch 4412/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.7344 - mean_absolute_error: 12.0306\n",
      "Epoch 4413/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 427.5809 - mean_absolute_error: 12.3261\n",
      "Epoch 4414/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.5932 - mean_absolute_error: 12.1660\n",
      "Epoch 4415/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.5056 - mean_absolute_error: 11.7817\n",
      "Epoch 4416/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 375.5216 - mean_absolute_error: 10.9221\n",
      "Epoch 4417/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 426.8627 - mean_absolute_error: 12.1083\n",
      "Epoch 4418/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.1029 - mean_absolute_error: 11.7503\n",
      "Epoch 4419/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.4964 - mean_absolute_error: 12.0151\n",
      "Epoch 4420/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 423.1197 - mean_absolute_error: 11.9537\n",
      "Epoch 4421/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 404.0558 - mean_absolute_error: 11.8990\n",
      "Epoch 4422/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.7855 - mean_absolute_error: 11.6915\n",
      "Epoch 4423/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 402.7112 - mean_absolute_error: 11.6420\n",
      "Epoch 4424/5000\n",
      "344/344 [==============================] - 0s 254us/step - loss: 397.4490 - mean_absolute_error: 11.4771\n",
      "Epoch 4425/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 425.1680 - mean_absolute_error: 11.5599\n",
      "Epoch 4426/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 400.2747 - mean_absolute_error: 11.5517\n",
      "Epoch 4427/5000\n",
      "344/344 [==============================] - 0s 224us/step - loss: 400.6606 - mean_absolute_error: 11.5443\n",
      "Epoch 4428/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.3340 - mean_absolute_error: 11.5950\n",
      "Epoch 4429/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 405.0623 - mean_absolute_error: 11.5447\n",
      "Epoch 4430/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 406.6810 - mean_absolute_error: 11.8727\n",
      "Epoch 4431/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.4030 - mean_absolute_error: 11.8133\n",
      "Epoch 4432/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.7914 - mean_absolute_error: 11.6650\n",
      "Epoch 4433/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 413.1252 - mean_absolute_error: 11.6764\n",
      "Epoch 4434/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 424.1844 - mean_absolute_error: 12.4280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4435/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.4385 - mean_absolute_error: 12.0217\n",
      "Epoch 4436/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 418.3649 - mean_absolute_error: 12.0496\n",
      "Epoch 4437/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 407.0420 - mean_absolute_error: 11.4918\n",
      "Epoch 4438/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.8488 - mean_absolute_error: 11.9481\n",
      "Epoch 4439/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.0020 - mean_absolute_error: 11.5299\n",
      "Epoch 4440/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.9853 - mean_absolute_error: 12.0840\n",
      "Epoch 4441/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 385.3135 - mean_absolute_error: 11.2582\n",
      "Epoch 4442/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 394.4471 - mean_absolute_error: 11.3197\n",
      "Epoch 4443/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 457.9107 - mean_absolute_error: 11.9827\n",
      "Epoch 4444/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 406.1288 - mean_absolute_error: 11.5696\n",
      "Epoch 4445/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.0651 - mean_absolute_error: 12.0883\n",
      "Epoch 4446/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.7326 - mean_absolute_error: 11.6161\n",
      "Epoch 4447/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 408.0063 - mean_absolute_error: 11.9387\n",
      "Epoch 4448/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 410.1703 - mean_absolute_error: 11.9634\n",
      "Epoch 4449/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.7359 - mean_absolute_error: 11.7122\n",
      "Epoch 4450/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 398.4160 - mean_absolute_error: 11.5430\n",
      "Epoch 4451/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.6877 - mean_absolute_error: 11.8094\n",
      "Epoch 4452/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.8875 - mean_absolute_error: 11.7519\n",
      "Epoch 4453/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 393.6635 - mean_absolute_error: 11.4678\n",
      "Epoch 4454/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.6936 - mean_absolute_error: 11.8882\n",
      "Epoch 4455/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 416.2503 - mean_absolute_error: 11.9852\n",
      "Epoch 4456/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 441.5741 - mean_absolute_error: 12.0017\n",
      "Epoch 4457/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 389.6108 - mean_absolute_error: 11.5719\n",
      "Epoch 4458/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.0283 - mean_absolute_error: 11.4973\n",
      "Epoch 4459/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.2861 - mean_absolute_error: 11.7437\n",
      "Epoch 4460/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 420.6309 - mean_absolute_error: 12.2030\n",
      "Epoch 4461/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.8667 - mean_absolute_error: 11.8148\n",
      "Epoch 4462/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 402.8732 - mean_absolute_error: 11.4128\n",
      "Epoch 4463/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 414.5780 - mean_absolute_error: 12.1345\n",
      "Epoch 4464/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.6142 - mean_absolute_error: 12.5423\n",
      "Epoch 4465/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.6646 - mean_absolute_error: 11.8494\n",
      "Epoch 4466/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 392.6813 - mean_absolute_error: 11.1611\n",
      "Epoch 4467/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.9624 - mean_absolute_error: 12.1260\n",
      "Epoch 4468/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 412.0789 - mean_absolute_error: 11.9656\n",
      "Epoch 4469/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 411.3467 - mean_absolute_error: 11.8410\n",
      "Epoch 4470/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.4649 - mean_absolute_error: 12.1736\n",
      "Epoch 4471/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 397.2445 - mean_absolute_error: 11.6509\n",
      "Epoch 4472/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 421.7092 - mean_absolute_error: 12.0154\n",
      "Epoch 4473/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 416.7977 - mean_absolute_error: 12.0421\n",
      "Epoch 4474/5000\n",
      "344/344 [==============================] - 0s 224us/step - loss: 413.8838 - mean_absolute_error: 11.8268\n",
      "Epoch 4475/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 398.7339 - mean_absolute_error: 11.5574\n",
      "Epoch 4476/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 398.4921 - mean_absolute_error: 11.7587\n",
      "Epoch 4477/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 406.7094 - mean_absolute_error: 11.9273\n",
      "Epoch 4478/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.2795 - mean_absolute_error: 11.8774\n",
      "Epoch 4479/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 418.2376 - mean_absolute_error: 12.1543\n",
      "Epoch 4480/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 399.2563 - mean_absolute_error: 11.6462\n",
      "Epoch 4481/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 417.5267 - mean_absolute_error: 11.8483\n",
      "Epoch 4482/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 473.2551 - mean_absolute_error: 12.3730\n",
      "Epoch 4483/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 405.9645 - mean_absolute_error: 11.6392\n",
      "Epoch 4484/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 391.6396 - mean_absolute_error: 11.4481\n",
      "Epoch 4485/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 394.0562 - mean_absolute_error: 11.4525\n",
      "Epoch 4486/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.9040 - mean_absolute_error: 11.8881\n",
      "Epoch 4487/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.8004 - mean_absolute_error: 11.5127\n",
      "Epoch 4488/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 428.9792 - mean_absolute_error: 12.5550\n",
      "Epoch 4489/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.0103 - mean_absolute_error: 12.0768\n",
      "Epoch 4490/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 426.5411 - mean_absolute_error: 12.1630\n",
      "Epoch 4491/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 422.7761 - mean_absolute_error: 11.8531\n",
      "Epoch 4492/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 451.3969 - mean_absolute_error: 12.5976\n",
      "Epoch 4493/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 402.0453 - mean_absolute_error: 11.4097\n",
      "Epoch 4494/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 416.7111 - mean_absolute_error: 12.0412\n",
      "Epoch 4495/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 413.0319 - mean_absolute_error: 12.0494\n",
      "Epoch 4496/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.0734 - mean_absolute_error: 12.2672\n",
      "Epoch 4497/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 417.5859 - mean_absolute_error: 12.2097\n",
      "Epoch 4498/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.9828 - mean_absolute_error: 11.6020\n",
      "Epoch 4499/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 431.8573 - mean_absolute_error: 12.3333\n",
      "Epoch 4500/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 402.5205 - mean_absolute_error: 11.4530\n",
      "Epoch 4501/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.7185 - mean_absolute_error: 12.3285\n",
      "Epoch 4502/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 406.5050 - mean_absolute_error: 11.8031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4503/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.8440 - mean_absolute_error: 11.9388\n",
      "Epoch 4504/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 416.5708 - mean_absolute_error: 12.0260\n",
      "Epoch 4505/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 399.0671 - mean_absolute_error: 11.2689\n",
      "Epoch 4506/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.8012 - mean_absolute_error: 12.0865\n",
      "Epoch 4507/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 401.5501 - mean_absolute_error: 11.4568\n",
      "Epoch 4508/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 416.5487 - mean_absolute_error: 12.0679\n",
      "Epoch 4509/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.0230 - mean_absolute_error: 11.5508\n",
      "Epoch 4510/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.7388 - mean_absolute_error: 11.8099\n",
      "Epoch 4511/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 437.5583 - mean_absolute_error: 12.3119\n",
      "Epoch 4512/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.4153 - mean_absolute_error: 12.1175\n",
      "Epoch 4513/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 404.7869 - mean_absolute_error: 11.5458\n",
      "Epoch 4514/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 418.1795 - mean_absolute_error: 12.2788\n",
      "Epoch 4515/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 429.0291 - mean_absolute_error: 12.2740\n",
      "Epoch 4516/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 396.0973 - mean_absolute_error: 11.4048\n",
      "Epoch 4517/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 415.9905 - mean_absolute_error: 12.1037\n",
      "Epoch 4518/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.9820 - mean_absolute_error: 12.0487\n",
      "Epoch 4519/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 392.3051 - mean_absolute_error: 11.2899\n",
      "Epoch 4520/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 441.1782 - mean_absolute_error: 12.1292\n",
      "Epoch 4521/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 414.8865 - mean_absolute_error: 12.2693\n",
      "Epoch 4522/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.7508 - mean_absolute_error: 11.7966\n",
      "Epoch 4523/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 392.9330 - mean_absolute_error: 11.3480\n",
      "Epoch 4524/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.0861 - mean_absolute_error: 11.9779\n",
      "Epoch 4525/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 398.3221 - mean_absolute_error: 11.4667\n",
      "Epoch 4526/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 393.6966 - mean_absolute_error: 11.3589\n",
      "Epoch 4527/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.2969 - mean_absolute_error: 11.6606\n",
      "Epoch 4528/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 431.1508 - mean_absolute_error: 12.0103\n",
      "Epoch 4529/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 394.9734 - mean_absolute_error: 11.1680\n",
      "Epoch 4530/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.2975 - mean_absolute_error: 11.5990\n",
      "Epoch 4531/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.3987 - mean_absolute_error: 12.1212\n",
      "Epoch 4532/5000\n",
      "344/344 [==============================] - 0s 224us/step - loss: 400.7327 - mean_absolute_error: 11.6710\n",
      "Epoch 4533/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.3030 - mean_absolute_error: 12.0237\n",
      "Epoch 4534/5000\n",
      "344/344 [==============================] - 0s 237us/step - loss: 391.6824 - mean_absolute_error: 11.5198\n",
      "Epoch 4535/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.7512 - mean_absolute_error: 11.6292\n",
      "Epoch 4536/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 437.0054 - mean_absolute_error: 12.1454\n",
      "Epoch 4537/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 435.7089 - mean_absolute_error: 12.2512\n",
      "Epoch 4538/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.4207 - mean_absolute_error: 11.9812\n",
      "Epoch 4539/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.1716 - mean_absolute_error: 11.7747\n",
      "Epoch 4540/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 402.1106 - mean_absolute_error: 11.7694\n",
      "Epoch 4541/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 384.1767 - mean_absolute_error: 11.3421\n",
      "Epoch 4542/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 425.1241 - mean_absolute_error: 12.0427\n",
      "Epoch 4543/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 378.6805 - mean_absolute_error: 11.4944\n",
      "Epoch 4544/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.0121 - mean_absolute_error: 11.5096\n",
      "Epoch 4545/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.1793 - mean_absolute_error: 11.5499\n",
      "Epoch 4546/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 381.3488 - mean_absolute_error: 11.0359\n",
      "Epoch 4547/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.0795 - mean_absolute_error: 11.9758\n",
      "Epoch 4548/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 402.1555 - mean_absolute_error: 11.6320\n",
      "Epoch 4549/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.0837 - mean_absolute_error: 11.8498\n",
      "Epoch 4550/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 438.1803 - mean_absolute_error: 12.2039\n",
      "Epoch 4551/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 444.0559 - mean_absolute_error: 12.3127\n",
      "Epoch 4552/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 398.8524 - mean_absolute_error: 11.5937\n",
      "Epoch 4553/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.6917 - mean_absolute_error: 11.6976\n",
      "Epoch 4554/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 386.9853 - mean_absolute_error: 11.3307\n",
      "Epoch 4555/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 416.2923 - mean_absolute_error: 11.9734\n",
      "Epoch 4556/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.1238 - mean_absolute_error: 11.8919\n",
      "Epoch 4557/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 396.9184 - mean_absolute_error: 11.6539\n",
      "Epoch 4558/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 394.4395 - mean_absolute_error: 11.6370\n",
      "Epoch 4559/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 401.0736 - mean_absolute_error: 11.6883\n",
      "Epoch 4560/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.8051 - mean_absolute_error: 12.0772\n",
      "Epoch 4561/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 415.5586 - mean_absolute_error: 12.2194\n",
      "Epoch 4562/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 408.0322 - mean_absolute_error: 11.9271\n",
      "Epoch 4563/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 427.5767 - mean_absolute_error: 12.3171\n",
      "Epoch 4564/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 401.8451 - mean_absolute_error: 11.7513\n",
      "Epoch 4565/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 422.0458 - mean_absolute_error: 11.8691\n",
      "Epoch 4566/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 423.1461 - mean_absolute_error: 12.0127\n",
      "Epoch 4567/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 429.6237 - mean_absolute_error: 12.3378\n",
      "Epoch 4568/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 446.1831 - mean_absolute_error: 12.4611\n",
      "Epoch 4569/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 398.5069 - mean_absolute_error: 11.5814\n",
      "Epoch 4570/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.1686 - mean_absolute_error: 12.1631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4571/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 408.6370 - mean_absolute_error: 11.9703\n",
      "Epoch 4572/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 441.2383 - mean_absolute_error: 12.3021\n",
      "Epoch 4573/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 416.8205 - mean_absolute_error: 11.8934\n",
      "Epoch 4574/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 397.3510 - mean_absolute_error: 11.4955\n",
      "Epoch 4575/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 435.4767 - mean_absolute_error: 12.0660\n",
      "Epoch 4576/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.6312 - mean_absolute_error: 11.6965\n",
      "Epoch 4577/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.7239 - mean_absolute_error: 11.8230\n",
      "Epoch 4578/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 402.4831 - mean_absolute_error: 11.4847\n",
      "Epoch 4579/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 420.5470 - mean_absolute_error: 12.0754\n",
      "Epoch 4580/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 406.4243 - mean_absolute_error: 11.7095\n",
      "Epoch 4581/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 388.9249 - mean_absolute_error: 11.5024\n",
      "Epoch 4582/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 399.8323 - mean_absolute_error: 11.4303\n",
      "Epoch 4583/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.1698 - mean_absolute_error: 12.3278\n",
      "Epoch 4584/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.5723 - mean_absolute_error: 11.5514\n",
      "Epoch 4585/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 423.0051 - mean_absolute_error: 12.0113\n",
      "Epoch 4586/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 428.3018 - mean_absolute_error: 12.4142\n",
      "Epoch 4587/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 416.1591 - mean_absolute_error: 12.1065\n",
      "Epoch 4588/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 427.4127 - mean_absolute_error: 12.3840\n",
      "Epoch 4589/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 413.6690 - mean_absolute_error: 12.0333\n",
      "Epoch 4590/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 435.8019 - mean_absolute_error: 12.1903\n",
      "Epoch 4591/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.5111 - mean_absolute_error: 11.7497\n",
      "Epoch 4592/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.8967 - mean_absolute_error: 11.6772\n",
      "Epoch 4593/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 433.7037 - mean_absolute_error: 11.8525\n",
      "Epoch 4594/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.7768 - mean_absolute_error: 11.7537\n",
      "Epoch 4595/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.7557 - mean_absolute_error: 11.8652\n",
      "Epoch 4596/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 418.2969 - mean_absolute_error: 12.0268\n",
      "Epoch 4597/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.4902 - mean_absolute_error: 11.8226\n",
      "Epoch 4598/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 400.4651 - mean_absolute_error: 11.5430\n",
      "Epoch 4599/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 402.9402 - mean_absolute_error: 11.6572\n",
      "Epoch 4600/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.3216 - mean_absolute_error: 11.9467\n",
      "Epoch 4601/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 394.3220 - mean_absolute_error: 11.3536\n",
      "Epoch 4602/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 410.8949 - mean_absolute_error: 11.8429\n",
      "Epoch 4603/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 424.0827 - mean_absolute_error: 12.1571\n",
      "Epoch 4604/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 438.0164 - mean_absolute_error: 12.6265\n",
      "Epoch 4605/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 426.9362 - mean_absolute_error: 12.1103\n",
      "Epoch 4606/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 397.1693 - mean_absolute_error: 11.4858\n",
      "Epoch 4607/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.3920 - mean_absolute_error: 11.6564\n",
      "Epoch 4608/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 370.7154 - mean_absolute_error: 10.8854\n",
      "Epoch 4609/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.9759 - mean_absolute_error: 12.1202\n",
      "Epoch 4610/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 398.8725 - mean_absolute_error: 11.5928\n",
      "Epoch 4611/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 415.0180 - mean_absolute_error: 11.8288\n",
      "Epoch 4612/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.3022 - mean_absolute_error: 11.8308\n",
      "Epoch 4613/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 407.0214 - mean_absolute_error: 11.8929\n",
      "Epoch 4614/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.1694 - mean_absolute_error: 11.5201\n",
      "Epoch 4615/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.3026 - mean_absolute_error: 11.7112\n",
      "Epoch 4616/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 413.4318 - mean_absolute_error: 11.9243\n",
      "Epoch 4617/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 391.1692 - mean_absolute_error: 11.5000\n",
      "Epoch 4618/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 400.7035 - mean_absolute_error: 11.9071\n",
      "Epoch 4619/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 401.9736 - mean_absolute_error: 11.6174\n",
      "Epoch 4620/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.9420 - mean_absolute_error: 12.2882\n",
      "Epoch 4621/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.6796 - mean_absolute_error: 11.7803\n",
      "Epoch 4622/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.8936 - mean_absolute_error: 12.1362\n",
      "Epoch 4623/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 419.1892 - mean_absolute_error: 11.8576\n",
      "Epoch 4624/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 400.7337 - mean_absolute_error: 11.7678\n",
      "Epoch 4625/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.1372 - mean_absolute_error: 11.4864\n",
      "Epoch 4626/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 399.1523 - mean_absolute_error: 11.2491\n",
      "Epoch 4627/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.2377 - mean_absolute_error: 12.0660\n",
      "Epoch 4628/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.3275 - mean_absolute_error: 11.9150\n",
      "Epoch 4629/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 399.2740 - mean_absolute_error: 11.5295\n",
      "Epoch 4630/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 404.0486 - mean_absolute_error: 11.6675\n",
      "Epoch 4631/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.0707 - mean_absolute_error: 11.5694\n",
      "Epoch 4632/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 404.6732 - mean_absolute_error: 11.5613\n",
      "Epoch 4633/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.6974 - mean_absolute_error: 12.0311\n",
      "Epoch 4634/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 400.9614 - mean_absolute_error: 11.3944\n",
      "Epoch 4635/5000\n",
      "344/344 [==============================] - 0s 224us/step - loss: 417.3071 - mean_absolute_error: 11.8522\n",
      "Epoch 4636/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 401.6908 - mean_absolute_error: 11.6187\n",
      "Epoch 4637/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 402.8475 - mean_absolute_error: 11.5415\n",
      "Epoch 4638/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 432.7865 - mean_absolute_error: 12.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4639/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 402.2250 - mean_absolute_error: 11.5774\n",
      "Epoch 4640/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.1215 - mean_absolute_error: 11.8383\n",
      "Epoch 4641/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 405.2737 - mean_absolute_error: 11.8499\n",
      "Epoch 4642/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 425.8367 - mean_absolute_error: 12.1162\n",
      "Epoch 4643/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 392.6935 - mean_absolute_error: 11.3024\n",
      "Epoch 4644/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 388.6413 - mean_absolute_error: 11.3447\n",
      "Epoch 4645/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 408.1059 - mean_absolute_error: 11.6616\n",
      "Epoch 4646/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.5421 - mean_absolute_error: 11.4964\n",
      "Epoch 4647/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.9931 - mean_absolute_error: 11.6523\n",
      "Epoch 4648/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 399.1920 - mean_absolute_error: 11.5599\n",
      "Epoch 4649/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 501.2893 - mean_absolute_error: 12.9780\n",
      "Epoch 4650/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 412.1456 - mean_absolute_error: 11.7368\n",
      "Epoch 4651/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.0896 - mean_absolute_error: 11.6958\n",
      "Epoch 4652/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.5553 - mean_absolute_error: 11.8780\n",
      "Epoch 4653/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 422.8944 - mean_absolute_error: 12.0304\n",
      "Epoch 4654/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.7910 - mean_absolute_error: 11.9162\n",
      "Epoch 4655/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 400.0160 - mean_absolute_error: 11.6685\n",
      "Epoch 4656/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 427.5621 - mean_absolute_error: 12.1274\n",
      "Epoch 4657/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 394.8570 - mean_absolute_error: 11.6017\n",
      "Epoch 4658/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 395.7214 - mean_absolute_error: 11.4382\n",
      "Epoch 4659/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 430.8510 - mean_absolute_error: 12.2824\n",
      "Epoch 4660/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 426.0944 - mean_absolute_error: 12.3237\n",
      "Epoch 4661/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.6105 - mean_absolute_error: 12.1203\n",
      "Epoch 4662/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.4873 - mean_absolute_error: 11.8293\n",
      "Epoch 4663/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 410.8242 - mean_absolute_error: 12.0051\n",
      "Epoch 4664/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.5179 - mean_absolute_error: 11.8083\n",
      "Epoch 4665/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.8495 - mean_absolute_error: 11.7246\n",
      "Epoch 4666/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.5679 - mean_absolute_error: 11.7059\n",
      "Epoch 4667/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 395.4821 - mean_absolute_error: 11.3452\n",
      "Epoch 4668/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 435.9832 - mean_absolute_error: 11.9455\n",
      "Epoch 4669/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 410.6201 - mean_absolute_error: 11.7462\n",
      "Epoch 4670/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.9876 - mean_absolute_error: 11.8080\n",
      "Epoch 4671/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 403.3854 - mean_absolute_error: 11.6990\n",
      "Epoch 4672/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 417.7394 - mean_absolute_error: 11.8357\n",
      "Epoch 4673/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 403.4467 - mean_absolute_error: 11.5693\n",
      "Epoch 4674/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.3164 - mean_absolute_error: 11.4627\n",
      "Epoch 4675/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 430.6151 - mean_absolute_error: 12.2916\n",
      "Epoch 4676/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 397.3439 - mean_absolute_error: 11.5292\n",
      "Epoch 4677/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 398.9806 - mean_absolute_error: 11.5966\n",
      "Epoch 4678/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.2563 - mean_absolute_error: 12.0184\n",
      "Epoch 4679/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.7354 - mean_absolute_error: 11.5489\n",
      "Epoch 4680/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 411.0123 - mean_absolute_error: 11.9249\n",
      "Epoch 4681/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 415.2444 - mean_absolute_error: 11.8936\n",
      "Epoch 4682/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.3608 - mean_absolute_error: 12.0441\n",
      "Epoch 4683/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 399.4243 - mean_absolute_error: 11.8021\n",
      "Epoch 4684/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 410.6597 - mean_absolute_error: 12.1375\n",
      "Epoch 4685/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 447.4076 - mean_absolute_error: 12.5650\n",
      "Epoch 4686/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.6109 - mean_absolute_error: 11.8084\n",
      "Epoch 4687/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.0273 - mean_absolute_error: 11.9756\n",
      "Epoch 4688/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 427.7216 - mean_absolute_error: 12.2866\n",
      "Epoch 4689/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 392.3282 - mean_absolute_error: 11.4615\n",
      "Epoch 4690/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.2722 - mean_absolute_error: 12.0147\n",
      "Epoch 4691/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 396.0868 - mean_absolute_error: 11.3451\n",
      "Epoch 4692/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 436.4414 - mean_absolute_error: 12.1316\n",
      "Epoch 4693/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 390.0479 - mean_absolute_error: 11.3784\n",
      "Epoch 4694/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.6493 - mean_absolute_error: 11.9676\n",
      "Epoch 4695/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 409.9331 - mean_absolute_error: 11.8895\n",
      "Epoch 4696/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 423.9171 - mean_absolute_error: 12.0507\n",
      "Epoch 4697/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 412.0228 - mean_absolute_error: 11.8306\n",
      "Epoch 4698/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 417.6747 - mean_absolute_error: 12.0705\n",
      "Epoch 4699/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 418.5099 - mean_absolute_error: 12.0153\n",
      "Epoch 4700/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.7274 - mean_absolute_error: 12.0554\n",
      "Epoch 4701/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 395.9237 - mean_absolute_error: 11.5030\n",
      "Epoch 4702/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.9464 - mean_absolute_error: 12.0336\n",
      "Epoch 4703/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.9545 - mean_absolute_error: 11.8463\n",
      "Epoch 4704/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 388.6476 - mean_absolute_error: 11.3326\n",
      "Epoch 4705/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 412.4612 - mean_absolute_error: 11.9632\n",
      "Epoch 4706/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 397.0590 - mean_absolute_error: 11.6646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4707/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.2707 - mean_absolute_error: 11.5853\n",
      "Epoch 4708/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 395.8106 - mean_absolute_error: 11.2255\n",
      "Epoch 4709/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 399.7118 - mean_absolute_error: 11.4855\n",
      "Epoch 4710/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 419.2835 - mean_absolute_error: 12.0661\n",
      "Epoch 4711/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 392.8341 - mean_absolute_error: 11.4239\n",
      "Epoch 4712/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 455.7310 - mean_absolute_error: 12.5800\n",
      "Epoch 4713/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 425.8386 - mean_absolute_error: 11.9150\n",
      "Epoch 4714/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 418.7690 - mean_absolute_error: 11.9198\n",
      "Epoch 4715/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.1652 - mean_absolute_error: 11.9195\n",
      "Epoch 4716/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.0641 - mean_absolute_error: 11.7901\n",
      "Epoch 4717/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 424.8316 - mean_absolute_error: 12.2139\n",
      "Epoch 4718/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 401.1237 - mean_absolute_error: 11.7914\n",
      "Epoch 4719/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 400.8307 - mean_absolute_error: 11.8270\n",
      "Epoch 4720/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 396.9110 - mean_absolute_error: 11.4165\n",
      "Epoch 4721/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 425.9952 - mean_absolute_error: 11.8691\n",
      "Epoch 4722/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 415.7382 - mean_absolute_error: 11.8927\n",
      "Epoch 4723/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 443.9763 - mean_absolute_error: 11.8779\n",
      "Epoch 4724/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.3516 - mean_absolute_error: 11.5492\n",
      "Epoch 4725/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.7632 - mean_absolute_error: 11.7472\n",
      "Epoch 4726/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 421.2726 - mean_absolute_error: 12.4870\n",
      "Epoch 4727/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 417.7194 - mean_absolute_error: 12.3228\n",
      "Epoch 4728/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 400.0099 - mean_absolute_error: 11.6822\n",
      "Epoch 4729/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 406.0206 - mean_absolute_error: 11.7280\n",
      "Epoch 4730/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 405.6219 - mean_absolute_error: 11.6536\n",
      "Epoch 4731/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.3154 - mean_absolute_error: 11.9415\n",
      "Epoch 4732/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.7081 - mean_absolute_error: 12.3053\n",
      "Epoch 4733/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.8079 - mean_absolute_error: 11.8323\n",
      "Epoch 4734/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 409.1482 - mean_absolute_error: 11.5940\n",
      "Epoch 4735/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.0112 - mean_absolute_error: 11.7527\n",
      "Epoch 4736/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 399.5775 - mean_absolute_error: 11.6367\n",
      "Epoch 4737/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 403.7723 - mean_absolute_error: 11.7325\n",
      "Epoch 4738/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 406.9800 - mean_absolute_error: 11.7879\n",
      "Epoch 4739/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 382.6711 - mean_absolute_error: 11.3741\n",
      "Epoch 4740/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 402.4101 - mean_absolute_error: 11.7671\n",
      "Epoch 4741/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 410.3644 - mean_absolute_error: 11.6630\n",
      "Epoch 4742/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 391.4776 - mean_absolute_error: 11.2695\n",
      "Epoch 4743/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 393.6812 - mean_absolute_error: 11.2220\n",
      "Epoch 4744/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.9890 - mean_absolute_error: 11.8311\n",
      "Epoch 4745/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 405.7523 - mean_absolute_error: 11.5500\n",
      "Epoch 4746/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 405.5689 - mean_absolute_error: 11.6870\n",
      "Epoch 4747/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 400.4909 - mean_absolute_error: 11.4945\n",
      "Epoch 4748/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 400.9700 - mean_absolute_error: 11.7611\n",
      "Epoch 4749/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 395.0814 - mean_absolute_error: 11.5427\n",
      "Epoch 4750/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 405.0846 - mean_absolute_error: 11.3208\n",
      "Epoch 4751/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.9241 - mean_absolute_error: 11.9431\n",
      "Epoch 4752/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 423.8136 - mean_absolute_error: 11.8928\n",
      "Epoch 4753/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 381.7797 - mean_absolute_error: 11.0370\n",
      "Epoch 4754/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 395.7079 - mean_absolute_error: 11.5648\n",
      "Epoch 4755/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 425.9536 - mean_absolute_error: 12.2095\n",
      "Epoch 4756/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 397.3265 - mean_absolute_error: 11.6525\n",
      "Epoch 4757/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 397.0204 - mean_absolute_error: 11.4390\n",
      "Epoch 4758/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 412.7111 - mean_absolute_error: 11.7349\n",
      "Epoch 4759/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 390.4778 - mean_absolute_error: 11.5072\n",
      "Epoch 4760/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 437.5291 - mean_absolute_error: 12.2742\n",
      "Epoch 4761/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 393.0277 - mean_absolute_error: 11.6095\n",
      "Epoch 4762/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 408.1685 - mean_absolute_error: 11.8260\n",
      "Epoch 4763/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.5598 - mean_absolute_error: 12.1280\n",
      "Epoch 4764/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.2031 - mean_absolute_error: 11.9048\n",
      "Epoch 4765/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 411.2088 - mean_absolute_error: 11.9037\n",
      "Epoch 4766/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 405.6525 - mean_absolute_error: 11.9600\n",
      "Epoch 4767/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 397.9021 - mean_absolute_error: 11.5708\n",
      "Epoch 4768/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 409.4457 - mean_absolute_error: 11.9782\n",
      "Epoch 4769/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 407.8577 - mean_absolute_error: 11.8897\n",
      "Epoch 4770/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 427.7922 - mean_absolute_error: 12.4464\n",
      "Epoch 4771/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 423.7439 - mean_absolute_error: 11.8572\n",
      "Epoch 4772/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 396.3306 - mean_absolute_error: 11.5954\n",
      "Epoch 4773/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.0338 - mean_absolute_error: 11.7584\n",
      "Epoch 4774/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 406.9605 - mean_absolute_error: 12.0126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4775/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.4511 - mean_absolute_error: 11.8973\n",
      "Epoch 4776/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 423.8349 - mean_absolute_error: 12.0381\n",
      "Epoch 4777/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 417.6149 - mean_absolute_error: 11.9036\n",
      "Epoch 4778/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 419.4472 - mean_absolute_error: 11.8664\n",
      "Epoch 4779/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 402.0401 - mean_absolute_error: 11.5547\n",
      "Epoch 4780/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.9762 - mean_absolute_error: 11.8108\n",
      "Epoch 4781/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 398.1545 - mean_absolute_error: 11.8093\n",
      "Epoch 4782/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 414.4966 - mean_absolute_error: 11.9401\n",
      "Epoch 4783/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.5473 - mean_absolute_error: 11.7149\n",
      "Epoch 4784/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.6045 - mean_absolute_error: 12.0242\n",
      "Epoch 4785/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 412.0523 - mean_absolute_error: 11.9865\n",
      "Epoch 4786/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 444.8307 - mean_absolute_error: 11.9929\n",
      "Epoch 4787/5000\n",
      "344/344 [==============================] - 0s 220us/step - loss: 404.8289 - mean_absolute_error: 11.6632\n",
      "Epoch 4788/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 409.4398 - mean_absolute_error: 11.6937\n",
      "Epoch 4789/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 396.5690 - mean_absolute_error: 11.5482\n",
      "Epoch 4790/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 422.9336 - mean_absolute_error: 12.4159\n",
      "Epoch 4791/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 387.2259 - mean_absolute_error: 11.4909\n",
      "Epoch 4792/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.8350 - mean_absolute_error: 11.6597\n",
      "Epoch 4793/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.3016 - mean_absolute_error: 11.6902\n",
      "Epoch 4794/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 390.1698 - mean_absolute_error: 11.3417\n",
      "Epoch 4795/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.4246 - mean_absolute_error: 11.6892\n",
      "Epoch 4796/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 411.6110 - mean_absolute_error: 11.8684\n",
      "Epoch 4797/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 421.6083 - mean_absolute_error: 11.8292\n",
      "Epoch 4798/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.3945 - mean_absolute_error: 11.9696\n",
      "Epoch 4799/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.2102 - mean_absolute_error: 11.6271\n",
      "Epoch 4800/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 415.2170 - mean_absolute_error: 12.0528\n",
      "Epoch 4801/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 416.4305 - mean_absolute_error: 12.0080\n",
      "Epoch 4802/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 408.9525 - mean_absolute_error: 11.9005\n",
      "Epoch 4803/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 424.3423 - mean_absolute_error: 11.9708\n",
      "Epoch 4804/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 395.1909 - mean_absolute_error: 11.8854\n",
      "Epoch 4805/5000\n",
      "344/344 [==============================] - 0s 227us/step - loss: 422.0432 - mean_absolute_error: 11.8727\n",
      "Epoch 4806/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 408.0837 - mean_absolute_error: 11.7091\n",
      "Epoch 4807/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 405.7384 - mean_absolute_error: 11.9018\n",
      "Epoch 4808/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.5373 - mean_absolute_error: 12.1825\n",
      "Epoch 4809/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 424.8016 - mean_absolute_error: 12.1063\n",
      "Epoch 4810/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 405.5085 - mean_absolute_error: 11.6410\n",
      "Epoch 4811/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 396.6252 - mean_absolute_error: 11.5852\n",
      "Epoch 4812/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 399.8458 - mean_absolute_error: 11.4739\n",
      "Epoch 4813/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 401.0558 - mean_absolute_error: 11.9466\n",
      "Epoch 4814/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 385.9038 - mean_absolute_error: 11.2207\n",
      "Epoch 4815/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 407.8286 - mean_absolute_error: 11.6902\n",
      "Epoch 4816/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.5392 - mean_absolute_error: 11.7597\n",
      "Epoch 4817/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 409.1955 - mean_absolute_error: 11.7308\n",
      "Epoch 4818/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 397.4151 - mean_absolute_error: 11.4950\n",
      "Epoch 4819/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.7370 - mean_absolute_error: 11.8162\n",
      "Epoch 4820/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 416.8815 - mean_absolute_error: 11.5044\n",
      "Epoch 4821/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 404.5540 - mean_absolute_error: 11.8230\n",
      "Epoch 4822/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 413.1717 - mean_absolute_error: 12.0482\n",
      "Epoch 4823/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 424.8395 - mean_absolute_error: 12.0856\n",
      "Epoch 4824/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 406.7964 - mean_absolute_error: 11.7954\n",
      "Epoch 4825/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 412.0188 - mean_absolute_error: 11.7499\n",
      "Epoch 4826/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 414.4921 - mean_absolute_error: 12.2399\n",
      "Epoch 4827/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 398.5264 - mean_absolute_error: 11.7870\n",
      "Epoch 4828/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 387.8929 - mean_absolute_error: 11.1309\n",
      "Epoch 4829/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 445.7522 - mean_absolute_error: 12.6468\n",
      "Epoch 4830/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 427.9045 - mean_absolute_error: 12.0676\n",
      "Epoch 4831/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 414.2508 - mean_absolute_error: 12.1818\n",
      "Epoch 4832/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 398.4156 - mean_absolute_error: 11.3480\n",
      "Epoch 4833/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 427.8703 - mean_absolute_error: 12.3466\n",
      "Epoch 4834/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.6000 - mean_absolute_error: 12.2815\n",
      "Epoch 4835/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 411.5988 - mean_absolute_error: 11.9088\n",
      "Epoch 4836/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 482.5887 - mean_absolute_error: 13.0806\n",
      "Epoch 4837/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 402.3826 - mean_absolute_error: 11.7674\n",
      "Epoch 4838/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 416.7614 - mean_absolute_error: 12.0288\n",
      "Epoch 4839/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 408.0056 - mean_absolute_error: 11.7482\n",
      "Epoch 4840/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 422.1152 - mean_absolute_error: 11.8263\n",
      "Epoch 4841/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 386.9486 - mean_absolute_error: 11.3879\n",
      "Epoch 4842/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 421.3300 - mean_absolute_error: 12.0476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4843/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 400.6797 - mean_absolute_error: 11.5205\n",
      "Epoch 4844/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 402.0161 - mean_absolute_error: 11.6957\n",
      "Epoch 4845/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 407.5957 - mean_absolute_error: 11.7726\n",
      "Epoch 4846/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 433.3456 - mean_absolute_error: 12.2433\n",
      "Epoch 4847/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 408.3670 - mean_absolute_error: 12.0423\n",
      "Epoch 4848/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 412.9405 - mean_absolute_error: 11.9248\n",
      "Epoch 4849/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 428.5981 - mean_absolute_error: 11.9597\n",
      "Epoch 4850/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 403.4836 - mean_absolute_error: 11.7099\n",
      "Epoch 4851/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 408.3241 - mean_absolute_error: 11.7045\n",
      "Epoch 4852/5000\n",
      "344/344 [==============================] - 0s 223us/step - loss: 402.8923 - mean_absolute_error: 11.7179\n",
      "Epoch 4853/5000\n",
      "344/344 [==============================] - 0s 226us/step - loss: 400.4519 - mean_absolute_error: 11.3833\n",
      "Epoch 4854/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 404.6164 - mean_absolute_error: 11.6389\n",
      "Epoch 4855/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 436.5764 - mean_absolute_error: 12.6294\n",
      "Epoch 4856/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 404.4844 - mean_absolute_error: 11.9322\n",
      "Epoch 4857/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 423.0008 - mean_absolute_error: 11.9338\n",
      "Epoch 4858/5000\n",
      "344/344 [==============================] - 0s 225us/step - loss: 401.2794 - mean_absolute_error: 11.5025\n",
      "Epoch 4859/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 431.2415 - mean_absolute_error: 12.2588\n",
      "Epoch 4860/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.6114 - mean_absolute_error: 12.0432\n",
      "Epoch 4861/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 395.2893 - mean_absolute_error: 11.6858\n",
      "Epoch 4862/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 410.8822 - mean_absolute_error: 11.8662\n",
      "Epoch 4863/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 405.8053 - mean_absolute_error: 11.7162\n",
      "Epoch 4864/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 380.2891 - mean_absolute_error: 11.5192\n",
      "Epoch 4865/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 425.3722 - mean_absolute_error: 11.8964\n",
      "Epoch 4866/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 428.8973 - mean_absolute_error: 12.1342\n",
      "Epoch 4867/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 420.0385 - mean_absolute_error: 11.9570\n",
      "Epoch 4868/5000\n",
      "344/344 [==============================] - 0s 255us/step - loss: 408.5882 - mean_absolute_error: 11.7218\n",
      "Epoch 4869/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 398.2188 - mean_absolute_error: 11.8738\n",
      "Epoch 4870/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 398.9328 - mean_absolute_error: 11.3732\n",
      "Epoch 4871/5000\n",
      "344/344 [==============================] - 0s 231us/step - loss: 416.4984 - mean_absolute_error: 12.0368\n",
      "Epoch 4872/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 397.1176 - mean_absolute_error: 11.5321\n",
      "Epoch 4873/5000\n",
      "344/344 [==============================] - 0s 250us/step - loss: 404.6078 - mean_absolute_error: 11.4840\n",
      "Epoch 4874/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 414.2075 - mean_absolute_error: 11.9419\n",
      "Epoch 4875/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 407.1872 - mean_absolute_error: 11.9917\n",
      "Epoch 4876/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.3042 - mean_absolute_error: 12.2769\n",
      "Epoch 4877/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 409.1041 - mean_absolute_error: 12.0291\n",
      "Epoch 4878/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 398.8612 - mean_absolute_error: 11.7208\n",
      "Epoch 4879/5000\n",
      "344/344 [==============================] - 0s 270us/step - loss: 411.5895 - mean_absolute_error: 11.8010\n",
      "Epoch 4880/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 402.6072 - mean_absolute_error: 11.6141\n",
      "Epoch 4881/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 406.7436 - mean_absolute_error: 11.8404\n",
      "Epoch 4882/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 422.6189 - mean_absolute_error: 11.8534\n",
      "Epoch 4883/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 413.2607 - mean_absolute_error: 12.1141\n",
      "Epoch 4884/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 420.8031 - mean_absolute_error: 11.9913\n",
      "Epoch 4885/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 404.6137 - mean_absolute_error: 11.8089\n",
      "Epoch 4886/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 397.2524 - mean_absolute_error: 11.8369\n",
      "Epoch 4887/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 400.7621 - mean_absolute_error: 11.7487\n",
      "Epoch 4888/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.3513 - mean_absolute_error: 11.5359\n",
      "Epoch 4889/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 420.1107 - mean_absolute_error: 11.9971\n",
      "Epoch 4890/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.2393 - mean_absolute_error: 11.7969\n",
      "Epoch 4891/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.8046 - mean_absolute_error: 12.0822\n",
      "Epoch 4892/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 433.1121 - mean_absolute_error: 12.3892\n",
      "Epoch 4893/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 408.4573 - mean_absolute_error: 11.7897\n",
      "Epoch 4894/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 405.4800 - mean_absolute_error: 11.9042\n",
      "Epoch 4895/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 404.1324 - mean_absolute_error: 11.5378\n",
      "Epoch 4896/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 422.9333 - mean_absolute_error: 12.1011\n",
      "Epoch 4897/5000\n",
      "344/344 [==============================] - 0s 261us/step - loss: 427.1341 - mean_absolute_error: 12.1388\n",
      "Epoch 4898/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 409.7160 - mean_absolute_error: 11.6592\n",
      "Epoch 4899/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 411.9543 - mean_absolute_error: 11.5372\n",
      "Epoch 4900/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 392.5535 - mean_absolute_error: 11.4261\n",
      "Epoch 4901/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 410.0107 - mean_absolute_error: 11.5795\n",
      "Epoch 4902/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.3396 - mean_absolute_error: 11.7303\n",
      "Epoch 4903/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 405.4753 - mean_absolute_error: 11.7873\n",
      "Epoch 4904/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 427.6828 - mean_absolute_error: 12.2344\n",
      "Epoch 4905/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 398.0037 - mean_absolute_error: 11.6606\n",
      "Epoch 4906/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 426.9600 - mean_absolute_error: 12.4317\n",
      "Epoch 4907/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 414.0481 - mean_absolute_error: 11.7012\n",
      "Epoch 4908/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 498.6215 - mean_absolute_error: 12.5709\n",
      "Epoch 4909/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 423.7262 - mean_absolute_error: 12.1981\n",
      "Epoch 4910/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 425.6418 - mean_absolute_error: 12.0909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4911/5000\n",
      "344/344 [==============================] - 0s 236us/step - loss: 404.9182 - mean_absolute_error: 11.5649\n",
      "Epoch 4912/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 416.8997 - mean_absolute_error: 11.8077\n",
      "Epoch 4913/5000\n",
      "344/344 [==============================] - 0s 264us/step - loss: 399.1811 - mean_absolute_error: 11.5913\n",
      "Epoch 4914/5000\n",
      "344/344 [==============================] - 0s 278us/step - loss: 393.3000 - mean_absolute_error: 11.6208\n",
      "Epoch 4915/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 392.9018 - mean_absolute_error: 11.4470\n",
      "Epoch 4916/5000\n",
      "344/344 [==============================] - 0s 294us/step - loss: 421.4068 - mean_absolute_error: 12.0928\n",
      "Epoch 4917/5000\n",
      "344/344 [==============================] - 0s 248us/step - loss: 420.4854 - mean_absolute_error: 12.1990\n",
      "Epoch 4918/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 420.4021 - mean_absolute_error: 12.2171\n",
      "Epoch 4919/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 412.4973 - mean_absolute_error: 11.5720\n",
      "Epoch 4920/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 426.6117 - mean_absolute_error: 12.0942\n",
      "Epoch 4921/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 407.6925 - mean_absolute_error: 11.5919\n",
      "Epoch 4922/5000\n",
      "344/344 [==============================] - 0s 228us/step - loss: 407.9570 - mean_absolute_error: 11.9719\n",
      "Epoch 4923/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 394.4474 - mean_absolute_error: 11.5797\n",
      "Epoch 4924/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.1614 - mean_absolute_error: 11.6263\n",
      "Epoch 4925/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 416.7145 - mean_absolute_error: 12.1867\n",
      "Epoch 4926/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 393.6829 - mean_absolute_error: 11.7169\n",
      "Epoch 4927/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 407.2990 - mean_absolute_error: 11.7961\n",
      "Epoch 4928/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 408.7883 - mean_absolute_error: 11.5385\n",
      "Epoch 4929/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 396.5467 - mean_absolute_error: 11.7149\n",
      "Epoch 4930/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 419.9116 - mean_absolute_error: 12.0773\n",
      "Epoch 4931/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 408.8102 - mean_absolute_error: 11.8212\n",
      "Epoch 4932/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 413.7291 - mean_absolute_error: 11.7316\n",
      "Epoch 4933/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 407.3284 - mean_absolute_error: 11.4816\n",
      "Epoch 4934/5000\n",
      "344/344 [==============================] - 0s 233us/step - loss: 417.3080 - mean_absolute_error: 11.8968\n",
      "Epoch 4935/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 399.7279 - mean_absolute_error: 11.7540\n",
      "Epoch 4936/5000\n",
      "344/344 [==============================] - 0s 246us/step - loss: 412.6741 - mean_absolute_error: 11.9826\n",
      "Epoch 4937/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 417.3149 - mean_absolute_error: 12.0302\n",
      "Epoch 4938/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 405.2993 - mean_absolute_error: 11.5495\n",
      "Epoch 4939/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 413.9299 - mean_absolute_error: 11.9317\n",
      "Epoch 4940/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 402.0493 - mean_absolute_error: 11.4598\n",
      "Epoch 4941/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 412.1093 - mean_absolute_error: 11.8549\n",
      "Epoch 4942/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 420.7718 - mean_absolute_error: 11.8513\n",
      "Epoch 4943/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 391.3652 - mean_absolute_error: 11.3395\n",
      "Epoch 4944/5000\n",
      "344/344 [==============================] - 0s 234us/step - loss: 419.6800 - mean_absolute_error: 11.8967\n",
      "Epoch 4945/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 408.1877 - mean_absolute_error: 11.7397\n",
      "Epoch 4946/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 398.9883 - mean_absolute_error: 11.4274\n",
      "Epoch 4947/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 398.3638 - mean_absolute_error: 11.6151\n",
      "Epoch 4948/5000\n",
      "344/344 [==============================] - 0s 239us/step - loss: 408.6944 - mean_absolute_error: 11.9105\n",
      "Epoch 4949/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 389.9769 - mean_absolute_error: 11.2927\n",
      "Epoch 4950/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 418.4627 - mean_absolute_error: 12.0843\n",
      "Epoch 4951/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 432.3638 - mean_absolute_error: 11.9820\n",
      "Epoch 4952/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 407.9118 - mean_absolute_error: 11.6478\n",
      "Epoch 4953/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 398.7000 - mean_absolute_error: 11.8818\n",
      "Epoch 4954/5000\n",
      "344/344 [==============================] - 0s 262us/step - loss: 391.5648 - mean_absolute_error: 11.3037\n",
      "Epoch 4955/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 416.2086 - mean_absolute_error: 11.9532\n",
      "Epoch 4956/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 410.4738 - mean_absolute_error: 11.9839\n",
      "Epoch 4957/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 397.1534 - mean_absolute_error: 11.5684\n",
      "Epoch 4958/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 406.8926 - mean_absolute_error: 11.7684\n",
      "Epoch 4959/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.1364 - mean_absolute_error: 11.6007\n",
      "Epoch 4960/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 431.2061 - mean_absolute_error: 11.8895\n",
      "Epoch 4961/5000\n",
      "344/344 [==============================] - 0s 252us/step - loss: 398.2815 - mean_absolute_error: 11.4960\n",
      "Epoch 4962/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 417.0756 - mean_absolute_error: 12.0393\n",
      "Epoch 4963/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 419.0563 - mean_absolute_error: 11.7198\n",
      "Epoch 4964/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 403.3591 - mean_absolute_error: 11.7054\n",
      "Epoch 4965/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 422.4928 - mean_absolute_error: 12.0902\n",
      "Epoch 4966/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 409.4193 - mean_absolute_error: 11.7067\n",
      "Epoch 4967/5000\n",
      "344/344 [==============================] - 0s 240us/step - loss: 414.4923 - mean_absolute_error: 12.0433\n",
      "Epoch 4968/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 403.8694 - mean_absolute_error: 11.7535\n",
      "Epoch 4969/5000\n",
      "344/344 [==============================] - 0s 242us/step - loss: 401.1969 - mean_absolute_error: 11.5821\n",
      "Epoch 4970/5000\n",
      "344/344 [==============================] - 0s 245us/step - loss: 400.6280 - mean_absolute_error: 11.9387\n",
      "Epoch 4971/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 422.1860 - mean_absolute_error: 11.9294\n",
      "Epoch 4972/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 432.2111 - mean_absolute_error: 12.0942\n",
      "Epoch 4973/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 507.0447 - mean_absolute_error: 12.3350\n",
      "Epoch 4974/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 405.1585 - mean_absolute_error: 11.7211\n",
      "Epoch 4975/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 420.4637 - mean_absolute_error: 12.2422\n",
      "Epoch 4976/5000\n",
      "344/344 [==============================] - 0s 232us/step - loss: 404.6048 - mean_absolute_error: 11.9344\n",
      "Epoch 4977/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 394.2028 - mean_absolute_error: 11.3567\n",
      "Epoch 4978/5000\n",
      "344/344 [==============================] - 0s 247us/step - loss: 417.0523 - mean_absolute_error: 12.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4979/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 408.1450 - mean_absolute_error: 11.7726\n",
      "Epoch 4980/5000\n",
      "344/344 [==============================] - 0s 251us/step - loss: 390.9515 - mean_absolute_error: 11.6511\n",
      "Epoch 4981/5000\n",
      "344/344 [==============================] - 0s 258us/step - loss: 406.3760 - mean_absolute_error: 11.6784\n",
      "Epoch 4982/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 411.4655 - mean_absolute_error: 11.8617\n",
      "Epoch 4983/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 418.3659 - mean_absolute_error: 11.9191\n",
      "Epoch 4984/5000\n",
      "344/344 [==============================] - 0s 333us/step - loss: 393.8355 - mean_absolute_error: 11.3186\n",
      "Epoch 4985/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 417.7085 - mean_absolute_error: 11.7074\n",
      "Epoch 4986/5000\n",
      "344/344 [==============================] - 0s 235us/step - loss: 407.1101 - mean_absolute_error: 12.0484\n",
      "Epoch 4987/5000\n",
      "344/344 [==============================] - 0s 230us/step - loss: 412.1344 - mean_absolute_error: 11.9194\n",
      "Epoch 4988/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 454.1309 - mean_absolute_error: 12.1705\n",
      "Epoch 4989/5000\n",
      "344/344 [==============================] - 0s 243us/step - loss: 407.5729 - mean_absolute_error: 11.5349\n",
      "Epoch 4990/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 415.1368 - mean_absolute_error: 11.9309\n",
      "Epoch 4991/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 421.4247 - mean_absolute_error: 12.1325\n",
      "Epoch 4992/5000\n",
      "344/344 [==============================] - 0s 229us/step - loss: 419.4326 - mean_absolute_error: 12.1226\n",
      "Epoch 4993/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 409.4489 - mean_absolute_error: 11.7641\n",
      "Epoch 4994/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 393.9759 - mean_absolute_error: 11.5638\n",
      "Epoch 4995/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 392.6078 - mean_absolute_error: 11.5311\n",
      "Epoch 4996/5000\n",
      "344/344 [==============================] - 0s 249us/step - loss: 401.1913 - mean_absolute_error: 11.7214\n",
      "Epoch 4997/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 416.8564 - mean_absolute_error: 11.8712\n",
      "Epoch 4998/5000\n",
      "344/344 [==============================] - 0s 244us/step - loss: 404.0153 - mean_absolute_error: 11.6145\n",
      "Epoch 4999/5000\n",
      "344/344 [==============================] - 0s 238us/step - loss: 392.9371 - mean_absolute_error: 11.4301\n",
      "Epoch 5000/5000\n",
      "344/344 [==============================] - 0s 241us/step - loss: 403.7438 - mean_absolute_error: 11.4502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a69fc6b860>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleModel.fit(x=X_train, y=y_train, epochs=5000, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 8s 207ms/step\n",
      "\n",
      "Loss = 834.8848900428185\n",
      "Test mean absolute error = 14.357913836454733\n"
     ]
    }
   ],
   "source": [
    "preds = simpleModel.evaluate(x=X_test, y=y_test)\n",
    "### END CODE HERE ###\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test mean absolute error = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedding_scaled = scale(X_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_embedding_scaled[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 201)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 201)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(simpleModel, to_file='simpleModel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 201)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedding_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.304261898810203"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_embedding_scaled, y)\n",
    "#R_2 = reg.score(X_embedding, y)\n",
    "#print('linear regression r2: ', R_2)\n",
    "y_pred = reg.predict(X_embedding_scaled)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matrix</th>\n",
       "      <th>filler</th>\n",
       "      <th>filler percentage</th>\n",
       "      <th>matrix_embedding_0</th>\n",
       "      <th>matrix_embedding_1</th>\n",
       "      <th>matrix_embedding_2</th>\n",
       "      <th>matrix_embedding_3</th>\n",
       "      <th>matrix_embedding_4</th>\n",
       "      <th>matrix_embedding_5</th>\n",
       "      <th>matrix_embedding_6</th>\n",
       "      <th>...</th>\n",
       "      <th>filler_embedding_0</th>\n",
       "      <th>filler_embedding_1</th>\n",
       "      <th>filler_embedding_2</th>\n",
       "      <th>filler_embedding_3</th>\n",
       "      <th>filler_embedding_4</th>\n",
       "      <th>filler_embedding_5</th>\n",
       "      <th>filler_embedding_6</th>\n",
       "      <th>filler_embedding_7</th>\n",
       "      <th>filler_embedding_8</th>\n",
       "      <th>filler_embedding_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bisphenol A PC</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.192542</td>\n",
       "      <td>-1.632548</td>\n",
       "      <td>1.659807</td>\n",
       "      <td>1.341893</td>\n",
       "      <td>0.178591</td>\n",
       "      <td>0.386626</td>\n",
       "      <td>1.017890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bisphenol A PC</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.192542</td>\n",
       "      <td>-1.632548</td>\n",
       "      <td>1.659807</td>\n",
       "      <td>1.341893</td>\n",
       "      <td>0.178591</td>\n",
       "      <td>0.386626</td>\n",
       "      <td>1.017890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bisphenol A PC</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.192542</td>\n",
       "      <td>-1.632548</td>\n",
       "      <td>1.659807</td>\n",
       "      <td>1.341893</td>\n",
       "      <td>0.178591</td>\n",
       "      <td>0.386626</td>\n",
       "      <td>1.017890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bisphenol A PC</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.192542</td>\n",
       "      <td>-1.632548</td>\n",
       "      <td>1.659807</td>\n",
       "      <td>1.341893</td>\n",
       "      <td>0.178591</td>\n",
       "      <td>0.386626</td>\n",
       "      <td>1.017890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bisphenol A PC</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.192542</td>\n",
       "      <td>-1.632548</td>\n",
       "      <td>1.659807</td>\n",
       "      <td>1.341893</td>\n",
       "      <td>0.178591</td>\n",
       "      <td>0.386626</td>\n",
       "      <td>1.017890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EPDM</td>\n",
       "      <td>PANI-organoclay</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-0.613252</td>\n",
       "      <td>-2.009651</td>\n",
       "      <td>1.656685</td>\n",
       "      <td>1.279108</td>\n",
       "      <td>0.628480</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.356163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438009</td>\n",
       "      <td>-1.828649</td>\n",
       "      <td>1.200803</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.594996</td>\n",
       "      <td>0.211015</td>\n",
       "      <td>0.222315</td>\n",
       "      <td>0.581289</td>\n",
       "      <td>-0.237836</td>\n",
       "      <td>-0.822522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EPDM</td>\n",
       "      <td>PANI-organoclay</td>\n",
       "      <td>20.00</td>\n",
       "      <td>-0.613252</td>\n",
       "      <td>-2.009651</td>\n",
       "      <td>1.656685</td>\n",
       "      <td>1.279108</td>\n",
       "      <td>0.628480</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.356163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438009</td>\n",
       "      <td>-1.828649</td>\n",
       "      <td>1.200803</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.594996</td>\n",
       "      <td>0.211015</td>\n",
       "      <td>0.222315</td>\n",
       "      <td>0.581289</td>\n",
       "      <td>-0.237836</td>\n",
       "      <td>-0.822522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EPDM</td>\n",
       "      <td>PANI-organoclay</td>\n",
       "      <td>30.00</td>\n",
       "      <td>-0.613252</td>\n",
       "      <td>-2.009651</td>\n",
       "      <td>1.656685</td>\n",
       "      <td>1.279108</td>\n",
       "      <td>0.628480</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.356163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438009</td>\n",
       "      <td>-1.828649</td>\n",
       "      <td>1.200803</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.594996</td>\n",
       "      <td>0.211015</td>\n",
       "      <td>0.222315</td>\n",
       "      <td>0.581289</td>\n",
       "      <td>-0.237836</td>\n",
       "      <td>-0.822522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EPDM</td>\n",
       "      <td>PANI-organoclay</td>\n",
       "      <td>40.00</td>\n",
       "      <td>-0.613252</td>\n",
       "      <td>-2.009651</td>\n",
       "      <td>1.656685</td>\n",
       "      <td>1.279108</td>\n",
       "      <td>0.628480</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.356163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438009</td>\n",
       "      <td>-1.828649</td>\n",
       "      <td>1.200803</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.594996</td>\n",
       "      <td>0.211015</td>\n",
       "      <td>0.222315</td>\n",
       "      <td>0.581289</td>\n",
       "      <td>-0.237836</td>\n",
       "      <td>-0.822522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EPDM</td>\n",
       "      <td>PANI-organoclay</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.613252</td>\n",
       "      <td>-2.009651</td>\n",
       "      <td>1.656685</td>\n",
       "      <td>1.279108</td>\n",
       "      <td>0.628480</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.356163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438009</td>\n",
       "      <td>-1.828649</td>\n",
       "      <td>1.200803</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.594996</td>\n",
       "      <td>0.211015</td>\n",
       "      <td>0.222315</td>\n",
       "      <td>0.581289</td>\n",
       "      <td>-0.237836</td>\n",
       "      <td>-0.822522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>Na-montmorillonite</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.782710</td>\n",
       "      <td>-1.936885</td>\n",
       "      <td>0.865395</td>\n",
       "      <td>1.073750</td>\n",
       "      <td>0.697836</td>\n",
       "      <td>0.353082</td>\n",
       "      <td>-0.625494</td>\n",
       "      <td>-0.098894</td>\n",
       "      <td>-0.988201</td>\n",
       "      <td>-0.401390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>Na-montmorillonite</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.782710</td>\n",
       "      <td>-1.936885</td>\n",
       "      <td>0.865395</td>\n",
       "      <td>1.073750</td>\n",
       "      <td>0.697836</td>\n",
       "      <td>0.353082</td>\n",
       "      <td>-0.625494</td>\n",
       "      <td>-0.098894</td>\n",
       "      <td>-0.988201</td>\n",
       "      <td>-0.401390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>Na-montmorillonite</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.782710</td>\n",
       "      <td>-1.936885</td>\n",
       "      <td>0.865395</td>\n",
       "      <td>1.073750</td>\n",
       "      <td>0.697836</td>\n",
       "      <td>0.353082</td>\n",
       "      <td>-0.625494</td>\n",
       "      <td>-0.098894</td>\n",
       "      <td>-0.988201</td>\n",
       "      <td>-0.401390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>Na-montmorillonite</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.782710</td>\n",
       "      <td>-1.936885</td>\n",
       "      <td>0.865395</td>\n",
       "      <td>1.073750</td>\n",
       "      <td>0.697836</td>\n",
       "      <td>0.353082</td>\n",
       "      <td>-0.625494</td>\n",
       "      <td>-0.098894</td>\n",
       "      <td>-0.988201</td>\n",
       "      <td>-0.401390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>Na-montmorillonite</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.782710</td>\n",
       "      <td>-1.936885</td>\n",
       "      <td>0.865395</td>\n",
       "      <td>1.073750</td>\n",
       "      <td>0.697836</td>\n",
       "      <td>0.353082</td>\n",
       "      <td>-0.625494</td>\n",
       "      <td>-0.098894</td>\n",
       "      <td>-0.988201</td>\n",
       "      <td>-0.401390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.700052</td>\n",
       "      <td>-2.180860</td>\n",
       "      <td>2.324012</td>\n",
       "      <td>0.278129</td>\n",
       "      <td>1.540644</td>\n",
       "      <td>0.165931</td>\n",
       "      <td>0.770470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329110</td>\n",
       "      <td>-1.867637</td>\n",
       "      <td>1.356459</td>\n",
       "      <td>0.748859</td>\n",
       "      <td>0.334538</td>\n",
       "      <td>-0.182986</td>\n",
       "      <td>-0.437511</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.825460</td>\n",
       "      <td>-0.887080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.700052</td>\n",
       "      <td>-2.180860</td>\n",
       "      <td>2.324012</td>\n",
       "      <td>0.278129</td>\n",
       "      <td>1.540644</td>\n",
       "      <td>0.165931</td>\n",
       "      <td>0.770470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329110</td>\n",
       "      <td>-1.867637</td>\n",
       "      <td>1.356459</td>\n",
       "      <td>0.748859</td>\n",
       "      <td>0.334538</td>\n",
       "      <td>-0.182986</td>\n",
       "      <td>-0.437511</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.825460</td>\n",
       "      <td>-0.887080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.700052</td>\n",
       "      <td>-2.180860</td>\n",
       "      <td>2.324012</td>\n",
       "      <td>0.278129</td>\n",
       "      <td>1.540644</td>\n",
       "      <td>0.165931</td>\n",
       "      <td>0.770470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329110</td>\n",
       "      <td>-1.867637</td>\n",
       "      <td>1.356459</td>\n",
       "      <td>0.748859</td>\n",
       "      <td>0.334538</td>\n",
       "      <td>-0.182986</td>\n",
       "      <td>-0.437511</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.825460</td>\n",
       "      <td>-0.887080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.700052</td>\n",
       "      <td>-2.180860</td>\n",
       "      <td>2.324012</td>\n",
       "      <td>0.278129</td>\n",
       "      <td>1.540644</td>\n",
       "      <td>0.165931</td>\n",
       "      <td>0.770470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329110</td>\n",
       "      <td>-1.867637</td>\n",
       "      <td>1.356459</td>\n",
       "      <td>0.748859</td>\n",
       "      <td>0.334538</td>\n",
       "      <td>-0.182986</td>\n",
       "      <td>-0.437511</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.825460</td>\n",
       "      <td>-0.887080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.700052</td>\n",
       "      <td>-2.180860</td>\n",
       "      <td>2.324012</td>\n",
       "      <td>0.278129</td>\n",
       "      <td>1.540644</td>\n",
       "      <td>0.165931</td>\n",
       "      <td>0.770470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329110</td>\n",
       "      <td>-1.867637</td>\n",
       "      <td>1.356459</td>\n",
       "      <td>0.748859</td>\n",
       "      <td>0.334538</td>\n",
       "      <td>-0.182986</td>\n",
       "      <td>-0.437511</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.825460</td>\n",
       "      <td>-0.887080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.700052</td>\n",
       "      <td>-2.180860</td>\n",
       "      <td>2.324012</td>\n",
       "      <td>0.278129</td>\n",
       "      <td>1.540644</td>\n",
       "      <td>0.165931</td>\n",
       "      <td>0.770470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329110</td>\n",
       "      <td>-1.867637</td>\n",
       "      <td>1.356459</td>\n",
       "      <td>0.748859</td>\n",
       "      <td>0.334538</td>\n",
       "      <td>-0.182986</td>\n",
       "      <td>-0.437511</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.825460</td>\n",
       "      <td>-0.887080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SC-15 epoxy</td>\n",
       "      <td>SWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.700052</td>\n",
       "      <td>-2.180860</td>\n",
       "      <td>2.324012</td>\n",
       "      <td>0.278129</td>\n",
       "      <td>1.540644</td>\n",
       "      <td>0.165931</td>\n",
       "      <td>0.770470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329110</td>\n",
       "      <td>-1.867637</td>\n",
       "      <td>1.356459</td>\n",
       "      <td>0.748859</td>\n",
       "      <td>0.334538</td>\n",
       "      <td>-0.182986</td>\n",
       "      <td>-0.437511</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.825460</td>\n",
       "      <td>-0.887080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.096003</td>\n",
       "      <td>-0.286935</td>\n",
       "      <td>0.441681</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>-0.027919</td>\n",
       "      <td>-0.297818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.096003</td>\n",
       "      <td>-0.286935</td>\n",
       "      <td>0.441681</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>-0.027919</td>\n",
       "      <td>-0.297818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.096003</td>\n",
       "      <td>-0.286935</td>\n",
       "      <td>0.441681</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>-0.027919</td>\n",
       "      <td>-0.297818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.096003</td>\n",
       "      <td>-0.286935</td>\n",
       "      <td>0.441681</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>-0.027919</td>\n",
       "      <td>-0.297818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.096003</td>\n",
       "      <td>-0.286935</td>\n",
       "      <td>0.441681</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>-0.027919</td>\n",
       "      <td>-0.297818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.096003</td>\n",
       "      <td>-0.286935</td>\n",
       "      <td>0.441681</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>-0.027919</td>\n",
       "      <td>-0.297818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.096003</td>\n",
       "      <td>-0.286935</td>\n",
       "      <td>0.441681</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>-0.027919</td>\n",
       "      <td>-0.297818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DGEBA</td>\n",
       "      <td>MWCNT</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.096003</td>\n",
       "      <td>-0.286935</td>\n",
       "      <td>0.441681</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>-0.027919</td>\n",
       "      <td>-0.297818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550864</td>\n",
       "      <td>-4.518711</td>\n",
       "      <td>1.692080</td>\n",
       "      <td>1.566751</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>-0.750696</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>1.449176</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>poly(vinyl butyral)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.320863</td>\n",
       "      <td>-0.227312</td>\n",
       "      <td>2.612893</td>\n",
       "      <td>0.426401</td>\n",
       "      <td>1.372306</td>\n",
       "      <td>1.256093</td>\n",
       "      <td>-1.129196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>poly(vinyl butyral)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.320863</td>\n",
       "      <td>-0.227312</td>\n",
       "      <td>2.612893</td>\n",
       "      <td>0.426401</td>\n",
       "      <td>1.372306</td>\n",
       "      <td>1.256093</td>\n",
       "      <td>-1.129196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>poly(vinyl butyral)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.320863</td>\n",
       "      <td>-0.227312</td>\n",
       "      <td>2.612893</td>\n",
       "      <td>0.426401</td>\n",
       "      <td>1.372306</td>\n",
       "      <td>1.256093</td>\n",
       "      <td>-1.129196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>poly(vinyl butyral)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.320863</td>\n",
       "      <td>-0.227312</td>\n",
       "      <td>2.612893</td>\n",
       "      <td>0.426401</td>\n",
       "      <td>1.372306</td>\n",
       "      <td>1.256093</td>\n",
       "      <td>-1.129196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>poly(vinyl butyral)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.320863</td>\n",
       "      <td>-0.227312</td>\n",
       "      <td>2.612893</td>\n",
       "      <td>0.426401</td>\n",
       "      <td>1.372306</td>\n",
       "      <td>1.256093</td>\n",
       "      <td>-1.129196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.381263</td>\n",
       "      <td>-0.313671</td>\n",
       "      <td>2.720820</td>\n",
       "      <td>0.379035</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>1.330841</td>\n",
       "      <td>-1.418151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.381263</td>\n",
       "      <td>-0.313671</td>\n",
       "      <td>2.720820</td>\n",
       "      <td>0.379035</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>1.330841</td>\n",
       "      <td>-1.418151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.381263</td>\n",
       "      <td>-0.313671</td>\n",
       "      <td>2.720820</td>\n",
       "      <td>0.379035</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>1.330841</td>\n",
       "      <td>-1.418151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.381263</td>\n",
       "      <td>-0.313671</td>\n",
       "      <td>2.720820</td>\n",
       "      <td>0.379035</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>1.330841</td>\n",
       "      <td>-1.418151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.381263</td>\n",
       "      <td>-0.313671</td>\n",
       "      <td>2.720820</td>\n",
       "      <td>0.379035</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>1.330841</td>\n",
       "      <td>-1.418151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.381263</td>\n",
       "      <td>-0.313671</td>\n",
       "      <td>2.720820</td>\n",
       "      <td>0.379035</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>1.330841</td>\n",
       "      <td>-1.418151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.381263</td>\n",
       "      <td>-0.313671</td>\n",
       "      <td>2.720820</td>\n",
       "      <td>0.379035</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>1.330841</td>\n",
       "      <td>-1.418151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.381263</td>\n",
       "      <td>-0.313671</td>\n",
       "      <td>2.720820</td>\n",
       "      <td>0.379035</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>1.330841</td>\n",
       "      <td>-1.418151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>poly(vinyl alcohol)</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.381263</td>\n",
       "      <td>-0.313671</td>\n",
       "      <td>2.720820</td>\n",
       "      <td>0.379035</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>1.330841</td>\n",
       "      <td>-1.418151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>polybutylene succinate</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-0.083313</td>\n",
       "      <td>-0.081606</td>\n",
       "      <td>0.267521</td>\n",
       "      <td>0.117444</td>\n",
       "      <td>0.105140</td>\n",
       "      <td>-0.027380</td>\n",
       "      <td>-0.083885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>polybutylene succinate</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-0.083313</td>\n",
       "      <td>-0.081606</td>\n",
       "      <td>0.267521</td>\n",
       "      <td>0.117444</td>\n",
       "      <td>0.105140</td>\n",
       "      <td>-0.027380</td>\n",
       "      <td>-0.083885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>polybutylene succinate</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.083313</td>\n",
       "      <td>-0.081606</td>\n",
       "      <td>0.267521</td>\n",
       "      <td>0.117444</td>\n",
       "      <td>0.105140</td>\n",
       "      <td>-0.027380</td>\n",
       "      <td>-0.083885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>epoxy</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.520492</td>\n",
       "      <td>-3.907013</td>\n",
       "      <td>3.073305</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>2.355958</td>\n",
       "      <td>0.420001</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>bisphenol-A phthalonitrile</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.072395</td>\n",
       "      <td>-0.579112</td>\n",
       "      <td>1.485731</td>\n",
       "      <td>0.316660</td>\n",
       "      <td>0.740780</td>\n",
       "      <td>0.122093</td>\n",
       "      <td>-0.295983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>bisphenol-A phthalonitrile</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.072395</td>\n",
       "      <td>-0.579112</td>\n",
       "      <td>1.485731</td>\n",
       "      <td>0.316660</td>\n",
       "      <td>0.740780</td>\n",
       "      <td>0.122093</td>\n",
       "      <td>-0.295983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>bisphenol-A phthalonitrile</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.072395</td>\n",
       "      <td>-0.579112</td>\n",
       "      <td>1.485731</td>\n",
       "      <td>0.316660</td>\n",
       "      <td>0.740780</td>\n",
       "      <td>0.122093</td>\n",
       "      <td>-0.295983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>bisphenol-A phthalonitrile</td>\n",
       "      <td>titanium dioxide</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.072395</td>\n",
       "      <td>-0.579112</td>\n",
       "      <td>1.485731</td>\n",
       "      <td>0.316660</td>\n",
       "      <td>0.740780</td>\n",
       "      <td>0.122093</td>\n",
       "      <td>-0.295983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143969</td>\n",
       "      <td>-0.345050</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>0.413839</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>-0.482864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         matrix              filler  filler percentage  \\\n",
       "0                bisphenol A PC               MWCNT              10.00   \n",
       "1                bisphenol A PC               MWCNT               2.00   \n",
       "2                bisphenol A PC               MWCNT               5.00   \n",
       "3                bisphenol A PC               MWCNT               5.00   \n",
       "4                bisphenol A PC               MWCNT               0.00   \n",
       "5                          EPDM     PANI-organoclay              10.00   \n",
       "6                          EPDM     PANI-organoclay              20.00   \n",
       "7                          EPDM     PANI-organoclay              30.00   \n",
       "8                          EPDM     PANI-organoclay              40.00   \n",
       "9                          EPDM     PANI-organoclay               0.00   \n",
       "10                        epoxy  Na-montmorillonite               0.00   \n",
       "11                        epoxy  Na-montmorillonite               1.00   \n",
       "12                        epoxy  Na-montmorillonite               7.00   \n",
       "13                        epoxy  Na-montmorillonite               1.00   \n",
       "14                        epoxy  Na-montmorillonite               7.00   \n",
       "15                  SC-15 epoxy               SWCNT               0.00   \n",
       "16                  SC-15 epoxy               SWCNT               0.50   \n",
       "17                  SC-15 epoxy               SWCNT               0.50   \n",
       "18                  SC-15 epoxy               SWCNT               0.50   \n",
       "19                  SC-15 epoxy               SWCNT               0.50   \n",
       "20                  SC-15 epoxy               SWCNT               0.50   \n",
       "21                  SC-15 epoxy               SWCNT               0.50   \n",
       "22                        DGEBA               MWCNT               0.05   \n",
       "23                        DGEBA               MWCNT               0.05   \n",
       "24                        DGEBA               MWCNT               0.10   \n",
       "25                        DGEBA               MWCNT               0.10   \n",
       "26                        DGEBA               MWCNT               0.25   \n",
       "27                        DGEBA               MWCNT               0.25   \n",
       "28                        DGEBA               MWCNT               0.50   \n",
       "29                        DGEBA               MWCNT               0.50   \n",
       "..                          ...                 ...                ...   \n",
       "353         poly(vinyl butyral)    titanium dioxide               5.00   \n",
       "354         poly(vinyl butyral)    titanium dioxide               7.00   \n",
       "355         poly(vinyl butyral)    titanium dioxide               7.00   \n",
       "356         poly(vinyl butyral)    titanium dioxide               0.00   \n",
       "357         poly(vinyl butyral)    titanium dioxide               0.00   \n",
       "358         poly(vinyl alcohol)    titanium dioxide               1.50   \n",
       "359         poly(vinyl alcohol)    titanium dioxide               0.20   \n",
       "360         poly(vinyl alcohol)    titanium dioxide               0.50   \n",
       "361         poly(vinyl alcohol)    titanium dioxide               1.00   \n",
       "362         poly(vinyl alcohol)    titanium dioxide               1.50   \n",
       "363         poly(vinyl alcohol)    titanium dioxide               1.50   \n",
       "364         poly(vinyl alcohol)    titanium dioxide               1.50   \n",
       "365         poly(vinyl alcohol)    titanium dioxide               1.50   \n",
       "366         poly(vinyl alcohol)    titanium dioxide               0.00   \n",
       "367                       epoxy    titanium dioxide               5.00   \n",
       "368                       epoxy    titanium dioxide              10.00   \n",
       "369                       epoxy    titanium dioxide              15.00   \n",
       "370                       epoxy    titanium dioxide               0.00   \n",
       "371      polybutylene succinate    titanium dioxide               5.00   \n",
       "372      polybutylene succinate    titanium dioxide              10.00   \n",
       "373      polybutylene succinate    titanium dioxide               0.00   \n",
       "374                       epoxy    titanium dioxide               0.50   \n",
       "375                       epoxy    titanium dioxide               1.00   \n",
       "376                       epoxy    titanium dioxide               3.00   \n",
       "377                       epoxy    titanium dioxide               4.00   \n",
       "378                       epoxy    titanium dioxide               0.00   \n",
       "379  bisphenol-A phthalonitrile    titanium dioxide               0.00   \n",
       "380  bisphenol-A phthalonitrile    titanium dioxide               2.00   \n",
       "381  bisphenol-A phthalonitrile    titanium dioxide               4.00   \n",
       "382  bisphenol-A phthalonitrile    titanium dioxide               6.00   \n",
       "\n",
       "     matrix_embedding_0  matrix_embedding_1  matrix_embedding_2  \\\n",
       "0              0.192542           -1.632548            1.659807   \n",
       "1              0.192542           -1.632548            1.659807   \n",
       "2              0.192542           -1.632548            1.659807   \n",
       "3              0.192542           -1.632548            1.659807   \n",
       "4              0.192542           -1.632548            1.659807   \n",
       "5             -0.613252           -2.009651            1.656685   \n",
       "6             -0.613252           -2.009651            1.656685   \n",
       "7             -0.613252           -2.009651            1.656685   \n",
       "8             -0.613252           -2.009651            1.656685   \n",
       "9             -0.613252           -2.009651            1.656685   \n",
       "10             1.520492           -3.907013            3.073305   \n",
       "11             1.520492           -3.907013            3.073305   \n",
       "12             1.520492           -3.907013            3.073305   \n",
       "13             1.520492           -3.907013            3.073305   \n",
       "14             1.520492           -3.907013            3.073305   \n",
       "15             0.700052           -2.180860            2.324012   \n",
       "16             0.700052           -2.180860            2.324012   \n",
       "17             0.700052           -2.180860            2.324012   \n",
       "18             0.700052           -2.180860            2.324012   \n",
       "19             0.700052           -2.180860            2.324012   \n",
       "20             0.700052           -2.180860            2.324012   \n",
       "21             0.700052           -2.180860            2.324012   \n",
       "22            -0.096003           -0.286935            0.441681   \n",
       "23            -0.096003           -0.286935            0.441681   \n",
       "24            -0.096003           -0.286935            0.441681   \n",
       "25            -0.096003           -0.286935            0.441681   \n",
       "26            -0.096003           -0.286935            0.441681   \n",
       "27            -0.096003           -0.286935            0.441681   \n",
       "28            -0.096003           -0.286935            0.441681   \n",
       "29            -0.096003           -0.286935            0.441681   \n",
       "..                  ...                 ...                 ...   \n",
       "353            1.320863           -0.227312            2.612893   \n",
       "354            1.320863           -0.227312            2.612893   \n",
       "355            1.320863           -0.227312            2.612893   \n",
       "356            1.320863           -0.227312            2.612893   \n",
       "357            1.320863           -0.227312            2.612893   \n",
       "358            1.381263           -0.313671            2.720820   \n",
       "359            1.381263           -0.313671            2.720820   \n",
       "360            1.381263           -0.313671            2.720820   \n",
       "361            1.381263           -0.313671            2.720820   \n",
       "362            1.381263           -0.313671            2.720820   \n",
       "363            1.381263           -0.313671            2.720820   \n",
       "364            1.381263           -0.313671            2.720820   \n",
       "365            1.381263           -0.313671            2.720820   \n",
       "366            1.381263           -0.313671            2.720820   \n",
       "367            1.520492           -3.907013            3.073305   \n",
       "368            1.520492           -3.907013            3.073305   \n",
       "369            1.520492           -3.907013            3.073305   \n",
       "370            1.520492           -3.907013            3.073305   \n",
       "371           -0.083313           -0.081606            0.267521   \n",
       "372           -0.083313           -0.081606            0.267521   \n",
       "373           -0.083313           -0.081606            0.267521   \n",
       "374            1.520492           -3.907013            3.073305   \n",
       "375            1.520492           -3.907013            3.073305   \n",
       "376            1.520492           -3.907013            3.073305   \n",
       "377            1.520492           -3.907013            3.073305   \n",
       "378            1.520492           -3.907013            3.073305   \n",
       "379            0.072395           -0.579112            1.485731   \n",
       "380            0.072395           -0.579112            1.485731   \n",
       "381            0.072395           -0.579112            1.485731   \n",
       "382            0.072395           -0.579112            1.485731   \n",
       "\n",
       "     matrix_embedding_3  matrix_embedding_4  matrix_embedding_5  \\\n",
       "0              1.341893            0.178591            0.386626   \n",
       "1              1.341893            0.178591            0.386626   \n",
       "2              1.341893            0.178591            0.386626   \n",
       "3              1.341893            0.178591            0.386626   \n",
       "4              1.341893            0.178591            0.386626   \n",
       "5              1.279108            0.628480            0.002984   \n",
       "6              1.279108            0.628480            0.002984   \n",
       "7              1.279108            0.628480            0.002984   \n",
       "8              1.279108            0.628480            0.002984   \n",
       "9              1.279108            0.628480            0.002984   \n",
       "10             0.084399            2.355958            0.420001   \n",
       "11             0.084399            2.355958            0.420001   \n",
       "12             0.084399            2.355958            0.420001   \n",
       "13             0.084399            2.355958            0.420001   \n",
       "14             0.084399            2.355958            0.420001   \n",
       "15             0.278129            1.540644            0.165931   \n",
       "16             0.278129            1.540644            0.165931   \n",
       "17             0.278129            1.540644            0.165931   \n",
       "18             0.278129            1.540644            0.165931   \n",
       "19             0.278129            1.540644            0.165931   \n",
       "20             0.278129            1.540644            0.165931   \n",
       "21             0.278129            1.540644            0.165931   \n",
       "22             0.127820            0.107686           -0.027919   \n",
       "23             0.127820            0.107686           -0.027919   \n",
       "24             0.127820            0.107686           -0.027919   \n",
       "25             0.127820            0.107686           -0.027919   \n",
       "26             0.127820            0.107686           -0.027919   \n",
       "27             0.127820            0.107686           -0.027919   \n",
       "28             0.127820            0.107686           -0.027919   \n",
       "29             0.127820            0.107686           -0.027919   \n",
       "..                  ...                 ...                 ...   \n",
       "353            0.426401            1.372306            1.256093   \n",
       "354            0.426401            1.372306            1.256093   \n",
       "355            0.426401            1.372306            1.256093   \n",
       "356            0.426401            1.372306            1.256093   \n",
       "357            0.426401            1.372306            1.256093   \n",
       "358            0.379035            1.422607            1.330841   \n",
       "359            0.379035            1.422607            1.330841   \n",
       "360            0.379035            1.422607            1.330841   \n",
       "361            0.379035            1.422607            1.330841   \n",
       "362            0.379035            1.422607            1.330841   \n",
       "363            0.379035            1.422607            1.330841   \n",
       "364            0.379035            1.422607            1.330841   \n",
       "365            0.379035            1.422607            1.330841   \n",
       "366            0.379035            1.422607            1.330841   \n",
       "367            0.084399            2.355958            0.420001   \n",
       "368            0.084399            2.355958            0.420001   \n",
       "369            0.084399            2.355958            0.420001   \n",
       "370            0.084399            2.355958            0.420001   \n",
       "371            0.117444            0.105140           -0.027380   \n",
       "372            0.117444            0.105140           -0.027380   \n",
       "373            0.117444            0.105140           -0.027380   \n",
       "374            0.084399            2.355958            0.420001   \n",
       "375            0.084399            2.355958            0.420001   \n",
       "376            0.084399            2.355958            0.420001   \n",
       "377            0.084399            2.355958            0.420001   \n",
       "378            0.084399            2.355958            0.420001   \n",
       "379            0.316660            0.740780            0.122093   \n",
       "380            0.316660            0.740780            0.122093   \n",
       "381            0.316660            0.740780            0.122093   \n",
       "382            0.316660            0.740780            0.122093   \n",
       "\n",
       "     matrix_embedding_6         ...          filler_embedding_0  \\\n",
       "0              1.017890         ...                    0.550864   \n",
       "1              1.017890         ...                    0.550864   \n",
       "2              1.017890         ...                    0.550864   \n",
       "3              1.017890         ...                    0.550864   \n",
       "4              1.017890         ...                    0.550864   \n",
       "5              0.356163         ...                   -0.438009   \n",
       "6              0.356163         ...                   -0.438009   \n",
       "7              0.356163         ...                   -0.438009   \n",
       "8              0.356163         ...                   -0.438009   \n",
       "9              0.356163         ...                   -0.438009   \n",
       "10             1.333048         ...                   -0.782710   \n",
       "11             1.333048         ...                   -0.782710   \n",
       "12             1.333048         ...                   -0.782710   \n",
       "13             1.333048         ...                   -0.782710   \n",
       "14             1.333048         ...                   -0.782710   \n",
       "15             0.770470         ...                   -0.329110   \n",
       "16             0.770470         ...                   -0.329110   \n",
       "17             0.770470         ...                   -0.329110   \n",
       "18             0.770470         ...                   -0.329110   \n",
       "19             0.770470         ...                   -0.329110   \n",
       "20             0.770470         ...                   -0.329110   \n",
       "21             0.770470         ...                   -0.329110   \n",
       "22            -0.297818         ...                    0.550864   \n",
       "23            -0.297818         ...                    0.550864   \n",
       "24            -0.297818         ...                    0.550864   \n",
       "25            -0.297818         ...                    0.550864   \n",
       "26            -0.297818         ...                    0.550864   \n",
       "27            -0.297818         ...                    0.550864   \n",
       "28            -0.297818         ...                    0.550864   \n",
       "29            -0.297818         ...                    0.550864   \n",
       "..                  ...         ...                         ...   \n",
       "353           -1.129196         ...                   -0.143969   \n",
       "354           -1.129196         ...                   -0.143969   \n",
       "355           -1.129196         ...                   -0.143969   \n",
       "356           -1.129196         ...                   -0.143969   \n",
       "357           -1.129196         ...                   -0.143969   \n",
       "358           -1.418151         ...                   -0.143969   \n",
       "359           -1.418151         ...                   -0.143969   \n",
       "360           -1.418151         ...                   -0.143969   \n",
       "361           -1.418151         ...                   -0.143969   \n",
       "362           -1.418151         ...                   -0.143969   \n",
       "363           -1.418151         ...                   -0.143969   \n",
       "364           -1.418151         ...                   -0.143969   \n",
       "365           -1.418151         ...                   -0.143969   \n",
       "366           -1.418151         ...                   -0.143969   \n",
       "367            1.333048         ...                   -0.143969   \n",
       "368            1.333048         ...                   -0.143969   \n",
       "369            1.333048         ...                   -0.143969   \n",
       "370            1.333048         ...                   -0.143969   \n",
       "371           -0.083885         ...                   -0.143969   \n",
       "372           -0.083885         ...                   -0.143969   \n",
       "373           -0.083885         ...                   -0.143969   \n",
       "374            1.333048         ...                   -0.143969   \n",
       "375            1.333048         ...                   -0.143969   \n",
       "376            1.333048         ...                   -0.143969   \n",
       "377            1.333048         ...                   -0.143969   \n",
       "378            1.333048         ...                   -0.143969   \n",
       "379           -0.295983         ...                   -0.143969   \n",
       "380           -0.295983         ...                   -0.143969   \n",
       "381           -0.295983         ...                   -0.143969   \n",
       "382           -0.295983         ...                   -0.143969   \n",
       "\n",
       "     filler_embedding_1  filler_embedding_2  filler_embedding_3  \\\n",
       "0             -4.518711            1.692080            1.566751   \n",
       "1             -4.518711            1.692080            1.566751   \n",
       "2             -4.518711            1.692080            1.566751   \n",
       "3             -4.518711            1.692080            1.566751   \n",
       "4             -4.518711            1.692080            1.566751   \n",
       "5             -1.828649            1.200803            0.887500   \n",
       "6             -1.828649            1.200803            0.887500   \n",
       "7             -1.828649            1.200803            0.887500   \n",
       "8             -1.828649            1.200803            0.887500   \n",
       "9             -1.828649            1.200803            0.887500   \n",
       "10            -1.936885            0.865395            1.073750   \n",
       "11            -1.936885            0.865395            1.073750   \n",
       "12            -1.936885            0.865395            1.073750   \n",
       "13            -1.936885            0.865395            1.073750   \n",
       "14            -1.936885            0.865395            1.073750   \n",
       "15            -1.867637            1.356459            0.748859   \n",
       "16            -1.867637            1.356459            0.748859   \n",
       "17            -1.867637            1.356459            0.748859   \n",
       "18            -1.867637            1.356459            0.748859   \n",
       "19            -1.867637            1.356459            0.748859   \n",
       "20            -1.867637            1.356459            0.748859   \n",
       "21            -1.867637            1.356459            0.748859   \n",
       "22            -4.518711            1.692080            1.566751   \n",
       "23            -4.518711            1.692080            1.566751   \n",
       "24            -4.518711            1.692080            1.566751   \n",
       "25            -4.518711            1.692080            1.566751   \n",
       "26            -4.518711            1.692080            1.566751   \n",
       "27            -4.518711            1.692080            1.566751   \n",
       "28            -4.518711            1.692080            1.566751   \n",
       "29            -4.518711            1.692080            1.566751   \n",
       "..                  ...                 ...                 ...   \n",
       "353           -0.345050            1.085308            0.413839   \n",
       "354           -0.345050            1.085308            0.413839   \n",
       "355           -0.345050            1.085308            0.413839   \n",
       "356           -0.345050            1.085308            0.413839   \n",
       "357           -0.345050            1.085308            0.413839   \n",
       "358           -0.345050            1.085308            0.413839   \n",
       "359           -0.345050            1.085308            0.413839   \n",
       "360           -0.345050            1.085308            0.413839   \n",
       "361           -0.345050            1.085308            0.413839   \n",
       "362           -0.345050            1.085308            0.413839   \n",
       "363           -0.345050            1.085308            0.413839   \n",
       "364           -0.345050            1.085308            0.413839   \n",
       "365           -0.345050            1.085308            0.413839   \n",
       "366           -0.345050            1.085308            0.413839   \n",
       "367           -0.345050            1.085308            0.413839   \n",
       "368           -0.345050            1.085308            0.413839   \n",
       "369           -0.345050            1.085308            0.413839   \n",
       "370           -0.345050            1.085308            0.413839   \n",
       "371           -0.345050            1.085308            0.413839   \n",
       "372           -0.345050            1.085308            0.413839   \n",
       "373           -0.345050            1.085308            0.413839   \n",
       "374           -0.345050            1.085308            0.413839   \n",
       "375           -0.345050            1.085308            0.413839   \n",
       "376           -0.345050            1.085308            0.413839   \n",
       "377           -0.345050            1.085308            0.413839   \n",
       "378           -0.345050            1.085308            0.413839   \n",
       "379           -0.345050            1.085308            0.413839   \n",
       "380           -0.345050            1.085308            0.413839   \n",
       "381           -0.345050            1.085308            0.413839   \n",
       "382           -0.345050            1.085308            0.413839   \n",
       "\n",
       "     filler_embedding_4  filler_embedding_5  filler_embedding_6  \\\n",
       "0              0.425759           -0.750696           -1.206770   \n",
       "1              0.425759           -0.750696           -1.206770   \n",
       "2              0.425759           -0.750696           -1.206770   \n",
       "3              0.425759           -0.750696           -1.206770   \n",
       "4              0.425759           -0.750696           -1.206770   \n",
       "5              0.594996            0.211015            0.222315   \n",
       "6              0.594996            0.211015            0.222315   \n",
       "7              0.594996            0.211015            0.222315   \n",
       "8              0.594996            0.211015            0.222315   \n",
       "9              0.594996            0.211015            0.222315   \n",
       "10             0.697836            0.353082           -0.625494   \n",
       "11             0.697836            0.353082           -0.625494   \n",
       "12             0.697836            0.353082           -0.625494   \n",
       "13             0.697836            0.353082           -0.625494   \n",
       "14             0.697836            0.353082           -0.625494   \n",
       "15             0.334538           -0.182986           -0.437511   \n",
       "16             0.334538           -0.182986           -0.437511   \n",
       "17             0.334538           -0.182986           -0.437511   \n",
       "18             0.334538           -0.182986           -0.437511   \n",
       "19             0.334538           -0.182986           -0.437511   \n",
       "20             0.334538           -0.182986           -0.437511   \n",
       "21             0.334538           -0.182986           -0.437511   \n",
       "22             0.425759           -0.750696           -1.206770   \n",
       "23             0.425759           -0.750696           -1.206770   \n",
       "24             0.425759           -0.750696           -1.206770   \n",
       "25             0.425759           -0.750696           -1.206770   \n",
       "26             0.425759           -0.750696           -1.206770   \n",
       "27             0.425759           -0.750696           -1.206770   \n",
       "28             0.425759           -0.750696           -1.206770   \n",
       "29             0.425759           -0.750696           -1.206770   \n",
       "..                  ...                 ...                 ...   \n",
       "353            0.525125           -0.085625           -0.493714   \n",
       "354            0.525125           -0.085625           -0.493714   \n",
       "355            0.525125           -0.085625           -0.493714   \n",
       "356            0.525125           -0.085625           -0.493714   \n",
       "357            0.525125           -0.085625           -0.493714   \n",
       "358            0.525125           -0.085625           -0.493714   \n",
       "359            0.525125           -0.085625           -0.493714   \n",
       "360            0.525125           -0.085625           -0.493714   \n",
       "361            0.525125           -0.085625           -0.493714   \n",
       "362            0.525125           -0.085625           -0.493714   \n",
       "363            0.525125           -0.085625           -0.493714   \n",
       "364            0.525125           -0.085625           -0.493714   \n",
       "365            0.525125           -0.085625           -0.493714   \n",
       "366            0.525125           -0.085625           -0.493714   \n",
       "367            0.525125           -0.085625           -0.493714   \n",
       "368            0.525125           -0.085625           -0.493714   \n",
       "369            0.525125           -0.085625           -0.493714   \n",
       "370            0.525125           -0.085625           -0.493714   \n",
       "371            0.525125           -0.085625           -0.493714   \n",
       "372            0.525125           -0.085625           -0.493714   \n",
       "373            0.525125           -0.085625           -0.493714   \n",
       "374            0.525125           -0.085625           -0.493714   \n",
       "375            0.525125           -0.085625           -0.493714   \n",
       "376            0.525125           -0.085625           -0.493714   \n",
       "377            0.525125           -0.085625           -0.493714   \n",
       "378            0.525125           -0.085625           -0.493714   \n",
       "379            0.525125           -0.085625           -0.493714   \n",
       "380            0.525125           -0.085625           -0.493714   \n",
       "381            0.525125           -0.085625           -0.493714   \n",
       "382            0.525125           -0.085625           -0.493714   \n",
       "\n",
       "     filler_embedding_7  filler_embedding_8  filler_embedding_9  \n",
       "0              1.449176            0.251798            0.124248  \n",
       "1              1.449176            0.251798            0.124248  \n",
       "2              1.449176            0.251798            0.124248  \n",
       "3              1.449176            0.251798            0.124248  \n",
       "4              1.449176            0.251798            0.124248  \n",
       "5              0.581289           -0.237836           -0.822522  \n",
       "6              0.581289           -0.237836           -0.822522  \n",
       "7              0.581289           -0.237836           -0.822522  \n",
       "8              0.581289           -0.237836           -0.822522  \n",
       "9              0.581289           -0.237836           -0.822522  \n",
       "10            -0.098894           -0.988201           -0.401390  \n",
       "11            -0.098894           -0.988201           -0.401390  \n",
       "12            -0.098894           -0.988201           -0.401390  \n",
       "13            -0.098894           -0.988201           -0.401390  \n",
       "14            -0.098894           -0.988201           -0.401390  \n",
       "15             0.416482            0.825460           -0.887080  \n",
       "16             0.416482            0.825460           -0.887080  \n",
       "17             0.416482            0.825460           -0.887080  \n",
       "18             0.416482            0.825460           -0.887080  \n",
       "19             0.416482            0.825460           -0.887080  \n",
       "20             0.416482            0.825460           -0.887080  \n",
       "21             0.416482            0.825460           -0.887080  \n",
       "22             1.449176            0.251798            0.124248  \n",
       "23             1.449176            0.251798            0.124248  \n",
       "24             1.449176            0.251798            0.124248  \n",
       "25             1.449176            0.251798            0.124248  \n",
       "26             1.449176            0.251798            0.124248  \n",
       "27             1.449176            0.251798            0.124248  \n",
       "28             1.449176            0.251798            0.124248  \n",
       "29             1.449176            0.251798            0.124248  \n",
       "..                  ...                 ...                 ...  \n",
       "353           -0.106737           -0.710071           -0.482864  \n",
       "354           -0.106737           -0.710071           -0.482864  \n",
       "355           -0.106737           -0.710071           -0.482864  \n",
       "356           -0.106737           -0.710071           -0.482864  \n",
       "357           -0.106737           -0.710071           -0.482864  \n",
       "358           -0.106737           -0.710071           -0.482864  \n",
       "359           -0.106737           -0.710071           -0.482864  \n",
       "360           -0.106737           -0.710071           -0.482864  \n",
       "361           -0.106737           -0.710071           -0.482864  \n",
       "362           -0.106737           -0.710071           -0.482864  \n",
       "363           -0.106737           -0.710071           -0.482864  \n",
       "364           -0.106737           -0.710071           -0.482864  \n",
       "365           -0.106737           -0.710071           -0.482864  \n",
       "366           -0.106737           -0.710071           -0.482864  \n",
       "367           -0.106737           -0.710071           -0.482864  \n",
       "368           -0.106737           -0.710071           -0.482864  \n",
       "369           -0.106737           -0.710071           -0.482864  \n",
       "370           -0.106737           -0.710071           -0.482864  \n",
       "371           -0.106737           -0.710071           -0.482864  \n",
       "372           -0.106737           -0.710071           -0.482864  \n",
       "373           -0.106737           -0.710071           -0.482864  \n",
       "374           -0.106737           -0.710071           -0.482864  \n",
       "375           -0.106737           -0.710071           -0.482864  \n",
       "376           -0.106737           -0.710071           -0.482864  \n",
       "377           -0.106737           -0.710071           -0.482864  \n",
       "378           -0.106737           -0.710071           -0.482864  \n",
       "379           -0.106737           -0.710071           -0.482864  \n",
       "380           -0.106737           -0.710071           -0.482864  \n",
       "381           -0.106737           -0.710071           -0.482864  \n",
       "382           -0.106737           -0.710071           -0.482864  \n",
       "\n",
       "[383 rows x 23 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MWCNT': array([ 0.55086416, -4.51871109,  1.6920799 ,  1.56675076,  0.42575949,\n",
       "        -0.75069565, -1.20676959,  1.44917583,  0.25179839,  0.12424786]),\n",
       " 'PANI-organoclay': array([-0.43800949, -1.8286491 ,  1.20080251,  0.88750005,  0.59499562,\n",
       "         0.21101476,  0.22231548,  0.58128893, -0.23783574, -0.82252178]),\n",
       " 'Na-montmorillonite': array([-0.78271002, -1.93688473,  0.86539462,  1.07374999,  0.69783625,\n",
       "         0.35308173, -0.62549374, -0.09889354, -0.98820141, -0.40138971]),\n",
       " 'SWCNT': array([-0.32910991, -1.86763716,  1.35645902,  0.74885857,  0.3345376 ,\n",
       "        -0.18298559, -0.43751082,  0.41648161,  0.82546049, -0.88708031]),\n",
       " 'graphene platelet': array([ 0.26536921, -1.83385324,  1.17463055,  1.20818263,  2.00783521,\n",
       "         1.21362227, -0.55061544,  1.53515393, -2.04789037, -0.10040238]),\n",
       " 'graphene': array([ 1.31299651, -1.72147596,  1.7397002 ,  1.49586642,  2.23058581,\n",
       "         2.17566586, -0.20950468,  1.98398519, -3.15768814,  0.43581003]),\n",
       " 'graphene oxide': array([ 1.24591959, -1.41075975,  1.72847444,  1.10619298,  1.58916032,\n",
       "         2.02553988, -1.14541522,  1.48053712, -3.50186634, -0.41970107]),\n",
       " 'CLO30B': array([-0.78042984, -1.74215496,  1.09852219,  1.18551469,  0.6749981 ,\n",
       "         0.14704737, -0.37619564,  0.72968721, -0.60199136, -1.03048432]),\n",
       " 'NAN': array([-0.51303709, -1.05302835,  1.19605231,  0.93931299,  0.53824633,\n",
       "         0.08169177,  0.01202125,  0.44297004, -0.39662087, -0.8430137 ]),\n",
       " 'SEP': array([-0.69111019, -1.23352313,  1.24210382,  0.78132647,  0.44174504,\n",
       "        -0.15369676, -0.01402364,  0.43961495, -0.31212804, -1.13492429]),\n",
       " 'SOMM100': array([-0.57119656, -1.2628026 ,  1.08039939,  0.72726631,  0.43564597,\n",
       "        -0.05226183, -0.03612777,  0.43162143, -0.35772499, -0.87546146]),\n",
       " 'SOMMEE': array([-0.76158708, -2.13131452,  1.2906183 ,  1.24403596,  0.60425359,\n",
       "         0.05869298, -0.07792927,  0.96118426, -0.29680502, -1.18211722]),\n",
       " 'clay': array([-1.1972723 , -4.40273523,  0.71994573,  1.35661709,  1.6785388 ,\n",
       "         0.78963864,  0.04282912,  1.61485028, -1.73039377,  0.50584882]),\n",
       " 'organo-MMT': array([-1.36236566, -3.72520339,  0.49254949,  1.63134882,  0.23325981,\n",
       "         0.57929376, -0.46134639, -0.32941   , -0.59295318, -0.21405641]),\n",
       " 'CaCO3': array([-0.30369809, -2.91639066,  1.81045902,  0.49171075,  0.96872753,\n",
       "         0.07232532,  0.03707575,  1.32025647, -0.08685587, -0.51807022]),\n",
       " 'silica': array([-1.04203296, -4.55780268,  1.1762383 ,  1.01771176,  0.74764138,\n",
       "         1.75780666, -0.33466932,  2.36482096, -0.70686299,  0.37258747]),\n",
       " 'cellulose nanowhiskers': array([-0.35891556, -0.95869201,  1.29623127,  0.27742151,  0.68640058,\n",
       "         0.10976626, -0.78261051, -0.12490551, -1.29617555, -0.89446227]),\n",
       " 'butanol cellulose nanowhiskers': array([-0.38868041, -0.90749892,  1.20790486,  0.26442288,  0.55616962,\n",
       "         0.07415845, -0.77540421, -0.24172273, -1.0539387 , -0.80289736]),\n",
       " 'surfactant cellulose nanowhiskers': array([-0.49693159, -1.62147796,  1.39844676,  0.20193608,  0.66825356,\n",
       "         0.24542768, -1.25946544,  0.05674485, -1.43707074, -0.78506165]),\n",
       " 'surfactant': array([-0.77296364, -2.94704986,  1.60287774,  0.05096521,  0.6319595 ,\n",
       "         0.51675051, -2.2131753 ,  0.42004555, -1.7188611 , -0.5662604 ]),\n",
       " 'CNW': array([-0.66158539, -3.33849549,  1.87631464,  0.70755088,  0.79656237,\n",
       "         0.1246759 , -0.85865641,  0.40714127, -1.09364259, -1.5204078 ]),\n",
       " 'PMMA-g-MWCNT': array([ 0.07140028, -4.63268924,  1.88735729,  1.21610141,  0.15757739,\n",
       "         0.80609563,  0.32760316,  1.99252534, -0.22995934, -0.10646386]),\n",
       " 'Na-MMT': array([-1.78347582, -4.64689326,  0.5258993 ,  1.96469307,  0.4770079 ,\n",
       "         0.65994316, -0.7799972 , -0.65765622, -0.98515049, -0.26702777]),\n",
       " 'PDMS-clay': array([-0.97540867, -3.68104756,  1.20170328,  1.26175207,  1.31912246,\n",
       "         0.46241352, -0.03726377,  1.32341641, -1.06322156, -0.26224366]),\n",
       " 'montmorillonite': array([-0.14218618, -0.70155066,  0.83351117,  0.63843769,  0.65420711,\n",
       "         0.39310557, -0.48616028,  0.18581578, -1.08714592, -0.03635888]),\n",
       " 'TiO2': array([ 0.05075401, -5.47760439,  1.14691186,  1.62704062,  1.14036512,\n",
       "         0.85445631,  0.8136912 ,  1.58604312, -1.38497722,  0.39373428]),\n",
       " 'MMA-MWCNT': array([-0.06009981, -3.81351614,  1.76134074,  0.84840554,  0.24819911,\n",
       "        -0.12764524, -1.76736373,  0.6595741 , -0.51034403, -0.33671248]),\n",
       " 'PMMA-g-expandable graphite': array([ 0.1908531 , -2.41878211,  1.46677905,  0.638566  ,  0.84021284,\n",
       "         1.41432258,  0.35491912,  1.28830125, -2.05174293, -0.95841836]),\n",
       " 'expandable graphite': array([ 0.49031145, -1.25483948,  1.15885124,  0.52512297,  1.31562161,\n",
       "         0.94004042, -0.39860928,  0.66451445, -2.72175586, -1.26903975]),\n",
       " 'expanded graphite': array([ 0.49031145, -1.25483948,  1.15885124,  0.52512297,  1.31562161,\n",
       "         0.94004042, -0.39860928,  0.66451445, -2.72175586, -1.26903975]),\n",
       " 'graphite': array([ 1.17980218, -1.52612293,  0.61339945,  0.42302018,  1.50452328,\n",
       "         1.45744216, -0.2712239 ,  0.92853898, -3.87220573, -1.26305509]),\n",
       " 'ZrO2': array([-0.25793847, -0.92166436,  0.86947924,  0.59708887,  0.20403826,\n",
       "         0.36970782,  0.1360203 ,  0.2678571 , -0.66187114, -0.31909445]),\n",
       " 'organo clay (Closite 20A)': array([-0.88914293, -2.86578715,  0.77526209,  1.09949544,  0.96625401,\n",
       "         0.47069886, -0.04234822,  0.94386993, -0.91762802, -0.0773145 ]),\n",
       " 'PMMA-g-silica': array([-0.72504827, -4.65223503,  1.62943649,  0.9415819 ,  0.31851833,\n",
       "         2.06034678,  0.76365329,  2.4503479 , -0.70929003,  0.01770595]),\n",
       " 'titanium dioxide': array([-0.14396921, -0.34504957,  1.08530813,  0.4138388 ,  0.52512468,\n",
       "        -0.08562495, -0.49371408, -0.10673738, -0.71007052, -0.48286374])}"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filler_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
